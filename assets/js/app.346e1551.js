(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var r,o,s=e[0],l=e[1],c=e[2],u=0,p=[];u<s.length;u++)o=s[u],Object.prototype.hasOwnProperty.call(a,o)&&a[o]&&p.push(a[o][0]),a[o]=0;for(r in l)Object.prototype.hasOwnProperty.call(l,r)&&(n[r]=l[r]);for(d&&d(e);p.length;)p.shift()();return i.push.apply(i,c||[]),t()}function t(){for(var n,e=0;e<i.length;e++){for(var t=i[e],r=!0,s=1;s<t.length;s++){var l=t[s];0!==a[l]&&(r=!1)}r&&(i.splice(e--,1),n=o(o.s=t[0]))}return n}var r={},a={1:0},i=[];function o(e){if(r[e])return r[e].exports;var t=r[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,o),t.l=!0,t.exports}o.e=function(n){var e=[],t=a[n];if(0!==t)if(t)e.push(t[2]);else{var r=new Promise((function(e,r){t=a[n]=[e,r]}));e.push(t[2]=r);var i,s=document.createElement("script");s.charset="utf-8",s.timeout=120,o.nc&&s.setAttribute("nonce",o.nc),s.src=function(n){return o.p+"assets/js/"+({}[n]||n)+"."+{2:"2bb1a3f0",3:"9cf196df",4:"5d4b1e3e",5:"7b963edb",6:"cd22f69f",7:"56bd88c1",8:"682d07e5",9:"f02c9057",10:"941f9595",11:"b7d791b9",12:"ebbfbefa",13:"55bee0ae",14:"1e95b815",15:"2d2eef87",16:"39294289",17:"743ca12b",18:"50024288",19:"cfa6e429",20:"da3fce67",21:"419116e7",22:"6d444788",23:"c331d239",24:"f09ffbc2",25:"954abaad",26:"4a4aff6b",27:"1aaac913",28:"4cd79971",29:"40208485",30:"f3086bc0",31:"8acc6cef",32:"e9cde725",33:"1ee5100f",34:"e22db86e",35:"4eafac50",36:"1c1ee1f4",37:"677fb893",38:"9cd6536e",39:"733cb66f",40:"c37b65b2",41:"1f7a5823",42:"d5d8d61c",43:"0440be56",44:"46973971",45:"30b89f29",46:"84eaf89e",47:"0a145016",48:"8c43259c",49:"fa78dd64",50:"84e3f3a9",51:"477ee945",52:"f118ef1f",53:"a43cea39",54:"24040505",55:"48b7784e",56:"d6fc5474",57:"2be4b3b9",58:"12e8eb95",59:"11d2261d",60:"3ff6cfa9",61:"21178592",62:"1352608c",63:"050641e9",64:"d6d2d9e3",65:"434963df",66:"d0d97246",67:"e329127c",68:"7188bc65",69:"868797a3",70:"fe5b1b21",71:"f427eba0",72:"8f3d4a59",73:"a3c0ad82",74:"4411d6f8",75:"22170cc4",76:"beca6f44",77:"04a63c9c",78:"a6f5f2b5",79:"419b9cef",80:"fea58868",81:"5621bd89",82:"64069ab7",83:"37c14276",84:"ae6c6209",85:"b89b8c71",86:"edc5934a",87:"f9e215fa",88:"40c5928c",89:"be2ef4b1",90:"8c27d903",91:"1ede16f3",92:"118ff1df",93:"9773dab5",94:"400d48d0",95:"a2f813ab",96:"ac3ab234"}[n]+".js"}(n);var l=new Error;i=function(e){s.onerror=s.onload=null,clearTimeout(c);var t=a[n];if(0!==t){if(t){var r=e&&("load"===e.type?"missing":e.type),i=e&&e.target&&e.target.src;l.message="Loading chunk "+n+" failed.\n("+r+": "+i+")",l.name="ChunkLoadError",l.type=r,l.request=i,t[1](l)}a[n]=void 0}};var c=setTimeout((function(){i({type:"timeout",target:s})}),12e4);s.onerror=s.onload=i,document.head.appendChild(s)}return Promise.all(e)},o.m=n,o.c=r,o.d=function(n,e,t){o.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},o.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},o.t=function(n,e){if(1&e&&(n=o(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(o.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var r in n)o.d(t,r,function(e){return n[e]}.bind(null,r));return t},o.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return o.d(e,"a",e),e},o.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},o.p="/",o.oe=function(n){throw console.error(n),n};var s=window.webpackJsonp=window.webpackJsonp||[],l=s.push.bind(s);s.push=e,s=s.slice();for(var c=0;c<s.length;c++)e(s[c]);var d=l;i.push([104,0]),t()}([function(n,e,t){var r=t(55),a=r.all;n.exports=r.IS_HTMLDDA?function(n){return"function"==typeof n||n===a}:function(n){return"function"==typeof n}},function(n,e,t){var r=t(27),a=Function.prototype,i=a.call,o=r&&a.bind.bind(i,i);n.exports=r?o:function(n){return function(){return i.apply(n,arguments)}}},function(n,e){n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e,t){"use strict";function r(n,e,t,r,a,i,o,s){var l,c="function"==typeof n?n.options:n;if(e&&(c.render=e,c.staticRenderFns=t,c._compiled=!0),r&&(c.functional=!0),i&&(c._scopeId="data-v-"+i),o?(l=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),a&&a.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(o)},c._ssrRegister=l):a&&(l=s?function(){a.call(this,(c.functional?this.parent:this).$root.$options.shadowRoot)}:a),l)if(c.functional){c._injectStyles=l;var d=c.render;c.render=function(n,e){return l.call(e),d(n,e)}}else{var u=c.beforeCreate;c.beforeCreate=u?[].concat(u,l):[l]}return{exports:n,options:c}}t.d(e,"a",(function(){return r}))},function(n,e){var t=function(n){return n&&n.Math==Math&&n};n.exports=t("object"==typeof globalThis&&globalThis)||t("object"==typeof window&&window)||t("object"==typeof self&&self)||t("object"==typeof global&&global)||function(){return this}()||Function("return this")()},function(n,e,t){var r=t(2);n.exports=!r((function(){return 7!=Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e){var t=Array.isArray;n.exports=t},function(n,e,t){var r=t(69),a="object"==typeof self&&self&&self.Object===Object&&self,i=r||a||Function("return this")();n.exports=i},function(n,e,t){var r=t(1),a=t(32),i=r({}.hasOwnProperty);n.exports=Object.hasOwn||function(n,e){return i(a(n),e)}},function(n,e,t){var r,a;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(a="function"==typeof(r=function(){var n,e,t={version:"0.2.0"},r=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function a(n,e,t){return n<e?e:n>t?t:n}function i(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(r[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=a(n,r.minimum,1),t.status=1===n?null:n;var l=t.render(!e),c=l.querySelector(r.barSelector),d=r.speed,u=r.easing;return l.offsetWidth,o((function(e){""===r.positionUsing&&(r.positionUsing=t.getPositioningCSS()),s(c,function(n,e,t){var a;return(a="translate3d"===r.positionUsing?{transform:"translate3d("+i(n)+"%,0,0)"}:"translate"===r.positionUsing?{transform:"translate("+i(n)+"%,0)"}:{"margin-left":i(n)+"%"}).transition="all "+e+"ms "+t,a}(n,d,u)),1===n?(s(l,{transition:"none",opacity:1}),l.offsetWidth,setTimeout((function(){s(l,{transition:"all "+d+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),d)}),d)):setTimeout(e,d)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),r.trickleSpeed)};return r.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*a(Math.random()*e,.1,.95)),e=a(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*r.trickleRate)},n=0,e=0,t.promise=function(r){return r&&"resolved"!==r.state()?(0===e&&t.start(),n++,e++,r.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");c(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=r.template;var a,o=e.querySelector(r.barSelector),l=n?"-100":i(t.status||0),d=document.querySelector(r.parent);return s(o,{transition:"all 0 linear",transform:"translate3d("+l+"%,0,0)"}),r.showSpinner||(a=e.querySelector(r.spinnerSelector))&&p(a),d!=document.body&&c(d,"nprogress-custom-parent"),d.appendChild(e),e},t.remove=function(){d(document.documentElement,"nprogress-busy"),d(document.querySelector(r.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&p(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var o=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),s=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var r,a=n.length,i=e.charAt(0).toUpperCase()+e.slice(1);a--;)if((r=n[a]+i)in t)return r;return e}(t))}function r(n,e,r){e=t(e),n.style[e]=r}return function(n,e){var t,a,i=arguments;if(2==i.length)for(t in e)void 0!==(a=e[t])&&e.hasOwnProperty(t)&&r(n,t,a);else r(n,i[1],i[2])}}();function l(n,e){return("string"==typeof n?n:u(n)).indexOf(" "+e+" ")>=0}function c(n,e){var t=u(n),r=t+e;l(t,e)||(n.className=r.substring(1))}function d(n,e){var t,r=u(n);l(n,e)&&(t=r.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function u(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function p(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?r.call(e,t,e,n):r)||(n.exports=a)},function(n,e,t){var r=t(0),a=t(55),i=a.all;n.exports=a.IS_HTMLDDA?function(n){return"object"==typeof n?null!==n:r(n)||n===i}:function(n){return"object"==typeof n?null!==n:r(n)}},function(n,e,t){var r=t(165),a=t(168);n.exports=function(n,e){var t=a(n,e);return r(t)?t:void 0}},function(n,e,t){"use strict";t.d(e,"e",(function(){return r})),t.d(e,"b",(function(){return i})),t.d(e,"j",(function(){return o})),t.d(e,"g",(function(){return l})),t.d(e,"h",(function(){return c})),t.d(e,"i",(function(){return d})),t.d(e,"c",(function(){return u})),t.d(e,"f",(function(){return p})),t.d(e,"l",(function(){return m})),t.d(e,"m",(function(){return f})),t.d(e,"d",(function(){return g})),t.d(e,"k",(function(){return v})),t.d(e,"n",(function(){return b})),t.d(e,"a",(function(){return k}));t(14);const r=/#.*$/,a=/\.(md|html)$/,i=/\/$/,o=/^[a-z]+:/i;function s(n){return decodeURI(n).replace(r,"").replace(a,"")}function l(n){return o.test(n)}function c(n){return/^mailto:/.test(n)}function d(n){return/^tel:/.test(n)}function u(n){if(l(n))return n;if(!n)return"404";const e=n.match(r),t=e?e[0]:"",a=s(n);return i.test(a)?n:a+".html"+t}function p(n,e){const t=n.hash,a=function(n){const e=n&&n.match(r);if(e)return e[0]}(e);if(a&&t!==a)return!1;return s(n.path)===s(e)}function m(n,e,t){if(l(e))return{type:"external",path:e};t&&(e=function(n,e,t){const r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;const a=e.split("/");t&&a[a.length-1]||a.pop();const i=n.replace(/^\//,"").split("/");for(let n=0;n<i.length;n++){const e=i[n];".."===e?a.pop():"."!==e&&a.push(e)}""!==a[0]&&a.unshift("");return a.join("/")}(e,t));const r=s(e);for(let e=0;e<n.length;e++)if(s(n[e].regularPath)===r)return Object.assign({},n[e],{type:"page",path:u(n[e].path)});return console.error(`[vuepress] No matching page found for sidebar item "${e}"`),{}}function f(n,e,t,r){const{pages:a,themeConfig:i}=t,o=r&&i.locales&&i.locales[r]||i;if("auto"===(n.frontmatter.sidebar||o.sidebar||i.sidebar))return h(n);const s=o.sidebar||i.sidebar;if(s){const{base:t,config:r}=function(n,e){if(Array.isArray(e))return{base:"/",config:e};for(const r in e)if(0===(t=n,/(\.html|\/)$/.test(t)?t:t+"/").indexOf(encodeURI(r)))return{base:r,config:e[r]};var t;return{}}(e,s);return"auto"===r?h(n):r?r.map(n=>function n(e,t,r,a=1){if("string"==typeof e)return m(t,e,r);if(Array.isArray(e))return Object.assign(m(t,e[0],r),{title:e[1]});{a>3&&console.error("[vuepress] detected a too deep nested sidebar group.");const i=e.children||[];return 0===i.length&&e.path?Object.assign(m(t,e.path,r),{title:e.title}):{type:"group",path:e.path,title:e.title,sidebarDepth:e.sidebarDepth,initialOpenGroupIndex:e.initialOpenGroupIndex,children:i.map(e=>n(e,t,r,a+1)),collapsable:!1!==e.collapsable}}}(n,a,t)):[]}return[]}function h(n){const e=g(n.headers||[]);return[{type:"group",collapsable:!1,title:n.title,path:null,children:e.map(e=>({type:"auto",title:e.title,basePath:n.path,path:n.path+"#"+e.slug,children:e.children||[]}))}]}function g(n){let e;return(n=n.map(n=>Object.assign({},n))).forEach(n=>{2===n.level?e=n:e&&(e.children||(e.children=[])).push(n)}),n.filter(n=>2===n.level)}function v(n){return Object.assign(n,{type:n.items&&n.items.length?"links":"link"})}function b(n){return Object.prototype.toString.call(n).match(/\[object (.*?)\]/)[1].toLowerCase()}function y(n){let e=n.frontmatter.date||n.lastUpdated||new Date,t=new Date(e);return"Invalid Date"==t&&e&&(t=new Date(e.replace(/-/g,"/"))),t.getTime()}function k(n,e){return y(e)-y(n)}},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){"use strict";var r=t(26),a=t(32),i=t(33),o=t(129),s=t(131);r({target:"Array",proto:!0,arity:1,forced:t(2)((function(){return 4294967297!==[].push.call({length:4294967296},1)}))||!function(){try{Object.defineProperty([],"length",{writable:!1}).push()}catch(n){return n instanceof TypeError}}()},{push:function(n){var e=a(this),t=i(e),r=arguments.length;s(t+r);for(var l=0;l<r;l++)e[t]=arguments[l],t++;return o(e,t),t}})},function(n,e,t){var r=t(17),a=t(150),i=t(151),o=r?r.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":o&&o in Object(n)?a(n):i(n)}},function(n,e,t){var r=t(5),a=t(18),i=t(35);n.exports=r?function(n,e,t){return a.f(n,e,i(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e,t){var r=t(7).Symbol;n.exports=r},function(n,e,t){var r=t(5),a=t(64),i=t(100),o=t(25),s=t(54),l=TypeError,c=Object.defineProperty,d=Object.getOwnPropertyDescriptor;e.f=r?i?function(n,e,t){if(o(n),e=s(e),o(t),"function"==typeof n&&"prototype"===e&&"value"in t&&"writable"in t&&!t.writable){var r=d(n,e);r&&r.writable&&(n[e]=t.value,t={configurable:"configurable"in t?t.configurable:r.configurable,enumerable:"enumerable"in t?t.enumerable:r.enumerable,writable:!1})}return c(n,e,t)}:c:function(n,e,t){if(o(n),e=s(e),o(t),a)try{return c(n,e,t)}catch(n){}if("get"in t||"set"in t)throw l("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){var r=t(1),a=r({}.toString),i=r("".slice);n.exports=function(n){return i(a(n),8,-1)}},function(n,e,t){var r=t(155),a=t(156),i=t(157),o=t(158),s=t(159);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=a,l.prototype.get=i,l.prototype.has=o,l.prototype.set=s,n.exports=l},function(n,e,t){var r=t(71);n.exports=function(n,e){for(var t=n.length;t--;)if(r(n[t][0],e))return t;return-1}},function(n,e,t){var r=t(11)(Object,"create");n.exports=r},function(n,e,t){var r=t(177);n.exports=function(n,e){var t=n.__data__;return r(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var r=t(45);n.exports=function(n){if("string"==typeof n||r(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){var r=t(10),a=String,i=TypeError;n.exports=function(n){if(r(n))return n;throw i(a(n)+" is not an object")}},function(n,e,t){var r=t(4),a=t(51).f,i=t(16),o=t(112),s=t(37),l=t(65),c=t(125);n.exports=function(n,e){var t,d,u,p,m,f=n.target,h=n.global,g=n.stat;if(t=h?r:g?r[f]||s(f,{}):(r[f]||{}).prototype)for(d in e){if(p=e[d],u=n.dontCallGetSet?(m=a(t,d))&&m.value:t[d],!c(h?d:f+(g?".":"#")+d,n.forced)&&void 0!==u){if(typeof p==typeof u)continue;l(p,u)}(n.sham||u&&u.sham)&&i(p,"sham",!0),o(t,d,p,n)}}},function(n,e,t){var r=t(2);n.exports=!r((function(){var n=function(){}.bind();return"function"!=typeof n||n.hasOwnProperty("prototype")}))},function(n,e,t){var r=t(47),a=t(52);n.exports=function(n){return r(a(n))}},function(n,e,t){var r=t(4),a=t(0),i=function(n){return a(n)?n:void 0};n.exports=function(n,e){return arguments.length<2?i(r[n]):r[n]&&r[n][e]}},function(n,e,t){var r=t(0),a=t(110),i=TypeError;n.exports=function(n){if(r(n))return n;throw i(a(n)+" is not a function")}},function(n,e,t){var r=t(4),a=t(61),i=t(8),o=t(63),s=t(59),l=t(58),c=r.Symbol,d=a("wks"),u=l?c.for||c:c&&c.withoutSetter||o;n.exports=function(n){return i(d,n)||(d[n]=s&&i(c,n)?c[n]:u("Symbol."+n)),d[n]}},function(n,e,t){var r=t(52),a=Object;n.exports=function(n){return a(r(n))}},function(n,e,t){var r=t(123);n.exports=function(n){return r(n.length)}},function(n,e,t){var r=t(27),a=Function.prototype.call;n.exports=r?a.bind(a):function(){return a.apply(a,arguments)}},function(n,e){n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e,t){var r=t(4),a=t(37),i=r["__core-js_shared__"]||a("__core-js_shared__",{});n.exports=i},function(n,e,t){var r=t(4),a=Object.defineProperty;n.exports=function(n,e){try{a(r,n,{value:e,configurable:!0,writable:!0})}catch(t){r[n]=e}return e}},function(n,e,t){var r=t(149),a=t(13),i=Object.prototype,o=i.hasOwnProperty,s=i.propertyIsEnumerable,l=r(function(){return arguments}())?r:function(n){return a(n)&&o.call(n,"callee")&&!s.call(n,"callee")};n.exports=l},function(n,e,t){var r=t(11)(t(7),"Map");n.exports=r},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var r=t(169),a=t(176),i=t(178),o=t(179),s=t(180);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=a,l.prototype.get=i,l.prototype.has=o,l.prototype.set=s,n.exports=l},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var r=t(6),a=t(45),i=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,o=/^\w*$/;n.exports=function(n,e){if(r(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!a(n))||(o.test(n)||!i.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var r=t(15),a=t(13);n.exports=function(n){return"symbol"==typeof n||a(n)&&"[object Symbol]"==r(n)}},function(n,e){n.exports=function(n){return n}},function(n,e,t){var r=t(1),a=t(2),i=t(19),o=Object,s=r("".split);n.exports=a((function(){return!o("z").propertyIsEnumerable(0)}))?function(n){return"String"==i(n)?s(n,""):o(n)}:o},function(n,e){n.exports={}},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e){var t=/^\s+|\s+$/g,r=/^[-+]0x[0-9a-f]+$/i,a=/^0b[01]+$/i,i=/^0o[0-7]+$/i,o=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,l="object"==typeof self&&self&&self.Object===Object&&self,c=s||l||Function("return this")(),d=Object.prototype.toString,u=Math.max,p=Math.min,m=function(){return c.Date.now()};function f(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function h(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==d.call(n)}(n))return NaN;if(f(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=f(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var s=a.test(n);return s||i.test(n)?o(n.slice(2),s?2:8):r.test(n)?NaN:+n}n.exports=function(n,e,t){var r,a,i,o,s,l,c=0,d=!1,g=!1,v=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function b(e){var t=r,i=a;return r=a=void 0,c=e,o=n.apply(i,t)}function y(n){return c=n,s=setTimeout(x,e),d?b(n):o}function k(n){var t=n-l;return void 0===l||t>=e||t<0||g&&n-c>=i}function x(){var n=m();if(k(n))return _(n);s=setTimeout(x,function(n){var t=e-(n-l);return g?p(t,i-(n-c)):t}(n))}function _(n){return s=void 0,v&&r?b(n):(r=a=void 0,o)}function w(){var n=m(),t=k(n);if(r=arguments,a=this,l=n,t){if(void 0===s)return y(l);if(g)return s=setTimeout(x,e),b(l)}return void 0===s&&(s=setTimeout(x,e)),o}return e=h(e)||0,f(t)&&(d=!!t.leading,i=(g="maxWait"in t)?u(h(t.maxWait)||0,e):i,v="trailing"in t?!!t.trailing:v),w.cancel=function(){void 0!==s&&clearTimeout(s),c=0,r=l=a=s=void 0},w.flush=function(){return void 0===s?o:_(m())},w}},function(n,e,t){var r=t(5),a=t(34),i=t(106),o=t(35),s=t(28),l=t(54),c=t(8),d=t(64),u=Object.getOwnPropertyDescriptor;e.f=r?u:function(n,e){if(n=s(n),e=l(e),d)try{return u(n,e)}catch(n){}if(c(n,e))return o(!a(i.f,n,e),n[e])}},function(n,e,t){var r=t(53),a=TypeError;n.exports=function(n){if(r(n))throw a("Can't call method on "+n);return n}},function(n,e){n.exports=function(n){return null==n}},function(n,e,t){var r=t(107),a=t(56);n.exports=function(n){var e=r(n,"string");return a(e)?e:e+""}},function(n,e){var t="object"==typeof document&&document.all,r=void 0===t&&void 0!==t;n.exports={all:t,IS_HTMLDDA:r}},function(n,e,t){var r=t(29),a=t(0),i=t(57),o=t(58),s=Object;n.exports=o?function(n){return"symbol"==typeof n}:function(n){var e=r("Symbol");return a(e)&&i(e.prototype,s(n))}},function(n,e,t){var r=t(1);n.exports=r({}.isPrototypeOf)},function(n,e,t){var r=t(59);n.exports=r&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){var r=t(60),a=t(2);n.exports=!!Object.getOwnPropertySymbols&&!a((function(){var n=Symbol();return!String(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&r&&r<41}))},function(n,e,t){var r,a,i=t(4),o=t(108),s=i.process,l=i.Deno,c=s&&s.versions||l&&l.version,d=c&&c.v8;d&&(a=(r=d.split("."))[0]>0&&r[0]<4?1:+(r[0]+r[1])),!a&&o&&(!(r=o.match(/Edge\/(\d+)/))||r[1]>=74)&&(r=o.match(/Chrome\/(\d+)/))&&(a=+r[1]),n.exports=a},function(n,e,t){var r=t(62),a=t(36);(n.exports=function(n,e){return a[n]||(a[n]=void 0!==e?e:{})})("versions",[]).push({version:"3.28.0",mode:r?"pure":"global",copyright:"© 2014-2023 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.28.0/LICENSE",source:"https://github.com/zloirock/core-js"})},function(n,e){n.exports=!1},function(n,e,t){var r=t(1),a=0,i=Math.random(),o=r(1..toString);n.exports=function(n){return"Symbol("+(void 0===n?"":n)+")_"+o(++a+i,36)}},function(n,e,t){var r=t(5),a=t(2),i=t(99);n.exports=!r&&!a((function(){return 7!=Object.defineProperty(i("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){var r=t(8),a=t(118),i=t(51),o=t(18);n.exports=function(n,e,t){for(var s=a(e),l=o.f,c=i.f,d=0;d<s.length;d++){var u=s[d];r(n,u)||t&&r(t,u)||l(n,u,c(e,u))}}},function(n,e,t){var r=t(122);n.exports=function(n){var e=+n;return e!=e||0===e?0:r(e)}},function(n,e,t){var r=t(135),a=t(25),i=t(136);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=r(Object.prototype,"__proto__","set"))(t,[]),e=t instanceof Array}catch(n){}return function(t,r){return a(t),i(r),e?n(t,r):t.__proto__=r,t}}():void 0)},function(n,e){n.exports=function(n,e){for(var t=-1,r=e.length,a=n.length;++t<r;)n[a+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var r=t(20),a=t(160),i=t(161),o=t(162),s=t(163),l=t(164);function c(n){var e=this.__data__=new r(n);this.size=e.size}c.prototype.clear=a,c.prototype.delete=i,c.prototype.get=o,c.prototype.has=s,c.prototype.set=l,n.exports=c},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var r=t(15),a=t(40);n.exports=function(n){if(!a(n))return!1;var e=r(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var r=t(181),a=t(13);n.exports=function n(e,t,i,o,s){return e===t||(null==e||null==t||!a(e)&&!a(t)?e!=e&&t!=t:r(e,t,i,o,n,s))}},function(n,e,t){var r=t(76),a=t(184),i=t(77);n.exports=function(n,e,t,o,s,l){var c=1&t,d=n.length,u=e.length;if(d!=u&&!(c&&u>d))return!1;var p=l.get(n),m=l.get(e);if(p&&m)return p==e&&m==n;var f=-1,h=!0,g=2&t?new r:void 0;for(l.set(n,e),l.set(e,n);++f<d;){var v=n[f],b=e[f];if(o)var y=c?o(b,v,f,e,n,l):o(v,b,f,n,e,l);if(void 0!==y){if(y)continue;h=!1;break}if(g){if(!a(e,(function(n,e){if(!i(g,e)&&(v===n||s(v,n,t,o,l)))return g.push(e)}))){h=!1;break}}else if(v!==b&&!s(v,b,t,o,l)){h=!1;break}}return l.delete(n),l.delete(e),h}},function(n,e,t){var r=t(41),a=t(182),i=t(183);function o(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new r;++e<t;)this.add(n[e])}o.prototype.add=o.prototype.push=a,o.prototype.has=i,n.exports=o},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var r=t(194),a=t(200),i=t(82);n.exports=function(n){return i(n)?r(n):a(n)}},function(n,e,t){(function(n){var r=t(7),a=t(196),i=e&&!e.nodeType&&e,o=i&&"object"==typeof n&&n&&!n.nodeType&&n,s=o&&o.exports===i?r.Buffer:void 0,l=(s?s.isBuffer:void 0)||a;n.exports=l}).call(this,t(49)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var r=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==r||"symbol"!=r&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var r=t(197),a=t(198),i=t(199),o=i&&i.isTypedArray,s=o?a(o):r;n.exports=s},function(n,e,t){var r=t(72),a=t(43);n.exports=function(n){return null!=n&&a(n.length)&&!r(n)}},function(n,e,t){var r=t(11)(t(7),"Set");n.exports=r},function(n,e,t){var r=t(40);n.exports=function(n){return n==n&&!r(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var r=t(87),a=t(24);n.exports=function(n,e){for(var t=0,i=(e=r(e,n)).length;null!=n&&t<i;)n=n[a(e[t++])];return t&&t==i?n:void 0}},function(n,e,t){var r=t(6),a=t(44),i=t(211),o=t(214);n.exports=function(n,e){return r(n)?n:a(n,e)?[n]:i(o(n))}},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(147),a=t(152),i=t(223),o=t(231),s=t(240),l=t(103),c=i((function(n){var e=l(n);return s(e)&&(e=void 0),o(r(n,1,s,!0),a(e,2))}));n.exports=c},function(n,e,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var r=/["'&<>]/;n.exports=function(n){var e,t=""+n,a=r.exec(t);if(!a)return t;var i="",o=0,s=0;for(o=a.index;o<t.length;o++){switch(t.charCodeAt(o)){case 34:e="&quot;";break;case 38:e="&amp;";break;case 39:e="&#39;";break;case 60:e="&lt;";break;case 62:e="&gt;";break;default:continue}s!==o&&(i+=t.substring(s,o)),s=o+1,i+=e}return s!==o?i+t.substring(s,o):i}},function(n,e,t){!function(){"use strict";n.exports={polyfill:function(){var n=window,e=document;if(!("scrollBehavior"in e.documentElement.style)||!0===n.__forceSmoothScrollPolyfill__){var t,r=n.HTMLElement||n.Element,a={scroll:n.scroll||n.scrollTo,scrollBy:n.scrollBy,elementScroll:r.prototype.scroll||s,scrollIntoView:r.prototype.scrollIntoView},i=n.performance&&n.performance.now?n.performance.now.bind(n.performance):Date.now,o=(t=n.navigator.userAgent,new RegExp(["MSIE ","Trident/","Edge/"].join("|")).test(t)?1:0);n.scroll=n.scrollTo=function(){void 0!==arguments[0]&&(!0!==l(arguments[0])?f.call(n,e.body,void 0!==arguments[0].left?~~arguments[0].left:n.scrollX||n.pageXOffset,void 0!==arguments[0].top?~~arguments[0].top:n.scrollY||n.pageYOffset):a.scroll.call(n,void 0!==arguments[0].left?arguments[0].left:"object"!=typeof arguments[0]?arguments[0]:n.scrollX||n.pageXOffset,void 0!==arguments[0].top?arguments[0].top:void 0!==arguments[1]?arguments[1]:n.scrollY||n.pageYOffset))},n.scrollBy=function(){void 0!==arguments[0]&&(l(arguments[0])?a.scrollBy.call(n,void 0!==arguments[0].left?arguments[0].left:"object"!=typeof arguments[0]?arguments[0]:0,void 0!==arguments[0].top?arguments[0].top:void 0!==arguments[1]?arguments[1]:0):f.call(n,e.body,~~arguments[0].left+(n.scrollX||n.pageXOffset),~~arguments[0].top+(n.scrollY||n.pageYOffset)))},r.prototype.scroll=r.prototype.scrollTo=function(){if(void 0!==arguments[0])if(!0!==l(arguments[0])){var n=arguments[0].left,e=arguments[0].top;f.call(this,this,void 0===n?this.scrollLeft:~~n,void 0===e?this.scrollTop:~~e)}else{if("number"==typeof arguments[0]&&void 0===arguments[1])throw new SyntaxError("Value could not be converted");a.elementScroll.call(this,void 0!==arguments[0].left?~~arguments[0].left:"object"!=typeof arguments[0]?~~arguments[0]:this.scrollLeft,void 0!==arguments[0].top?~~arguments[0].top:void 0!==arguments[1]?~~arguments[1]:this.scrollTop)}},r.prototype.scrollBy=function(){void 0!==arguments[0]&&(!0!==l(arguments[0])?this.scroll({left:~~arguments[0].left+this.scrollLeft,top:~~arguments[0].top+this.scrollTop,behavior:arguments[0].behavior}):a.elementScroll.call(this,void 0!==arguments[0].left?~~arguments[0].left+this.scrollLeft:~~arguments[0]+this.scrollLeft,void 0!==arguments[0].top?~~arguments[0].top+this.scrollTop:~~arguments[1]+this.scrollTop))},r.prototype.scrollIntoView=function(){if(!0!==l(arguments[0])){var t=p(this),r=t.getBoundingClientRect(),i=this.getBoundingClientRect();t!==e.body?(f.call(this,t,t.scrollLeft+i.left-r.left,t.scrollTop+i.top-r.top),"fixed"!==n.getComputedStyle(t).position&&n.scrollBy({left:r.left,top:r.top,behavior:"smooth"})):n.scrollBy({left:i.left,top:i.top,behavior:"smooth"})}else a.scrollIntoView.call(this,void 0===arguments[0]||arguments[0])}}function s(n,e){this.scrollLeft=n,this.scrollTop=e}function l(n){if(null===n||"object"!=typeof n||void 0===n.behavior||"auto"===n.behavior||"instant"===n.behavior)return!0;if("object"==typeof n&&"smooth"===n.behavior)return!1;throw new TypeError("behavior member of ScrollOptions "+n.behavior+" is not a valid value for enumeration ScrollBehavior.")}function c(n,e){return"Y"===e?n.clientHeight+o<n.scrollHeight:"X"===e?n.clientWidth+o<n.scrollWidth:void 0}function d(e,t){var r=n.getComputedStyle(e,null)["overflow"+t];return"auto"===r||"scroll"===r}function u(n){var e=c(n,"Y")&&d(n,"Y"),t=c(n,"X")&&d(n,"X");return e||t}function p(n){for(;n!==e.body&&!1===u(n);)n=n.parentNode||n.host;return n}function m(e){var t,r,a,o,s=(i()-e.startTime)/468;o=s=s>1?1:s,t=.5*(1-Math.cos(Math.PI*o)),r=e.startX+(e.x-e.startX)*t,a=e.startY+(e.y-e.startY)*t,e.method.call(e.scrollable,r,a),r===e.x&&a===e.y||n.requestAnimationFrame(m.bind(n,e))}function f(t,r,o){var l,c,d,u,p=i();t===e.body?(l=n,c=n.scrollX||n.pageXOffset,d=n.scrollY||n.pageYOffset,u=a.scroll):(l=t,c=t.scrollLeft,d=t.scrollTop,u=s),m({scrollable:l,method:u,startTime:p,startX:c,startY:d,x:r,y:o})}}}}()},function(n,e,t){"use strict";t.r(e);var r={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},a=(t(245),t(3)),i=Object(a.a)(r,(function(){return(0,this._self._c)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);e.default=i.exports},function(n,e,t){"use strict";t.r(e);var r={name:"CodeGroup",data:()=>({codeTabs:[],activeCodeTabIndex:-1}),watch:{activeCodeTabIndex(n){this.codeTabs.forEach(n=>{n.elm.classList.remove("theme-code-block__active")}),this.codeTabs[n].elm.classList.add("theme-code-block__active")}},mounted(){this.codeTabs=(this.$slots.default||[]).filter(n=>Boolean(n.componentOptions)).map((n,e)=>(""===n.componentOptions.propsData.active&&(this.activeCodeTabIndex=e),{title:n.componentOptions.propsData.title,elm:n.elm})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab(n){this.activeCodeTabIndex=n}}},a=(t(246),t(3)),i=Object(a.a)(r,(function(){var n=this,e=n._self._c;return e("div",{staticClass:"theme-code-group"},[e("div",{staticClass:"theme-code-group__nav"},[e("ul",{staticClass:"theme-code-group__ul"},n._l(n.codeTabs,(function(t,r){return e("li",{key:t.title,staticClass:"theme-code-group__li"},[e("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":r===n.activeCodeTabIndex},on:{click:function(e){return n.changeCodeTab(r)}}},[n._v("\n            "+n._s(t.title)+"\n          ")])])})),0)]),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length<1?e("pre",{staticClass:"pre-blank"},[n._v("// Make sure to add code blocks to your code group")]):n._e()],2)}),[],!1,null,"2f5f1757",null);e.default=i.exports},function(n,e){n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){var r=t(4),a=t(10),i=r.document,o=a(i)&&a(i.createElement);n.exports=function(n){return o?i.createElement(n):{}}},function(n,e,t){var r=t(5),a=t(2);n.exports=r&&a((function(){return 42!=Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(n,e,t){var r=t(61),a=t(63),i=r("keys");n.exports=function(n){return i[n]||(i[n]=a(n))}},function(n,e,t){var r=t(1),a=t(8),i=t(28),o=t(120).indexOf,s=t(48),l=r([].push);n.exports=function(n,e){var t,r=i(n),c=0,d=[];for(t in r)!a(s,t)&&a(r,t)&&l(d,t);for(;e.length>c;)a(r,t=e[c++])&&(~o(d,t)||l(d,t));return d}},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){n.exports=t(252)},function(n,e,t){"use strict";var r=t(26),a=t(126).left,i=t(127),o=t(60);r({target:"Array",proto:!0,forced:!t(128)&&o>79&&o<83||!i("reduce")},{reduce:function(n){var e=arguments.length;return a(this,n,e,e>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r={}.propertyIsEnumerable,a=Object.getOwnPropertyDescriptor,i=a&&!r.call({1:2},1);e.f=i?function(n){var e=a(this,n);return!!e&&e.enumerable}:r},function(n,e,t){var r=t(34),a=t(10),i=t(56),o=t(109),s=t(111),l=t(31),c=TypeError,d=l("toPrimitive");n.exports=function(n,e){if(!a(n)||i(n))return n;var t,l=o(n,d);if(l){if(void 0===e&&(e="default"),t=r(l,n,e),!a(t)||i(t))return t;throw c("Can't convert object to primitive value")}return void 0===e&&(e="number"),s(n,e)}},function(n,e){n.exports="undefined"!=typeof navigator&&String(navigator.userAgent)||""},function(n,e,t){var r=t(30),a=t(53);n.exports=function(n,e){var t=n[e];return a(t)?void 0:r(t)}},function(n,e){var t=String;n.exports=function(n){try{return t(n)}catch(n){return"Object"}}},function(n,e,t){var r=t(34),a=t(0),i=t(10),o=TypeError;n.exports=function(n,e){var t,s;if("string"===e&&a(t=n.toString)&&!i(s=r(t,n)))return s;if(a(t=n.valueOf)&&!i(s=r(t,n)))return s;if("string"!==e&&a(t=n.toString)&&!i(s=r(t,n)))return s;throw o("Can't convert object to primitive value")}},function(n,e,t){var r=t(0),a=t(18),i=t(113),o=t(37);n.exports=function(n,e,t,s){s||(s={});var l=s.enumerable,c=void 0!==s.name?s.name:e;if(r(t)&&i(t,c,s),s.global)l?n[e]=t:o(e,t);else{try{s.unsafe?n[e]&&(l=!0):delete n[e]}catch(n){}l?n[e]=t:a.f(n,e,{value:t,enumerable:!1,configurable:!s.nonConfigurable,writable:!s.nonWritable})}return n}},function(n,e,t){var r=t(1),a=t(2),i=t(0),o=t(8),s=t(5),l=t(114).CONFIGURABLE,c=t(115),d=t(116),u=d.enforce,p=d.get,m=String,f=Object.defineProperty,h=r("".slice),g=r("".replace),v=r([].join),b=s&&!a((function(){return 8!==f((function(){}),"length",{value:8}).length})),y=String(String).split("String"),k=n.exports=function(n,e,t){"Symbol("===h(m(e),0,7)&&(e="["+g(m(e),/^Symbol\(([^)]*)\)/,"$1")+"]"),t&&t.getter&&(e="get "+e),t&&t.setter&&(e="set "+e),(!o(n,"name")||l&&n.name!==e)&&(s?f(n,"name",{value:e,configurable:!0}):n.name=e),b&&t&&o(t,"arity")&&n.length!==t.arity&&f(n,"length",{value:t.arity});try{t&&o(t,"constructor")&&t.constructor?s&&f(n,"prototype",{writable:!1}):n.prototype&&(n.prototype=void 0)}catch(n){}var r=u(n);return o(r,"source")||(r.source=v(y,"string"==typeof e?e:"")),n};Function.prototype.toString=k((function(){return i(this)&&p(this).source||c(this)}),"toString")},function(n,e,t){var r=t(5),a=t(8),i=Function.prototype,o=r&&Object.getOwnPropertyDescriptor,s=a(i,"name"),l=s&&"something"===function(){}.name,c=s&&(!r||r&&o(i,"name").configurable);n.exports={EXISTS:s,PROPER:l,CONFIGURABLE:c}},function(n,e,t){var r=t(1),a=t(0),i=t(36),o=r(Function.toString);a(i.inspectSource)||(i.inspectSource=function(n){return o(n)}),n.exports=i.inspectSource},function(n,e,t){var r,a,i,o=t(117),s=t(4),l=t(10),c=t(16),d=t(8),u=t(36),p=t(101),m=t(48),f=s.TypeError,h=s.WeakMap;if(o||u.state){var g=u.state||(u.state=new h);g.get=g.get,g.has=g.has,g.set=g.set,r=function(n,e){if(g.has(n))throw f("Object already initialized");return e.facade=n,g.set(n,e),e},a=function(n){return g.get(n)||{}},i=function(n){return g.has(n)}}else{var v=p("state");m[v]=!0,r=function(n,e){if(d(n,v))throw f("Object already initialized");return e.facade=n,c(n,v,e),e},a=function(n){return d(n,v)?n[v]:{}},i=function(n){return d(n,v)}}n.exports={set:r,get:a,has:i,enforce:function(n){return i(n)?a(n):r(n,{})},getterFor:function(n){return function(e){var t;if(!l(e)||(t=a(e)).type!==n)throw f("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){var r=t(4),a=t(0),i=r.WeakMap;n.exports=a(i)&&/native code/.test(String(i))},function(n,e,t){var r=t(29),a=t(1),i=t(119),o=t(124),s=t(25),l=a([].concat);n.exports=r("Reflect","ownKeys")||function(n){var e=i.f(s(n)),t=o.f;return t?l(e,t(n)):e}},function(n,e,t){var r=t(102),a=t(98).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return r(n,a)}},function(n,e,t){var r=t(28),a=t(121),i=t(33),o=function(n){return function(e,t,o){var s,l=r(e),c=i(l),d=a(o,c);if(n&&t!=t){for(;c>d;)if((s=l[d++])!=s)return!0}else for(;c>d;d++)if((n||d in l)&&l[d]===t)return n||d||0;return!n&&-1}};n.exports={includes:o(!0),indexOf:o(!1)}},function(n,e,t){var r=t(66),a=Math.max,i=Math.min;n.exports=function(n,e){var t=r(n);return t<0?a(t+e,0):i(t,e)}},function(n,e){var t=Math.ceil,r=Math.floor;n.exports=Math.trunc||function(n){var e=+n;return(e>0?r:t)(e)}},function(n,e,t){var r=t(66),a=Math.min;n.exports=function(n){return n>0?a(r(n),9007199254740991):0}},function(n,e){e.f=Object.getOwnPropertySymbols},function(n,e,t){var r=t(2),a=t(0),i=/#|\.prototype\./,o=function(n,e){var t=l[s(n)];return t==d||t!=c&&(a(e)?r(e):!!e)},s=o.normalize=function(n){return String(n).replace(i,".").toLowerCase()},l=o.data={},c=o.NATIVE="N",d=o.POLYFILL="P";n.exports=o},function(n,e,t){var r=t(30),a=t(32),i=t(47),o=t(33),s=TypeError,l=function(n){return function(e,t,l,c){r(t);var d=a(e),u=i(d),p=o(d),m=n?p-1:0,f=n?-1:1;if(l<2)for(;;){if(m in u){c=u[m],m+=f;break}if(m+=f,n?m<0:p<=m)throw s("Reduce of empty array with no initial value")}for(;n?m>=0:p>m;m+=f)m in u&&(c=t(c,u[m],m,d));return c}};n.exports={left:l(!1),right:l(!0)}},function(n,e,t){"use strict";var r=t(2);n.exports=function(n,e){var t=[][n];return!!t&&r((function(){t.call(null,e||function(){return 1},1)}))}},function(n,e,t){var r=t(19);n.exports="undefined"!=typeof process&&"process"==r(process)},function(n,e,t){"use strict";var r=t(5),a=t(130),i=TypeError,o=Object.getOwnPropertyDescriptor,s=r&&!function(){if(void 0!==this)return!0;try{Object.defineProperty([],"length",{writable:!1}).length=1}catch(n){return n instanceof TypeError}}();n.exports=s?function(n,e){if(a(n)&&!o(n,"length").writable)throw i("Cannot set read only .length");return n.length=e}:function(n,e){return n.length=e}},function(n,e,t){var r=t(19);n.exports=Array.isArray||function(n){return"Array"==r(n)}},function(n,e){var t=TypeError;n.exports=function(n){if(n>9007199254740991)throw t("Maximum allowed index exceeded");return n}},function(n,e,t){var r=t(26),a=t(4),i=t(133),o=t(134),s=a.WebAssembly,l=7!==Error("e",{cause:7}).cause,c=function(n,e){var t={};t[n]=o(n,e,l),r({global:!0,constructor:!0,arity:1,forced:l},t)},d=function(n,e){if(s&&s[n]){var t={};t[n]=o("WebAssembly."+n,e,l),r({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:l},t)}};c("Error",(function(n){return function(e){return i(n,this,arguments)}})),c("EvalError",(function(n){return function(e){return i(n,this,arguments)}})),c("RangeError",(function(n){return function(e){return i(n,this,arguments)}})),c("ReferenceError",(function(n){return function(e){return i(n,this,arguments)}})),c("SyntaxError",(function(n){return function(e){return i(n,this,arguments)}})),c("TypeError",(function(n){return function(e){return i(n,this,arguments)}})),c("URIError",(function(n){return function(e){return i(n,this,arguments)}})),d("CompileError",(function(n){return function(e){return i(n,this,arguments)}})),d("LinkError",(function(n){return function(e){return i(n,this,arguments)}})),d("RuntimeError",(function(n){return function(e){return i(n,this,arguments)}}))},function(n,e,t){var r=t(27),a=Function.prototype,i=a.apply,o=a.call;n.exports="object"==typeof Reflect&&Reflect.apply||(r?o.bind(i):function(){return o.apply(i,arguments)})},function(n,e,t){"use strict";var r=t(29),a=t(8),i=t(16),o=t(57),s=t(67),l=t(65),c=t(137),d=t(138),u=t(139),p=t(143),m=t(144),f=t(5),h=t(62);n.exports=function(n,e,t,g){var v=g?2:1,b=n.split("."),y=b[b.length-1],k=r.apply(null,b);if(k){var x=k.prototype;if(!h&&a(x,"cause")&&delete x.cause,!t)return k;var _=r("Error"),w=e((function(n,e){var t=u(g?e:n,void 0),r=g?new k(n):new k;return void 0!==t&&i(r,"message",t),m(r,w,r.stack,2),this&&o(x,this)&&d(r,this,w),arguments.length>v&&p(r,arguments[v]),r}));if(w.prototype=x,"Error"!==y?s?s(w,_):l(w,_,{name:!0}):f&&"stackTraceLimit"in k&&(c(w,k,"stackTraceLimit"),c(w,k,"prepareStackTrace")),l(w,k),!h)try{x.name!==y&&i(x,"name",y),x.constructor=w}catch(n){}return w}}},function(n,e,t){var r=t(1),a=t(30);n.exports=function(n,e,t){try{return r(a(Object.getOwnPropertyDescriptor(n,e)[t]))}catch(n){}}},function(n,e,t){var r=t(0),a=String,i=TypeError;n.exports=function(n){if("object"==typeof n||r(n))return n;throw i("Can't set "+a(n)+" as a prototype")}},function(n,e,t){var r=t(18).f;n.exports=function(n,e,t){t in n||r(n,t,{configurable:!0,get:function(){return e[t]},set:function(n){e[t]=n}})}},function(n,e,t){var r=t(0),a=t(10),i=t(67);n.exports=function(n,e,t){var o,s;return i&&r(o=e.constructor)&&o!==t&&a(s=o.prototype)&&s!==t.prototype&&i(n,s),n}},function(n,e,t){var r=t(140);n.exports=function(n,e){return void 0===n?arguments.length<2?"":e:r(n)}},function(n,e,t){var r=t(141),a=String;n.exports=function(n){if("Symbol"===r(n))throw TypeError("Cannot convert a Symbol value to a string");return a(n)}},function(n,e,t){var r=t(142),a=t(0),i=t(19),o=t(31)("toStringTag"),s=Object,l="Arguments"==i(function(){return arguments}());n.exports=r?i:function(n){var e,t,r;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=s(n),o))?t:l?i(e):"Object"==(r=i(e))&&a(e.callee)?"Arguments":r}},function(n,e,t){var r={};r[t(31)("toStringTag")]="z",n.exports="[object z]"===String(r)},function(n,e,t){var r=t(10),a=t(16);n.exports=function(n,e){r(e)&&"cause"in e&&a(n,"cause",e.cause)}},function(n,e,t){var r=t(16),a=t(145),i=t(146),o=Error.captureStackTrace;n.exports=function(n,e,t,s){i&&(o?o(n,e):r(n,"stack",a(t,s)))}},function(n,e,t){var r=t(1),a=Error,i=r("".replace),o=String(a("zxcasd").stack),s=/\n\s*at [^:]*:[^\n]*/,l=s.test(o);n.exports=function(n,e){if(l&&"string"==typeof n&&!a.prepareStackTrace)for(;e--;)n=i(n,s,"");return n}},function(n,e,t){var r=t(2),a=t(35);n.exports=!r((function(){var n=Error("a");return!("stack"in n)||(Object.defineProperty(n,"stack",a(1,7)),7!==n.stack)}))},function(n,e,t){var r=t(68),a=t(148);n.exports=function n(e,t,i,o,s){var l=-1,c=e.length;for(i||(i=a),s||(s=[]);++l<c;){var d=e[l];t>0&&i(d)?t>1?n(d,t-1,i,o,s):r(s,d):o||(s[s.length]=d)}return s}},function(n,e,t){var r=t(17),a=t(38),i=t(6),o=r?r.isConcatSpreadable:void 0;n.exports=function(n){return i(n)||a(n)||!!(o&&n&&n[o])}},function(n,e,t){var r=t(15),a=t(13);n.exports=function(n){return a(n)&&"[object Arguments]"==r(n)}},function(n,e,t){var r=t(17),a=Object.prototype,i=a.hasOwnProperty,o=a.toString,s=r?r.toStringTag:void 0;n.exports=function(n){var e=i.call(n,s),t=n[s];try{n[s]=void 0;var r=!0}catch(n){}var a=o.call(n);return r&&(e?n[s]=t:delete n[s]),a}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var r=t(153),a=t(209),i=t(46),o=t(6),s=t(220);n.exports=function(n){return"function"==typeof n?n:null==n?i:"object"==typeof n?o(n)?a(n[0],n[1]):r(n):s(n)}},function(n,e,t){var r=t(154),a=t(208),i=t(85);n.exports=function(n){var e=a(n);return 1==e.length&&e[0][2]?i(e[0][0],e[0][1]):function(t){return t===n||r(t,n,e)}}},function(n,e,t){var r=t(70),a=t(74);n.exports=function(n,e,t,i){var o=t.length,s=o,l=!i;if(null==n)return!s;for(n=Object(n);o--;){var c=t[o];if(l&&c[2]?c[1]!==n[c[0]]:!(c[0]in n))return!1}for(;++o<s;){var d=(c=t[o])[0],u=n[d],p=c[1];if(l&&c[2]){if(void 0===u&&!(d in n))return!1}else{var m=new r;if(i)var f=i(u,p,d,n,e,m);if(!(void 0===f?a(p,u,3,i,m):f))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var r=t(21),a=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=r(e,n);return!(t<0)&&(t==e.length-1?e.pop():a.call(e,t,1),--this.size,!0)}},function(n,e,t){var r=t(21);n.exports=function(n){var e=this.__data__,t=r(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var r=t(21);n.exports=function(n){return r(this.__data__,n)>-1}},function(n,e,t){var r=t(21);n.exports=function(n,e){var t=this.__data__,a=r(t,n);return a<0?(++this.size,t.push([n,e])):t[a][1]=e,this}},function(n,e,t){var r=t(20);n.exports=function(){this.__data__=new r,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var r=t(20),a=t(39),i=t(41);n.exports=function(n,e){var t=this.__data__;if(t instanceof r){var o=t.__data__;if(!a||o.length<199)return o.push([n,e]),this.size=++t.size,this;t=this.__data__=new i(o)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var r=t(72),a=t(166),i=t(40),o=t(73),s=/^\[object .+?Constructor\]$/,l=Function.prototype,c=Object.prototype,d=l.toString,u=c.hasOwnProperty,p=RegExp("^"+d.call(u).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!i(n)||a(n))&&(r(n)?p:s).test(o(n))}},function(n,e,t){var r,a=t(167),i=(r=/[^.]+$/.exec(a&&a.keys&&a.keys.IE_PROTO||""))?"Symbol(src)_1."+r:"";n.exports=function(n){return!!i&&i in n}},function(n,e,t){var r=t(7)["__core-js_shared__"];n.exports=r},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var r=t(170),a=t(20),i=t(39);n.exports=function(){this.size=0,this.__data__={hash:new r,map:new(i||a),string:new r}}},function(n,e,t){var r=t(171),a=t(172),i=t(173),o=t(174),s=t(175);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=a,l.prototype.get=i,l.prototype.has=o,l.prototype.set=s,n.exports=l},function(n,e,t){var r=t(22);n.exports=function(){this.__data__=r?r(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var r=t(22),a=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(r){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return a.call(e,n)?e[n]:void 0}},function(n,e,t){var r=t(22),a=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return r?void 0!==e[n]:a.call(e,n)}},function(n,e,t){var r=t(22);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=r&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var r=t(23);n.exports=function(n){var e=r(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var r=t(23);n.exports=function(n){return r(this,n).get(n)}},function(n,e,t){var r=t(23);n.exports=function(n){return r(this,n).has(n)}},function(n,e,t){var r=t(23);n.exports=function(n,e){var t=r(this,n),a=t.size;return t.set(n,e),this.size+=t.size==a?0:1,this}},function(n,e,t){var r=t(70),a=t(75),i=t(185),o=t(188),s=t(204),l=t(6),c=t(79),d=t(81),u="[object Object]",p=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,m,f,h){var g=l(n),v=l(e),b=g?"[object Array]":s(n),y=v?"[object Array]":s(e),k=(b="[object Arguments]"==b?u:b)==u,x=(y="[object Arguments]"==y?u:y)==u,_=b==y;if(_&&c(n)){if(!c(e))return!1;g=!0,k=!1}if(_&&!k)return h||(h=new r),g||d(n)?a(n,e,t,m,f,h):i(n,e,b,t,m,f,h);if(!(1&t)){var w=k&&p.call(n,"__wrapped__"),E=x&&p.call(e,"__wrapped__");if(w||E){var S=w?n.value():n,T=E?e.value():e;return h||(h=new r),f(S,T,t,m,h)}}return!!_&&(h||(h=new r),o(n,e,t,m,f,h))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length;++t<r;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var r=t(17),a=t(186),i=t(71),o=t(75),s=t(187),l=t(42),c=r?r.prototype:void 0,d=c?c.valueOf:void 0;n.exports=function(n,e,t,r,c,u,p){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!u(new a(n),new a(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return i(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var m=s;case"[object Set]":var f=1&r;if(m||(m=l),n.size!=e.size&&!f)return!1;var h=p.get(n);if(h)return h==e;r|=2,p.set(n,e);var g=o(m(n),m(e),r,c,u,p);return p.delete(n),g;case"[object Symbol]":if(d)return d.call(n)==d.call(e)}return!1}},function(n,e,t){var r=t(7).Uint8Array;n.exports=r},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,r){t[++e]=[r,n]})),t}},function(n,e,t){var r=t(189),a=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,i,o,s){var l=1&t,c=r(n),d=c.length;if(d!=r(e).length&&!l)return!1;for(var u=d;u--;){var p=c[u];if(!(l?p in e:a.call(e,p)))return!1}var m=s.get(n),f=s.get(e);if(m&&f)return m==e&&f==n;var h=!0;s.set(n,e),s.set(e,n);for(var g=l;++u<d;){var v=n[p=c[u]],b=e[p];if(i)var y=l?i(b,v,p,e,n,s):i(v,b,p,n,e,s);if(!(void 0===y?v===b||o(v,b,t,i,s):y)){h=!1;break}g||(g="constructor"==p)}if(h&&!g){var k=n.constructor,x=e.constructor;k==x||!("constructor"in n)||!("constructor"in e)||"function"==typeof k&&k instanceof k&&"function"==typeof x&&x instanceof x||(h=!1)}return s.delete(n),s.delete(e),h}},function(n,e,t){var r=t(190),a=t(191),i=t(78);n.exports=function(n){return r(n,i,a)}},function(n,e,t){var r=t(68),a=t(6);n.exports=function(n,e,t){var i=e(n);return a(n)?i:r(i,t(n))}},function(n,e,t){var r=t(192),a=t(193),i=Object.prototype.propertyIsEnumerable,o=Object.getOwnPropertySymbols,s=o?function(n){return null==n?[]:(n=Object(n),r(o(n),(function(e){return i.call(n,e)})))}:a;n.exports=s},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,a=0,i=[];++t<r;){var o=n[t];e(o,t,n)&&(i[a++]=o)}return i}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var r=t(195),a=t(38),i=t(6),o=t(79),s=t(80),l=t(81),c=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=i(n),d=!t&&a(n),u=!t&&!d&&o(n),p=!t&&!d&&!u&&l(n),m=t||d||u||p,f=m?r(n.length,String):[],h=f.length;for(var g in n)!e&&!c.call(n,g)||m&&("length"==g||u&&("offset"==g||"parent"==g)||p&&("buffer"==g||"byteLength"==g||"byteOffset"==g)||s(g,h))||f.push(g);return f}},function(n,e){n.exports=function(n,e){for(var t=-1,r=Array(n);++t<n;)r[t]=e(t);return r}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var r=t(15),a=t(43),i=t(13),o={};o["[object Float32Array]"]=o["[object Float64Array]"]=o["[object Int8Array]"]=o["[object Int16Array]"]=o["[object Int32Array]"]=o["[object Uint8Array]"]=o["[object Uint8ClampedArray]"]=o["[object Uint16Array]"]=o["[object Uint32Array]"]=!0,o["[object Arguments]"]=o["[object Array]"]=o["[object ArrayBuffer]"]=o["[object Boolean]"]=o["[object DataView]"]=o["[object Date]"]=o["[object Error]"]=o["[object Function]"]=o["[object Map]"]=o["[object Number]"]=o["[object Object]"]=o["[object RegExp]"]=o["[object Set]"]=o["[object String]"]=o["[object WeakMap]"]=!1,n.exports=function(n){return i(n)&&a(n.length)&&!!o[r(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var r=t(69),a=e&&!e.nodeType&&e,i=a&&"object"==typeof n&&n&&!n.nodeType&&n,o=i&&i.exports===a&&r.process,s=function(){try{var n=i&&i.require&&i.require("util").types;return n||o&&o.binding&&o.binding("util")}catch(n){}}();n.exports=s}).call(this,t(49)(n))},function(n,e,t){var r=t(201),a=t(202),i=Object.prototype.hasOwnProperty;n.exports=function(n){if(!r(n))return a(n);var e=[];for(var t in Object(n))i.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var r=t(203)(Object.keys,Object);n.exports=r},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var r=t(205),a=t(39),i=t(206),o=t(83),s=t(207),l=t(15),c=t(73),d=c(r),u=c(a),p=c(i),m=c(o),f=c(s),h=l;(r&&"[object DataView]"!=h(new r(new ArrayBuffer(1)))||a&&"[object Map]"!=h(new a)||i&&"[object Promise]"!=h(i.resolve())||o&&"[object Set]"!=h(new o)||s&&"[object WeakMap]"!=h(new s))&&(h=function(n){var e=l(n),t="[object Object]"==e?n.constructor:void 0,r=t?c(t):"";if(r)switch(r){case d:return"[object DataView]";case u:return"[object Map]";case p:return"[object Promise]";case m:return"[object Set]";case f:return"[object WeakMap]"}return e}),n.exports=h},function(n,e,t){var r=t(11)(t(7),"DataView");n.exports=r},function(n,e,t){var r=t(11)(t(7),"Promise");n.exports=r},function(n,e,t){var r=t(11)(t(7),"WeakMap");n.exports=r},function(n,e,t){var r=t(84),a=t(78);n.exports=function(n){for(var e=a(n),t=e.length;t--;){var i=e[t],o=n[i];e[t]=[i,o,r(o)]}return e}},function(n,e,t){var r=t(74),a=t(210),i=t(217),o=t(44),s=t(84),l=t(85),c=t(24);n.exports=function(n,e){return o(n)&&s(e)?l(c(n),e):function(t){var o=a(t,n);return void 0===o&&o===e?i(t,n):r(e,o,3)}}},function(n,e,t){var r=t(86);n.exports=function(n,e,t){var a=null==n?void 0:r(n,e);return void 0===a?t:a}},function(n,e,t){var r=t(212),a=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,i=/\\(\\)?/g,o=r((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(a,(function(n,t,r,a){e.push(r?a.replace(i,"$1"):t||n)})),e}));n.exports=o},function(n,e,t){var r=t(213);n.exports=function(n){var e=r(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var r=t(41);function a(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var r=arguments,a=e?e.apply(this,r):r[0],i=t.cache;if(i.has(a))return i.get(a);var o=n.apply(this,r);return t.cache=i.set(a,o)||i,o};return t.cache=new(a.Cache||r),t}a.Cache=r,n.exports=a},function(n,e,t){var r=t(215);n.exports=function(n){return null==n?"":r(n)}},function(n,e,t){var r=t(17),a=t(216),i=t(6),o=t(45),s=r?r.prototype:void 0,l=s?s.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(i(e))return a(e,n)+"";if(o(e))return l?l.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,a=Array(r);++t<r;)a[t]=e(n[t],t,n);return a}},function(n,e,t){var r=t(218),a=t(219);n.exports=function(n,e){return null!=n&&a(n,e,r)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var r=t(87),a=t(38),i=t(6),o=t(80),s=t(43),l=t(24);n.exports=function(n,e,t){for(var c=-1,d=(e=r(e,n)).length,u=!1;++c<d;){var p=l(e[c]);if(!(u=null!=n&&t(n,p)))break;n=n[p]}return u||++c!=d?u:!!(d=null==n?0:n.length)&&s(d)&&o(p,d)&&(i(n)||a(n))}},function(n,e,t){var r=t(221),a=t(222),i=t(44),o=t(24);n.exports=function(n){return i(n)?r(o(n)):a(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var r=t(86);n.exports=function(n){return function(e){return r(e,n)}}},function(n,e,t){var r=t(46),a=t(224),i=t(226);n.exports=function(n,e){return i(a(n,e,r),n+"")}},function(n,e,t){var r=t(225),a=Math.max;n.exports=function(n,e,t){return e=a(void 0===e?n.length-1:e,0),function(){for(var i=arguments,o=-1,s=a(i.length-e,0),l=Array(s);++o<s;)l[o]=i[e+o];o=-1;for(var c=Array(e+1);++o<e;)c[o]=i[o];return c[e]=t(l),r(n,this,c)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var r=t(227),a=t(230)(r);n.exports=a},function(n,e,t){var r=t(228),a=t(229),i=t(46),o=a?function(n,e){return a(n,"toString",{configurable:!0,enumerable:!1,value:r(e),writable:!0})}:i;n.exports=o},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var r=t(11),a=function(){try{var n=r(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=a},function(n,e){var t=Date.now;n.exports=function(n){var e=0,r=0;return function(){var a=t(),i=16-(a-r);if(r=a,i>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var r=t(76),a=t(232),i=t(237),o=t(77),s=t(238),l=t(42);n.exports=function(n,e,t){var c=-1,d=a,u=n.length,p=!0,m=[],f=m;if(t)p=!1,d=i;else if(u>=200){var h=e?null:s(n);if(h)return l(h);p=!1,d=o,f=new r}else f=e?[]:m;n:for(;++c<u;){var g=n[c],v=e?e(g):g;if(g=t||0!==g?g:0,p&&v==v){for(var b=f.length;b--;)if(f[b]===v)continue n;e&&f.push(v),m.push(g)}else d(f,v,t)||(f!==m&&f.push(v),m.push(g))}return m}},function(n,e,t){var r=t(233);n.exports=function(n,e){return!!(null==n?0:n.length)&&r(n,e,0)>-1}},function(n,e,t){var r=t(234),a=t(235),i=t(236);n.exports=function(n,e,t){return e==e?i(n,e,t):r(n,a,t)}},function(n,e){n.exports=function(n,e,t,r){for(var a=n.length,i=t+(r?1:-1);r?i--:++i<a;)if(e(n[i],i,n))return i;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var r=t-1,a=n.length;++r<a;)if(n[r]===e)return r;return-1}},function(n,e){n.exports=function(n,e,t){for(var r=-1,a=null==n?0:n.length;++r<a;)if(t(e,n[r]))return!0;return!1}},function(n,e,t){var r=t(83),a=t(239),i=t(42),o=r&&1/i(new r([,-0]))[1]==1/0?function(n){return new r(n)}:a;n.exports=o},function(n,e){n.exports=function(){}},function(n,e,t){var r=t(82),a=t(13);n.exports=function(n){return a(n)&&r(n)}},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(88)},function(n,e,t){"use strict";t(89)},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(90)},function(n,e,t){"use strict";t(91)},function(n,e,t){"use strict";t(92)},function(n,e,t){"use strict";t.r(e);
/*!
 * Vue.js v2.7.14
 * (c) 2014-2022 Evan You
 * Released under the MIT License.
 */
var r=Object.freeze({}),a=Array.isArray;function i(n){return null==n}function o(n){return null!=n}function s(n){return!0===n}function l(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function c(n){return"function"==typeof n}function d(n){return null!==n&&"object"==typeof n}var u=Object.prototype.toString;function p(n){return"[object Object]"===u.call(n)}function m(n){return"[object RegExp]"===u.call(n)}function f(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function h(n){return o(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function g(n){return null==n?"":Array.isArray(n)||p(n)&&n.toString===u?JSON.stringify(n,null,2):String(n)}function v(n){var e=parseFloat(n);return isNaN(e)?n:e}function b(n,e){for(var t=Object.create(null),r=n.split(","),a=0;a<r.length;a++)t[r[a]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}b("slot,component",!0);var y=b("key,ref,slot,slot-scope,is");function k(n,e){var t=n.length;if(t){if(e===n[t-1])return void(n.length=t-1);var r=n.indexOf(e);if(r>-1)return n.splice(r,1)}}var x=Object.prototype.hasOwnProperty;function _(n,e){return x.call(n,e)}function w(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var E=/-(\w)/g,S=w((function(n){return n.replace(E,(function(n,e){return e?e.toUpperCase():""}))})),T=w((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),A=/\B([A-Z])/g,I=w((function(n){return n.replace(A,"-$1").toLowerCase()}));var C=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var r=arguments.length;return r?r>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function z(n,e){e=e||0;for(var t=n.length-e,r=new Array(t);t--;)r[t]=n[t+e];return r}function B(n,e){for(var t in e)n[t]=e[t];return n}function R(n){for(var e={},t=0;t<n.length;t++)n[t]&&B(e,n[t]);return e}function M(n,e,t){}var L=function(n,e,t){return!1},P=function(n){return n};function O(n,e){if(n===e)return!0;var t=d(n),r=d(e);if(!t||!r)return!t&&!r&&String(n)===String(e);try{var a=Array.isArray(n),i=Array.isArray(e);if(a&&i)return n.length===e.length&&n.every((function(n,t){return O(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(a||i)return!1;var o=Object.keys(n),s=Object.keys(e);return o.length===s.length&&o.every((function(t){return O(n[t],e[t])}))}catch(n){return!1}}function D(n,e){for(var t=0;t<n.length;t++)if(O(n[t],e))return t;return-1}function j(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}function N(n,e){return n===e?0===n&&1/n!=1/e:n==n||e==e}var F=["component","directive","filter"],q=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],K={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:L,isReservedAttr:L,isUnknownElement:L,getTagNamespace:M,parsePlatformTagName:P,mustUseProp:L,async:!0,_lifecycleHooks:q},U=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function $(n){var e=(n+"").charCodeAt(0);return 36===e||95===e}function G(n,e,t,r){Object.defineProperty(n,e,{value:t,enumerable:!!r,writable:!0,configurable:!0})}var H=new RegExp("[^".concat(U.source,".$_\\d]"));var V="__proto__"in{},J="undefined"!=typeof window,Q=J&&window.navigator.userAgent.toLowerCase(),W=Q&&/msie|trident/.test(Q),X=Q&&Q.indexOf("msie 9.0")>0,Z=Q&&Q.indexOf("edge/")>0;Q&&Q.indexOf("android");var Y=Q&&/iphone|ipad|ipod|ios/.test(Q);Q&&/chrome\/\d+/.test(Q),Q&&/phantomjs/.test(Q);var nn,en=Q&&Q.match(/firefox\/(\d+)/),tn={}.watch,rn=!1;if(J)try{var an={};Object.defineProperty(an,"passive",{get:function(){rn=!0}}),window.addEventListener("test-passive",null,an)}catch(n){}var on=function(){return void 0===nn&&(nn=!J&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),nn},sn=J&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function ln(n){return"function"==typeof n&&/native code/.test(n.toString())}var cn,dn="undefined"!=typeof Symbol&&ln(Symbol)&&"undefined"!=typeof Reflect&&ln(Reflect.ownKeys);cn="undefined"!=typeof Set&&ln(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var un=null;function pn(n){void 0===n&&(n=null),n||un&&un._scope.off(),un=n,n&&n._scope.on()}var mn=function(){function n(n,e,t,r,a,i,o,s){this.tag=n,this.data=e,this.children=t,this.text=r,this.elm=a,this.ns=void 0,this.context=i,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=o,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(n.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),n}(),fn=function(n){void 0===n&&(n="");var e=new mn;return e.text=n,e.isComment=!0,e};function hn(n){return new mn(void 0,void 0,void 0,String(n))}function gn(n){var e=new mn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}var vn=0,bn=[],yn=function(){function n(){this._pending=!1,this.id=vn++,this.subs=[]}return n.prototype.addSub=function(n){this.subs.push(n)},n.prototype.removeSub=function(n){this.subs[this.subs.indexOf(n)]=null,this._pending||(this._pending=!0,bn.push(this))},n.prototype.depend=function(e){n.target&&n.target.addDep(this)},n.prototype.notify=function(n){var e=this.subs.filter((function(n){return n}));for(var t=0,r=e.length;t<r;t++){0,e[t].update()}},n}();yn.target=null;var kn=[];function xn(n){kn.push(n),yn.target=n}function _n(){kn.pop(),yn.target=kn[kn.length-1]}var wn=Array.prototype,En=Object.create(wn);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=wn[n];G(En,n,(function(){for(var t=[],r=0;r<arguments.length;r++)t[r]=arguments[r];var a,i=e.apply(this,t),o=this.__ob__;switch(n){case"push":case"unshift":a=t;break;case"splice":a=t.slice(2)}return a&&o.observeArray(a),o.dep.notify(),i}))}));var Sn=Object.getOwnPropertyNames(En),Tn={},An=!0;function In(n){An=n}var Cn={notify:M,depend:M,addSub:M,removeSub:M},zn=function(){function n(n,e,t){if(void 0===e&&(e=!1),void 0===t&&(t=!1),this.value=n,this.shallow=e,this.mock=t,this.dep=t?Cn:new yn,this.vmCount=0,G(n,"__ob__",this),a(n)){if(!t)if(V)n.__proto__=En;else for(var r=0,i=Sn.length;r<i;r++){G(n,s=Sn[r],En[s])}e||this.observeArray(n)}else{var o=Object.keys(n);for(r=0;r<o.length;r++){var s;Rn(n,s=o[r],Tn,void 0,e,t)}}}return n.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)Bn(n[e],!1,this.mock)},n}();function Bn(n,e,t){return n&&_(n,"__ob__")&&n.__ob__ instanceof zn?n.__ob__:!An||!t&&on()||!a(n)&&!p(n)||!Object.isExtensible(n)||n.__v_skip||Nn(n)||n instanceof mn?void 0:new zn(n,e,t)}function Rn(n,e,t,r,i,o){var s=new yn,l=Object.getOwnPropertyDescriptor(n,e);if(!l||!1!==l.configurable){var c=l&&l.get,d=l&&l.set;c&&!d||t!==Tn&&2!==arguments.length||(t=n[e]);var u=!i&&Bn(t,!1,o);return Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=c?c.call(n):t;return yn.target&&(s.depend(),u&&(u.dep.depend(),a(e)&&Pn(e))),Nn(e)&&!i?e.value:e},set:function(e){var r=c?c.call(n):t;if(N(r,e)){if(d)d.call(n,e);else{if(c)return;if(!i&&Nn(r)&&!Nn(e))return void(r.value=e);t=e}u=!i&&Bn(e,!1,o),s.notify()}}}),s}}function Mn(n,e,t){if(!jn(n)){var r=n.__ob__;return a(n)&&f(e)?(n.length=Math.max(n.length,e),n.splice(e,1,t),r&&!r.shallow&&r.mock&&Bn(t,!1,!0),t):e in n&&!(e in Object.prototype)?(n[e]=t,t):n._isVue||r&&r.vmCount?t:r?(Rn(r.value,e,t,void 0,r.shallow,r.mock),r.dep.notify(),t):(n[e]=t,t)}}function Ln(n,e){if(a(n)&&f(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||jn(n)||_(n,e)&&(delete n[e],t&&t.dep.notify())}}function Pn(n){for(var e=void 0,t=0,r=n.length;t<r;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),a(e)&&Pn(e)}function On(n){return Dn(n,!0),G(n,"__v_isShallow",!0),n}function Dn(n,e){if(!jn(n)){Bn(n,e,on());0}}function jn(n){return!(!n||!n.__v_isReadonly)}function Nn(n){return!(!n||!0!==n.__v_isRef)}function Fn(n,e,t){Object.defineProperty(n,t,{enumerable:!0,configurable:!0,get:function(){var n=e[t];if(Nn(n))return n.value;var r=n&&n.__ob__;return r&&r.dep.depend(),n},set:function(n){var r=e[t];Nn(r)&&!Nn(n)?r.value=n:e[t]=n}})}"".concat("watcher"," callback"),"".concat("watcher"," getter"),"".concat("watcher"," cleanup");var qn;var Kn=function(){function n(n){void 0===n&&(n=!1),this.detached=n,this.active=!0,this.effects=[],this.cleanups=[],this.parent=qn,!n&&qn&&(this.index=(qn.scopes||(qn.scopes=[])).push(this)-1)}return n.prototype.run=function(n){if(this.active){var e=qn;try{return qn=this,n()}finally{qn=e}}else 0},n.prototype.on=function(){qn=this},n.prototype.off=function(){qn=this.parent},n.prototype.stop=function(n){if(this.active){var e=void 0,t=void 0;for(e=0,t=this.effects.length;e<t;e++)this.effects[e].teardown();for(e=0,t=this.cleanups.length;e<t;e++)this.cleanups[e]();if(this.scopes)for(e=0,t=this.scopes.length;e<t;e++)this.scopes[e].stop(!0);if(!this.detached&&this.parent&&!n){var r=this.parent.scopes.pop();r&&r!==this&&(this.parent.scopes[this.index]=r,r.index=this.index)}this.parent=void 0,this.active=!1}},n}();function Un(n){var e=n._provided,t=n.$parent&&n.$parent._provided;return t===e?n._provided=Object.create(t):e}var $n=w((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),r="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=r?n.slice(1):n,once:t,capture:r,passive:e}}));function Gn(n,e){function t(){var n=t.fns;if(!a(n))return Ae(n,null,arguments,e,"v-on handler");for(var r=n.slice(),i=0;i<r.length;i++)Ae(r[i],null,arguments,e,"v-on handler")}return t.fns=n,t}function Hn(n,e,t,r,a,o){var l,c,d,u;for(l in n)c=n[l],d=e[l],u=$n(l),i(c)||(i(d)?(i(c.fns)&&(c=n[l]=Gn(c,o)),s(u.once)&&(c=n[l]=a(u.name,c,u.capture)),t(u.name,c,u.capture,u.passive,u.params)):c!==d&&(d.fns=c,n[l]=d));for(l in e)i(n[l])&&r((u=$n(l)).name,e[l],u.capture)}function Vn(n,e,t){var r;n instanceof mn&&(n=n.data.hook||(n.data.hook={}));var a=n[e];function l(){t.apply(this,arguments),k(r.fns,l)}i(a)?r=Gn([l]):o(a.fns)&&s(a.merged)?(r=a).fns.push(l):r=Gn([a,l]),r.merged=!0,n[e]=r}function Jn(n,e,t,r,a){if(o(e)){if(_(e,t))return n[t]=e[t],a||delete e[t],!0;if(_(e,r))return n[t]=e[r],a||delete e[r],!0}return!1}function Qn(n){return l(n)?[hn(n)]:a(n)?function n(e,t){var r,c,d,u,p=[];for(r=0;r<e.length;r++)i(c=e[r])||"boolean"==typeof c||(d=p.length-1,u=p[d],a(c)?c.length>0&&(Wn((c=n(c,"".concat(t||"","_").concat(r)))[0])&&Wn(u)&&(p[d]=hn(u.text+c[0].text),c.shift()),p.push.apply(p,c)):l(c)?Wn(u)?p[d]=hn(u.text+c):""!==c&&p.push(hn(c)):Wn(c)&&Wn(u)?p[d]=hn(u.text+c.text):(s(e._isVList)&&o(c.tag)&&i(c.key)&&o(t)&&(c.key="__vlist".concat(t,"_").concat(r,"__")),p.push(c)));return p}(n):void 0}function Wn(n){return o(n)&&o(n.text)&&!1===n.isComment}function Xn(n,e){var t,r,i,s,l=null;if(a(n)||"string"==typeof n)for(l=new Array(n.length),t=0,r=n.length;t<r;t++)l[t]=e(n[t],t);else if("number"==typeof n)for(l=new Array(n),t=0;t<n;t++)l[t]=e(t+1,t);else if(d(n))if(dn&&n[Symbol.iterator]){l=[];for(var c=n[Symbol.iterator](),u=c.next();!u.done;)l.push(e(u.value,l.length)),u=c.next()}else for(i=Object.keys(n),l=new Array(i.length),t=0,r=i.length;t<r;t++)s=i[t],l[t]=e(n[s],s,t);return o(l)||(l=[]),l._isVList=!0,l}function Zn(n,e,t,r){var a,i=this.$scopedSlots[n];i?(t=t||{},r&&(t=B(B({},r),t)),a=i(t)||(c(e)?e():e)):a=this.$slots[n]||(c(e)?e():e);var o=t&&t.slot;return o?this.$createElement("template",{slot:o},a):a}function Yn(n){return zt(this.$options,"filters",n,!0)||P}function ne(n,e){return a(n)?-1===n.indexOf(e):n!==e}function ee(n,e,t,r,a){var i=K.keyCodes[e]||t;return a&&r&&!K.keyCodes[e]?ne(a,r):i?ne(i,n):r?I(r)!==e:void 0===n}function te(n,e,t,r,i){if(t)if(d(t)){a(t)&&(t=R(t));var o=void 0,s=function(a){if("class"===a||"style"===a||y(a))o=n;else{var s=n.attrs&&n.attrs.type;o=r||K.mustUseProp(e,s,a)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var l=S(a),c=I(a);l in o||c in o||(o[a]=t[a],i&&((n.on||(n.on={}))["update:".concat(a)]=function(n){t[a]=n}))};for(var l in t)s(l)}else;return n}function re(n,e){var t=this._staticTrees||(this._staticTrees=[]),r=t[n];return r&&!e||ie(r=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,this._c,this),"__static__".concat(n),!1),r}function ae(n,e,t){return ie(n,"__once__".concat(e).concat(t?"_".concat(t):""),!0),n}function ie(n,e,t){if(a(n))for(var r=0;r<n.length;r++)n[r]&&"string"!=typeof n[r]&&oe(n[r],"".concat(e,"_").concat(r),t);else oe(n,e,t)}function oe(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function se(n,e){if(e)if(p(e)){var t=n.on=n.on?B({},n.on):{};for(var r in e){var a=t[r],i=e[r];t[r]=a?[].concat(a,i):i}}else;return n}function le(n,e,t,r){e=e||{$stable:!t};for(var i=0;i<n.length;i++){var o=n[i];a(o)?le(o,e,t):o&&(o.proxy&&(o.fn.proxy=!0),e[o.key]=o.fn)}return r&&(e.$key=r),e}function ce(n,e){for(var t=0;t<e.length;t+=2){var r=e[t];"string"==typeof r&&r&&(n[e[t]]=e[t+1])}return n}function de(n,e){return"string"==typeof n?e+n:n}function ue(n){n._o=ae,n._n=v,n._s=g,n._l=Xn,n._t=Zn,n._q=O,n._i=D,n._m=re,n._f=Yn,n._k=ee,n._b=te,n._v=hn,n._e=fn,n._u=le,n._g=se,n._d=ce,n._p=de}function pe(n,e){if(!n||!n.length)return{};for(var t={},r=0,a=n.length;r<a;r++){var i=n[r],o=i.data;if(o&&o.attrs&&o.attrs.slot&&delete o.attrs.slot,i.context!==e&&i.fnContext!==e||!o||null==o.slot)(t.default||(t.default=[])).push(i);else{var s=o.slot,l=t[s]||(t[s]=[]);"template"===i.tag?l.push.apply(l,i.children||[]):l.push(i)}}for(var c in t)t[c].every(me)&&delete t[c];return t}function me(n){return n.isComment&&!n.asyncFactory||" "===n.text}function fe(n){return n.isComment&&n.asyncFactory}function he(n,e,t,a){var i,o=Object.keys(t).length>0,s=e?!!e.$stable:!o,l=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(s&&a&&a!==r&&l===a.$key&&!o&&!a.$hasNormal)return a;for(var c in i={},e)e[c]&&"$"!==c[0]&&(i[c]=ge(n,t,c,e[c]))}else i={};for(var d in t)d in i||(i[d]=ve(t,d));return e&&Object.isExtensible(e)&&(e._normalized=i),G(i,"$stable",s),G(i,"$key",l),G(i,"$hasNormal",o),i}function ge(n,e,t,r){var i=function(){var e=un;pn(n);var t=arguments.length?r.apply(null,arguments):r({}),i=(t=t&&"object"==typeof t&&!a(t)?[t]:Qn(t))&&t[0];return pn(e),t&&(!i||1===t.length&&i.isComment&&!fe(i))?void 0:t};return r.proxy&&Object.defineProperty(e,t,{get:i,enumerable:!0,configurable:!0}),i}function ve(n,e){return function(){return n[e]}}function be(n){return{get attrs(){if(!n._attrsProxy){var e=n._attrsProxy={};G(e,"_v_attr_proxy",!0),ye(e,n.$attrs,r,n,"$attrs")}return n._attrsProxy},get listeners(){n._listenersProxy||ye(n._listenersProxy={},n.$listeners,r,n,"$listeners");return n._listenersProxy},get slots(){return function(n){n._slotsProxy||xe(n._slotsProxy={},n.$scopedSlots);return n._slotsProxy}(n)},emit:C(n.$emit,n),expose:function(e){e&&Object.keys(e).forEach((function(t){return Fn(n,e,t)}))}}}function ye(n,e,t,r,a){var i=!1;for(var o in e)o in n?e[o]!==t[o]&&(i=!0):(i=!0,ke(n,o,r,a));for(var o in n)o in e||(i=!0,delete n[o]);return i}function ke(n,e,t,r){Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){return t[r][e]}})}function xe(n,e){for(var t in e)n[t]=e[t];for(var t in n)t in e||delete n[t]}var _e=null;function we(n,e){return(n.__esModule||dn&&"Module"===n[Symbol.toStringTag])&&(n=n.default),d(n)?e.extend(n):n}function Ee(n){if(a(n))for(var e=0;e<n.length;e++){var t=n[e];if(o(t)&&(o(t.componentOptions)||fe(t)))return t}}function Se(n,e,t,r,u,p){return(a(t)||l(t))&&(u=r,r=t,t=void 0),s(p)&&(u=2),function(n,e,t,r,l){if(o(t)&&o(t.__ob__))return fn();o(t)&&o(t.is)&&(e=t.is);if(!e)return fn();0;a(r)&&c(r[0])&&((t=t||{}).scopedSlots={default:r[0]},r.length=0);2===l?r=Qn(r):1===l&&(r=function(n){for(var e=0;e<n.length;e++)if(a(n[e]))return Array.prototype.concat.apply([],n);return n}(r));var u,p;if("string"==typeof e){var m=void 0;p=n.$vnode&&n.$vnode.ns||K.getTagNamespace(e),u=K.isReservedTag(e)?new mn(K.parsePlatformTagName(e),t,r,void 0,void 0,n):t&&t.pre||!o(m=zt(n.$options,"components",e))?new mn(e,t,r,void 0,void 0,n):kt(m,t,n,r,e)}else u=kt(e,t,n,r);return a(u)?u:o(u)?(o(p)&&function n(e,t,r){e.ns=t,"foreignObject"===e.tag&&(t=void 0,r=!0);if(o(e.children))for(var a=0,l=e.children.length;a<l;a++){var c=e.children[a];o(c.tag)&&(i(c.ns)||s(r)&&"svg"!==c.tag)&&n(c,t,r)}}(u,p),o(t)&&function(n){d(n.style)&&Ke(n.style);d(n.class)&&Ke(n.class)}(t),u):fn()}(n,e,t,r,u)}function Te(n,e,t){xn();try{if(e)for(var r=e;r=r.$parent;){var a=r.$options.errorCaptured;if(a)for(var i=0;i<a.length;i++)try{if(!1===a[i].call(r,n,e,t))return}catch(n){Ie(n,r,"errorCaptured hook")}}Ie(n,e,t)}finally{_n()}}function Ae(n,e,t,r,a){var i;try{(i=t?n.apply(e,t):n.call(e))&&!i._isVue&&h(i)&&!i._handled&&(i.catch((function(n){return Te(n,r,a+" (Promise/async)")})),i._handled=!0)}catch(n){Te(n,r,a)}return i}function Ie(n,e,t){if(K.errorHandler)try{return K.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Ce(e,null,"config.errorHandler")}Ce(n,e,t)}function Ce(n,e,t){if(!J||"undefined"==typeof console)throw n;console.error(n)}var ze,Be=!1,Re=[],Me=!1;function Le(){Me=!1;var n=Re.slice(0);Re.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&ln(Promise)){var Pe=Promise.resolve();ze=function(){Pe.then(Le),Y&&setTimeout(M)},Be=!0}else if(W||"undefined"==typeof MutationObserver||!ln(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())ze="undefined"!=typeof setImmediate&&ln(setImmediate)?function(){setImmediate(Le)}:function(){setTimeout(Le,0)};else{var Oe=1,De=new MutationObserver(Le),je=document.createTextNode(String(Oe));De.observe(je,{characterData:!0}),ze=function(){Oe=(Oe+1)%2,je.data=String(Oe)},Be=!0}function Ne(n,e){var t;if(Re.push((function(){if(n)try{n.call(e)}catch(n){Te(n,e,"nextTick")}else t&&t(e)})),Me||(Me=!0,ze()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}function Fe(n){return function(e,t){if(void 0===t&&(t=un),t)return function(n,e,t){var r=n.$options;r[e]=Tt(r[e],t)}(t,n,e)}}Fe("beforeMount"),Fe("mounted"),Fe("beforeUpdate"),Fe("updated"),Fe("beforeDestroy"),Fe("destroyed"),Fe("activated"),Fe("deactivated"),Fe("serverPrefetch"),Fe("renderTracked"),Fe("renderTriggered"),Fe("errorCaptured");var qe=new cn;function Ke(n){return function n(e,t){var r,i,o=a(e);if(!o&&!d(e)||e.__v_skip||Object.isFrozen(e)||e instanceof mn)return;if(e.__ob__){var s=e.__ob__.dep.id;if(t.has(s))return;t.add(s)}if(o)for(r=e.length;r--;)n(e[r],t);else if(Nn(e))n(e.value,t);else for(i=Object.keys(e),r=i.length;r--;)n(e[i[r]],t)}(n,qe),qe.clear(),n}var Ue,$e=0,Ge=function(){function n(n,e,t,r,a){var i,o;i=this,void 0===(o=qn&&!qn._vm?qn:n?n._scope:void 0)&&(o=qn),o&&o.active&&o.effects.push(i),(this.vm=n)&&a&&(n._watcher=this),r?(this.deep=!!r.deep,this.user=!!r.user,this.lazy=!!r.lazy,this.sync=!!r.sync,this.before=r.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++$e,this.active=!0,this.post=!1,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new cn,this.newDepIds=new cn,this.expression="",c(e)?this.getter=e:(this.getter=function(n){if(!H.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=M)),this.value=this.lazy?void 0:this.get()}return n.prototype.get=function(){var n;xn(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;Te(n,e,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&Ke(n),_n(),this.cleanupDeps()}return n},n.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},n.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},n.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():pt(this)},n.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||d(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'.concat(this.expression,'"');Ae(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},n.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},n.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},n.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&k(this.vm._scope.effects,this),this.active){for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},n}();function He(n,e){Ue.$on(n,e)}function Ve(n,e){Ue.$off(n,e)}function Je(n,e){var t=Ue;return function r(){var a=e.apply(null,arguments);null!==a&&t.$off(n,r)}}function Qe(n,e,t){Ue=n,Hn(e,t||{},He,Ve,Je,n),Ue=void 0}var We=null;function Xe(n){var e=We;return We=n,function(){We=e}}function Ze(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function Ye(n,e){if(e){if(n._directInactive=!1,Ze(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)Ye(n.$children[t]);nt(n,"activated")}}function nt(n,e,t,r){void 0===r&&(r=!0),xn();var a=un;r&&pn(n);var i=n.$options[e],o="".concat(e," hook");if(i)for(var s=0,l=i.length;s<l;s++)Ae(i[s],n,t||null,n,o);n._hasHookEvent&&n.$emit("hook:"+e),r&&pn(a),_n()}var et=[],tt=[],rt={},at=!1,it=!1,ot=0;var st=0,lt=Date.now;if(J&&!W){var ct=window.performance;ct&&"function"==typeof ct.now&&lt()>document.createEvent("Event").timeStamp&&(lt=function(){return ct.now()})}var dt=function(n,e){if(n.post){if(!e.post)return 1}else if(e.post)return-1;return n.id-e.id};function ut(){var n,e;for(st=lt(),it=!0,et.sort(dt),ot=0;ot<et.length;ot++)(n=et[ot]).before&&n.before(),e=n.id,rt[e]=null,n.run();var t=tt.slice(),r=et.slice();ot=et.length=tt.length=0,rt={},at=it=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,Ye(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],r=t.vm;r&&r._watcher===t&&r._isMounted&&!r._isDestroyed&&nt(r,"updated")}}(r),function(){for(var n=0;n<bn.length;n++){var e=bn[n];e.subs=e.subs.filter((function(n){return n})),e._pending=!1}bn.length=0}(),sn&&K.devtools&&sn.emit("flush")}function pt(n){var e=n.id;if(null==rt[e]&&(n!==yn.target||!n.noRecurse)){if(rt[e]=!0,it){for(var t=et.length-1;t>ot&&et[t].id>n.id;)t--;et.splice(t+1,0,n)}else et.push(n);at||(at=!0,Ne(ut))}}function mt(n,e){if(n){for(var t=Object.create(null),r=dn?Reflect.ownKeys(n):Object.keys(n),a=0;a<r.length;a++){var i=r[a];if("__ob__"!==i){var o=n[i].from;if(o in e._provided)t[i]=e._provided[o];else if("default"in n[i]){var s=n[i].default;t[i]=c(s)?s.call(e):s}else 0}}return t}}function ft(n,e,t,i,o){var l,c=this,d=o.options;_(i,"_uid")?(l=Object.create(i))._original=i:(l=i,i=i._original);var u=s(d._compiled),p=!u;this.data=n,this.props=e,this.children=t,this.parent=i,this.listeners=n.on||r,this.injections=mt(d.inject,i),this.slots=function(){return c.$slots||he(i,n.scopedSlots,c.$slots=pe(t,i)),c.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return he(i,n.scopedSlots,this.slots())}}),u&&(this.$options=d,this.$slots=this.slots(),this.$scopedSlots=he(i,n.scopedSlots,this.$slots)),d._scopeId?this._c=function(n,e,t,r){var o=Se(l,n,e,t,r,p);return o&&!a(o)&&(o.fnScopeId=d._scopeId,o.fnContext=i),o}:this._c=function(n,e,t,r){return Se(l,n,e,t,r,p)}}function ht(n,e,t,r,a){var i=gn(n);return i.fnContext=t,i.fnOptions=r,e.slot&&((i.data||(i.data={})).slot=e.slot),i}function gt(n,e){for(var t in e)n[S(t)]=e[t]}function vt(n){return n.name||n.__name||n._componentTag}ue(ft.prototype);var bt={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;bt.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},r=n.data.inlineTemplate;o(r)&&(t.render=r.render,t.staticRenderFns=r.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,We)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,a,i){var o=a.data.scopedSlots,s=n.$scopedSlots,l=!!(o&&!o.$stable||s!==r&&!s.$stable||o&&n.$scopedSlots.$key!==o.$key||!o&&n.$scopedSlots.$key),c=!!(i||n.$options._renderChildren||l),d=n.$vnode;n.$options._parentVnode=a,n.$vnode=a,n._vnode&&(n._vnode.parent=a),n.$options._renderChildren=i;var u=a.data.attrs||r;n._attrsProxy&&ye(n._attrsProxy,u,d.data&&d.data.attrs||r,n,"$attrs")&&(c=!0),n.$attrs=u,t=t||r;var p=n.$options._parentListeners;if(n._listenersProxy&&ye(n._listenersProxy,t,p||r,n,"$listeners"),n.$listeners=n.$options._parentListeners=t,Qe(n,t,p),e&&n.$options.props){In(!1);for(var m=n._props,f=n.$options._propKeys||[],h=0;h<f.length;h++){var g=f[h],v=n.$options.props;m[g]=Bt(g,v,e,n)}In(!0),n.$options.propsData=e}c&&(n.$slots=pe(i,a.context),n.$forceUpdate())}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,r=n.componentInstance;r._isMounted||(r._isMounted=!0,nt(r,"mounted")),n.data.keepAlive&&(t._isMounted?((e=r)._inactive=!1,tt.push(e)):Ye(r,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(!(t&&(e._directInactive=!0,Ze(e))||e._inactive)){e._inactive=!0;for(var r=0;r<e.$children.length;r++)n(e.$children[r]);nt(e,"deactivated")}}(e,!0):e.$destroy())}},yt=Object.keys(bt);function kt(n,e,t,l,c){if(!i(n)){var u=t.$options._base;if(d(n)&&(n=u.extend(n)),"function"==typeof n){var p;if(i(n.cid)&&void 0===(n=function(n,e){if(s(n.error)&&o(n.errorComp))return n.errorComp;if(o(n.resolved))return n.resolved;var t=_e;if(t&&o(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t),s(n.loading)&&o(n.loadingComp))return n.loadingComp;if(t&&!o(n.owners)){var r=n.owners=[t],a=!0,l=null,c=null;t.$on("hook:destroyed",(function(){return k(r,t)}));var u=function(n){for(var e=0,t=r.length;e<t;e++)r[e].$forceUpdate();n&&(r.length=0,null!==l&&(clearTimeout(l),l=null),null!==c&&(clearTimeout(c),c=null))},p=j((function(t){n.resolved=we(t,e),a?r.length=0:u(!0)})),m=j((function(e){o(n.errorComp)&&(n.error=!0,u(!0))})),f=n(p,m);return d(f)&&(h(f)?i(n.resolved)&&f.then(p,m):h(f.component)&&(f.component.then(p,m),o(f.error)&&(n.errorComp=we(f.error,e)),o(f.loading)&&(n.loadingComp=we(f.loading,e),0===f.delay?n.loading=!0:l=setTimeout((function(){l=null,i(n.resolved)&&i(n.error)&&(n.loading=!0,u(!1))}),f.delay||200)),o(f.timeout)&&(c=setTimeout((function(){c=null,i(n.resolved)&&m(null)}),f.timeout)))),a=!1,n.loading?n.loadingComp:n.resolved}}(p=n,u)))return function(n,e,t,r,a){var i=fn();return i.asyncFactory=n,i.asyncMeta={data:e,context:t,children:r,tag:a},i}(p,e,t,l,c);e=e||{},Gt(n),o(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",r=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var i=e.on||(e.on={}),s=i[r],l=e.model.callback;o(s)?(a(s)?-1===s.indexOf(l):s!==l)&&(i[r]=[l].concat(s)):i[r]=l}(n.options,e);var m=function(n,e,t){var r=e.options.props;if(!i(r)){var a={},s=n.attrs,l=n.props;if(o(s)||o(l))for(var c in r){var d=I(c);Jn(a,l,c,d,!0)||Jn(a,s,c,d,!1)}return a}}(e,n);if(s(n.options.functional))return function(n,e,t,i,s){var l=n.options,c={},d=l.props;if(o(d))for(var u in d)c[u]=Bt(u,d,e||r);else o(t.attrs)&&gt(c,t.attrs),o(t.props)&&gt(c,t.props);var p=new ft(t,c,s,i,n),m=l.render.call(null,p._c,p);if(m instanceof mn)return ht(m,t,p.parent,l,p);if(a(m)){for(var f=Qn(m)||[],h=new Array(f.length),g=0;g<f.length;g++)h[g]=ht(f[g],t,p.parent,l,p);return h}}(n,m,e,t,l);var f=e.on;if(e.on=e.nativeOn,s(n.options.abstract)){var g=e.slot;e={},g&&(e.slot=g)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<yt.length;t++){var r=yt[t],a=e[r],i=bt[r];a===i||a&&a._merged||(e[r]=a?xt(i,a):i)}}(e);var v=vt(n.options)||c;return new mn("vue-component-".concat(n.cid).concat(v?"-".concat(v):""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:m,listeners:f,tag:c,children:l},p)}}}function xt(n,e){var t=function(t,r){n(t,r),e(t,r)};return t._merged=!0,t}var _t=M,wt=K.optionMergeStrategies;function Et(n,e,t){if(void 0===t&&(t=!0),!e)return n;for(var r,a,i,o=dn?Reflect.ownKeys(e):Object.keys(e),s=0;s<o.length;s++)"__ob__"!==(r=o[s])&&(a=n[r],i=e[r],t&&_(n,r)?a!==i&&p(a)&&p(i)&&Et(a,i):Mn(n,r,i));return n}function St(n,e,t){return t?function(){var r=c(e)?e.call(t,t):e,a=c(n)?n.call(t,t):n;return r?Et(r,a):a}:e?n?function(){return Et(c(e)?e.call(this,this):e,c(n)?n.call(this,this):n)}:e:n}function Tt(n,e){var t=e?n?n.concat(e):a(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function At(n,e,t,r){var a=Object.create(n||null);return e?B(a,e):a}wt.data=function(n,e,t){return t?St(n,e,t):e&&"function"!=typeof e?n:St(n,e)},q.forEach((function(n){wt[n]=Tt})),F.forEach((function(n){wt[n+"s"]=At})),wt.watch=function(n,e,t,r){if(n===tn&&(n=void 0),e===tn&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var i={};for(var o in B(i,n),e){var s=i[o],l=e[o];s&&!a(s)&&(s=[s]),i[o]=s?s.concat(l):a(l)?l:[l]}return i},wt.props=wt.methods=wt.inject=wt.computed=function(n,e,t,r){if(!n)return e;var a=Object.create(null);return B(a,n),e&&B(a,e),a},wt.provide=function(n,e){return n?function(){var t=Object.create(null);return Et(t,c(n)?n.call(this):n),e&&Et(t,c(e)?e.call(this):e,!1),t}:e};var It=function(n,e){return void 0===e?n:e};function Ct(n,e,t){if(c(e)&&(e=e.options),function(n,e){var t=n.props;if(t){var r,i,o={};if(a(t))for(r=t.length;r--;)"string"==typeof(i=t[r])&&(o[S(i)]={type:null});else if(p(t))for(var s in t)i=t[s],o[S(s)]=p(i)?i:{type:i};else 0;n.props=o}}(e),function(n,e){var t=n.inject;if(t){var r=n.inject={};if(a(t))for(var i=0;i<t.length;i++)r[t[i]]={from:t[i]};else if(p(t))for(var o in t){var s=t[o];r[o]=p(s)?B({from:o},s):{from:s}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var r=e[t];c(r)&&(e[t]={bind:r,update:r})}}(e),!e._base&&(e.extends&&(n=Ct(n,e.extends,t)),e.mixins))for(var r=0,i=e.mixins.length;r<i;r++)n=Ct(n,e.mixins[r],t);var o,s={};for(o in n)l(o);for(o in e)_(n,o)||l(o);function l(r){var a=wt[r]||It;s[r]=a(n[r],e[r],t,r)}return s}function zt(n,e,t,r){if("string"==typeof t){var a=n[e];if(_(a,t))return a[t];var i=S(t);if(_(a,i))return a[i];var o=T(i);return _(a,o)?a[o]:a[t]||a[i]||a[o]}}function Bt(n,e,t,r){var a=e[n],i=!_(t,n),o=t[n],s=Pt(Boolean,a.type);if(s>-1)if(i&&!_(a,"default"))o=!1;else if(""===o||o===I(n)){var l=Pt(String,a.type);(l<0||s<l)&&(o=!0)}if(void 0===o){o=function(n,e,t){if(!_(e,"default"))return;var r=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return c(r)&&"Function"!==Mt(e.type)?r.call(n):r}(r,a,n);var d=An;In(!0),Bn(o),In(d)}return o}var Rt=/^\s*function (\w+)/;function Mt(n){var e=n&&n.toString().match(Rt);return e?e[1]:""}function Lt(n,e){return Mt(n)===Mt(e)}function Pt(n,e){if(!a(e))return Lt(e,n)?0:-1;for(var t=0,r=e.length;t<r;t++)if(Lt(e[t],n))return t;return-1}var Ot={enumerable:!0,configurable:!0,get:M,set:M};function Dt(n,e,t){Ot.get=function(){return this[e][t]},Ot.set=function(n){this[e][t]=n},Object.defineProperty(n,t,Ot)}function jt(n){var e=n.$options;if(e.props&&function(n,e){var t=n.$options.propsData||{},r=n._props=On({}),a=n.$options._propKeys=[];n.$parent&&In(!1);var i=function(i){a.push(i);var o=Bt(i,e,t,n);Rn(r,i,o),i in n||Dt(n,"_props",i)};for(var o in e)i(o);In(!0)}(n,e.props),function(n){var e=n.$options,t=e.setup;if(t){var r=n._setupContext=be(n);pn(n),xn();var a=Ae(t,null,[n._props||On({}),r],n,"setup");if(_n(),pn(),c(a))e.render=a;else if(d(a))if(n._setupState=a,a.__sfc){var i=n._setupProxy={};for(var o in a)"__sfc"!==o&&Fn(i,a,o)}else for(var o in a)$(o)||Fn(n,a,o);else 0}}(n),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?M:C(e[t],n)}(n,e.methods),e.data)!function(n){var e=n.$options.data;p(e=n._data=c(e)?function(n,e){xn();try{return n.call(e,e)}catch(n){return Te(n,e,"data()"),{}}finally{_n()}}(e,n):e||{})||(e={});var t=Object.keys(e),r=n.$options.props,a=(n.$options.methods,t.length);for(;a--;){var i=t[a];0,r&&_(r,i)||$(i)||Dt(n,"_data",i)}var o=Bn(e);o&&o.vmCount++}(n);else{var t=Bn(n._data={});t&&t.vmCount++}e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),r=on();for(var a in e){var i=e[a],o=c(i)?i:i.get;0,r||(t[a]=new Ge(n,o||M,M,Nt)),a in n||Ft(n,a,i)}}(n,e.computed),e.watch&&e.watch!==tn&&function(n,e){for(var t in e){var r=e[t];if(a(r))for(var i=0;i<r.length;i++)Ut(n,t,r[i]);else Ut(n,t,r)}}(n,e.watch)}var Nt={lazy:!0};function Ft(n,e,t){var r=!on();c(t)?(Ot.get=r?qt(e):Kt(t),Ot.set=M):(Ot.get=t.get?r&&!1!==t.cache?qt(e):Kt(t.get):M,Ot.set=t.set||M),Object.defineProperty(n,e,Ot)}function qt(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),yn.target&&e.depend(),e.value}}function Kt(n){return function(){return n.call(this,this)}}function Ut(n,e,t,r){return p(t)&&(r=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,r)}var $t=0;function Gt(n){var e=n.options;if(n.super){var t=Gt(n.super);if(t!==n.superOptions){n.superOptions=t;var r=function(n){var e,t=n.options,r=n.sealedOptions;for(var a in t)t[a]!==r[a]&&(e||(e={}),e[a]=t[a]);return e}(n);r&&B(n.extendOptions,r),(e=n.options=Ct(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function Ht(n){this._init(n)}function Vt(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,r=t.cid,a=n._Ctor||(n._Ctor={});if(a[r])return a[r];var i=vt(n)||vt(t.options);var o=function(n){this._init(n)};return(o.prototype=Object.create(t.prototype)).constructor=o,o.cid=e++,o.options=Ct(t.options,n),o.super=t,o.options.props&&function(n){var e=n.options.props;for(var t in e)Dt(n.prototype,"_props",t)}(o),o.options.computed&&function(n){var e=n.options.computed;for(var t in e)Ft(n.prototype,t,e[t])}(o),o.extend=t.extend,o.mixin=t.mixin,o.use=t.use,F.forEach((function(n){o[n]=t[n]})),i&&(o.options.components[i]=o),o.superOptions=t.options,o.extendOptions=n,o.sealedOptions=B({},o.options),a[r]=o,o}}function Jt(n){return n&&(vt(n.Ctor.options)||n.tag)}function Qt(n,e){return a(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!m(n)&&n.test(e)}function Wt(n,e){var t=n.cache,r=n.keys,a=n._vnode;for(var i in t){var o=t[i];if(o){var s=o.name;s&&!e(s)&&Xt(t,i,r,a)}}}function Xt(n,e,t,r){var a=n[e];!a||r&&a.tag===r.tag||a.componentInstance.$destroy(),n[e]=null,k(t,e)}!function(n){n.prototype._init=function(n){var e=this;e._uid=$t++,e._isVue=!0,e.__v_skip=!0,e._scope=new Kn(!0),e._scope._vm=!0,n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),r=e._parentVnode;t.parent=e.parent,t._parentVnode=r;var a=r.componentOptions;t.propsData=a.propsData,t._parentListeners=a.listeners,t._renderChildren=a.children,t._componentTag=a.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=Ct(Gt(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._provided=t?t._provided:Object.create(null),n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&Qe(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,a=t&&t.context;n.$slots=pe(e._renderChildren,a),n.$scopedSlots=t?he(n.$parent,t.data.scopedSlots,n.$slots):r,n._c=function(e,t,r,a){return Se(n,e,t,r,a,!1)},n.$createElement=function(e,t,r,a){return Se(n,e,t,r,a,!0)};var i=t&&t.data;Rn(n,"$attrs",i&&i.attrs||r,null,!0),Rn(n,"$listeners",e._parentListeners||r,null,!0)}(e),nt(e,"beforeCreate",void 0,!1),function(n){var e=mt(n.$options.inject,n);e&&(In(!1),Object.keys(e).forEach((function(t){Rn(n,t,e[t])})),In(!0))}(e),jt(e),function(n){var e=n.$options.provide;if(e){var t=c(e)?e.call(n):e;if(!d(t))return;for(var r=Un(n),a=dn?Reflect.ownKeys(t):Object.keys(t),i=0;i<a.length;i++){var o=a[i];Object.defineProperty(r,o,Object.getOwnPropertyDescriptor(t,o))}}}(e),nt(e,"created"),e.$options.el&&e.$mount(e.$options.el)}}(Ht),function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=Mn,n.prototype.$delete=Ln,n.prototype.$watch=function(n,e,t){if(p(e))return Ut(this,n,e,t);(t=t||{}).user=!0;var r=new Ge(this,n,e,t);if(t.immediate){var a='callback for immediate watcher "'.concat(r.expression,'"');xn(),Ae(e,this,[r.value],this,a),_n()}return function(){r.teardown()}}}(Ht),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var r=this;if(a(n))for(var i=0,o=n.length;i<o;i++)r.$on(n[i],t);else(r._events[n]||(r._events[n]=[])).push(t),e.test(n)&&(r._hasHookEvent=!0);return r},n.prototype.$once=function(n,e){var t=this;function r(){t.$off(n,r),e.apply(t,arguments)}return r.fn=e,t.$on(n,r),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(a(n)){for(var r=0,i=n.length;r<i;r++)t.$off(n[r],e);return t}var o,s=t._events[n];if(!s)return t;if(!e)return t._events[n]=null,t;for(var l=s.length;l--;)if((o=s[l])===e||o.fn===e){s.splice(l,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?z(t):t;for(var r=z(arguments,1),a='event handler for "'.concat(n,'"'),i=0,o=t.length;i<o;i++)Ae(t[i],e,r,e,a)}return e}}(Ht),function(n){n.prototype._update=function(n,e){var t=this,r=t.$el,a=t._vnode,i=Xe(t);t._vnode=n,t.$el=a?t.__patch__(a,n):t.__patch__(t.$el,n,e,!1),i(),r&&(r.__vue__=null),t.$el&&(t.$el.__vue__=t);for(var o=t;o&&o.$vnode&&o.$parent&&o.$vnode===o.$parent._vnode;)o.$parent.$el=o.$el,o=o.$parent},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){nt(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||k(e.$children,n),n._scope.stop(),n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),nt(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}(Ht),function(n){ue(n.prototype),n.prototype.$nextTick=function(n){return Ne(n,this)},n.prototype._render=function(){var n,e=this,t=e.$options,r=t.render,i=t._parentVnode;i&&e._isMounted&&(e.$scopedSlots=he(e.$parent,i.data.scopedSlots,e.$slots,e.$scopedSlots),e._slotsProxy&&xe(e._slotsProxy,e.$scopedSlots)),e.$vnode=i;try{pn(e),_e=e,n=r.call(e._renderProxy,e.$createElement)}catch(t){Te(t,e,"render"),n=e._vnode}finally{_e=null,pn()}return a(n)&&1===n.length&&(n=n[0]),n instanceof mn||(n=fn()),n.parent=i,n}}(Ht);var Zt=[String,RegExp,Array],Yt={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Zt,exclude:Zt,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,r=this.keyToCache;if(t){var a=t.tag,i=t.componentInstance,o=t.componentOptions;n[r]={name:Jt(o),tag:a,componentInstance:i},e.push(r),this.max&&e.length>parseInt(this.max)&&Xt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)Xt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){Wt(n,(function(n){return Qt(e,n)}))})),this.$watch("exclude",(function(e){Wt(n,(function(n){return!Qt(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=Ee(n),t=e&&e.componentOptions;if(t){var r=Jt(t),a=this.include,i=this.exclude;if(a&&(!r||!Qt(a,r))||i&&r&&Qt(i,r))return e;var o=this.cache,s=this.keys,l=null==e.key?t.Ctor.cid+(t.tag?"::".concat(t.tag):""):e.key;o[l]?(e.componentInstance=o[l].componentInstance,k(s,l),s.push(l)):(this.vnodeToCache=e,this.keyToCache=l),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return K}};Object.defineProperty(n,"config",e),n.util={warn:_t,extend:B,mergeOptions:Ct,defineReactive:Rn},n.set=Mn,n.delete=Ln,n.nextTick=Ne,n.observable=function(n){return Bn(n),n},n.options=Object.create(null),F.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,B(n.options.components,Yt),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=z(arguments,1);return t.unshift(this),c(n.install)?n.install.apply(n,t):c(n)&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=Ct(this.options,n),this}}(n),Vt(n),function(n){F.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&p(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&c(t)&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}(Ht),Object.defineProperty(Ht.prototype,"$isServer",{get:on}),Object.defineProperty(Ht.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Ht,"FunctionalRenderContext",{value:ft}),Ht.version="2.7.14";var nr=b("style,class"),er=b("input,textarea,option,select,progress"),tr=b("contenteditable,draggable,spellcheck"),rr=b("events,caret,typing,plaintext-only"),ar=b("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),ir="http://www.w3.org/1999/xlink",or=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},sr=function(n){return or(n)?n.slice(6,n.length):""},lr=function(n){return null==n||!1===n};function cr(n){for(var e=n.data,t=n,r=n;o(r.componentInstance);)(r=r.componentInstance._vnode)&&r.data&&(e=dr(r.data,e));for(;o(t=t.parent);)t&&t.data&&(e=dr(e,t.data));return function(n,e){if(o(n)||o(e))return ur(n,pr(e));return""}(e.staticClass,e.class)}function dr(n,e){return{staticClass:ur(n.staticClass,e.staticClass),class:o(n.class)?[n.class,e.class]:e.class}}function ur(n,e){return n?e?n+" "+e:n:e||""}function pr(n){return Array.isArray(n)?function(n){for(var e,t="",r=0,a=n.length;r<a;r++)o(e=pr(n[r]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):d(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var mr={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},fr=b("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),hr=b("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),gr=function(n){return fr(n)||hr(n)};var vr=Object.create(null);var br=b("text,number,password,search,email,tel,url");var yr=Object.freeze({__proto__:null,createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(mr[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),kr={create:function(n,e){xr(e)},update:function(n,e){n.data.ref!==e.data.ref&&(xr(n,!0),xr(e))},destroy:function(n){xr(n,!0)}};function xr(n,e){var t=n.data.ref;if(o(t)){var r=n.context,i=n.componentInstance||n.elm,s=e?null:i,l=e?void 0:i;if(c(t))Ae(t,r,[s],r,"template ref function");else{var d=n.data.refInFor,u="string"==typeof t||"number"==typeof t,p=Nn(t),m=r.$refs;if(u||p)if(d){var f=u?m[t]:t.value;e?a(f)&&k(f,i):a(f)?f.includes(i)||f.push(i):u?(m[t]=[i],_r(r,t,m[t])):t.value=[i]}else if(u){if(e&&m[t]!==i)return;m[t]=l,_r(r,t,s)}else if(p){if(e&&t.value!==i)return;t.value=s}else 0}}}function _r(n,e,t){var r=n._setupState;r&&_(r,e)&&(Nn(r[e])?r[e].value=t:r[e]=t)}var wr=new mn("",{},[]),Er=["create","activate","update","remove","destroy"];function Sr(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&o(n.data)===o(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,r=o(t=n.data)&&o(t=t.attrs)&&t.type,a=o(t=e.data)&&o(t=t.attrs)&&t.type;return r===a||br(r)&&br(a)}(n,e)||s(n.isAsyncPlaceholder)&&i(e.asyncFactory.error))}function Tr(n,e,t){var r,a,i={};for(r=e;r<=t;++r)o(a=n[r].key)&&(i[a]=r);return i}var Ar={create:Ir,update:Ir,destroy:function(n){Ir(n,wr)}};function Ir(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,r,a,i=n===wr,o=e===wr,s=zr(n.data.directives,n.context),l=zr(e.data.directives,e.context),c=[],d=[];for(t in l)r=s[t],a=l[t],r?(a.oldValue=r.value,a.oldArg=r.arg,Rr(a,"update",e,n),a.def&&a.def.componentUpdated&&d.push(a)):(Rr(a,"bind",e,n),a.def&&a.def.inserted&&c.push(a));if(c.length){var u=function(){for(var t=0;t<c.length;t++)Rr(c[t],"inserted",e,n)};i?Vn(e,"insert",u):u()}d.length&&Vn(e,"postpatch",(function(){for(var t=0;t<d.length;t++)Rr(d[t],"componentUpdated",e,n)}));if(!i)for(t in s)l[t]||Rr(s[t],"unbind",n,n,o)}(n,e)}var Cr=Object.create(null);function zr(n,e){var t,r,a=Object.create(null);if(!n)return a;for(t=0;t<n.length;t++){if((r=n[t]).modifiers||(r.modifiers=Cr),a[Br(r)]=r,e._setupState&&e._setupState.__sfc){var i=r.def||zt(e,"_setupState","v-"+r.name);r.def="function"==typeof i?{bind:i,update:i}:i}r.def=r.def||zt(e.$options,"directives",r.name)}return a}function Br(n){return n.rawName||"".concat(n.name,".").concat(Object.keys(n.modifiers||{}).join("."))}function Rr(n,e,t,r,a){var i=n.def&&n.def[e];if(i)try{i(t.elm,n,t,r,a)}catch(r){Te(r,t.context,"directive ".concat(n.name," ").concat(e," hook"))}}var Mr=[kr,Ar];function Lr(n,e){var t=e.componentOptions;if(!(o(t)&&!1===t.Ctor.options.inheritAttrs||i(n.data.attrs)&&i(e.data.attrs))){var r,a,l=e.elm,c=n.data.attrs||{},d=e.data.attrs||{};for(r in(o(d.__ob__)||s(d._v_attr_proxy))&&(d=e.data.attrs=B({},d)),d)a=d[r],c[r]!==a&&Pr(l,r,a,e.data.pre);for(r in(W||Z)&&d.value!==c.value&&Pr(l,"value",d.value),c)i(d[r])&&(or(r)?l.removeAttributeNS(ir,sr(r)):tr(r)||l.removeAttribute(r))}}function Pr(n,e,t,r){r||n.tagName.indexOf("-")>-1?Or(n,e,t):ar(e)?lr(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):tr(e)?n.setAttribute(e,function(n,e){return lr(e)||"false"===e?"false":"contenteditable"===n&&rr(e)?e:"true"}(e,t)):or(e)?lr(t)?n.removeAttributeNS(ir,sr(e)):n.setAttributeNS(ir,e,t):Or(n,e,t)}function Or(n,e,t){if(lr(t))n.removeAttribute(e);else{if(W&&!X&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var r=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",r)};n.addEventListener("input",r),n.__ieph=!0}n.setAttribute(e,t)}}var Dr={create:Lr,update:Lr};function jr(n,e){var t=e.elm,r=e.data,a=n.data;if(!(i(r.staticClass)&&i(r.class)&&(i(a)||i(a.staticClass)&&i(a.class)))){var s=cr(e),l=t._transitionClasses;o(l)&&(s=ur(s,pr(l))),s!==t._prevClass&&(t.setAttribute("class",s),t._prevClass=s)}}var Nr,Fr={create:jr,update:jr};function qr(n,e,t){var r=Nr;return function a(){var i=e.apply(null,arguments);null!==i&&$r(n,a,t,r)}}var Kr=Be&&!(en&&Number(en[1])<=53);function Ur(n,e,t,r){if(Kr){var a=st,i=e;e=i._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=a||n.timeStamp<=0||n.target.ownerDocument!==document)return i.apply(this,arguments)}}Nr.addEventListener(n,e,rn?{capture:t,passive:r}:t)}function $r(n,e,t,r){(r||Nr).removeEventListener(n,e._wrapper||e,t)}function Gr(n,e){if(!i(n.data.on)||!i(e.data.on)){var t=e.data.on||{},r=n.data.on||{};Nr=e.elm||n.elm,function(n){if(o(n.__r)){var e=W?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}o(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),Hn(t,r,Ur,$r,qr,e.context),Nr=void 0}}var Hr,Vr={create:Gr,update:Gr,destroy:function(n){return Gr(n,wr)}};function Jr(n,e){if(!i(n.data.domProps)||!i(e.data.domProps)){var t,r,a=e.elm,l=n.data.domProps||{},c=e.data.domProps||{};for(t in(o(c.__ob__)||s(c._v_attr_proxy))&&(c=e.data.domProps=B({},c)),l)t in c||(a[t]="");for(t in c){if(r=c[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),r===l[t])continue;1===a.childNodes.length&&a.removeChild(a.childNodes[0])}if("value"===t&&"PROGRESS"!==a.tagName){a._value=r;var d=i(r)?"":String(r);Qr(a,d)&&(a.value=d)}else if("innerHTML"===t&&hr(a.tagName)&&i(a.innerHTML)){(Hr=Hr||document.createElement("div")).innerHTML="<svg>".concat(r,"</svg>");for(var u=Hr.firstChild;a.firstChild;)a.removeChild(a.firstChild);for(;u.firstChild;)a.appendChild(u.firstChild)}else if(r!==l[t])try{a[t]=r}catch(n){}}}}function Qr(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,r=n._vModifiers;if(o(r)){if(r.number)return v(t)!==v(e);if(r.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Wr={create:Jr,update:Jr},Xr=w((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var r=n.split(t);r.length>1&&(e[r[0].trim()]=r[1].trim())}})),e}));function Zr(n){var e=Yr(n.style);return n.staticStyle?B(n.staticStyle,e):e}function Yr(n){return Array.isArray(n)?R(n):"string"==typeof n?Xr(n):n}var na,ea=/^--/,ta=/\s*!important$/,ra=function(n,e,t){if(ea.test(e))n.style.setProperty(e,t);else if(ta.test(t))n.style.setProperty(I(e),t.replace(ta,""),"important");else{var r=ia(e);if(Array.isArray(t))for(var a=0,i=t.length;a<i;a++)n.style[r]=t[a];else n.style[r]=t}},aa=["Webkit","Moz","ms"],ia=w((function(n){if(na=na||document.createElement("div").style,"filter"!==(n=S(n))&&n in na)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<aa.length;t++){var r=aa[t]+e;if(r in na)return r}}));function oa(n,e){var t=e.data,r=n.data;if(!(i(t.staticStyle)&&i(t.style)&&i(r.staticStyle)&&i(r.style))){var a,s,l=e.elm,c=r.staticStyle,d=r.normalizedStyle||r.style||{},u=c||d,p=Yr(e.data.style)||{};e.data.normalizedStyle=o(p.__ob__)?B({},p):p;var m=function(n,e){var t,r={};if(e)for(var a=n;a.componentInstance;)(a=a.componentInstance._vnode)&&a.data&&(t=Zr(a.data))&&B(r,t);(t=Zr(n.data))&&B(r,t);for(var i=n;i=i.parent;)i.data&&(t=Zr(i.data))&&B(r,t);return r}(e,!0);for(s in u)i(m[s])&&ra(l,s,"");for(s in m)(a=m[s])!==u[s]&&ra(l,s,null==a?"":a)}}var sa={create:oa,update:oa},la=/\s+/;function ca(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(la).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" ".concat(n.getAttribute("class")||""," ");t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function da(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(la).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" ".concat(n.getAttribute("class")||""," "),r=" "+e+" ";t.indexOf(r)>=0;)t=t.replace(r," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function ua(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&B(e,pa(n.name||"v")),B(e,n),e}return"string"==typeof n?pa(n):void 0}}var pa=w((function(n){return{enterClass:"".concat(n,"-enter"),enterToClass:"".concat(n,"-enter-to"),enterActiveClass:"".concat(n,"-enter-active"),leaveClass:"".concat(n,"-leave"),leaveToClass:"".concat(n,"-leave-to"),leaveActiveClass:"".concat(n,"-leave-active")}})),ma=J&&!X,fa="transition",ha="transitionend",ga="animation",va="animationend";ma&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(fa="WebkitTransition",ha="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(ga="WebkitAnimation",va="webkitAnimationEnd"));var ba=J?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function ya(n){ba((function(){ba(n)}))}function ka(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),ca(n,e))}function xa(n,e){n._transitionClasses&&k(n._transitionClasses,e),da(n,e)}function _a(n,e,t){var r=Ea(n,e),a=r.type,i=r.timeout,o=r.propCount;if(!a)return t();var s="transition"===a?ha:va,l=0,c=function(){n.removeEventListener(s,d),t()},d=function(e){e.target===n&&++l>=o&&c()};setTimeout((function(){l<o&&c()}),i+1),n.addEventListener(s,d)}var wa=/\b(transform|all)(,|$)/;function Ea(n,e){var t,r=window.getComputedStyle(n),a=(r[fa+"Delay"]||"").split(", "),i=(r[fa+"Duration"]||"").split(", "),o=Sa(a,i),s=(r[ga+"Delay"]||"").split(", "),l=(r[ga+"Duration"]||"").split(", "),c=Sa(s,l),d=0,u=0;return"transition"===e?o>0&&(t="transition",d=o,u=i.length):"animation"===e?c>0&&(t="animation",d=c,u=l.length):u=(t=(d=Math.max(o,c))>0?o>c?"transition":"animation":null)?"transition"===t?i.length:l.length:0,{type:t,timeout:d,propCount:u,hasTransform:"transition"===t&&wa.test(r[fa+"Property"])}}function Sa(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return Ta(e)+Ta(n[t])})))}function Ta(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function Aa(n,e){var t=n.elm;o(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var r=ua(n.data.transition);if(!i(r)&&!o(t._enterCb)&&1===t.nodeType){for(var a=r.css,s=r.type,l=r.enterClass,u=r.enterToClass,p=r.enterActiveClass,m=r.appearClass,f=r.appearToClass,h=r.appearActiveClass,g=r.beforeEnter,b=r.enter,y=r.afterEnter,k=r.enterCancelled,x=r.beforeAppear,_=r.appear,w=r.afterAppear,E=r.appearCancelled,S=r.duration,T=We,A=We.$vnode;A&&A.parent;)T=A.context,A=A.parent;var I=!T._isMounted||!n.isRootInsert;if(!I||_||""===_){var C=I&&m?m:l,z=I&&h?h:p,B=I&&f?f:u,R=I&&x||g,M=I&&c(_)?_:b,L=I&&w||y,P=I&&E||k,O=v(d(S)?S.enter:S);0;var D=!1!==a&&!X,N=za(M),F=t._enterCb=j((function(){D&&(xa(t,B),xa(t,z)),F.cancelled?(D&&xa(t,C),P&&P(t)):L&&L(t),t._enterCb=null}));n.data.show||Vn(n,"insert",(function(){var e=t.parentNode,r=e&&e._pending&&e._pending[n.key];r&&r.tag===n.tag&&r.elm._leaveCb&&r.elm._leaveCb(),M&&M(t,F)})),R&&R(t),D&&(ka(t,C),ka(t,z),ya((function(){xa(t,C),F.cancelled||(ka(t,B),N||(Ca(O)?setTimeout(F,O):_a(t,s,F)))}))),n.data.show&&(e&&e(),M&&M(t,F)),D||N||F()}}}function Ia(n,e){var t=n.elm;o(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var r=ua(n.data.transition);if(i(r)||1!==t.nodeType)return e();if(!o(t._leaveCb)){var a=r.css,s=r.type,l=r.leaveClass,c=r.leaveToClass,u=r.leaveActiveClass,p=r.beforeLeave,m=r.leave,f=r.afterLeave,h=r.leaveCancelled,g=r.delayLeave,b=r.duration,y=!1!==a&&!X,k=za(m),x=v(d(b)?b.leave:b);0;var _=t._leaveCb=j((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),y&&(xa(t,c),xa(t,u)),_.cancelled?(y&&xa(t,l),h&&h(t)):(e(),f&&f(t)),t._leaveCb=null}));g?g(w):w()}function w(){_.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),p&&p(t),y&&(ka(t,l),ka(t,u),ya((function(){xa(t,l),_.cancelled||(ka(t,c),k||(Ca(x)?setTimeout(_,x):_a(t,s,_)))}))),m&&m(t,_),y||k||_())}}function Ca(n){return"number"==typeof n&&!isNaN(n)}function za(n){if(i(n))return!1;var e=n.fns;return o(e)?za(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function Ba(n,e){!0!==e.data.show&&Aa(e)}var Ra=function(n){var e,t,r={},c=n.modules,d=n.nodeOps;for(e=0;e<Er.length;++e)for(r[Er[e]]=[],t=0;t<c.length;++t)o(c[t][Er[e]])&&r[Er[e]].push(c[t][Er[e]]);function u(n){var e=d.parentNode(n);o(e)&&d.removeChild(e,n)}function p(n,e,t,a,i,l,c){if(o(n.elm)&&o(l)&&(n=l[c]=gn(n)),n.isRootInsert=!i,!function(n,e,t,a){var i=n.data;if(o(i)){var l=o(n.componentInstance)&&i.keepAlive;if(o(i=i.hook)&&o(i=i.init)&&i(n,!1),o(n.componentInstance))return m(n,e),f(t,n.elm,a),s(l)&&function(n,e,t,a){var i,s=n;for(;s.componentInstance;)if(s=s.componentInstance._vnode,o(i=s.data)&&o(i=i.transition)){for(i=0;i<r.activate.length;++i)r.activate[i](wr,s);e.push(s);break}f(t,n.elm,a)}(n,e,t,a),!0}}(n,e,t,a)){var u=n.data,p=n.children,g=n.tag;o(g)?(n.elm=n.ns?d.createElementNS(n.ns,g):d.createElement(g,n),y(n),h(n,p,e),o(u)&&v(n,e),f(t,n.elm,a)):s(n.isComment)?(n.elm=d.createComment(n.text),f(t,n.elm,a)):(n.elm=d.createTextNode(n.text),f(t,n.elm,a))}}function m(n,e){o(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,g(n)?(v(n,e),y(n)):(xr(n),e.push(n))}function f(n,e,t){o(n)&&(o(t)?d.parentNode(t)===n&&d.insertBefore(n,e,t):d.appendChild(n,e))}function h(n,e,t){if(a(e)){0;for(var r=0;r<e.length;++r)p(e[r],t,n.elm,null,!0,e,r)}else l(n.text)&&d.appendChild(n.elm,d.createTextNode(String(n.text)))}function g(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return o(n.tag)}function v(n,t){for(var a=0;a<r.create.length;++a)r.create[a](wr,n);o(e=n.data.hook)&&(o(e.create)&&e.create(wr,n),o(e.insert)&&t.push(n))}function y(n){var e;if(o(e=n.fnScopeId))d.setStyleScope(n.elm,e);else for(var t=n;t;)o(e=t.context)&&o(e=e.$options._scopeId)&&d.setStyleScope(n.elm,e),t=t.parent;o(e=We)&&e!==n.context&&e!==n.fnContext&&o(e=e.$options._scopeId)&&d.setStyleScope(n.elm,e)}function k(n,e,t,r,a,i){for(;r<=a;++r)p(t[r],i,n,e,!1,t,r)}function x(n){var e,t,a=n.data;if(o(a))for(o(e=a.hook)&&o(e=e.destroy)&&e(n),e=0;e<r.destroy.length;++e)r.destroy[e](n);if(o(e=n.children))for(t=0;t<n.children.length;++t)x(n.children[t])}function _(n,e,t){for(;e<=t;++e){var r=n[e];o(r)&&(o(r.tag)?(w(r),x(r)):u(r.elm))}}function w(n,e){if(o(e)||o(n.data)){var t,a=r.remove.length+1;for(o(e)?e.listeners+=a:e=function(n,e){function t(){0==--t.listeners&&u(n)}return t.listeners=e,t}(n.elm,a),o(t=n.componentInstance)&&o(t=t._vnode)&&o(t.data)&&w(t,e),t=0;t<r.remove.length;++t)r.remove[t](n,e);o(t=n.data.hook)&&o(t=t.remove)?t(n,e):e()}else u(n.elm)}function E(n,e,t,r){for(var a=t;a<r;a++){var i=e[a];if(o(i)&&Sr(n,i))return a}}function S(n,e,t,a,l,c){if(n!==e){o(e.elm)&&o(a)&&(e=a[l]=gn(e));var u=e.elm=n.elm;if(s(n.isAsyncPlaceholder))o(e.asyncFactory.resolved)?I(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(s(e.isStatic)&&s(n.isStatic)&&e.key===n.key&&(s(e.isCloned)||s(e.isOnce)))e.componentInstance=n.componentInstance;else{var m,f=e.data;o(f)&&o(m=f.hook)&&o(m=m.prepatch)&&m(n,e);var h=n.children,v=e.children;if(o(f)&&g(e)){for(m=0;m<r.update.length;++m)r.update[m](n,e);o(m=f.hook)&&o(m=m.update)&&m(n,e)}i(e.text)?o(h)&&o(v)?h!==v&&function(n,e,t,r,a){var s,l,c,u=0,m=0,f=e.length-1,h=e[0],g=e[f],v=t.length-1,b=t[0],y=t[v],x=!a;for(0;u<=f&&m<=v;)i(h)?h=e[++u]:i(g)?g=e[--f]:Sr(h,b)?(S(h,b,r,t,m),h=e[++u],b=t[++m]):Sr(g,y)?(S(g,y,r,t,v),g=e[--f],y=t[--v]):Sr(h,y)?(S(h,y,r,t,v),x&&d.insertBefore(n,h.elm,d.nextSibling(g.elm)),h=e[++u],y=t[--v]):Sr(g,b)?(S(g,b,r,t,m),x&&d.insertBefore(n,g.elm,h.elm),g=e[--f],b=t[++m]):(i(s)&&(s=Tr(e,u,f)),i(l=o(b.key)?s[b.key]:E(b,e,u,f))?p(b,r,n,h.elm,!1,t,m):Sr(c=e[l],b)?(S(c,b,r,t,m),e[l]=void 0,x&&d.insertBefore(n,c.elm,h.elm)):p(b,r,n,h.elm,!1,t,m),b=t[++m]);u>f?k(n,i(t[v+1])?null:t[v+1].elm,t,m,v,r):m>v&&_(e,u,f)}(u,h,v,t,c):o(v)?(o(n.text)&&d.setTextContent(u,""),k(u,null,v,0,v.length-1,t)):o(h)?_(h,0,h.length-1):o(n.text)&&d.setTextContent(u,""):n.text!==e.text&&d.setTextContent(u,e.text),o(f)&&o(m=f.hook)&&o(m=m.postpatch)&&m(n,e)}}}function T(n,e,t){if(s(t)&&o(n.parent))n.parent.data.pendingInsert=e;else for(var r=0;r<e.length;++r)e[r].data.hook.insert(e[r])}var A=b("attrs,class,staticClass,staticStyle,key");function I(n,e,t,r){var a,i=e.tag,l=e.data,c=e.children;if(r=r||l&&l.pre,e.elm=n,s(e.isComment)&&o(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(o(l)&&(o(a=l.hook)&&o(a=a.init)&&a(e,!0),o(a=e.componentInstance)))return m(e,t),!0;if(o(i)){if(o(c))if(n.hasChildNodes())if(o(a=l)&&o(a=a.domProps)&&o(a=a.innerHTML)){if(a!==n.innerHTML)return!1}else{for(var d=!0,u=n.firstChild,p=0;p<c.length;p++){if(!u||!I(u,c[p],t,r)){d=!1;break}u=u.nextSibling}if(!d||u)return!1}else h(e,c,t);if(o(l)){var f=!1;for(var g in l)if(!A(g)){f=!0,v(e,t);break}!f&&l.class&&Ke(l.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,a){if(!i(e)){var l,c=!1,u=[];if(i(n))c=!0,p(e,u);else{var m=o(n.nodeType);if(!m&&Sr(n,e))S(n,e,u,null,null,a);else{if(m){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),s(t)&&I(n,e,u))return T(e,u,!0),n;l=n,n=new mn(d.tagName(l).toLowerCase(),{},[],void 0,l)}var f=n.elm,h=d.parentNode(f);if(p(e,u,f._leaveCb?null:h,d.nextSibling(f)),o(e.parent))for(var v=e.parent,b=g(e);v;){for(var y=0;y<r.destroy.length;++y)r.destroy[y](v);if(v.elm=e.elm,b){for(var k=0;k<r.create.length;++k)r.create[k](wr,v);var w=v.data.hook.insert;if(w.merged)for(var E=1;E<w.fns.length;E++)w.fns[E]()}else xr(v);v=v.parent}o(h)?_([n],0,0):o(n.tag)&&x(n)}}return T(e,u,c),e.elm}o(n)&&x(n)}}({nodeOps:yr,modules:[Dr,Fr,Vr,Wr,sa,J?{create:Ba,activate:Ba,remove:function(n,e){!0!==n.data.show?Ia(n,e):e()}}:{}].concat(Mr)});X&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&Fa(n,"input")}));var Ma={inserted:function(n,e,t,r){"select"===t.tag?(r.elm&&!r.elm._vOptions?Vn(t,"postpatch",(function(){Ma.componentUpdated(n,e,t)})):La(n,e,t.context),n._vOptions=[].map.call(n.options,Da)):("textarea"===t.tag||br(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",ja),n.addEventListener("compositionend",Na),n.addEventListener("change",Na),X&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){La(n,e,t.context);var r=n._vOptions,a=n._vOptions=[].map.call(n.options,Da);if(a.some((function(n,e){return!O(n,r[e])})))(n.multiple?e.value.some((function(n){return Oa(n,a)})):e.value!==e.oldValue&&Oa(e.value,a))&&Fa(n,"change")}}};function La(n,e,t){Pa(n,e,t),(W||Z)&&setTimeout((function(){Pa(n,e,t)}),0)}function Pa(n,e,t){var r=e.value,a=n.multiple;if(!a||Array.isArray(r)){for(var i,o,s=0,l=n.options.length;s<l;s++)if(o=n.options[s],a)i=D(r,Da(o))>-1,o.selected!==i&&(o.selected=i);else if(O(Da(o),r))return void(n.selectedIndex!==s&&(n.selectedIndex=s));a||(n.selectedIndex=-1)}}function Oa(n,e){return e.every((function(e){return!O(e,n)}))}function Da(n){return"_value"in n?n._value:n.value}function ja(n){n.target.composing=!0}function Na(n){n.target.composing&&(n.target.composing=!1,Fa(n.target,"input"))}function Fa(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function qa(n){return!n.componentInstance||n.data&&n.data.transition?n:qa(n.componentInstance._vnode)}var Ka={model:Ma,show:{bind:function(n,e,t){var r=e.value,a=(t=qa(t)).data&&t.data.transition,i=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;r&&a?(t.data.show=!0,Aa(t,(function(){n.style.display=i}))):n.style.display=r?i:"none"},update:function(n,e,t){var r=e.value;!r!=!e.oldValue&&((t=qa(t)).data&&t.data.transition?(t.data.show=!0,r?Aa(t,(function(){n.style.display=n.__vOriginalDisplay})):Ia(t,(function(){n.style.display="none"}))):n.style.display=r?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,r,a){a||(n.style.display=n.__vOriginalDisplay)}}},Ua={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function $a(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?$a(Ee(e.children)):n}function Ga(n){var e={},t=n.$options;for(var r in t.propsData)e[r]=n[r];var a=t._parentListeners;for(var r in a)e[S(r)]=a[r];return e}function Ha(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var Va=function(n){return n.tag||fe(n)},Ja=function(n){return"show"===n.name},Qa={name:"transition",props:Ua,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(Va)).length){0;var r=this.mode;0;var a=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return a;var i=$a(a);if(!i)return a;if(this._leaving)return Ha(n,a);var o="__transition-".concat(this._uid,"-");i.key=null==i.key?i.isComment?o+"comment":o+i.tag:l(i.key)?0===String(i.key).indexOf(o)?i.key:o+i.key:i.key;var s=(i.data||(i.data={})).transition=Ga(this),c=this._vnode,d=$a(c);if(i.data.directives&&i.data.directives.some(Ja)&&(i.data.show=!0),d&&d.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(i,d)&&!fe(d)&&(!d.componentInstance||!d.componentInstance._vnode.isComment)){var u=d.data.transition=B({},s);if("out-in"===r)return this._leaving=!0,Vn(u,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),Ha(n,a);if("in-out"===r){if(fe(i))return c;var p,m=function(){p()};Vn(s,"afterEnter",m),Vn(s,"enterCancelled",m),Vn(u,"delayLeave",(function(n){p=n}))}}return a}}},Wa=B({tag:String,moveClass:String},Ua);function Xa(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function Za(n){n.data.newPos=n.elm.getBoundingClientRect()}function Ya(n){var e=n.data.pos,t=n.data.newPos,r=e.left-t.left,a=e.top-t.top;if(r||a){n.data.moved=!0;var i=n.elm.style;i.transform=i.WebkitTransform="translate(".concat(r,"px,").concat(a,"px)"),i.transitionDuration="0s"}}delete Wa.mode;var ni={Transition:Qa,TransitionGroup:{props:Wa,beforeMount:function(){var n=this,e=this._update;this._update=function(t,r){var a=Xe(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,a(),e.call(n,t,r)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),r=this.prevChildren=this.children,a=this.$slots.default||[],i=this.children=[],o=Ga(this),s=0;s<a.length;s++){if((d=a[s]).tag)if(null!=d.key&&0!==String(d.key).indexOf("__vlist"))i.push(d),t[d.key]=d,(d.data||(d.data={})).transition=o;else;}if(r){var l=[],c=[];for(s=0;s<r.length;s++){var d;(d=r[s]).data.transition=o,d.data.pos=d.elm.getBoundingClientRect(),t[d.key]?l.push(d):c.push(d)}this.kept=n(e,null,l),this.removed=c}return n(e,null,i)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(Xa),n.forEach(Za),n.forEach(Ya),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,r=t.style;ka(t,e),r.transform=r.WebkitTransform=r.transitionDuration="",t.addEventListener(ha,t._moveCb=function n(r){r&&r.target!==t||r&&!/transform$/.test(r.propertyName)||(t.removeEventListener(ha,n),t._moveCb=null,xa(t,e))})}})))},methods:{hasMove:function(n,e){if(!ma)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){da(t,n)})),ca(t,e),t.style.display="none",this.$el.appendChild(t);var r=Ea(t);return this.$el.removeChild(t),this._hasMove=r.hasTransform}}}};function ei(n,e){for(var t in e)n[t]=e[t];return n}Ht.config.mustUseProp=function(n,e,t){return"value"===t&&er(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},Ht.config.isReservedTag=gr,Ht.config.isReservedAttr=nr,Ht.config.getTagNamespace=function(n){return hr(n)?"svg":"math"===n?"math":void 0},Ht.config.isUnknownElement=function(n){if(!J)return!0;if(gr(n))return!1;if(n=n.toLowerCase(),null!=vr[n])return vr[n];var e=document.createElement(n);return n.indexOf("-")>-1?vr[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:vr[n]=/HTMLUnknownElement/.test(e.toString())},B(Ht.options.directives,Ka),B(Ht.options.components,ni),Ht.prototype.__patch__=J?Ra:M,Ht.prototype.$mount=function(n,e){return function(n,e,t){var r;n.$el=e,n.$options.render||(n.$options.render=fn),nt(n,"beforeMount"),r=function(){n._update(n._render(),t)},new Ge(n,r,M,{before:function(){n._isMounted&&!n._isDestroyed&&nt(n,"beforeUpdate")}},!0),t=!1;var a=n._preWatchers;if(a)for(var i=0;i<a.length;i++)a[i].run();return null==n.$vnode&&(n._isMounted=!0,nt(n,"mounted")),n}(this,n=n&&J?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},J&&setTimeout((function(){K.devtools&&sn&&sn.emit("init",Ht)}),0);var ti=/[!'()*]/g,ri=function(n){return"%"+n.charCodeAt(0).toString(16)},ai=/%2C/g,ii=function(n){return encodeURIComponent(n).replace(ti,ri).replace(ai,",")};function oi(n){try{return decodeURIComponent(n)}catch(n){0}return n}var si=function(n){return null==n||"object"==typeof n?n:String(n)};function li(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),r=oi(t.shift()),a=t.length>0?oi(t.join("=")):null;void 0===e[r]?e[r]=a:Array.isArray(e[r])?e[r].push(a):e[r]=[e[r],a]})),e):e}function ci(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return ii(e);if(Array.isArray(t)){var r=[];return t.forEach((function(n){void 0!==n&&(null===n?r.push(ii(e)):r.push(ii(e)+"="+ii(n)))})),r.join("&")}return ii(e)+"="+ii(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var di=/\/?$/;function ui(n,e,t,r){var a=r&&r.options.stringifyQuery,i=e.query||{};try{i=pi(i)}catch(n){}var o={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:i,params:e.params||{},fullPath:hi(e,a),matched:n?fi(n):[]};return t&&(o.redirectedFrom=hi(t,a)),Object.freeze(o)}function pi(n){if(Array.isArray(n))return n.map(pi);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=pi(n[t]);return e}return n}var mi=ui(null,{path:"/"});function fi(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function hi(n,e){var t=n.path,r=n.query;void 0===r&&(r={});var a=n.hash;return void 0===a&&(a=""),(t||"/")+(e||ci)(r)+a}function gi(n,e,t){return e===mi?n===e:!!e&&(n.path&&e.path?n.path.replace(di,"")===e.path.replace(di,"")&&(t||n.hash===e.hash&&vi(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&vi(n.query,e.query)&&vi(n.params,e.params))))}function vi(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),r=Object.keys(e).sort();return t.length===r.length&&t.every((function(t,a){var i=n[t];if(r[a]!==t)return!1;var o=e[t];return null==i||null==o?i===o:"object"==typeof i&&"object"==typeof o?vi(i,o):String(i)===String(o)}))}function bi(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var r in t.instances){var a=t.instances[r],i=t.enteredCbs[r];if(a&&i){delete t.enteredCbs[r];for(var o=0;o<i.length;o++)a._isBeingDestroyed||i[o](a)}}}}var yi={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,r=e.children,a=e.parent,i=e.data;i.routerView=!0;for(var o=a.$createElement,s=t.name,l=a.$route,c=a._routerViewCache||(a._routerViewCache={}),d=0,u=!1;a&&a._routerRoot!==a;){var p=a.$vnode?a.$vnode.data:{};p.routerView&&d++,p.keepAlive&&a._directInactive&&a._inactive&&(u=!0),a=a.$parent}if(i.routerViewDepth=d,u){var m=c[s],f=m&&m.component;return f?(m.configProps&&ki(f,i,m.route,m.configProps),o(f,i,r)):o()}var h=l.matched[d],g=h&&h.components[s];if(!h||!g)return c[s]=null,o();c[s]={component:g},i.registerRouteInstance=function(n,e){var t=h.instances[s];(e&&t!==n||!e&&t===n)&&(h.instances[s]=e)},(i.hook||(i.hook={})).prepatch=function(n,e){h.instances[s]=e.componentInstance},i.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==h.instances[s]&&(h.instances[s]=n.componentInstance),bi(l)};var v=h.props&&h.props[s];return v&&(ei(c[s],{route:l,configProps:v}),ki(g,i,l,v)),o(g,i,r)}};function ki(n,e,t,r){var a=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,r);if(a){a=e.props=ei({},a);var i=e.attrs=e.attrs||{};for(var o in a)n.props&&o in n.props||(i[o]=a[o],delete a[o])}}function xi(n,e,t){var r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;var a=e.split("/");t&&a[a.length-1]||a.pop();for(var i=n.replace(/^\//,"").split("/"),o=0;o<i.length;o++){var s=i[o];".."===s?a.pop():"."!==s&&a.push(s)}return""!==a[0]&&a.unshift(""),a.join("/")}function _i(n){return n.replace(/\/(?:\s*\/)+/g,"/")}var wi=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},Ei=ji,Si=zi,Ti=function(n,e){return Ri(zi(n,e),e)},Ai=Ri,Ii=Di,Ci=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function zi(n,e){for(var t,r=[],a=0,i=0,o="",s=e&&e.delimiter||"/";null!=(t=Ci.exec(n));){var l=t[0],c=t[1],d=t.index;if(o+=n.slice(i,d),i=d+l.length,c)o+=c[1];else{var u=n[i],p=t[2],m=t[3],f=t[4],h=t[5],g=t[6],v=t[7];o&&(r.push(o),o="");var b=null!=p&&null!=u&&u!==p,y="+"===g||"*"===g,k="?"===g||"*"===g,x=t[2]||s,_=f||h;r.push({name:m||a++,prefix:p||"",delimiter:x,optional:k,repeat:y,partial:b,asterisk:!!v,pattern:_?Li(_):v?".*":"[^"+Mi(x)+"]+?"})}}return i<n.length&&(o+=n.substr(i)),o&&r.push(o),r}function Bi(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function Ri(n,e){for(var t=new Array(n.length),r=0;r<n.length;r++)"object"==typeof n[r]&&(t[r]=new RegExp("^(?:"+n[r].pattern+")$",Oi(e)));return function(e,r){for(var a="",i=e||{},o=(r||{}).pretty?Bi:encodeURIComponent,s=0;s<n.length;s++){var l=n[s];if("string"!=typeof l){var c,d=i[l.name];if(null==d){if(l.optional){l.partial&&(a+=l.prefix);continue}throw new TypeError('Expected "'+l.name+'" to be defined')}if(wi(d)){if(!l.repeat)throw new TypeError('Expected "'+l.name+'" to not repeat, but received `'+JSON.stringify(d)+"`");if(0===d.length){if(l.optional)continue;throw new TypeError('Expected "'+l.name+'" to not be empty')}for(var u=0;u<d.length;u++){if(c=o(d[u]),!t[s].test(c))throw new TypeError('Expected all "'+l.name+'" to match "'+l.pattern+'", but received `'+JSON.stringify(c)+"`");a+=(0===u?l.prefix:l.delimiter)+c}}else{if(c=l.asterisk?encodeURI(d).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):o(d),!t[s].test(c))throw new TypeError('Expected "'+l.name+'" to match "'+l.pattern+'", but received "'+c+'"');a+=l.prefix+c}}else a+=l}return a}}function Mi(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function Li(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function Pi(n,e){return n.keys=e,n}function Oi(n){return n&&n.sensitive?"":"i"}function Di(n,e,t){wi(e)||(t=e||t,e=[]);for(var r=(t=t||{}).strict,a=!1!==t.end,i="",o=0;o<n.length;o++){var s=n[o];if("string"==typeof s)i+=Mi(s);else{var l=Mi(s.prefix),c="(?:"+s.pattern+")";e.push(s),s.repeat&&(c+="(?:"+l+c+")*"),i+=c=s.optional?s.partial?l+"("+c+")?":"(?:"+l+"("+c+"))?":l+"("+c+")"}}var d=Mi(t.delimiter||"/"),u=i.slice(-d.length)===d;return r||(i=(u?i.slice(0,-d.length):i)+"(?:"+d+"(?=$))?"),i+=a?"$":r&&u?"":"(?="+d+"|$)",Pi(new RegExp("^"+i,Oi(t)),e)}function ji(n,e,t){return wi(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var r=0;r<t.length;r++)e.push({name:r,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return Pi(n,e)}(n,e):wi(n)?function(n,e,t){for(var r=[],a=0;a<n.length;a++)r.push(ji(n[a],e,t).source);return Pi(new RegExp("(?:"+r.join("|")+")",Oi(t)),e)}(n,e,t):function(n,e,t){return Di(zi(n,t),e,t)}(n,e,t)}Ei.parse=Si,Ei.compile=Ti,Ei.tokensToFunction=Ai,Ei.tokensToRegExp=Ii;var Ni=Object.create(null);function Fi(n,e,t){e=e||{};try{var r=Ni[n]||(Ni[n]=Ei.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),r(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function qi(n,e,t,r){var a="string"==typeof n?{path:n}:n;if(a._normalized)return a;if(a.name){var i=(a=ei({},n)).params;return i&&"object"==typeof i&&(a.params=ei({},i)),a}if(!a.path&&a.params&&e){(a=ei({},a))._normalized=!0;var o=ei(ei({},e.params),a.params);if(e.name)a.name=e.name,a.params=o;else if(e.matched.length){var s=e.matched[e.matched.length-1].path;a.path=Fi(s,o,e.path)}else 0;return a}var l=function(n){var e="",t="",r=n.indexOf("#");r>=0&&(e=n.slice(r),n=n.slice(0,r));var a=n.indexOf("?");return a>=0&&(t=n.slice(a+1),n=n.slice(0,a)),{path:n,query:t,hash:e}}(a.path||""),c=e&&e.path||"/",d=l.path?xi(l.path,c,t||a.append):c,u=function(n,e,t){void 0===e&&(e={});var r,a=t||li;try{r=a(n||"")}catch(n){r={}}for(var i in e){var o=e[i];r[i]=Array.isArray(o)?o.map(si):si(o)}return r}(l.query,a.query,r&&r.options.parseQuery),p=a.hash||l.hash;return p&&"#"!==p.charAt(0)&&(p="#"+p),{_normalized:!0,path:d,query:u,hash:p}}var Ki,Ui=function(){},$i={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,r=this.$route,a=t.resolve(this.to,r,this.append),i=a.location,o=a.route,s=a.href,l={},c=t.options.linkActiveClass,d=t.options.linkExactActiveClass,u=null==c?"router-link-active":c,p=null==d?"router-link-exact-active":d,m=null==this.activeClass?u:this.activeClass,f=null==this.exactActiveClass?p:this.exactActiveClass,h=o.redirectedFrom?ui(null,qi(o.redirectedFrom),null,t):o;l[f]=gi(r,h,this.exactPath),l[m]=this.exact||this.exactPath?l[f]:function(n,e){return 0===n.path.replace(di,"/").indexOf(e.path.replace(di,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(r,h);var g=l[f]?this.ariaCurrentValue:null,v=function(n){Gi(n)&&(e.replace?t.replace(i,Ui):t.push(i,Ui))},b={click:Gi};Array.isArray(this.event)?this.event.forEach((function(n){b[n]=v})):b[this.event]=v;var y={class:l},k=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:s,route:o,navigate:v,isActive:l[m],isExactActive:l[f]});if(k){if(1===k.length)return k[0];if(k.length>1||!k.length)return 0===k.length?n():n("span",{},k)}if("a"===this.tag)y.on=b,y.attrs={href:s,"aria-current":g};else{var x=function n(e){var t;if(e)for(var r=0;r<e.length;r++){if("a"===(t=e[r]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(x){x.isStatic=!1;var _=x.data=ei({},x.data);for(var w in _.on=_.on||{},_.on){var E=_.on[w];w in b&&(_.on[w]=Array.isArray(E)?E:[E])}for(var S in b)S in _.on?_.on[S].push(b[S]):_.on[S]=v;var T=x.data.attrs=ei({},x.data.attrs);T.href=s,T["aria-current"]=g}else y.on=b}return n(this.tag,y,this.$slots.default)}};function Gi(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Hi="undefined"!=typeof window;function Vi(n,e,t,r,a){var i=e||[],o=t||Object.create(null),s=r||Object.create(null);n.forEach((function(n){!function n(e,t,r,a,i,o){var s=a.path,l=a.name;0;var c=a.pathToRegexpOptions||{},d=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return _i(e.path+"/"+n)}(s,i,c.strict);"boolean"==typeof a.caseSensitive&&(c.sensitive=a.caseSensitive);var u={path:d,regex:Ji(d,c),components:a.components||{default:a.component},alias:a.alias?"string"==typeof a.alias?[a.alias]:a.alias:[],instances:{},enteredCbs:{},name:l,parent:i,matchAs:o,redirect:a.redirect,beforeEnter:a.beforeEnter,meta:a.meta||{},props:null==a.props?{}:a.components?a.props:{default:a.props}};a.children&&a.children.forEach((function(a){var i=o?_i(o+"/"+a.path):void 0;n(e,t,r,a,u,i)}));t[u.path]||(e.push(u.path),t[u.path]=u);if(void 0!==a.alias)for(var p=Array.isArray(a.alias)?a.alias:[a.alias],m=0;m<p.length;++m){0;var f={path:p[m],children:a.children};n(e,t,r,f,i,u.path||"/")}l&&(r[l]||(r[l]=u))}(i,o,s,n,a)}));for(var l=0,c=i.length;l<c;l++)"*"===i[l]&&(i.push(i.splice(l,1)[0]),c--,l--);return{pathList:i,pathMap:o,nameMap:s}}function Ji(n,e){return Ei(n,[],e)}function Qi(n,e){var t=Vi(n),r=t.pathList,a=t.pathMap,i=t.nameMap;function o(n,t,o){var s=qi(n,t,!1,e),c=s.name;if(c){var d=i[c];if(!d)return l(null,s);var u=d.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof s.params&&(s.params={}),t&&"object"==typeof t.params)for(var p in t.params)!(p in s.params)&&u.indexOf(p)>-1&&(s.params[p]=t.params[p]);return s.path=Fi(d.path,s.params),l(d,s,o)}if(s.path){s.params={};for(var m=0;m<r.length;m++){var f=r[m],h=a[f];if(Wi(h.regex,s.path,s.params))return l(h,s,o)}}return l(null,s)}function s(n,t){var r=n.redirect,a="function"==typeof r?r(ui(n,t,null,e)):r;if("string"==typeof a&&(a={path:a}),!a||"object"!=typeof a)return l(null,t);var s=a,c=s.name,d=s.path,u=t.query,p=t.hash,m=t.params;if(u=s.hasOwnProperty("query")?s.query:u,p=s.hasOwnProperty("hash")?s.hash:p,m=s.hasOwnProperty("params")?s.params:m,c){i[c];return o({_normalized:!0,name:c,query:u,hash:p,params:m},void 0,t)}if(d){var f=function(n,e){return xi(n,e.parent?e.parent.path:"/",!0)}(d,n);return o({_normalized:!0,path:Fi(f,m),query:u,hash:p},void 0,t)}return l(null,t)}function l(n,t,r){return n&&n.redirect?s(n,r||t):n&&n.matchAs?function(n,e,t){var r=o({_normalized:!0,path:Fi(t,e.params)});if(r){var a=r.matched,i=a[a.length-1];return e.params=r.params,l(i,e)}return l(null,e)}(0,t,n.matchAs):ui(n,t,r,e)}return{match:o,addRoute:function(n,e){var t="object"!=typeof n?i[n]:void 0;Vi([e||n],r,a,i,t),t&&t.alias.length&&Vi(t.alias.map((function(n){return{path:n,children:[e]}})),r,a,i,t)},getRoutes:function(){return r.map((function(n){return a[n]}))},addRoutes:function(n){Vi(n,r,a,i)}}}function Wi(n,e,t){var r=e.match(n);if(!r)return!1;if(!t)return!0;for(var a=1,i=r.length;a<i;++a){var o=n.keys[a-1];o&&(t[o.name||"pathMatch"]="string"==typeof r[a]?oi(r[a]):r[a])}return!0}var Xi=Hi&&window.performance&&window.performance.now?window.performance:Date;function Zi(){return Xi.now().toFixed(3)}var Yi=Zi();function no(){return Yi}function eo(n){return Yi=n}var to=Object.create(null);function ro(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=ei({},window.history.state);return t.key=no(),window.history.replaceState(t,"",e),window.addEventListener("popstate",oo),function(){window.removeEventListener("popstate",oo)}}function ao(n,e,t,r){if(n.app){var a=n.options.scrollBehavior;a&&n.app.$nextTick((function(){var i=function(){var n=no();if(n)return to[n]}(),o=a.call(n,e,t,r?i:null);o&&("function"==typeof o.then?o.then((function(n){po(n,i)})).catch((function(n){0})):po(o,i))}))}}function io(){var n=no();n&&(to[n]={x:window.pageXOffset,y:window.pageYOffset})}function oo(n){io(),n.state&&n.state.key&&eo(n.state.key)}function so(n){return co(n.x)||co(n.y)}function lo(n){return{x:co(n.x)?n.x:window.pageXOffset,y:co(n.y)?n.y:window.pageYOffset}}function co(n){return"number"==typeof n}var uo=/^#\d/;function po(n,e){var t,r="object"==typeof n;if(r&&"string"==typeof n.selector){var a=uo.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(a){var i=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),r=n.getBoundingClientRect();return{x:r.left-t.left-e.x,y:r.top-t.top-e.y}}(a,i={x:co((t=i).x)?t.x:0,y:co(t.y)?t.y:0})}else so(n)&&(e=lo(n))}else r&&so(n)&&(e=lo(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var mo,fo=Hi&&((-1===(mo=window.navigator.userAgent).indexOf("Android 2.")&&-1===mo.indexOf("Android 4.0")||-1===mo.indexOf("Mobile Safari")||-1!==mo.indexOf("Chrome")||-1!==mo.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function ho(n,e){io();var t=window.history;try{if(e){var r=ei({},t.state);r.key=no(),t.replaceState(r,"",n)}else t.pushState({key:eo(Zi())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function go(n){ho(n,!0)}var vo={redirected:2,aborted:4,cancelled:8,duplicated:16};function bo(n,e){return ko(n,e,vo.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return xo.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function yo(n,e){return ko(n,e,vo.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function ko(n,e,t,r){var a=new Error(r);return a._isRouter=!0,a.from=n,a.to=e,a.type=t,a}var xo=["params","query","hash"];function _o(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function wo(n,e){return _o(n)&&n._isRouter&&(null==e||n.type===e)}function Eo(n,e,t){var r=function(a){a>=n.length?t():n[a]?e(n[a],(function(){r(a+1)})):r(a+1)};r(0)}function So(n){return function(e,t,r){var a=!1,i=0,o=null;To(n,(function(n,e,t,s){if("function"==typeof n&&void 0===n.cid){a=!0,i++;var l,c=Co((function(e){var a;((a=e).__esModule||Io&&"Module"===a[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:Ki.extend(e),t.components[s]=e,--i<=0&&r()})),d=Co((function(n){var e="Failed to resolve async component "+s+": "+n;o||(o=_o(n)?n:new Error(e),r(o))}));try{l=n(c,d)}catch(n){d(n)}if(l)if("function"==typeof l.then)l.then(c,d);else{var u=l.component;u&&"function"==typeof u.then&&u.then(c,d)}}})),a||r()}}function To(n,e){return Ao(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function Ao(n){return Array.prototype.concat.apply([],n)}var Io="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Co(n){var e=!1;return function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];if(!e)return e=!0,n.apply(this,t)}}var zo=function(n,e){this.router=n,this.base=function(n){if(!n)if(Hi){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=mi,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Bo(n,e,t,r){var a=To(n,(function(n,r,a,i){var o=function(n,e){"function"!=typeof n&&(n=Ki.extend(n));return n.options[e]}(n,e);if(o)return Array.isArray(o)?o.map((function(n){return t(n,r,a,i)})):t(o,r,a,i)}));return Ao(r?a.reverse():a)}function Ro(n,e){if(e)return function(){return n.apply(e,arguments)}}zo.prototype.listen=function(n){this.cb=n},zo.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},zo.prototype.onError=function(n){this.errorCbs.push(n)},zo.prototype.transitionTo=function(n,e,t){var r,a=this;try{r=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var i=this.current;this.confirmTransition(r,(function(){a.updateRoute(r),e&&e(r),a.ensureURL(),a.router.afterHooks.forEach((function(n){n&&n(r,i)})),a.ready||(a.ready=!0,a.readyCbs.forEach((function(n){n(r)})))}),(function(n){t&&t(n),n&&!a.ready&&(wo(n,vo.redirected)&&i===mi||(a.ready=!0,a.readyErrorCbs.forEach((function(e){e(n)}))))}))},zo.prototype.confirmTransition=function(n,e,t){var r=this,a=this.current;this.pending=n;var i,o,s=function(n){!wo(n)&&_o(n)&&(r.errorCbs.length?r.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},l=n.matched.length-1,c=a.matched.length-1;if(gi(n,a)&&l===c&&n.matched[l]===a.matched[c])return this.ensureURL(),n.hash&&ao(this.router,a,n,!1),s(((o=ko(i=a,n,vo.duplicated,'Avoided redundant navigation to current location: "'+i.fullPath+'".')).name="NavigationDuplicated",o));var d=function(n,e){var t,r=Math.max(n.length,e.length);for(t=0;t<r&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),u=d.updated,p=d.deactivated,m=d.activated,f=[].concat(function(n){return Bo(n,"beforeRouteLeave",Ro,!0)}(p),this.router.beforeHooks,function(n){return Bo(n,"beforeRouteUpdate",Ro)}(u),m.map((function(n){return n.beforeEnter})),So(m)),h=function(e,t){if(r.pending!==n)return s(yo(a,n));try{e(n,a,(function(e){!1===e?(r.ensureURL(!0),s(function(n,e){return ko(n,e,vo.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(a,n))):_o(e)?(r.ensureURL(!0),s(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(s(bo(a,n)),"object"==typeof e&&e.replace?r.replace(e):r.push(e)):t(e)}))}catch(n){s(n)}};Eo(f,h,(function(){Eo(function(n){return Bo(n,"beforeRouteEnter",(function(n,e,t,r){return function(n,e,t){return function(r,a,i){return n(r,a,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),i(n)}))}}(n,t,r)}))}(m).concat(r.router.resolveHooks),h,(function(){if(r.pending!==n)return s(yo(a,n));r.pending=null,e(n),r.router.app&&r.router.app.$nextTick((function(){bi(n)}))}))}))},zo.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},zo.prototype.setupListeners=function(){},zo.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=mi,this.pending=null};var Mo=function(n){function e(e,t){n.call(this,e,t),this._startLocation=Lo(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,r=fo&&t;r&&this.listeners.push(ro());var a=function(){var t=n.current,a=Lo(n.base);n.current===mi&&a===n._startLocation||n.transitionTo(a,(function(n){r&&ao(e,n,t,!0)}))};window.addEventListener("popstate",a),this.listeners.push((function(){window.removeEventListener("popstate",a)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){ho(_i(r.base+n.fullPath)),ao(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){go(_i(r.base+n.fullPath)),ao(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(Lo(this.base)!==this.current.fullPath){var e=_i(this.base+this.current.fullPath);n?ho(e):go(e)}},e.prototype.getCurrentLocation=function(){return Lo(this.base)},e}(zo);function Lo(n){var e=window.location.pathname,t=e.toLowerCase(),r=n.toLowerCase();return!n||t!==r&&0!==t.indexOf(_i(r+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var Po=function(n){function e(e,t,r){n.call(this,e,t),r&&function(n){var e=Lo(n);if(!/^\/#/.test(e))return window.location.replace(_i(n+"/#"+e)),!0}(this.base)||Oo()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=fo&&e;t&&this.listeners.push(ro());var r=function(){var e=n.current;Oo()&&n.transitionTo(Do(),(function(r){t&&ao(n.router,r,e,!0),fo||Fo(r.fullPath)}))},a=fo?"popstate":"hashchange";window.addEventListener(a,r),this.listeners.push((function(){window.removeEventListener(a,r)}))}},e.prototype.push=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){No(n.fullPath),ao(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){Fo(n.fullPath),ao(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;Do()!==e&&(n?No(e):Fo(e))},e.prototype.getCurrentLocation=function(){return Do()},e}(zo);function Oo(){var n=Do();return"/"===n.charAt(0)||(Fo("/"+n),!1)}function Do(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function jo(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function No(n){fo?ho(jo(n)):window.location.hash=n}function Fo(n){fo?go(jo(n)):window.location.replace(jo(n))}var qo=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index+1).concat(n),r.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var r=this.stack[t];this.confirmTransition(r,(function(){var n=e.current;e.index=t,e.updateRoute(r),e.router.afterHooks.forEach((function(e){e&&e(r,n)}))}),(function(n){wo(n,vo.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(zo),Ko=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Qi(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!fo&&!1!==n.fallback,this.fallback&&(e="hash"),Hi||(e="abstract"),this.mode=e,e){case"history":this.history=new Mo(this,n.base);break;case"hash":this.history=new Po(this,n.base,this.fallback);break;case"abstract":this.history=new qo(this,n.base);break;default:0}},Uo={currentRoute:{configurable:!0}};Ko.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},Uo.currentRoute.get=function(){return this.history&&this.history.current},Ko.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof Mo||t instanceof Po){var r=function(n){t.setupListeners(),function(n){var r=t.current,a=e.options.scrollBehavior;fo&&a&&"fullPath"in n&&ao(e,n,r,!1)}(n)};t.transitionTo(t.getCurrentLocation(),r,r)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},Ko.prototype.beforeEach=function(n){return Go(this.beforeHooks,n)},Ko.prototype.beforeResolve=function(n){return Go(this.resolveHooks,n)},Ko.prototype.afterEach=function(n){return Go(this.afterHooks,n)},Ko.prototype.onReady=function(n,e){this.history.onReady(n,e)},Ko.prototype.onError=function(n){this.history.onError(n)},Ko.prototype.push=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.push(n,e,t)}));this.history.push(n,e,t)},Ko.prototype.replace=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.replace(n,e,t)}));this.history.replace(n,e,t)},Ko.prototype.go=function(n){this.history.go(n)},Ko.prototype.back=function(){this.go(-1)},Ko.prototype.forward=function(){this.go(1)},Ko.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},Ko.prototype.resolve=function(n,e,t){var r=qi(n,e=e||this.history.current,t,this),a=this.match(r,e),i=a.redirectedFrom||a.fullPath;return{location:r,route:a,href:function(n,e,t){var r="hash"===t?"#"+e:e;return n?_i(n+"/"+r):r}(this.history.base,i,this.mode),normalizedTo:r,resolved:a}},Ko.prototype.getRoutes=function(){return this.matcher.getRoutes()},Ko.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==mi&&this.history.transitionTo(this.history.getCurrentLocation())},Ko.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==mi&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(Ko.prototype,Uo);var $o=Ko;function Go(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}Ko.install=function n(e){if(!n.installed||Ki!==e){n.installed=!0,Ki=e;var t=function(n){return void 0!==n},r=function(n,e){var r=n.$options._parentVnode;t(r)&&t(r=r.data)&&t(r=r.registerRouteInstance)&&r(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,r(this,this)},destroyed:function(){r(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",yi),e.component("RouterLink",$i);var a=e.config.optionMergeStrategies;a.beforeRouteEnter=a.beforeRouteLeave=a.beforeRouteUpdate=a.created}},Ko.version="3.6.5",Ko.isNavigationFailure=wo,Ko.NavigationFailureType=vo,Ko.START_LOCATION=mi,Hi&&window.Vue&&window.Vue.use(Ko);t(105);t(14),t(132);var Ho={NotFound:()=>Promise.all([t.e(0),t.e(4)]).then(t.bind(null,335)),Layout:()=>Promise.all([t.e(0),t.e(2)]).then(t.bind(null,334))},Vo={"v-3a75d5b2":()=>t.e(6).then(t.bind(null,336)),"v-66629ea2":()=>t.e(7).then(t.bind(null,337)),"v-4445b44e":()=>t.e(8).then(t.bind(null,338)),"v-4751e44c":()=>t.e(10).then(t.bind(null,339)),"v-1984cd25":()=>t.e(11).then(t.bind(null,340)),"v-d2301728":()=>t.e(12).then(t.bind(null,341)),"v-b1cae4ee":()=>t.e(13).then(t.bind(null,342)),"v-8f05bed0":()=>t.e(9).then(t.bind(null,343)),"v-8d21212e":()=>t.e(14).then(t.bind(null,344)),"v-262abfa1":()=>t.e(15).then(t.bind(null,345)),"v-6f2e8e58":()=>t.e(17).then(t.bind(null,346)),"v-d17c9944":()=>t.e(16).then(t.bind(null,347)),"v-2489de58":()=>t.e(18).then(t.bind(null,348)),"v-52136b18":()=>t.e(19).then(t.bind(null,349)),"v-ec24f742":()=>t.e(20).then(t.bind(null,350)),"v-2fe1c292":()=>t.e(21).then(t.bind(null,351)),"v-3ad03cd2":()=>t.e(23).then(t.bind(null,352)),"v-f8ca3edc":()=>t.e(24).then(t.bind(null,353)),"v-6ab22c04":()=>t.e(25).then(t.bind(null,354)),"v-58dee060":()=>t.e(26).then(t.bind(null,355)),"v-6ecce798":()=>t.e(29).then(t.bind(null,356)),"v-062906bf":()=>t.e(27).then(t.bind(null,357)),"v-3f7f455b":()=>t.e(28).then(t.bind(null,358)),"v-611dc400":()=>t.e(30).then(t.bind(null,359)),"v-0d1fe552":()=>t.e(31).then(t.bind(null,360)),"v-33c9c057":()=>t.e(32).then(t.bind(null,361)),"v-265e6c6a":()=>t.e(33).then(t.bind(null,362)),"v-b225d99c":()=>t.e(22).then(t.bind(null,363)),"v-585a6957":()=>t.e(34).then(t.bind(null,364)),"v-22135ad2":()=>t.e(35).then(t.bind(null,365)),"v-897d32c4":()=>t.e(38).then(t.bind(null,366)),"v-bf2e1f52":()=>t.e(36).then(t.bind(null,367)),"v-18836f34":()=>t.e(37).then(t.bind(null,368)),"v-34050fae":()=>t.e(39).then(t.bind(null,369)),"v-74f9cb10":()=>t.e(42).then(t.bind(null,370)),"v-471876c8":()=>t.e(40).then(t.bind(null,371)),"v-1858d133":()=>t.e(43).then(t.bind(null,372)),"v-f5bde88e":()=>t.e(44).then(t.bind(null,373)),"v-bbb4debc":()=>t.e(45).then(t.bind(null,374)),"v-d62b5838":()=>t.e(41).then(t.bind(null,375)),"v-0a6bb5e5":()=>t.e(46).then(t.bind(null,376)),"v-24bec208":()=>t.e(47).then(t.bind(null,377)),"v-20d4825a":()=>t.e(48).then(t.bind(null,378)),"v-70c2530b":()=>t.e(49).then(t.bind(null,379)),"v-46223bf5":()=>t.e(54).then(t.bind(null,380)),"v-4ae78607":()=>t.e(52).then(t.bind(null,381)),"v-4b9be2e2":()=>t.e(50).then(t.bind(null,382)),"v-cb83c1e2":()=>t.e(53).then(t.bind(null,383)),"v-66cbb422":()=>t.e(55).then(t.bind(null,384)),"v-37a31fef":()=>t.e(56).then(t.bind(null,385)),"v-4633e0e5":()=>t.e(57).then(t.bind(null,386)),"v-629fc96e":()=>t.e(58).then(t.bind(null,387)),"v-ca2c37f2":()=>t.e(61).then(t.bind(null,388)),"v-13e764ec":()=>t.e(63).then(t.bind(null,389)),"v-4f35af8e":()=>t.e(60).then(t.bind(null,390)),"v-4735ad30":()=>t.e(65).then(t.bind(null,391)),"v-03535536":()=>t.e(64).then(t.bind(null,392)),"v-44e6151e":()=>t.e(66).then(t.bind(null,393)),"v-35d02571":()=>t.e(59).then(t.bind(null,394)),"v-e08ea78c":()=>t.e(62).then(t.bind(null,395)),"v-56cefa9b":()=>t.e(67).then(t.bind(null,396)),"v-db9fa682":()=>t.e(68).then(t.bind(null,397)),"v-384a84e1":()=>t.e(71).then(t.bind(null,398)),"v-58cdf8c8":()=>t.e(70).then(t.bind(null,399)),"v-6e742411":()=>t.e(72).then(t.bind(null,400)),"v-63fd0ca6":()=>t.e(69).then(t.bind(null,401)),"v-389af7e5":()=>t.e(73).then(t.bind(null,402)),"v-39371ab4":()=>t.e(75).then(t.bind(null,403)),"v-7e805f34":()=>t.e(74).then(t.bind(null,404)),"v-18245398":()=>t.e(76).then(t.bind(null,405)),"v-372327de":()=>t.e(51).then(t.bind(null,406)),"v-76c0fdcc":()=>t.e(78).then(t.bind(null,407)),"v-015ece1a":()=>t.e(80).then(t.bind(null,408)),"v-5913e204":()=>t.e(77).then(t.bind(null,409)),"v-8f96befe":()=>t.e(81).then(t.bind(null,410)),"v-70073a00":()=>t.e(83).then(t.bind(null,411)),"v-140f256d":()=>t.e(79).then(t.bind(null,412)),"v-37fa14fa":()=>t.e(82).then(t.bind(null,413)),"v-e8e0160c":()=>t.e(84).then(t.bind(null,414)),"v-d5f92e9a":()=>t.e(85).then(t.bind(null,415)),"v-2ff99942":()=>t.e(86).then(t.bind(null,416)),"v-4055a79c":()=>t.e(91).then(t.bind(null,417)),"v-0545b0a1":()=>t.e(87).then(t.bind(null,418)),"v-8263629e":()=>t.e(89).then(t.bind(null,419)),"v-012dc53d":()=>t.e(92).then(t.bind(null,420)),"v-095f08a6":()=>t.e(93).then(t.bind(null,421)),"v-5fc224a0":()=>t.e(88).then(t.bind(null,422)),"v-373c2e99":()=>t.e(95).then(t.bind(null,423)),"v-78f813a7":()=>t.e(94).then(t.bind(null,424)),"v-a2a48808":()=>t.e(96).then(t.bind(null,425)),"v-05363355":()=>Promise.all([t.e(0),t.e(5)]).then(t.bind(null,426)),"v-7887f0dc":()=>t.e(90).then(t.bind(null,427))};function Jo(n){const e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}const Qo=/-(\w)/g,Wo=Jo(n=>n.replace(Qo,(n,e)=>e?e.toUpperCase():"")),Xo=/\B([A-Z])/g,Zo=Jo(n=>n.replace(Xo,"-$1").toLowerCase()),Yo=Jo(n=>n.charAt(0).toUpperCase()+n.slice(1));function ns(n,e){if(!e)return;if(n(e))return n(e);return e.includes("-")?n(Yo(Wo(e))):n(Yo(e))||n(Zo(e))}const es=Object.assign({},Ho,Vo),ts=n=>es[n],rs=n=>Vo[n],as=n=>Ho[n],is=n=>Ht.component(n);function os(n){return ns(rs,n)}function ss(n){return ns(as,n)}function ls(n){return ns(ts,n)}function cs(n){return ns(is,n)}function ds(...n){return Promise.all(n.filter(n=>n).map(async n=>{if(!cs(n)&&ls(n)){const e=await ls(n)();Ht.component(n,e.default)}}))}function us(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}var ps=t(93),ms=t.n(ps),fs=t(94),hs=t.n(fs),gs={created(){if(this.siteMeta=this.$site.headTags.filter(([n])=>"meta"===n).map(([n,e])=>e),this.$ssrContext){const e=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(n=e)?n.map(n=>{let e="<meta";return Object.keys(n).forEach(t=>{e+=` ${t}="${hs()(n[t])}"`}),e+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=bs(this.$canonicalUrl)}var n},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const n=this.getMergedMetaTags();this.currentMetaTags=ys(n,this.currentMetaTags)},getMergedMetaTags(){const n=this.$page.frontmatter.meta||[];return ms()([{name:"description",content:this.$description}],n,this.siteMeta,ks)},updateCanonicalLink(){vs(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",bs(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){ys(null,this.currentMetaTags),vs()}};function vs(){const n=document.querySelector("link[rel='canonical']");n&&n.remove()}function bs(n=""){return n?`<link href="${n}" rel="canonical" />`:""}function ys(n,e){if(e&&[...e].filter(n=>n.parentNode===document.head).forEach(n=>document.head.removeChild(n)),n)return n.map(n=>{const e=document.createElement("meta");return Object.keys(n).forEach(t=>{e.setAttribute(t,n[t])}),document.head.appendChild(e),e})}function ks(n){for(const e of["name","property","itemprop"])if(n.hasOwnProperty(e))return n[e]+e;return JSON.stringify(n)}var xs=t(50),_s={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(xs)()((function(){this.setActiveHash()}),300),setActiveHash(){const n=[].slice.call(document.querySelectorAll(".sidebar-link")),e=[].slice.call(document.querySelectorAll(".header-anchor")).filter(e=>n.some(n=>n.hash===e.hash)),t=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),r=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),a=window.innerHeight+t;for(let n=0;n<e.length;n++){const i=e[n],o=e[n+1],s=0===n&&0===t||t>=i.parentElement.offsetTop+10&&(!o||t<o.parentElement.offsetTop-10),l=decodeURIComponent(this.$route.hash);if(s&&l!==decodeURIComponent(i.hash)){const t=i;if(a===r)for(let t=n+1;t<e.length;t++)if(l===decodeURIComponent(e[t].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(t.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},ws=t(9),Es=t.n(ws),Ss={mounted(){Es.a.configure({showSpinner:!1}),this.$router.beforeEach((n,e,t)=>{n.path===e.path||Ht.component(n.name)||Es.a.start(),t()}),this.$router.afterEach(()=>{Es.a.done(),this.isSidebarOpen=!1})}},Ts=(t(241),{mounted(){const n=Object.create(null);Es.a.configure({showSpinner:!1}),this.$router.beforeEach((e,t,r)=>{n[e.path]||Es.a.start(),r()}),this.$router.afterEach(e=>{n[e.path]=!0,Es.a.done()})}}),As=t(95),Is=t.n(As),Cs=(t(242),{mounted(){Is.a.polyfill()}});t(243),t(244);class zs{constructor(){this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}show({text:n="",duration:e=3e3}){let t=document.createElement("div");t.className="message move-in",t.innerHTML=`\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">${n}</div>\n    `,this.containerEl.appendChild(t),e>0&&setTimeout(()=>{this.close(t)},e)}close(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",()=>{n.remove()})}}var Bs={mounted(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy(){setTimeout(()=>{(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach(n=>{document.querySelectorAll(n).forEach(this.generateCopyButton)})},1e3)},generateCopyButton(n){if(n.classList.contains("codecopy-enabled"))return;const e=document.createElement("i");e.className="code-copy",e.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',e.title="Copy to clipboard",e.addEventListener("click",()=>{this.copyToClipboard(n.innerText)}),n.appendChild(e),n.classList.add("codecopy-enabled")},copyToClipboard(n){const e=document.createElement("textarea");e.value=n,e.setAttribute("readonly",""),e.style.position="absolute",e.style.left="-9999px",document.body.appendChild(e);const t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);e.select(),document.execCommand("copy");(new zs).show({text:"复制成功",duration:1e3}),document.body.removeChild(e),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}};!function(n,e){void 0===e&&(e={});var t=e.insertAt;if(n&&"undefined"!=typeof document){var r=document.head||document.getElementsByTagName("head")[0],a=document.createElement("style");a.type="text/css","top"===t&&r.firstChild?r.insertBefore(a,r.firstChild):r.appendChild(a),a.styleSheet?a.styleSheet.cssText=n:a.appendChild(document.createTextNode(n))}}("@media (max-width: 1000px) {\n  .vuepress-plugin-demo-block__h_code {\n    display: none;\n  }\n  .vuepress-plugin-demo-block__app {\n    margin-left: auto !important;\n    margin-right: auto !important;\n  }\n}\n.vuepress-plugin-demo-block__wrapper {\n  margin-top: 10px;\n  border: 1px solid #ebebeb;\n  border-radius: 4px;\n  transition: all 0.2s;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display {\n  height: 400px;\n  display: flex;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__app {\n  width: 300px;\n  border: 1px solid #ebebeb;\n  box-shadow: 1px 1px 3px #ebebeb;\n  margin-right: 5px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code {\n  flex: 1;\n  overflow: auto;\n  height: 100%;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code > pre {\n  overflow: visible;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  max-height: 400px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper div {\n  box-sizing: border-box;\n}\n.vuepress-plugin-demo-block__wrapper:hover {\n  box-shadow: 0 0 11px rgba(33, 33, 33, 0.2);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code {\n  overflow: hidden;\n  height: 0;\n  padding: 0 !important;\n  background-color: #282c34;\n  border-radius: 0 !important;\n  transition: height 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code pre {\n  margin: 0 !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  padding: 20px;\n  border-bottom: 1px solid #ebebeb;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer {\n  position: relative;\n  text-align: center;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__codepen {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__expand::before {\n  border-top: none;\n  border-right: 6px solid transparent;\n  border-bottom: 6px solid #ccc;\n  border-left: 6px solid transparent;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__codepen,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand span,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand::before {\n  border-top-color: #3eaf7c !important;\n  border-bottom-color: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover svg {\n  fill: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand-text {\n  transition: all 0.5s;\n  opacity: 0;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:nth-last-child(2) {\n  right: 50px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:last-child {\n  right: 10px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button {\n  border-color: transparent;\n  background-color: transparent;\n  font-size: 14px;\n  color: #3eaf7c;\n  cursor: pointer;\n  outline: none;\n  margin: 0;\n  width: 46px;\n  position: relative;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::before {\n  content: attr(data-tip);\n  white-space: nowrap;\n  position: absolute;\n  top: -30px;\n  left: 50%;\n  color: #eee;\n  line-height: 1;\n  z-index: 1000;\n  border-radius: 4px;\n  padding: 6px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  background-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::after {\n  content: '' !important;\n  display: block;\n  position: absolute;\n  left: 50%;\n  top: -5px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  border: 5px solid transparent;\n  border-top-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button svg {\n  width: 34px;\n  height: 20px;\n  fill: #ccc;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__codepen {\n  position: absolute;\n  top: 10px;\n  transition: all 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand {\n  position: relative;\n  width: 100px;\n  height: 40px;\n  margin: 0;\n  color: #3eaf7c;\n  font-size: 14px;\n  background-color: transparent;\n  border-color: transparent;\n  outline: none;\n  transition: all 0.5s;\n  cursor: pointer;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand::before {\n  content: \"\";\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  width: 0;\n  height: 0;\n  border-top: 6px solid #ccc;\n  border-right: 6px solid transparent;\n  border-left: 6px solid transparent;\n  -webkit-transform: translate(-50%, -50%);\n          transform: translate(-50%, -50%);\n}\n");var Rs={jsLib:[],cssLib:[],jsfiddle:!0,codepen:!0,codepenLayout:"left",codepenJsProcessor:"babel",codepenEditors:"101",horizontal:!1,vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"},Ms={},Ls=function(n){return'<div id="app">\n'.concat(n,"\n</div>")},Ps=function(n){return window.$VUEPRESS_DEMO_BLOCK&&void 0!==window.$VUEPRESS_DEMO_BLOCK[n]?window.$VUEPRESS_DEMO_BLOCK[n]:Rs[n]},Os=function n(e,t,r){var a=document.createElement(e);return t&&Object.keys(t).forEach((function(n){if(n.indexOf("data"))a[n]=t[n];else{var e=n.replace("data","");a.dataset[e]=t[n]}})),r&&r.forEach((function(e){var t=e.tag,r=e.attrs,i=e.children;a.appendChild(n(t,r,i))})),a},Ds=function(n,e,t){var r,a=(r=n.querySelectorAll(".".concat(e)),Array.prototype.slice.call(r));return 1!==a.length||t?a:a[0]},js=function(n,e){var t,r,a=n.match(/<style>([\s\S]+)<\/style>/),i=n.match(/<template>([\s\S]+)<\/template>/),o=n.match(/<script>([\s\S]+)<\/script>/),s={css:a&&a[1].replace(/^\n|\n$/g,""),html:i&&i[1].replace(/^\n|\n$/g,""),js:o&&o[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};s.htmlTpl=Ls(s.html),s.jsTpl=(t=s.js,r=t.replace(/export\s+default\s*?\{\n*/,"").replace(/\n*\}\s*$/,"").trim(),"new Vue({\n  el: '#app',\n  ".concat(r,"\n})")),s.script=function(n,e){var t=n.split(/export\s+default/),r="(function() {".concat(t[0]," ; return ").concat(t[1],"})()"),a=window.Babel?window.Babel.transform(r,{presets:["es2015"]}).code:r,i=[eval][0](a);return i.template=e,i}(s.js,s.html);var l=Ps("vue");return s.jsLib.unshift(l),s},Ns=function(n,e){var t,r=n.match(/<style>([\s\S]+)<\/style>/),a=n.match(/<html>([\s\S]+)<\/html>/),i=n.match(/<script>([\s\S]+)<\/script>/),o={css:r&&r[1].replace(/^\n|\n$/g,""),html:a&&a[1].replace(/^\n|\n$/g,""),js:i&&i[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};return o.htmlTpl=o.html,o.jsTpl=o.js,o.script=(t=o.js,window.Babel?window.Babel.transform(t,{presets:["es2015"]}).code:t),o},Fs=function(n){return n=n.replace("export default ","").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),n+='ReactDOM.render(React.createElement(App), document.getElementById("app"))'};function qs(){var n=Ds(document,"vuepress-plugin-demo-block__wrapper",!0);n.length?n.forEach((function(n){if("true"!==n.dataset.created){n.style.display="block";var e=Ds(n,"vuepress-plugin-demo-block__code"),t=Ds(n,"vuepress-plugin-demo-block__display"),r=Ds(n,"vuepress-plugin-demo-block__footer"),a=Ds(t,"vuepress-plugin-demo-block__app"),i=decodeURIComponent(n.dataset.code),o=decodeURIComponent(n.dataset.config),s=decodeURIComponent(n.dataset.type);o=o?JSON.parse(o):{};var l=e.querySelector("div").clientHeight,c="react"===s?function(n,e){var t=(0,window.Babel.transform)(n,{presets:["es2015","react"]}).code,r="(function(exports){var module={};module.exports=exports;".concat(t,";return module.exports.__esModule?module.exports.default:module.exports;})({})"),a=new Function("return ".concat(r))(),i={js:a,css:a.__style__||"",jsLib:e.jsLib||[],cssLib:e.cssLib||[],jsTpl:Fs(n),htmlTpl:Ls("")},o=Ps("react"),s=Ps("reactDOM");return i.jsLib.unshift(o,s),i}(i,o):"vanilla"===s?Ns(i,o):js(i,o),d=Os("button",{className:"".concat("vuepress-plugin-demo-block__expand")});if(r.appendChild(d),d.addEventListener("click",Ks.bind(null,d,l,e,r)),Ps("jsfiddle")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,a=n.jsLib,i=n.cssLib,o=a.concat(i).concat(Ps("cssLib")).concat(Ps("jsLib")).join(",");return Os("form",{className:"vuepress-plugin-demo-block__jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"css",value:e}},{tag:"input",attrs:{type:"hidden",name:"html",value:t}},{tag:"input",attrs:{type:"hidden",name:"js",value:r}},{tag:"input",attrs:{type:"hidden",name:"panel_js",value:3}},{tag:"input",attrs:{type:"hidden",name:"wrap",value:1}},{tag:"input",attrs:{type:"hidden",name:"resources",value:o}},{tag:"button",attrs:{type:"submit",className:"vuepress-plugin-demo-block__button",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088289967" class="icon" style="" viewBox="0 0 1170 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1952" xmlns:xlink="http://www.w3.org/1999/xlink" width="228.515625" height="200"><defs><style type="text/css"></style></defs><path d="M1028.571429 441.142857q63.428571 26.285714 102.571428 83.142857T1170.285714 650.857143q0 93.714286-67.428571 160.285714T940 877.714286q-2.285714 0-6.571429-0.285715t-6-0.285714H232q-97.142857-5.714286-164.571429-71.714286T0 645.142857q0-62.857143 31.428571-116t84-84q-6.857143-22.285714-6.857142-46.857143 0-65.714286 46.857142-112t113.714286-46.285714q54.285714 0 98.285714 33.142857 42.857143-88 127.142858-141.714286t186.571428-53.714285q94.857143 0 174.857143 46T982.571429 248.571429t46.571428 172q0 3.428571-0.285714 10.285714t-0.285714 10.285714zM267.428571 593.142857q0 69.714286 48 110.285714t118.857143 40.571429q78.285714 0 137.142857-56.571429-9.142857-11.428571-27.142857-32.285714T519.428571 626.285714q-38.285714 37.142857-82.285714 37.142857-31.428571 0-53.428571-19.142857T361.714286 594.285714q0-30.285714 22-49.714285t52.285714-19.428572q25.142857 0 48.285714 12t41.714286 31.428572 37.142857 42.857142 39.428572 46.857143 44 42.857143 55.428571 31.428572 69.428571 12q69.142857 0 116.857143-40.857143T936 594.857143q0-69.142857-48-109.714286t-118.285714-40.571428q-81.714286 0-137.714286 55.428571l53.142857 61.714286q37.714286-36.571429 81.142857-36.571429 29.714286 0 52.571429 18.857143t22.857143 48q0 32.571429-21.142857 52.285714t-53.714286 19.714286q-24.571429 0-47.142857-12t-41.142857-31.428571-37.428572-42.857143-39.714286-46.857143-44.285714-42.857143-55.142857-31.428571T434.285714 444.571429q-69.714286 0-118.285714 40.285714T267.428571 593.142857z" p-id="1953"></path></svg>',datatip:"JSFiddle"}}])}(c)),Ps("codepen")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,a=n.jsLib,i=n.cssLib,o=JSON.stringify({css:e,html:t,js:r,js_external:a.concat(Ps("jsLib")).join(";"),css_external:i.concat(Ps("cssLib")).join(";"),layout:Ps("codepenLayout"),js_pre_processor:Ps("codepenJsProcessor"),editors:Ps("codepenEditors")});return Os("form",{className:"vuepress-plugin-demo-block__codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"data",value:o}},{tag:"button",attrs:{type:"submit",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088271207" class="icon" style="" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1737" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><defs><style type="text/css"></style></defs><path d="M123.428571 668l344.571429 229.714286v-205.142857L277.142857 565.142857z m-35.428571-82.285714l110.285714-73.714286-110.285714-73.714286v147.428572z m468 312l344.571429-229.714286-153.714286-102.857143-190.857143 127.428572v205.142857z m-44-281.714286l155.428571-104-155.428571-104-155.428571 104zM277.142857 458.857143l190.857143-127.428572V126.285714L123.428571 356z m548.571429 53.142857l110.285714 73.714286V438.285714z m-78.857143-53.142857l153.714286-102.857143-344.571429-229.714286v205.142857z m277.142857-102.857143v312q0 23.428571-19.428571 36.571429l-468 312q-12 7.428571-24.571429 7.428571t-24.571429-7.428571L19.428571 704.571429q-19.428571-13.142857-19.428571-36.571429V356q0-23.428571 19.428571-36.571429L487.428571 7.428571q12-7.428571 24.571429-7.428571t24.571429 7.428571l468 312q19.428571 13.142857 19.428571 36.571429z" p-id="1738"></path></svg>',className:"vuepress-plugin-demo-block__button",datatip:"Codepen"}}])}(c)),void 0!==o.horizontal?o.horizontal:Ps("horizontal")){n.classList.add("vuepress-plugin-demo-block__horizontal");var u=e.firstChild.cloneNode(!0);u.classList.add("vuepress-plugin-demo-block__h_code"),t.appendChild(u)}if(c.css&&function(n){if(!Ms[n]){var e=Os("style",{innerHTML:n});document.body.appendChild(e),Ms[n]=!0}}(c.css),"react"===s)ReactDOM.render(React.createElement(c.js),a);else if("vue"===s){var p=(new(Vue.extend(c.script))).$mount();a.appendChild(p.$el)}else"vanilla"===s&&(a.innerHTML=c.html,new Function("return (function(){".concat(c.script,"})()"))());n.dataset.created="true"}})):setTimeout((function(n){qs()}),300)}function Ks(n,e,t,r){var a="1"!==n.dataset.isExpand;t.style.height=a?"".concat(e,"px"):0,a?r.classList.add("vuepress-plugin-demo-block__show-link"):r.classList.remove("vuepress-plugin-demo-block__show-link"),n.dataset.isExpand=a?"1":"0"}var Us={mounted:function(){window.$VUEPRESS_DEMO_BLOCK={jsfiddle:!1,codepen:!0,horizontal:!1},qs()},updated:function(){qs()}},$s="auto",Gs="zoom-in",Hs="zoom-out",Vs="grab",Js="move";function Qs(n,e,t){var r=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],a={passive:!1};r?n.addEventListener(e,t,a):n.removeEventListener(e,t,a)}function Ws(n,e){if(n){var t=new Image;t.onload=function(){e&&e(t)},t.src=n}}function Xs(n){return n.dataset.original?n.dataset.original:"A"===n.parentNode.tagName?n.parentNode.getAttribute("href"):null}function Zs(n,e,t){!function(n){var e=Ys,t=nl;if(n.transition){var r=n.transition;delete n.transition,n[e]=r}if(n.transform){var a=n.transform;delete n.transform,n[t]=a}}(e);var r=n.style,a={};for(var i in e)t&&(a[i]=r[i]||""),r[i]=e[i];return a}var Ys="transition",nl="transform",el="transform",tl="transitionend";var rl=function(){},al={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:rl,onClose:rl,onGrab:rl,onMove:rl,onRelease:rl,onBeforeOpen:rl,onBeforeClose:rl,onBeforeGrab:rl,onBeforeRelease:rl,onImageLoading:rl,onImageLoaded:rl},il={init:function(n){var e,t;e=this,t=n,Object.getOwnPropertyNames(Object.getPrototypeOf(e)).forEach((function(n){e[n]=e[n].bind(t)}))},click:function(n){if(n.preventDefault(),sl(n))return window.open(this.target.srcOriginal||n.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(n.currentTarget)},scroll:function(){var n=document.documentElement||document.body.parentNode||document.body,e=window.pageXOffset||n.scrollLeft,t=window.pageYOffset||n.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:e,y:t});var r=this.lastScrollPosition.x-e,a=this.lastScrollPosition.y-t,i=this.options.scrollThreshold;(Math.abs(a)>=i||Math.abs(r)>=i)&&(this.lastScrollPosition=null,this.close())},keydown:function(n){(function(n){return"Escape"===(n.key||n.code)||27===n.keyCode})(n)&&(this.released?this.close():this.release(this.close))},mousedown:function(n){if(ol(n)&&!sl(n)){n.preventDefault();var e=n.clientX,t=n.clientY;this.pressTimer=setTimeout(function(){this.grab(e,t)}.bind(this),200)}},mousemove:function(n){this.released||this.move(n.clientX,n.clientY)},mouseup:function(n){ol(n)&&!sl(n)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(n){n.preventDefault();var e=n.touches[0],t=e.clientX,r=e.clientY;this.pressTimer=setTimeout(function(){this.grab(t,r)}.bind(this),200)},touchmove:function(n){if(!this.released){var e=n.touches[0],t=e.clientX,r=e.clientY;this.move(t,r)}},touchend:function(n){(function(n){n.targetTouches.length})(n)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function ol(n){return 0===n.button}function sl(n){return n.metaKey||n.ctrlKey}var ll={init:function(n){this.el=document.createElement("div"),this.instance=n,this.parent=document.body,Zs(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(n.options),Qs(this.el,"click",n.handler.clickOverlay.bind(n))},updateStyle:function(n){Zs(this.el,{zIndex:n.zIndex,backgroundColor:n.bgColor,transition:"opacity\n        "+n.transitionDuration+"s\n        "+n.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},cl="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},dl=function(){function n(n,e){for(var t=0;t<e.length;t++){var r=e[t];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(n,r.key,r)}}return function(e,t,r){return t&&n(e.prototype,t),r&&n(e,r),e}}(),ul=Object.assign||function(n){for(var e=1;e<arguments.length;e++){var t=arguments[e];for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(n[r]=t[r])}return n},pl={init:function(n,e){this.el=n,this.instance=e,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=Xs(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var n=this.instance.options,e=n.zIndex,t=n.enableGrab,r=n.transitionDuration,a=n.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:e+1,cursor:t?Vs:Hs,transition:el+"\n        "+r+"s\n        "+a,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=Zs(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,Zs(this.el,{transform:"none"})},grab:function(n,e,t){var r=ml(),a=r.x-n,i=r.y-e;Zs(this.el,{cursor:Js,transform:"translate3d(\n        "+(this.translate.x+a)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(n,e,t){var r=ml(),a=r.x-n,i=r.y-e;Zs(this.el,{transition:el,transform:"translate3d(\n        "+(this.translate.x+a)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){Zs(this.el,this.styleClose)},restoreOpenStyle:function(){Zs(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var n=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var e=this.el.cloneNode(!1);e.setAttribute("src",this.srcOriginal),e.style.position="fixed",e.style.visibility="hidden",n.appendChild(e),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),n.removeChild(e)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var n=ml(),e=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:n.x-e,y:n.y-t}},calculateScale:function(){var n=this.el.dataset,e=n.zoomingHeight,t=n.zoomingWidth,r=this.instance.options,a=r.customSize,i=r.scaleBase;if(!a&&e&&t)return{x:t/this.rect.width,y:e/this.rect.height};if(a&&"object"===(void 0===a?"undefined":cl(a)))return{x:a.width/this.rect.width,y:a.height/this.rect.height};var o=this.rect.width/2,s=this.rect.height/2,l=ml(),c={x:l.x-o,y:l.y-s},d=c.x/o,u=c.y/s,p=i+Math.min(d,u);if(a&&"string"==typeof a){var m=t||this.el.naturalWidth,f=e||this.el.naturalHeight,h=parseFloat(a)*m/(100*this.rect.width),g=parseFloat(a)*f/(100*this.rect.height);if(p>h||p>g)return{x:h,y:g}}return{x:p,y:p}}};function ml(){var n=document.documentElement;return{x:Math.min(n.clientWidth,window.innerWidth)/2,y:Math.min(n.clientHeight,window.innerHeight)/2}}function fl(n,e,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(r){Qs(n,r,e[r],t)}))}var hl=function(){function n(e){!function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}(this,n),this.target=Object.create(pl),this.overlay=Object.create(ll),this.handler=Object.create(il),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=ul({},al,e),this.overlay.init(this),this.handler.init(this)}return dl(n,[{key:"listen",value:function(n){if("string"==typeof n)for(var e=document.querySelectorAll(n),t=e.length;t--;)this.listen(e[t]);else"IMG"===n.tagName&&(n.style.cursor=Gs,Qs(n,"click",this.handler.click),this.options.preloadImage&&Ws(Xs(n)));return this}},{key:"config",value:function(n){return n?(ul(this.options,n),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var r="string"==typeof n?document.querySelector(n):n;if("IMG"===r.tagName){if(this.options.onBeforeOpen(r),this.target.init(r,this),!this.options.preloadImage){var a=this.target.srcOriginal;null!=a&&(this.options.onImageLoading(r),Ws(a,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),Qs(document,"scroll",this.handler.scroll),Qs(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&Qs(window,"resize",this.handler.resizeWindow);var i=function n(){Qs(r,tl,n,!1),e.lock=!1,e.target.upgradeSource(),e.options.enableGrab&&fl(document,e.handler,!0),t(r)};return Qs(r,tl,i),this}}}},{key:"close",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=$s,this.overlay.fadeOut(),this.target.zoomOut(),Qs(document,"scroll",this.handler.scroll,!1),Qs(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&Qs(window,"resize",this.handler.resizeWindow,!1);var r=function r(){Qs(t,tl,r,!1),n.shown=!1,n.lock=!1,n.target.downgradeSource(),n.options.enableGrab&&fl(document,n.handler,!1),n.target.restoreCloseStyle(),n.overlay.remove(),e(t)};return Qs(t,tl,r),this}}},{key:"grab",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var a=this.target.el;this.options.onBeforeGrab(a),this.released=!1,this.target.grab(n,e,t);var i=function n(){Qs(a,tl,n,!1),r(a)};return Qs(a,tl,i),this}}},{key:"move",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=Js,this.target.move(n,e,t);var a=this.target.el,i=function n(){Qs(a,tl,n,!1),r(a)};return Qs(a,tl,i),this}}},{key:"release",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=$s,this.target.restoreOpenStyle();var r=function r(){Qs(t,tl,r,!1),n.lock=!1,n.released=!0,e(t)};return Qs(t,tl,r),this}}}]),n}();const gl=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),vl=Number("500");class bl{constructor(){this.instance=new hl(gl)}update(n=".theme-vdoing-content img:not(.no-zoom)"){"undefined"!=typeof window&&this.instance.listen(n)}updateDelay(n=".theme-vdoing-content img:not(.no-zoom)",e=vl){setTimeout(()=>this.update(n),e)}}var yl=[gs,_s,Ss,Ts,Cs,Bs,Us,{watch:{"$page.path"(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted(){this.$vuepress.zooming=new bl,this.$vuepress.zooming.updateDelay()}}],kl={name:"GlobalLayout",computed:{layout(){const n=this.getLayout();return us("layout",n),Ht.component(n)}},methods:{getLayout(){if(this.$page.path){const n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},xl=t(3),_l=Object(xl.a)(kl,(function(){return(0,this._self._c)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),n[e].push(...t);break;default:throw new Error("Unknown option name.")}}(_l,"mixins",yl);const wl=[{name:"v-3a75d5b2",path:"/pages/8e69ed/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-3a75d5b2").then(t)}},{path:"/pages/8e69ed/index.html",redirect:"/pages/8e69ed/"},{path:"/01.Java/01.Java基础/01.Java集合框架.html",redirect:"/pages/8e69ed/"},{name:"v-66629ea2",path:"/pages/ce6e6c/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-66629ea2").then(t)}},{path:"/pages/ce6e6c/index.html",redirect:"/pages/ce6e6c/"},{path:"/01.Java/01.Java基础/02.HashMap.html",redirect:"/pages/ce6e6c/"},{name:"v-4445b44e",path:"/pages/672ba8/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-4445b44e").then(t)}},{path:"/pages/672ba8/index.html",redirect:"/pages/672ba8/"},{path:"/01.Java/01.Java基础/03.Java刷题.html",redirect:"/pages/672ba8/"},{name:"v-4751e44c",path:"/pages/d47d28/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-4751e44c").then(t)}},{path:"/pages/d47d28/index.html",redirect:"/pages/d47d28/"},{path:"/01.Java/01.Java基础/06.线程池.html",redirect:"/pages/d47d28/"},{name:"v-1984cd25",path:"/pages/3edc81/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-1984cd25").then(t)}},{path:"/pages/3edc81/index.html",redirect:"/pages/3edc81/"},{path:"/01.Java/01.Java基础/简历.html",redirect:"/pages/3edc81/"},{name:"v-d2301728",path:"/pages/9749fb/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-d2301728").then(t)}},{path:"/pages/9749fb/index.html",redirect:"/pages/9749fb/"},{path:"/01.Java/02.中间件/00.消息队列.html",redirect:"/pages/9749fb/"},{name:"v-b1cae4ee",path:"/pages/467ce0/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-b1cae4ee").then(t)}},{path:"/pages/467ce0/index.html",redirect:"/pages/467ce0/"},{path:"/01.Java/02.中间件/01.ZooKeeper.html",redirect:"/pages/467ce0/"},{name:"v-8f05bed0",path:"/pages/4b289e/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-8f05bed0").then(t)}},{path:"/pages/4b289e/index.html",redirect:"/pages/4b289e/"},{path:"/01.Java/01.Java基础/05.流操作.html",redirect:"/pages/4b289e/"},{name:"v-8d21212e",path:"/pages/11f4c8/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-8d21212e").then(t)}},{path:"/pages/11f4c8/index.html",redirect:"/pages/11f4c8/"},{path:"/01.Java/02.中间件/02.Kafka.html",redirect:"/pages/11f4c8/"},{name:"v-262abfa1",path:"/pages/2ca146/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-262abfa1").then(t)}},{path:"/pages/2ca146/index.html",redirect:"/pages/2ca146/"},{path:"/01.Java/02.中间件/03.RabbitMQ.html",redirect:"/pages/2ca146/"},{name:"v-6f2e8e58",path:"/pages/7c79c1/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-6f2e8e58").then(t)}},{path:"/pages/7c79c1/index.html",redirect:"/pages/7c79c1/"},{path:"/01.Java/03.微服务/02.Seata.html",redirect:"/pages/7c79c1/"},{name:"v-d17c9944",path:"/pages/526796/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-d17c9944").then(t)}},{path:"/pages/526796/index.html",redirect:"/pages/526796/"},{path:"/01.Java/03.微服务/01.Sentinel.html",redirect:"/pages/526796/"},{name:"v-2489de58",path:"/pages/566e96/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-2489de58").then(t)}},{path:"/pages/566e96/index.html",redirect:"/pages/566e96/"},{path:"/01.Java/03.微服务/03.Redis.html",redirect:"/pages/566e96/"},{name:"v-52136b18",path:"/pages/663ad9/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-52136b18").then(t)}},{path:"/pages/663ad9/index.html",redirect:"/pages/663ad9/"},{path:"/01.Java/03.微服务/04.Canal.html",redirect:"/pages/663ad9/"},{name:"v-ec24f742",path:"/pages/78eabe/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-ec24f742").then(t)}},{path:"/pages/78eabe/index.html",redirect:"/pages/78eabe/"},{path:"/01.Java/03.微服务/05.常见面试题.html",redirect:"/pages/78eabe/"},{name:"v-2fe1c292",path:"/pages/23ed38/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-2fe1c292").then(t)}},{path:"/pages/23ed38/index.html",redirect:"/pages/23ed38/"},{path:"/01.Java/04.框架/01.spring.html",redirect:"/pages/23ed38/"},{name:"v-3ad03cd2",path:"/pages/418390/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-3ad03cd2").then(t)}},{path:"/pages/418390/index.html",redirect:"/pages/418390/"},{path:"/01.Java/04.框架/03.springbooteasy.html",redirect:"/pages/418390/"},{name:"v-f8ca3edc",path:"/pages/4ce008/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-f8ca3edc").then(t)}},{path:"/pages/4ce008/index.html",redirect:"/pages/4ce008/"},{path:"/01.Java/04.框架/04.Controller.html",redirect:"/pages/4ce008/"},{name:"v-6ab22c04",path:"/pages/533bbc/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-6ab22c04").then(t)}},{path:"/pages/533bbc/index.html",redirect:"/pages/533bbc/"},{path:"/01.Java/04.框架/10.NIO.html",redirect:"/pages/533bbc/"},{name:"v-58dee060",path:"/pages/20bd69/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-58dee060").then(t)}},{path:"/pages/20bd69/index.html",redirect:"/pages/20bd69/"},{path:"/01.Java/04.框架/11.Netty.html",redirect:"/pages/20bd69/"},{name:"v-6ecce798",path:"/pages/e60c12/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-6ecce798").then(t)}},{path:"/pages/e60c12/index.html",redirect:"/pages/e60c12/"},{path:"/01.Java/05.数据库/03.MySQL函数.html",redirect:"/pages/e60c12/"},{name:"v-062906bf",path:"/pages/c7801c/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-062906bf").then(t)}},{path:"/pages/c7801c/index.html",redirect:"/pages/c7801c/"},{path:"/01.Java/05.数据库/01.MySQL基础.html",redirect:"/pages/c7801c/"},{name:"v-3f7f455b",path:"/pages/e0425d/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-3f7f455b").then(t)}},{path:"/pages/e0425d/index.html",redirect:"/pages/e0425d/"},{path:"/01.Java/05.数据库/02.MySQL是怎么运行的.html",redirect:"/pages/e0425d/"},{name:"v-611dc400",path:"/pages/c38f55/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-611dc400").then(t)}},{path:"/pages/c38f55/index.html",redirect:"/pages/c38f55/"},{path:"/01.Java/05.数据库/04.MySQL易忘点.html",redirect:"/pages/c38f55/"},{name:"v-0d1fe552",path:"/pages/8d8ba3/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-0d1fe552").then(t)}},{path:"/pages/8d8ba3/index.html",redirect:"/pages/8d8ba3/"},{path:"/01.Java/05.数据库/07.MySQL锁.html",redirect:"/pages/8d8ba3/"},{name:"v-33c9c057",path:"/pages/361d44/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-33c9c057").then(t)}},{path:"/pages/361d44/index.html",redirect:"/pages/361d44/"},{path:"/01.Java/06.项目记录/01.statistics.html",redirect:"/pages/361d44/"},{name:"v-265e6c6a",path:"/pages/b95b70/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-265e6c6a").then(t)}},{path:"/pages/b95b70/index.html",redirect:"/pages/b95b70/"},{path:"/01.Java/06.项目记录/10.nowcode.html",redirect:"/pages/b95b70/"},{name:"v-b225d99c",path:"/pages/071fc0/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-b225d99c").then(t)}},{path:"/pages/071fc0/index.html",redirect:"/pages/071fc0/"},{path:"/01.Java/04.框架/02.springboot.html",redirect:"/pages/071fc0/"},{name:"v-585a6957",path:"/pages/532cfb/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-585a6957").then(t)}},{path:"/pages/532cfb/index.html",redirect:"/pages/532cfb/"},{path:"/01.Java/06.项目记录/20.comunity.html",redirect:"/pages/532cfb/"},{name:"v-22135ad2",path:"/pages/20b125/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-22135ad2").then(t)}},{path:"/pages/20b125/index.html",redirect:"/pages/20b125/"},{path:"/01.Java/06.项目记录/30.raft.html",redirect:"/pages/20b125/"},{name:"v-897d32c4",path:"/pages/d76f3c/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-897d32c4").then(t)}},{path:"/pages/d76f3c/index.html",redirect:"/pages/d76f3c/"},{path:"/01.Java/99.秋招/12.framework.html",redirect:"/pages/d76f3c/"},{name:"v-bf2e1f52",path:"/pages/b3c8f6/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-bf2e1f52").then(t)}},{path:"/pages/b3c8f6/index.html",redirect:"/pages/b3c8f6/"},{path:"/01.Java/06.项目记录/40.doubao.html",redirect:"/pages/b3c8f6/"},{name:"v-18836f34",path:"/pages/729f52/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-18836f34").then(t)}},{path:"/pages/729f52/index.html",redirect:"/pages/729f52/"},{path:"/01.Java/99.秋招/11.Redis.html",redirect:"/pages/729f52/"},{name:"v-34050fae",path:"/pages/b0a322/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-34050fae").then(t)}},{path:"/pages/b0a322/index.html",redirect:"/pages/b0a322/"},{path:"/01.Java/99.秋招/13.cloud.html",redirect:"/pages/b0a322/"},{name:"v-74f9cb10",path:"/pages/f1bf72/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-74f9cb10").then(t)}},{path:"/pages/f1bf72/index.html",redirect:"/pages/f1bf72/"},{path:"/01.Java/99.秋招/16.jvm.html",redirect:"/pages/f1bf72/"},{name:"v-471876c8",path:"/pages/a20dff/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-471876c8").then(t)}},{path:"/pages/a20dff/index.html",redirect:"/pages/a20dff/"},{path:"/01.Java/99.秋招/14.message.html",redirect:"/pages/a20dff/"},{name:"v-1858d133",path:"/pages/33bbc8/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-1858d133").then(t)}},{path:"/pages/33bbc8/index.html",redirect:"/pages/33bbc8/"},{path:"/01.Java/99.秋招/17.设计模式.html",redirect:"/pages/33bbc8/"},{name:"v-f5bde88e",path:"/pages/46dd43/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-f5bde88e").then(t)}},{path:"/pages/46dd43/index.html",redirect:"/pages/46dd43/"},{path:"/01.Java/99.秋招/18.一些场景.html",redirect:"/pages/46dd43/"},{name:"v-bbb4debc",path:"/pages/545d12/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-bbb4debc").then(t)}},{path:"/pages/545d12/index.html",redirect:"/pages/545d12/"},{path:"/01.Java/99.秋招/33.test.html",redirect:"/pages/545d12/"},{name:"v-d62b5838",path:"/pages/15ac4e/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-d62b5838").then(t)}},{path:"/pages/15ac4e/index.html",redirect:"/pages/15ac4e/"},{path:"/01.Java/99.秋招/15.juc.html",redirect:"/pages/15ac4e/"},{name:"v-0a6bb5e5",path:"/pages/69d257/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-0a6bb5e5").then(t)}},{path:"/pages/69d257/index.html",redirect:"/pages/69d257/"},{path:"/01.Java/99.秋招/99.一些疑问.html",redirect:"/pages/69d257/"},{name:"v-24bec208",path:"/pages/851a97/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-24bec208").then(t)}},{path:"/pages/851a97/index.html",redirect:"/pages/851a97/"},{path:"/01.Java/99.秋招/一些候选.html",redirect:"/pages/851a97/"},{name:"v-20d4825a",path:"/pages/4da935/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-20d4825a").then(t)}},{path:"/pages/4da935/index.html",redirect:"/pages/4da935/"},{path:"/01.Java/99.秋招/提前批.html",redirect:"/pages/4da935/"},{name:"v-70c2530b",path:"/pages/7d963b/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-70c2530b").then(t)}},{path:"/pages/7d963b/index.html",redirect:"/pages/7d963b/"},{path:"/01.Java/99.秋招/面试记录.html",redirect:"/pages/7d963b/"},{name:"v-46223bf5",path:"/pages/a2be9b/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-46223bf5").then(t)}},{path:"/pages/a2be9b/index.html",redirect:"/pages/a2be9b/"},{path:"/02.科研/01.室内实时三维重建/07.FlashFusion论文阅读.html",redirect:"/pages/a2be9b/"},{name:"v-4ae78607",path:"/pages/7bbbf3/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-4ae78607").then(t)}},{path:"/pages/7bbbf3/index.html",redirect:"/pages/7bbbf3/"},{path:"/02.科研/01.室内实时三维重建/03.Surfel Meshing .html",redirect:"/pages/7bbbf3/"},{name:"v-4b9be2e2",path:"/pages/aa9650/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-4b9be2e2").then(t)}},{path:"/pages/aa9650/index.html",redirect:"/pages/aa9650/"},{path:"/02.科研/01.室内实时三维重建/01.kinectFusion.html",redirect:"/pages/aa9650/"},{name:"v-cb83c1e2",path:"/pages/24a5f4/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-cb83c1e2").then(t)}},{path:"/pages/24a5f4/index.html",redirect:"/pages/24a5f4/"},{path:"/02.科研/01.室内实时三维重建/06.BAD_SLAM.html",redirect:"/pages/24a5f4/"},{name:"v-66cbb422",path:"/pages/c06e38/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-66cbb422").then(t)}},{path:"/pages/c06e38/index.html",redirect:"/pages/c06e38/"},{path:"/02.科研/01.室内实时三维重建/08.intrinsic3d论文阅读.html",redirect:"/pages/c06e38/"},{name:"v-37a31fef",path:"/pages/0af3d9/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-37a31fef").then(t)}},{path:"/pages/0af3d9/index.html",redirect:"/pages/0af3d9/"},{path:"/02.科研/01.室内实时三维重建/09.factor.html",redirect:"/pages/0af3d9/"},{name:"v-4633e0e5",path:"/pages/3a8868/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-4633e0e5").then(t)}},{path:"/pages/3a8868/index.html",redirect:"/pages/3a8868/"},{path:"/02.科研/01.室内实时三维重建/10.CLD_MVS.html",redirect:"/pages/3a8868/"},{name:"v-629fc96e",path:"/pages/49bbb9/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-629fc96e").then(t)}},{path:"/pages/49bbb9/index.html",redirect:"/pages/49bbb9/"},{path:"/02.科研/01.室内实时三维重建/11.TextureMe.html",redirect:"/pages/49bbb9/"},{name:"v-ca2c37f2",path:"/pages/cdb05f/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-ca2c37f2").then(t)}},{path:"/pages/cdb05f/index.html",redirect:"/pages/cdb05f/"},{path:"/02.科研/01.室内实时三维重建/bundlefusion.html",redirect:"/pages/cdb05f/"},{name:"v-13e764ec",path:"/pages/8487b5/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-13e764ec").then(t)}},{path:"/pages/8487b5/index.html",redirect:"/pages/8487b5/"},{path:"/02.科研/02.大规模三维重建/02.基于信息论自主探索.html",redirect:"/pages/8487b5/"},{name:"v-4f35af8e",path:"/pages/cc3afe/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-4f35af8e").then(t)}},{path:"/pages/cc3afe/index.html",redirect:"/pages/cc3afe/"},{path:"/02.科研/01.室内实时三维重建/14.ORB_SLAM2原理、代码流程文档.html",redirect:"/pages/cc3afe/"},{name:"v-4735ad30",path:"/pages/9af622/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-4735ad30").then(t)}},{path:"/pages/9af622/index.html",redirect:"/pages/9af622/"},{path:"/02.科研/02.大规模三维重建/04.基于投票的增量重建.html",redirect:"/pages/9af622/"},{name:"v-03535536",path:"/pages/299ec4/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-03535536").then(t)}},{path:"/pages/299ec4/index.html",redirect:"/pages/299ec4/"},{path:"/02.科研/02.大规模三维重建/03.TheiaSfM代码阅读.html",redirect:"/pages/299ec4/"},{name:"v-44e6151e",path:"/pages/7453b3/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-44e6151e").then(t)}},{path:"/pages/7453b3/index.html",redirect:"/pages/7453b3/"},{path:"/02.科研/02.大规模三维重建/05.外点去除.html",redirect:"/pages/7453b3/"},{name:"v-35d02571",path:"/pages/ed705b/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-35d02571").then(t)}},{path:"/pages/ed705b/index.html",redirect:"/pages/ed705b/"},{path:"/02.科研/01.室内实时三维重建/13.orbslam论文阅读笔记.html",redirect:"/pages/ed705b/"},{name:"v-e08ea78c",path:"/pages/98600a/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-e08ea78c").then(t)}},{path:"/pages/98600a/index.html",redirect:"/pages/98600a/"},{path:"/02.科研/02.大规模三维重建/01.MVS.html",redirect:"/pages/98600a/"},{name:"v-56cefa9b",path:"/pages/cc38e6/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-56cefa9b").then(t)}},{path:"/pages/cc38e6/index.html",redirect:"/pages/cc38e6/"},{path:"/02.科研/02.大规模三维重建/06.学习opengl.html",redirect:"/pages/cc38e6/"},{name:"v-db9fa682",path:"/pages/8a4bae/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-db9fa682").then(t)}},{path:"/pages/8a4bae/index.html",redirect:"/pages/8a4bae/"},{path:"/02.科研/02.大规模三维重建/07.密集匹配.html",redirect:"/pages/8a4bae/"},{name:"v-384a84e1",path:"/pages/fc7936/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-384a84e1").then(t)}},{path:"/pages/fc7936/index.html",redirect:"/pages/fc7936/"},{path:"/02.科研/02.大规模三维重建/10.自我描述.html",redirect:"/pages/fc7936/"},{name:"v-58cdf8c8",path:"/pages/4a64fa/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-58cdf8c8").then(t)}},{path:"/pages/4a64fa/index.html",redirect:"/pages/4a64fa/"},{path:"/02.科研/02.大规模三维重建/09.论文随记.html",redirect:"/pages/4a64fa/"},{name:"v-6e742411",path:"/pages/169752/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-6e742411").then(t)}},{path:"/pages/169752/index.html",redirect:"/pages/169752/"},{path:"/02.科研/02.大规模三维重建/11.theiaSfM代码.html",redirect:"/pages/169752/"},{name:"v-63fd0ca6",path:"/pages/270f1d/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-63fd0ca6").then(t)}},{path:"/pages/270f1d/index.html",redirect:"/pages/270f1d/"},{path:"/02.科研/02.大规模三维重建/08.雷达增强sfm.html",redirect:"/pages/270f1d/"},{name:"v-389af7e5",path:"/pages/24dfc7/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-389af7e5").then(t)}},{path:"/pages/24dfc7/index.html",redirect:"/pages/24dfc7/"},{path:"/02.科研/02.大规模三维重建/12.懊悔阅读论文1.html",redirect:"/pages/24dfc7/"},{name:"v-39371ab4",path:"/pages/f9d90b/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-39371ab4").then(t)}},{path:"/pages/f9d90b/index.html",redirect:"/pages/f9d90b/"},{path:"/02.科研/02.大规模三维重建/14. 懊悔阅读论文3.html",redirect:"/pages/f9d90b/"},{name:"v-7e805f34",path:"/pages/7387ee/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-7e805f34").then(t)}},{path:"/pages/7387ee/index.html",redirect:"/pages/7387ee/"},{path:"/02.科研/02.大规模三维重建/13. 懊悔阅读论文2.html",redirect:"/pages/7387ee/"},{name:"v-18245398",path:"/pages/696f8f/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-18245398").then(t)}},{path:"/pages/696f8f/index.html",redirect:"/pages/696f8f/"},{path:"/02.科研/02.大规模三维重建/15. 懊悔阅读论文4.html",redirect:"/pages/696f8f/"},{name:"v-372327de",path:"/pages/c6a110/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-372327de").then(t)}},{path:"/pages/c6a110/index.html",redirect:"/pages/c6a110/"},{path:"/02.科研/01.室内实时三维重建/02.EF论文理解.html",redirect:"/pages/c6a110/"},{name:"v-76c0fdcc",path:"/pages/3d257e/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-76c0fdcc").then(t)}},{path:"/pages/3d257e/index.html",redirect:"/pages/3d257e/"},{path:"/02.科研/03.我的工作/02.code.html",redirect:"/pages/3d257e/"},{name:"v-015ece1a",path:"/pages/8f3964/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-015ece1a").then(t)}},{path:"/pages/8f3964/index.html",redirect:"/pages/8f3964/"},{path:"/02.科研/03.我的工作/10.hybrid.html",redirect:"/pages/8f3964/"},{name:"v-5913e204",path:"/pages/c06b1c/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-5913e204").then(t)}},{path:"/pages/c06b1c/index.html",redirect:"/pages/c06b1c/"},{path:"/02.科研/03.我的工作/01.one.html",redirect:"/pages/c06b1c/"},{name:"v-8f96befe",path:"/pages/a2edb6/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-8f96befe").then(t)}},{path:"/pages/a2edb6/index.html",redirect:"/pages/a2edb6/"},{path:"/02.科研/03.我的工作/15.实验.html",redirect:"/pages/a2edb6/"},{name:"v-70073a00",path:"/pages/03900a/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-70073a00").then(t)}},{path:"/pages/03900a/index.html",redirect:"/pages/03900a/"},{path:"/02.科研/03.我的工作/30.two.html",redirect:"/pages/03900a/"},{name:"v-140f256d",path:"/pages/0c2f17/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-140f256d").then(t)}},{path:"/pages/0c2f17/index.html",redirect:"/pages/0c2f17/"},{path:"/02.科研/03.我的工作/03.实现流程.html",redirect:"/pages/0c2f17/"},{name:"v-37fa14fa",path:"/pages/f12e80/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-37fa14fa").then(t)}},{path:"/pages/f12e80/index.html",redirect:"/pages/f12e80/"},{path:"/02.科研/03.我的工作/20.EC.html",redirect:"/pages/f12e80/"},{name:"v-e8e0160c",path:"/pages/bcf6cd/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-e8e0160c").then(t)}},{path:"/pages/bcf6cd/index.html",redirect:"/pages/bcf6cd/"},{path:"/02.科研/03.我的工作/32.keyfram2.html",redirect:"/pages/bcf6cd/"},{name:"v-d5f92e9a",path:"/pages/0a2951/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-d5f92e9a").then(t)}},{path:"/pages/0a2951/index.html",redirect:"/pages/0a2951/"},{path:"/02.科研/03.我的工作/35.colmap增量.html",redirect:"/pages/0a2951/"},{name:"v-2ff99942",path:"/pages/a0d165/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-2ff99942").then(t)}},{path:"/pages/a0d165/index.html",redirect:"/pages/a0d165/"},{path:"/02.科研/03.我的工作/36.keyframe3.html",redirect:"/pages/a0d165/"},{name:"v-4055a79c",path:"/pages/7cc66a/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-4055a79c").then(t)}},{path:"/pages/7cc66a/index.html",redirect:"/pages/7cc66a/"},{path:"/03.生活/05.遥远的救世主.html",redirect:"/pages/7cc66a/"},{name:"v-0545b0a1",path:"/pages/149c7c/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-0545b0a1").then(t)}},{path:"/pages/149c7c/index.html",redirect:"/pages/149c7c/"},{path:"/02.科研/03.我的工作/38.苦难.html",redirect:"/pages/149c7c/"},{name:"v-8263629e",path:"/pages/db78e2/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-8263629e").then(t)}},{path:"/pages/db78e2/index.html",redirect:"/pages/db78e2/"},{path:"/03.生活/01.随笔.html",redirect:"/pages/db78e2/"},{name:"v-012dc53d",path:"/pages/76e940/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-012dc53d").then(t)}},{path:"/pages/76e940/index.html",redirect:"/pages/76e940/"},{path:"/03.生活/06.game.html",redirect:"/pages/76e940/"},{name:"v-095f08a6",path:"/pages/f5ba2a/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-095f08a6").then(t)}},{path:"/pages/f5ba2a/index.html",redirect:"/pages/f5ba2a/"},{path:"/03.生活/07.程序员的打怪升级.html",redirect:"/pages/f5ba2a/"},{name:"v-5fc224a0",path:"/pages/c8b13e/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-5fc224a0").then(t)}},{path:"/pages/c8b13e/index.html",redirect:"/pages/c8b13e/"},{path:"/02.科研/03.我的工作/66.sci.html",redirect:"/pages/c8b13e/"},{name:"v-373c2e99",path:"/pages/4dc62f/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-373c2e99").then(t)}},{path:"/pages/4dc62f/index.html",redirect:"/pages/4dc62f/"},{path:"/03.生活/09.爱情观变迁.html",redirect:"/pages/4dc62f/"},{name:"v-78f813a7",path:"/pages/c1356f/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-78f813a7").then(t)}},{path:"/pages/c1356f/index.html",redirect:"/pages/c1356f/"},{path:"/03.生活/08.技术人的求职指南.html",redirect:"/pages/c1356f/"},{name:"v-a2a48808",path:"/archives/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-a2a48808").then(t)}},{path:"/archives/index.html",redirect:"/archives/"},{path:"/@pages/archivesPage.html",redirect:"/archives/"},{name:"v-05363355",path:"/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-05363355").then(t)}},{path:"/index.html",redirect:"/"},{name:"v-7887f0dc",path:"/pages/a7f8a5/",component:_l,beforeEnter:(n,e,t)=>{ds("Layout","v-7887f0dc").then(t)}},{path:"/pages/a7f8a5/index.html",redirect:"/pages/a7f8a5/"},{path:"/03.生活/02.软挑比赛.html",redirect:"/pages/a7f8a5/"},{path:"*",component:_l}],El={title:"北冥无鱼",description:"一个基于VuePress的 知识管理&博客 主题",base:"/",headTags:[["link",{rel:"icon",href:"/img/tiger.png"}],["meta",{name:"keywords",content:"vuepress,theme,blog,vdoing"}],["meta",{name:"theme-color",content:"#11a8cd"}],["meta",{name:"referrer",content:"no-referrer-when-downgrade"}]],pages:[{title:"Java集合框架",frontmatter:{title:"Java集合框架",date:"2023-02-23T20:13:30.000Z",permalink:"/pages/8e69ed/"},regularPath:"/01.Java/01.Java%E5%9F%BA%E7%A1%80/01.Java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6.html",relativePath:"01.Java/01.Java基础/01.Java集合框架.md",key:"v-3a75d5b2",path:"/pages/8e69ed/",headers:[{level:3,title:"Collection集合中常见的Api",slug:"collection集合中常见的api",normalizedTitle:"collection集合中常见的api",charIndex:2},{level:4,title:"增：",slug:"增",normalizedTitle:"增：",charIndex:27},{level:4,title:"删：",slug:"删",normalizedTitle:"删：",charIndex:194},{level:4,title:"改：",slug:"改",normalizedTitle:"改：",charIndex:295},{level:4,title:"查：",slug:"查",normalizedTitle:"查：",charIndex:320},{level:4,title:"对集合整体的操作：",slug:"对集合整体的操作",normalizedTitle:"对集合整体的操作：",charIndex:436},{level:3,title:"List",slug:"list",normalizedTitle:"list",charIndex:541},{level:4,title:"与LinkedList的区别",slug:"与linkedlist的区别",normalizedTitle:"与linkedlist的区别",charIndex:551},{level:4,title:"与Vector的区别",slug:"与vector的区别",normalizedTitle:"与vector的区别",charIndex:1049},{level:3,title:"Queue & Deque",slug:"queue-deque",normalizedTitle:"queue &amp; deque",charIndex:null},{level:4,title:"Queue",slug:"queue",normalizedTitle:"queue",charIndex:1154},{level:4,title:"Deque",slug:"deque",normalizedTitle:"deque",charIndex:1162},{level:4,title:"实现类",slug:"实现类",normalizedTitle:"实现类",charIndex:1905},{level:4,title:"Stack",slug:"stack",normalizedTitle:"stack",charIndex:2346},{level:3,title:"Set",slug:"set",normalizedTitle:"set",charIndex:2468},{level:3,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:2823}],headersStr:"Collection集合中常见的Api 增： 删： 改： 查： 对集合整体的操作： List 与LinkedList的区别 与Vector的区别 Queue & Deque Queue Deque 实现类 Stack Set 总结",content:"# Collection集合中常见的Api\n\n\n\n# 增：\n\n * 方法传入的数据类型必须是 Object，所以当写入基本数据类型的时候，会做自动装箱 auto-boxing 和自动拆箱 unboxing。\n\nboolean add(E e);\n\n\n * 把另一个集合里的元素加到此集合中。\n\nboolean addAll(Collection<? extends E> c);\n\n\n# 删：\n\n * 删除的指定元素。\n\nboolean remove(Object o);\n\n\n * 删除集合B中的所有元素\n\nboolean removeAll(Collection<?> c);\n\n\n# 改：\n\n * 没有改, 可以用删和增来实现\n\n# 查：\n\n * 查集合中是否有某个特定的元素\n\nboolean contains(Object o);\n\n\n * 查集合 A 是否包含了集合 B：\n\nboolean containsAll(Collection<?> c);\n\n\n# 对集合整体的操作：\n\n * 判断集合是否为空\n\nboolean isEmpty();\n\n\n * 集合的大小\n\nint size();\n\n\n * 集合转成数组\n\nObject[] toArray();\n\n\n\n# List\n\n\n\n# 与LinkedList的区别\n\n> An ordered collection (also known as a sequence).\n> \n> Unlike sets, lists typically allow duplicate elements.\n\nList 的实现方式有LinkedList 和 ArrayList，一个链表一个数组，没什么好说的。\n\n功能   方法                    ARRAYLIST   LINKEDLIST\n增    add(E e)              O(1)        O(1)\n增    add(int index, E e)   O(n)        O(n)\n删    remove(int index)     O(n)        O(n)\n删    remove(E e)           O(1)        O(n)\n改    set(int index, E e)   O(1)        O(n)\n查    get(int index)        O(1)        O(n)\n\n# 与Vector的区别\n\nVector 中许多方法加了synchronized关键字，同步了，但效率低。\n\n> 线程安全区别\n> \n> 扩容区别\n\nArrayList扩容1.5倍，Vector扩容2倍。\n\n\n# Queue & Deque\n\n * Queue是单向队列； Deque是双向队列。\n\n# Queue\n\n功能   抛异常         返回值\n增    add(e)      offer(e)\n删    remove()    poll()\n瞧    element()   peek()\n\n为什么会抛异常呢？\n\n * 比如队列空了，那 remove() 就会抛异常，但是 poll() 就返回 null；element() 就会抛异常，而 peek() 就返回 null 就好了。\n\n那 add(e) 怎么会抛异常呢？\n\n有些 Queue 它会有容量的限制，比如 BlockingQueue，那如果已经达到了它最大的容量且不会扩容的，就会抛异常；但如果 offer(e)，就会 return false.\n\n那怎么选择呢？：\n\n * 首先，要用就用同一组 API，前后要统一；\n * 其次，根据需求。如果你需要它抛异常，那就是用抛异常的；不过做算法题时基本不用，所以选那组返回特殊值的就好了。\n\n# Deque\n\n功能   抛异常                           返回值\n增    addFirst(e)/ addLast(e)       offerFirst(e)/ offerLast(e)\n删    removeFirst()/ removeLast()   pollFirst()/ pollLast()\n瞧    getFirst()/ getLast()         peekFirst()/ peekLast()\n\n使用时同理，要用就用同一组。\n\nQueue 和 Deque 的这些 API 都是 O(1) 的时间复杂度，准确来说是均摊时间复杂度。\n\n# 实现类\n\n\n\n * 如果想实现「普通队列 - 先进先出」的语义，就使用 LinkedList 或者 ArrayDeque 来实现；\n * 如果想实现「优先队列」的语义，就使用 PriorityQueue；\n * 如果想实现「栈」的语义，就使用 ArrayDeque。\n\n在实现普通队列时，如何选择用LinkedList还是ArrayDeque呢？\n\n\n\nLinkedList还是ArrayDeque区别\n\n>  1. ArrayDeque 是一个可扩容的数组，LinkedList 是链表结构；\n>  2. ArrayDeque 里不可以存 null 值，但是 LinkedList 可以；\n>  3. ArrayDeque 在操作头尾端的增删操作时更高效，但是 LinkedList 只有在当要移除中间某个元素且已经找到了这个元素后的移除才是 O(1) 的；\n>  4. ArrayDeque 在内存使用方面更高效。\n\n非必要存null值时，推荐使用ArrayDeque。\n\n# Stack\n\n虽然Java有这个Stack类，官方文档说不让用了！因为Vector已经弃用，而Stack是继承它的。\n\n用ArrayDeque吧\n\nDeque<Integer> stack = new ArrayDeque<>();\n\n\n\n# Set\n\n\n\nSet 的常用实现类有三个：\n\nHashSet: 采用 Hashmap 的 key 来储存元素，主要特点是无序的，基本操作都是 O(1) 的时间复杂度，很快。\n\nLinkedHashSet: 这个是一个 HashSet + LinkedList 的结构，特点就是既拥有了 O(1) 的时间复杂度，又能够保留插入的顺序。\n\nTreeSet: 采用红黑树结构，特点是可以有序，可以用自然排序或者自定义比较器来排序；缺点就是查询速度没有 HashSet 快。\n\n那每个 Set 的底层实现其实就是对应的 Map：\n\n数值放在 map 中的 key 上，value 上放了个 PRESENT，是一个静态的 Object，相当于 place holder，每个 key 都指向这个 object。\n\n\n# 总结\n\n",normalizedContent:"# collection集合中常见的api\n\n\n\n# 增：\n\n * 方法传入的数据类型必须是 object，所以当写入基本数据类型的时候，会做自动装箱 auto-boxing 和自动拆箱 unboxing。\n\nboolean add(e e);\n\n\n * 把另一个集合里的元素加到此集合中。\n\nboolean addall(collection<? extends e> c);\n\n\n# 删：\n\n * 删除的指定元素。\n\nboolean remove(object o);\n\n\n * 删除集合b中的所有元素\n\nboolean removeall(collection<?> c);\n\n\n# 改：\n\n * 没有改, 可以用删和增来实现\n\n# 查：\n\n * 查集合中是否有某个特定的元素\n\nboolean contains(object o);\n\n\n * 查集合 a 是否包含了集合 b：\n\nboolean containsall(collection<?> c);\n\n\n# 对集合整体的操作：\n\n * 判断集合是否为空\n\nboolean isempty();\n\n\n * 集合的大小\n\nint size();\n\n\n * 集合转成数组\n\nobject[] toarray();\n\n\n\n# list\n\n\n\n# 与linkedlist的区别\n\n> an ordered collection (also known as a sequence).\n> \n> unlike sets, lists typically allow duplicate elements.\n\nlist 的实现方式有linkedlist 和 arraylist，一个链表一个数组，没什么好说的。\n\n功能   方法                    arraylist   linkedlist\n增    add(e e)              o(1)        o(1)\n增    add(int index, e e)   o(n)        o(n)\n删    remove(int index)     o(n)        o(n)\n删    remove(e e)           o(1)        o(n)\n改    set(int index, e e)   o(1)        o(n)\n查    get(int index)        o(1)        o(n)\n\n# 与vector的区别\n\nvector 中许多方法加了synchronized关键字，同步了，但效率低。\n\n> 线程安全区别\n> \n> 扩容区别\n\narraylist扩容1.5倍，vector扩容2倍。\n\n\n# queue & deque\n\n * queue是单向队列； deque是双向队列。\n\n# queue\n\n功能   抛异常         返回值\n增    add(e)      offer(e)\n删    remove()    poll()\n瞧    element()   peek()\n\n为什么会抛异常呢？\n\n * 比如队列空了，那 remove() 就会抛异常，但是 poll() 就返回 null；element() 就会抛异常，而 peek() 就返回 null 就好了。\n\n那 add(e) 怎么会抛异常呢？\n\n有些 queue 它会有容量的限制，比如 blockingqueue，那如果已经达到了它最大的容量且不会扩容的，就会抛异常；但如果 offer(e)，就会 return false.\n\n那怎么选择呢？：\n\n * 首先，要用就用同一组 api，前后要统一；\n * 其次，根据需求。如果你需要它抛异常，那就是用抛异常的；不过做算法题时基本不用，所以选那组返回特殊值的就好了。\n\n# deque\n\n功能   抛异常                           返回值\n增    addfirst(e)/ addlast(e)       offerfirst(e)/ offerlast(e)\n删    removefirst()/ removelast()   pollfirst()/ polllast()\n瞧    getfirst()/ getlast()         peekfirst()/ peeklast()\n\n使用时同理，要用就用同一组。\n\nqueue 和 deque 的这些 api 都是 o(1) 的时间复杂度，准确来说是均摊时间复杂度。\n\n# 实现类\n\n\n\n * 如果想实现「普通队列 - 先进先出」的语义，就使用 linkedlist 或者 arraydeque 来实现；\n * 如果想实现「优先队列」的语义，就使用 priorityqueue；\n * 如果想实现「栈」的语义，就使用 arraydeque。\n\n在实现普通队列时，如何选择用linkedlist还是arraydeque呢？\n\n\n\nlinkedlist还是arraydeque区别\n\n>  1. arraydeque 是一个可扩容的数组，linkedlist 是链表结构；\n>  2. arraydeque 里不可以存 null 值，但是 linkedlist 可以；\n>  3. arraydeque 在操作头尾端的增删操作时更高效，但是 linkedlist 只有在当要移除中间某个元素且已经找到了这个元素后的移除才是 o(1) 的；\n>  4. arraydeque 在内存使用方面更高效。\n\n非必要存null值时，推荐使用arraydeque。\n\n# stack\n\n虽然java有这个stack类，官方文档说不让用了！因为vector已经弃用，而stack是继承它的。\n\n用arraydeque吧\n\ndeque<integer> stack = new arraydeque<>();\n\n\n\n# set\n\n\n\nset 的常用实现类有三个：\n\nhashset: 采用 hashmap 的 key 来储存元素，主要特点是无序的，基本操作都是 o(1) 的时间复杂度，很快。\n\nlinkedhashset: 这个是一个 hashset + linkedlist 的结构，特点就是既拥有了 o(1) 的时间复杂度，又能够保留插入的顺序。\n\ntreeset: 采用红黑树结构，特点是可以有序，可以用自然排序或者自定义比较器来排序；缺点就是查询速度没有 hashset 快。\n\n那每个 set 的底层实现其实就是对应的 map：\n\n数值放在 map 中的 key 上，value 上放了个 present，是一个静态的 object，相当于 place holder，每个 key 都指向这个 object。\n\n\n# 总结\n\n",charsets:{cjk:!0}},{title:"Hashmap",frontmatter:{title:"Hashmap",date:"2023-02-24T10:40:58.000Z",permalink:"/pages/ce6e6c/"},regularPath:"/01.Java/01.Java%E5%9F%BA%E7%A1%80/02.HashMap.html",relativePath:"01.Java/01.Java基础/02.HashMap.md",key:"v-66629ea2",path:"/pages/ce6e6c/",headers:[{level:3,title:"底层数据结构",slug:"底层数据结构",normalizedTitle:"底层数据结构",charIndex:2},{level:3,title:"插入节点",slug:"插入节点",normalizedTitle:"插入节点",charIndex:174},{level:4,title:"扩容",slug:"扩容",normalizedTitle:"扩容",charIndex:210},{level:4,title:"头插法",slug:"头插法",normalizedTitle:"头插法",charIndex:189},{level:3,title:"重写equal 方法但不重写 hashcode方法",slug:"重写equal-方法但不重写-hashcode方法",normalizedTitle:"重写equal 方法但不重写 hashcode方法",charIndex:465}],headersStr:"底层数据结构 插入节点 扩容 头插法 重写equal 方法但不重写 hashcode方法",content:"# 底层数据结构\n\n * 由数组和链表组合构成的数据结构\n\n\n\nstatic class Node<K, V> implements Map.Entry<K, V>{\n    final int hash;\n    final K key;\n    V value;\n    Node<K,V> next;\n    \n    ...\n}\n\n\n\n# 插入节点\n\njava8 之前是头插法； java8之后是尾插法。\n\n# 扩容\n\n * Capacity：HashMap当前长度。\n\n * LoadFactor：负载因子，默认值0.75f。\n\n * 扩容：创建一个新的Entry空数组，长度是原数组的2倍。\n\n * ReHash：遍历原Entry数组，把所有的Entry重新Hash到新数组。\n\n扩容后每个key Hash到的index不一致，所以需要重新Hash。\n\n# 头插法\n\n在多线程中会导致循环链表。\n\n插入一个元素需要进行扩容时，当一个线程完成扩容，另一个线程将节点添加到新数组时就会产生指向问题，导致循环指向。\n\n\n# 重写equal 方法但不重写 hashcode方法\n\n保证两个前提\n\n>  1. 如果两个对象相同（即用equals比较返回true），那么它们的hashCode值一定要相同；\n>  2. 如果两个对象的hashCode相同，它们并不一定相同(即用equals比较返回false) 。\n\n如果重写了equal方法，使得两个对象相同，但是hashcode不同，这时将他们插入到不重复集合Map或者Set中，就会插入成功，与预期不符。",normalizedContent:"# 底层数据结构\n\n * 由数组和链表组合构成的数据结构\n\n\n\nstatic class node<k, v> implements map.entry<k, v>{\n    final int hash;\n    final k key;\n    v value;\n    node<k,v> next;\n    \n    ...\n}\n\n\n\n# 插入节点\n\njava8 之前是头插法； java8之后是尾插法。\n\n# 扩容\n\n * capacity：hashmap当前长度。\n\n * loadfactor：负载因子，默认值0.75f。\n\n * 扩容：创建一个新的entry空数组，长度是原数组的2倍。\n\n * rehash：遍历原entry数组，把所有的entry重新hash到新数组。\n\n扩容后每个key hash到的index不一致，所以需要重新hash。\n\n# 头插法\n\n在多线程中会导致循环链表。\n\n插入一个元素需要进行扩容时，当一个线程完成扩容，另一个线程将节点添加到新数组时就会产生指向问题，导致循环指向。\n\n\n# 重写equal 方法但不重写 hashcode方法\n\n保证两个前提\n\n>  1. 如果两个对象相同（即用equals比较返回true），那么它们的hashcode值一定要相同；\n>  2. 如果两个对象的hashcode相同，它们并不一定相同(即用equals比较返回false) 。\n\n如果重写了equal方法，使得两个对象相同，但是hashcode不同，这时将他们插入到不重复集合map或者set中，就会插入成功，与预期不符。",charsets:{cjk:!0}},{title:"Java常用api",frontmatter:{title:"Java常用api",date:"2023-03-09T12:40:18.000Z",permalink:"/pages/672ba8/"},regularPath:"/01.Java/01.Java%E5%9F%BA%E7%A1%80/03.Java%E5%88%B7%E9%A2%98.html",relativePath:"01.Java/01.Java基础/03.Java刷题.md",key:"v-4445b44e",path:"/pages/672ba8/",headers:[{level:3,title:"Class HashMap",slug:"class-hashmap-t1-t2",normalizedTitle:"class hashmap",charIndex:2},{level:3,title:"Class Stack",slug:"class-stack",normalizedTitle:"class stack",charIndex:739},{level:3,title:"Class PriorityQueue",slug:"class-priorityqueue",normalizedTitle:"class priorityqueue",charIndex:902},{level:3,title:"Interface Queue",slug:"interface-queue",normalizedTitle:"interface queue",charIndex:1038},{level:3,title:"Class ArrayDeque",slug:"class-arraydeque",normalizedTitle:"class arraydeque",charIndex:1100}],headersStr:"Class HashMap Class Stack Class PriorityQueue Interface Queue Class ArrayDeque",content:'# Class HashMap<T1, T2>\n\n// 创建HashMap对象\nHashMap<K, V> map = new HashMap<K, V>();\n\n// 添加键值对\nmap.put(key, value);\n\n// 获取键对应的值\nV value = map.get(key);\n\n// 移除键值对\nmap.remove(key);\n\n// 判断是否包含某个键\nboolean containsKey = map.containsKey(key);\n\n// 判断是否包含某个值\nboolean containsValue = map.containsValue(value);\n\n获取HashMap中键值对的数量\nint size = map.size();\n\n// 替换value，返回旧value\nV value = map.replace(key,value);\n\n// 清空HashMap\nmap.clear();\n\n// 遍历所有的键\nfor (K key : map.keySet()) {\n    System.out.println(key);\n}\n\n// 遍历所有的值\nfor (V value : map.values()) {\n    System.out.println(value);\n}\n\n// 遍历所有的键值对\nfor (Map.Entry<K, V> entry : map.entrySet()) {\n    K key = entry.getKey();\n    V value = entry.getValue();\n    System.out.println(key + ":" + value);\n}\n\n\n\n\n\n\n# Class Stack\n\nStack<Integer> stack = new Stack<>();  \npublic void push(E e);  \npublic E pop();  \npublic int size();  \npublic E peek();\npublic boolean empty();\n\n\n\n# Class PriorityQueue\n\nPriorityQueue(Comparator<? super E> comparator);\npublic boolean offer(E e);\npublic E peek();\npublic E poll();\n\n\n\n# Interface Queue\n\nboolean offer(E e);\nE poll();\nE peek();\n\n\n\n# Class ArrayDeque\n\nboolean offerFirst(E e);\nboolean\tofferLast(E e);\nE\tpollFirst();\nE\tpollLast();\nE\tpeekFirst()\nE\tpeekLast()\nint\tsize();\nboolean\tisEmpty();\n',normalizedContent:'# class hashmap<t1, t2>\n\n// 创建hashmap对象\nhashmap<k, v> map = new hashmap<k, v>();\n\n// 添加键值对\nmap.put(key, value);\n\n// 获取键对应的值\nv value = map.get(key);\n\n// 移除键值对\nmap.remove(key);\n\n// 判断是否包含某个键\nboolean containskey = map.containskey(key);\n\n// 判断是否包含某个值\nboolean containsvalue = map.containsvalue(value);\n\n获取hashmap中键值对的数量\nint size = map.size();\n\n// 替换value，返回旧value\nv value = map.replace(key,value);\n\n// 清空hashmap\nmap.clear();\n\n// 遍历所有的键\nfor (k key : map.keyset()) {\n    system.out.println(key);\n}\n\n// 遍历所有的值\nfor (v value : map.values()) {\n    system.out.println(value);\n}\n\n// 遍历所有的键值对\nfor (map.entry<k, v> entry : map.entryset()) {\n    k key = entry.getkey();\n    v value = entry.getvalue();\n    system.out.println(key + ":" + value);\n}\n\n\n\n\n\n\n# class stack\n\nstack<integer> stack = new stack<>();  \npublic void push(e e);  \npublic e pop();  \npublic int size();  \npublic e peek();\npublic boolean empty();\n\n\n\n# class priorityqueue\n\npriorityqueue(comparator<? super e> comparator);\npublic boolean offer(e e);\npublic e peek();\npublic e poll();\n\n\n\n# interface queue\n\nboolean offer(e e);\ne poll();\ne peek();\n\n\n\n# class arraydeque\n\nboolean offerfirst(e e);\nboolean\tofferlast(e e);\ne\tpollfirst();\ne\tpolllast();\ne\tpeekfirst()\ne\tpeeklast()\nint\tsize();\nboolean\tisempty();\n',charsets:{cjk:!0}},{title:"线程池",frontmatter:{title:"线程池",date:"2023-03-30T09:29:48.000Z",permalink:"/pages/d47d28/"},regularPath:"/01.Java/01.Java%E5%9F%BA%E7%A1%80/06.%E7%BA%BF%E7%A8%8B%E6%B1%A0.html",relativePath:"01.Java/01.Java基础/06.线程池.md",key:"v-4751e44c",path:"/pages/d47d28/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:3,title:"线程池是什么",slug:"线程池是什么",normalizedTitle:"线程池是什么",charIndex:9},{level:3,title:"线程池解决的问题是什么",slug:"线程池解决的问题是什么",normalizedTitle:"线程池解决的问题是什么",charIndex:353},{level:2,title:"线程池的核心设计与实现",slug:"线程池的核心设计与实现",normalizedTitle:"线程池的核心设计与实现",charIndex:652},{level:3,title:"JDK1.8中主要的类图",slug:"jdk1-8中主要的类图",normalizedTitle:"jdk1.8中主要的类图",charIndex:668},{level:3,title:"生命周期管理",slug:"生命周期管理",normalizedTitle:"生命周期管理",charIndex:1122},{level:3,title:"任务执行机制",slug:"任务执行机制",normalizedTitle:"任务执行机制",charIndex:1637},{level:4,title:"任务调度",slug:"任务调度",normalizedTitle:"任务调度",charIndex:1647},{level:4,title:"任务缓冲",slug:"任务缓冲",normalizedTitle:"任务缓冲",charIndex:1657},{level:4,title:"任务申请",slug:"任务申请",normalizedTitle:"任务申请",charIndex:1838},{level:4,title:"任务拒绝",slug:"任务拒绝",normalizedTitle:"任务拒绝",charIndex:1928},{level:3,title:"Worker线程管理",slug:"worker线程管理",normalizedTitle:"worker线程管理",charIndex:2422},{level:4,title:"Worker线程",slug:"worker线程",normalizedTitle:"worker线程",charIndex:2422},{level:4,title:"Worker线程增加",slug:"worker线程增加",normalizedTitle:"worker线程增加",charIndex:3068},{level:4,title:"Worker线程回收",slug:"worker线程回收",normalizedTitle:"worker线程回收",charIndex:3158},{level:4,title:"Worker线程执行任务",slug:"worker线程执行任务",normalizedTitle:"worker线程执行任务",charIndex:3292},{level:2,title:"线程池在业务中的实践",slug:"线程池在业务中的实践",normalizedTitle:"线程池在业务中的实践",charIndex:3311},{level:3,title:"场景1：快速响应用户请求",slug:"场景1-快速响应用户请求",normalizedTitle:"场景1：快速响应用户请求",charIndex:3326},{level:3,title:"场景2：快速处理批量任务",slug:"场景2-快速处理批量任务",normalizedTitle:"场景2：快速处理批量任务",charIndex:3427},{level:3,title:"实际问题及方案思考",slug:"实际问题及方案思考",normalizedTitle:"实际问题及方案思考",charIndex:3554}],headersStr:"前言 线程池是什么 线程池解决的问题是什么 线程池的核心设计与实现 JDK1.8中主要的类图 生命周期管理 任务执行机制 任务调度 任务缓冲 任务申请 任务拒绝 Worker线程管理 Worker线程 Worker线程增加 Worker线程回收 Worker线程执行任务 线程池在业务中的实践 场景1：快速响应用户请求 场景2：快速处理批量任务 实际问题及方案思考",content:"# 前言\n\n\n# 线程池是什么\n\n线程池（Thread Pool）是一种基于池化思想管理线程的工具，经常出现在多线程服务器中，如MySQL。\n\n使用线程池可以带来一系列好处：\n\n * 降低资源消耗：通过池化技术重复利用已创建的线程，降低线程创建和销毁造成的损耗。\n * 提高响应速度：任务到达时，无需等待线程创建即可立即执行。\n * 提高线程的可管理性：线程是稀缺资源，如果无限制创建，不仅会消耗系统资源，还会因为线程的不合理分布导致资源调度失衡，降低系统的稳定性。使用线程池可以进行统一的分配、调优和监控。\n * 提供更多更强大的功能：线程池具备可拓展性，允许开发人员向其中增加更多的功能。比如延时定时线程池ScheduledThreadPoolExecutor，就允许任务延期执行或定期执行。\n\n\n# 线程池解决的问题是什么\n\n 1. 频繁申请/销毁资源和调度资源，将带来额外的消耗，可能会非常巨大。\n 2. 对资源无限申请缺少抑制手段，易引发系统资源耗尽的风险。\n 3. 系统无法合理管理内部的资源分布，会降低系统的稳定性。\n\n除去线程池，还有其他比较典型的几种使用策略包括：\n\n 1. 内存池(Memory Pooling)：预先申请内存，提升申请内存速度，减少内存碎片。\n 2. 连接池(Connection Pooling)：预先申请数据库连接，提升申请连接的速度，降低系统的开销。\n 3. 实例池(Object Pooling)：循环使用对象，减少资源在初始化和释放时的昂贵损耗。\n\n\n# 线程池的核心设计与实现\n\n\n# JDK1.8中主要的类图\n\n\n\n顶层接口Executor提供了一种思想：将任务提交和任务执行进行解耦。用户无需关注如何创建线程，如何调度线程来执行任务，用户只需提供Runnable对象，将任务的运行逻辑提交到执行器(Executor)中，由Executor框架完成线程的调配和任务的执行部分。\n\nExecutorService是一个接口，扩展了Executor接口，定义了一些方法，例如submit()、shutdown()、shutdownNow()等，用于管理和控制线程池中的任务。\n\nAbstractExecutorService是一个抽象类，实现了ExecutorService接口中的大部分方法，但留下了一些抽象方法供子类实现。它提供了一些默认的行为，例如如何处理被拒绝的任务等。\n\n最下层的实现类ThreadPoolExecutor实现最复杂的运行部分，ThreadPoolExecutor将会一方面维护自身的生命周期，另一方面同时管理线程和任务，使两者良好的结合从而执行并行任务。\n\n\n\n\n# 生命周期管理\n\n线程池内部使用一个变量维护两个值：运行状态（runState）和线程数量（workerCount）。\n\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n\n\n高3位保存runState，低29位保存workerCount，两个变量之间互不干扰。用一个变量去存储两个值，可避免在做相关决策时，出现不一致的情况，不必为了维护两者的一致，而占用锁资源。\n\nThreadPoolExecutor的运行状态有5种，分别为：\n\n运行状态         状态描述\nRUNNING      能接受新提交的任务，并且也能处理阻塞队列中的任务\nSHUTDOWN     关闭状态，不在接受新提交的任务，但可以继续处理阻塞队列中已保存的任务\nSTOP         不能接收新任务，也不处理队列中的任务，会中断正在处理任务的线程\nTIDYING      所有的任务都已终止，workerCount(有效线程数)为0\nTERMINATED   在terminated()方法执行完后进入该状态\n\n其生命周期转换如下入所示：\n\n\n\n\n# 任务执行机制\n\n# 任务调度\n\n\n\n# 任务缓冲\n\n阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。\n\n\n\n# 任务申请\n\n任务的执行有两种可能：\n\n * 任务直接由新创建的线程执行。\n * 线程从任务队列中获取任务然后执行，执行完任务的空闲线程会再次去从队列中申请任务再去执行。\n\n\n\n# 任务拒绝\n\n任务拒绝模块是线程池的保护部分，线程池有一个最大的容量，当线程池的任务缓存队列已满，并且线程池中的线程数目达到maximumPoolSize时，就需要拒绝掉该任务，采取任务拒绝策略，保护线程池。\n\n可以实现这个接口定制拒绝策略\n\npublic interface RejectedExecutionHandler {\n    void rejectedExecution(Runnable r, ThreadPoolExecutor executor);\n}\n\n\nJDK中提供了四种拒绝策略\n\n 1. AbortPolicy：默认的拒绝策略，当线程池无法处理新的任务时，直接抛出RejectedExecutionException异常。\n 2. CallerRunsPolicy：当线程池无法处理新的任务时，将任务返回给调用者，由调用者线程执行。\n 3. DiscardPolicy：当线程池无法处理新的任务时，直接丢弃该任务，不做任何处理。\n 4. DiscardOldestPolicy：当线程池无法处理新的任务时，丢弃队列中最老的任务，然后将新的任务加入队列。\n\n\n# Worker线程管理\n\n# Worker线程\n\nprivate final class Worker extends AbstractQueuedSynchronizer implements Runnable{\n    final Thread thread;//Worker持有的线程\n    Runnable firstTask;//初始化的任务，可以为null\n}\n\n\n线程池需要管理线程的生命周期，需要在线程长时间不运行的时候进行回收。线程池使用一张Hash表去持有线程的引用，这样可以通过添加引用、移除引用这样的操作来控制线程的生命周期。\n\n这个时候重要的就是如何判断线程是否在运行。\n\nWorker是通过继承AQS，使用AQS来实现独占锁这个功能。没有使用可重入锁ReentrantLock，而是使用AQS，为的就是实现不可重入的特性去反应线程现在的执行状态。\n\n 1. lock方法一旦获取了独占锁，表示当前线程正在执行任务中。\n\n 2. 如果正在执行任务，则不应该中断线程。\n\n 3. 如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断。\n\n 4. 线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态；如果线程是空闲状态则可以安全回收。\n\n# Worker线程增加\n\n增加线程是通过线程池中的addWorker方法，这个分配线程的策略是在上个步骤完成的，该步骤仅仅完成增加线程，并使它运行，最后返回是否成功这个结果。\n\n# Worker线程回收\n\nWorker被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务。当Worker无法获取到任务，也就是获取的任务为空时，循环会结束，Worker会主动消除自身在线程池内的引用。\n\n\n\n# Worker线程执行任务\n\n\n\n\n# 线程池在业务中的实践\n\n\n# 场景1：快速响应用户请求\n\n用户发起的实时请求，服务追求响应时间。比如说用户要查看一个商品的信息，那么我们需要将商品维度的一系列信息如商品的价格、优惠、库存、图片等等聚合起来，展示给用户。\n\n\n\n\n# 场景2：快速处理批量任务\n\n离线的大量计算任务，需要快速执行。比如说，统计某个报表，需要计算出全国各个门店中有哪些商品有某种属性，用于后续营销策略的分析，那么我们需要查询全国所有门店中的所有商品，并且记录具有某属性的商品，然后快速生成报表。\n\n\n\n\n# 实际问题及方案思考",normalizedContent:"# 前言\n\n\n# 线程池是什么\n\n线程池（thread pool）是一种基于池化思想管理线程的工具，经常出现在多线程服务器中，如mysql。\n\n使用线程池可以带来一系列好处：\n\n * 降低资源消耗：通过池化技术重复利用已创建的线程，降低线程创建和销毁造成的损耗。\n * 提高响应速度：任务到达时，无需等待线程创建即可立即执行。\n * 提高线程的可管理性：线程是稀缺资源，如果无限制创建，不仅会消耗系统资源，还会因为线程的不合理分布导致资源调度失衡，降低系统的稳定性。使用线程池可以进行统一的分配、调优和监控。\n * 提供更多更强大的功能：线程池具备可拓展性，允许开发人员向其中增加更多的功能。比如延时定时线程池scheduledthreadpoolexecutor，就允许任务延期执行或定期执行。\n\n\n# 线程池解决的问题是什么\n\n 1. 频繁申请/销毁资源和调度资源，将带来额外的消耗，可能会非常巨大。\n 2. 对资源无限申请缺少抑制手段，易引发系统资源耗尽的风险。\n 3. 系统无法合理管理内部的资源分布，会降低系统的稳定性。\n\n除去线程池，还有其他比较典型的几种使用策略包括：\n\n 1. 内存池(memory pooling)：预先申请内存，提升申请内存速度，减少内存碎片。\n 2. 连接池(connection pooling)：预先申请数据库连接，提升申请连接的速度，降低系统的开销。\n 3. 实例池(object pooling)：循环使用对象，减少资源在初始化和释放时的昂贵损耗。\n\n\n# 线程池的核心设计与实现\n\n\n# jdk1.8中主要的类图\n\n\n\n顶层接口executor提供了一种思想：将任务提交和任务执行进行解耦。用户无需关注如何创建线程，如何调度线程来执行任务，用户只需提供runnable对象，将任务的运行逻辑提交到执行器(executor)中，由executor框架完成线程的调配和任务的执行部分。\n\nexecutorservice是一个接口，扩展了executor接口，定义了一些方法，例如submit()、shutdown()、shutdownnow()等，用于管理和控制线程池中的任务。\n\nabstractexecutorservice是一个抽象类，实现了executorservice接口中的大部分方法，但留下了一些抽象方法供子类实现。它提供了一些默认的行为，例如如何处理被拒绝的任务等。\n\n最下层的实现类threadpoolexecutor实现最复杂的运行部分，threadpoolexecutor将会一方面维护自身的生命周期，另一方面同时管理线程和任务，使两者良好的结合从而执行并行任务。\n\n\n\n\n# 生命周期管理\n\n线程池内部使用一个变量维护两个值：运行状态（runstate）和线程数量（workercount）。\n\nprivate final atomicinteger ctl = new atomicinteger(ctlof(running, 0));\n\n\n高3位保存runstate，低29位保存workercount，两个变量之间互不干扰。用一个变量去存储两个值，可避免在做相关决策时，出现不一致的情况，不必为了维护两者的一致，而占用锁资源。\n\nthreadpoolexecutor的运行状态有5种，分别为：\n\n运行状态         状态描述\nrunning      能接受新提交的任务，并且也能处理阻塞队列中的任务\nshutdown     关闭状态，不在接受新提交的任务，但可以继续处理阻塞队列中已保存的任务\nstop         不能接收新任务，也不处理队列中的任务，会中断正在处理任务的线程\ntidying      所有的任务都已终止，workercount(有效线程数)为0\nterminated   在terminated()方法执行完后进入该状态\n\n其生命周期转换如下入所示：\n\n\n\n\n# 任务执行机制\n\n# 任务调度\n\n\n\n# 任务缓冲\n\n阻塞队列(blockingqueue)是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。\n\n\n\n# 任务申请\n\n任务的执行有两种可能：\n\n * 任务直接由新创建的线程执行。\n * 线程从任务队列中获取任务然后执行，执行完任务的空闲线程会再次去从队列中申请任务再去执行。\n\n\n\n# 任务拒绝\n\n任务拒绝模块是线程池的保护部分，线程池有一个最大的容量，当线程池的任务缓存队列已满，并且线程池中的线程数目达到maximumpoolsize时，就需要拒绝掉该任务，采取任务拒绝策略，保护线程池。\n\n可以实现这个接口定制拒绝策略\n\npublic interface rejectedexecutionhandler {\n    void rejectedexecution(runnable r, threadpoolexecutor executor);\n}\n\n\njdk中提供了四种拒绝策略\n\n 1. abortpolicy：默认的拒绝策略，当线程池无法处理新的任务时，直接抛出rejectedexecutionexception异常。\n 2. callerrunspolicy：当线程池无法处理新的任务时，将任务返回给调用者，由调用者线程执行。\n 3. discardpolicy：当线程池无法处理新的任务时，直接丢弃该任务，不做任何处理。\n 4. discardoldestpolicy：当线程池无法处理新的任务时，丢弃队列中最老的任务，然后将新的任务加入队列。\n\n\n# worker线程管理\n\n# worker线程\n\nprivate final class worker extends abstractqueuedsynchronizer implements runnable{\n    final thread thread;//worker持有的线程\n    runnable firsttask;//初始化的任务，可以为null\n}\n\n\n线程池需要管理线程的生命周期，需要在线程长时间不运行的时候进行回收。线程池使用一张hash表去持有线程的引用，这样可以通过添加引用、移除引用这样的操作来控制线程的生命周期。\n\n这个时候重要的就是如何判断线程是否在运行。\n\nworker是通过继承aqs，使用aqs来实现独占锁这个功能。没有使用可重入锁reentrantlock，而是使用aqs，为的就是实现不可重入的特性去反应线程现在的执行状态。\n\n 1. lock方法一旦获取了独占锁，表示当前线程正在执行任务中。\n\n 2. 如果正在执行任务，则不应该中断线程。\n\n 3. 如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断。\n\n 4. 线程池在执行shutdown方法或tryterminate方法时会调用interruptidleworkers方法来中断空闲的线程，interruptidleworkers方法会使用trylock方法来判断线程池中的线程是否是空闲状态；如果线程是空闲状态则可以安全回收。\n\n# worker线程增加\n\n增加线程是通过线程池中的addworker方法，这个分配线程的策略是在上个步骤完成的，该步骤仅仅完成增加线程，并使它运行，最后返回是否成功这个结果。\n\n# worker线程回收\n\nworker被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务。当worker无法获取到任务，也就是获取的任务为空时，循环会结束，worker会主动消除自身在线程池内的引用。\n\n\n\n# worker线程执行任务\n\n\n\n\n# 线程池在业务中的实践\n\n\n# 场景1：快速响应用户请求\n\n用户发起的实时请求，服务追求响应时间。比如说用户要查看一个商品的信息，那么我们需要将商品维度的一系列信息如商品的价格、优惠、库存、图片等等聚合起来，展示给用户。\n\n\n\n\n# 场景2：快速处理批量任务\n\n离线的大量计算任务，需要快速执行。比如说，统计某个报表，需要计算出全国各个门店中有哪些商品有某种属性，用于后续营销策略的分析，那么我们需要查询全国所有门店中的所有商品，并且记录具有某属性的商品，然后快速生成报表。\n\n\n\n\n# 实际问题及方案思考",charsets:{cjk:!0}},{title:"简历",frontmatter:{title:"简历",date:"2023-03-02T21:08:29.000Z",permalink:"/pages/3edc81/"},regularPath:"/01.Java/01.Java%E5%9F%BA%E7%A1%80/%E7%AE%80%E5%8E%86.html",relativePath:"01.Java/01.Java基础/简历.md",key:"v-1984cd25",path:"/pages/3edc81/",headers:[{level:2,title:"竞赛经历",slug:"竞赛经历",normalizedTitle:"竞赛经历",charIndex:343},{level:4,title:"2022 “中国光谷·华为杯” 第十九届中国研究生数学建模竞赛 二等奖",slug:"_2022-中国光谷·华为杯-第十九届中国研究生数学建模竞赛-二等奖",normalizedTitle:"2022 “中国光谷·华为杯” 第十九届中国研究生数学建模竞赛 二等奖",charIndex:361},{level:4,title:"2023 华为软件精英挑战赛 粤港澳赛区 二等奖",slug:"_2023-华为软件精英挑战赛-粤港澳赛区-二等奖",normalizedTitle:"2023 华为软件精英挑战赛 粤港澳赛区 二等奖",charIndex:410},{level:2,title:"专业技能",slug:"专业技能",normalizedTitle:"专业技能",charIndex:454},{level:2,title:"项目经历",slug:"项目经历",normalizedTitle:"项目经历",charIndex:941},{level:3,title:"番茄自习室项目  (2022.11-至今)",slug:"番茄自习室项目-2022-11-至今",normalizedTitle:"番茄自习室项目  (2022.11-至今)",charIndex:null},{level:3,title:"Linux统计使用时间项目（2022.07-2022.09）",slug:"linux统计使用时间项目-2022-07-2022-09",normalizedTitle:"linux统计使用时间项目（2022.07-2022.09）",charIndex:1651},{level:3,title:"基于Java实现Raft共识算法（2023.03-2023-06）",slug:"基于java实现raft共识算法-2023-03-2023-06",normalizedTitle:"基于java实现raft共识算法（2023.03-2023-06）",charIndex:2246}],headersStr:"竞赛经历 2022 “中国光谷·华为杯” 第十九届中国研究生数学建模竞赛 二等奖 2023 华为软件精英挑战赛 粤港澳赛区 二等奖 专业技能 项目经历 番茄自习室项目  (2022.11-至今) Linux统计使用时间项目（2022.07-2022.09） 基于Java实现Raft共识算法（2023.03-2023-06）",content:" * * 李泽辉 - 后端开发\n     \n     男/1999/24岁           https://sleeplzh.top\n     15534447783          https://github.com/lzxiaohuihui\n     q895827938@163.com   \n     \n     ## 教育背景\n     \n     :::left 西安电子科技大学 - 计算机技术(211) - 硕士 :::\n     \n     2021.09 - 至今\n     \n     :::left 太原理工大学 - 信息与计算科学(211) - 学士 :::\n     \n     2017.09-2021.06\n     \n     \n     # 竞赛经历\n     \n     # 2022 “中国光谷·华为杯” 第十九届中国研究生数学建模竞赛 二等奖\n     \n     # 2023 华为软件精英挑战赛 粤港澳赛区 二等奖\n     \n     \n     # 专业技能\n     \n     * 熟悉进程、内存管理，TCP/IP协议栈，熟悉二进制数据表示、指令系统，熟练数据结构与算法、设计模式；\n     * 熟悉Java编程语言，类加载、JVM内存模型、垃圾回收G1收集器，了解Java并发编程技术；\n     * 熟练MySQL，熟悉事务、索引和日志，熟悉Redis数据类型，了解Redis持久化机制、过期键的删除策略；\n     * 熟练使用SpringBoot、Spring、Mybatis等常用框架，熟悉Spring IOC、AOP、自动配置；\n     * 熟悉RocketMQ和Kafka消息中间件、Spring Security认证授权，了解Spring Cloud Alibaba、Docker容器；\n     * 熟悉InfluxDB、MongoDB、Elasticsearch、RocksDB数据库使用，了解分布式事务、分布式锁；\n     * 熟练使用Linux操作系统、主流开发工具，熟悉HTML、CSS、JavaScript、Vue、Python爬虫。\n     \n     \n     \n     # 项目经历\n     \n     \n     # 番茄自习室项目 (2022.11-至今)\n     \n     * 项目描述： 该项目灵感来源于番茄todo App。该项目基于项目一实现了时间统计、分析、自习室排行榜、打卡、留言、点赞、登录注册等功能。主要使用了Spring Boot、MyBatis-Plus、MySQL、Redis、Kafka、InfluxDB、Spring Security和Jwt令牌等。\n     \n     * 主要工作：\n       \n       * 完成认证授权部分，将登录成功的用户信息和权限存放在Jwt令牌，以及页面对用户权限进行控制；\n       * 进行统一的异常处理，使用Spring AOP面向切面的思想统一的记录日志；\n       * 使用Redis优化项目中对热点数据(验证码、点赞、关注、打卡、用户数据等)的访问，提高数据的存取效率；\n       * 使用Kafka作为消息队列，在用户被点赞，评论，关注后，以系统通知的方式推送给用户；\n     \n     * 项目优化与收获：\n       \n       * 使用缓存和消息队列实现点赞和关注，并且使用重试队列保证写缓存和写消息队列一致，QPS从90/sec 提升到4000/sec；\n       \n       * 使用Redis BitMap存储每个用户的打卡情况，使用Zset实现自习室时长排行榜，后台定时线程池持久化打卡信息以及更新Zset分数；\n       \n       * 了解了InfluxDB底层存储原理，以及时序数据的存储优势。\n     \n     \n     \n     # Linux统计使用时间项目（2022.07-2022.09）\n     \n     * 项目描述：\n       \n       可以在Linux平台统计各软件使用时间的开源项目，灵感来源于手机中的屏幕使用时间，未来支持其它平台。实现了查看某一个时间端各天、各小时、各软件使用时间，以及IDEA和VS Code各项目打开时间，浏览器各网站浏览时间。主要使用了Spring Boot、MyBatis-Plus、SQLite、Caffeine、Netty、Vue和Echarts等。\n     \n     * 主要工作：\n       \n       * 使用Python监听焦点窗口变化，使用Netty IO多路复用以及生产者消费者机制提高数据接收的能力；\n       \n       * 从历史记录表中提炼出汇总表，提高历史数据查询能力，数据量是原表的1/20；\n       \n       * 使用本地缓存Caffeine提高查询效率，使用定时线程池保证数据一致性；\n     \n     * 项目优化：\n       \n       * 压缩需要缓存的数据，优化后一天的数据量仅占5.12KB内存;\n       * 仅从缓存中查询数据，使用异步方式更新缓存数据，对比SQLite查询方式从20 QPS提升到3w QPS。\n         \n     \n     \n     # 基于Java实现Raft共识算法（2023.03-2023-06）\n     \n     * 项目描述：\n       \n       要将上述项目扩展为微服务项目，必不可少会遇到分布式一致性，事务，锁等问题。本项目实现了领导者选举和日志复制模块，可解决上述问题。主要使用了SOFA-Bolt作为Rpc通信，RocksDB作为日志存储。\n     \n     * 主要工作：\n       \n       * 按照Raft论文描述，实现领导者选举模块和日志复制模块；\n       * 每个节点使用定时线程池执行心跳任务和选举任务，执行任务时，使用普通线程池模拟并行发送Rpc请求，使用CountDownLatch同步，进而判断所有回复中是否超过一半节点回复成功；\n       * 每个节点使用两份日志实现日志预写和日志提交，当日志复制过程超过一半节点回复成功则正式提交。\n     \n     * 项目优化： - 领导者在向跟随者并行复制日志的同时将日志写入自己的磁盘，对于客户端写请求响应时间从12ms降低到8ms。",normalizedContent:" * * 李泽辉 - 后端开发\n     \n     男/1999/24岁           https://sleeplzh.top\n     15534447783          https://github.com/lzxiaohuihui\n     q895827938@163.com   \n     \n     ## 教育背景\n     \n     :::left 西安电子科技大学 - 计算机技术(211) - 硕士 :::\n     \n     2021.09 - 至今\n     \n     :::left 太原理工大学 - 信息与计算科学(211) - 学士 :::\n     \n     2017.09-2021.06\n     \n     \n     # 竞赛经历\n     \n     # 2022 “中国光谷·华为杯” 第十九届中国研究生数学建模竞赛 二等奖\n     \n     # 2023 华为软件精英挑战赛 粤港澳赛区 二等奖\n     \n     \n     # 专业技能\n     \n     * 熟悉进程、内存管理，tcp/ip协议栈，熟悉二进制数据表示、指令系统，熟练数据结构与算法、设计模式；\n     * 熟悉java编程语言，类加载、jvm内存模型、垃圾回收g1收集器，了解java并发编程技术；\n     * 熟练mysql，熟悉事务、索引和日志，熟悉redis数据类型，了解redis持久化机制、过期键的删除策略；\n     * 熟练使用springboot、spring、mybatis等常用框架，熟悉spring ioc、aop、自动配置；\n     * 熟悉rocketmq和kafka消息中间件、spring security认证授权，了解spring cloud alibaba、docker容器；\n     * 熟悉influxdb、mongodb、elasticsearch、rocksdb数据库使用，了解分布式事务、分布式锁；\n     * 熟练使用linux操作系统、主流开发工具，熟悉html、css、javascript、vue、python爬虫。\n     \n     \n     \n     # 项目经历\n     \n     \n     # 番茄自习室项目 (2022.11-至今)\n     \n     * 项目描述： 该项目灵感来源于番茄todo app。该项目基于项目一实现了时间统计、分析、自习室排行榜、打卡、留言、点赞、登录注册等功能。主要使用了spring boot、mybatis-plus、mysql、redis、kafka、influxdb、spring security和jwt令牌等。\n     \n     * 主要工作：\n       \n       * 完成认证授权部分，将登录成功的用户信息和权限存放在jwt令牌，以及页面对用户权限进行控制；\n       * 进行统一的异常处理，使用spring aop面向切面的思想统一的记录日志；\n       * 使用redis优化项目中对热点数据(验证码、点赞、关注、打卡、用户数据等)的访问，提高数据的存取效率；\n       * 使用kafka作为消息队列，在用户被点赞，评论，关注后，以系统通知的方式推送给用户；\n     \n     * 项目优化与收获：\n       \n       * 使用缓存和消息队列实现点赞和关注，并且使用重试队列保证写缓存和写消息队列一致，qps从90/sec 提升到4000/sec；\n       \n       * 使用redis bitmap存储每个用户的打卡情况，使用zset实现自习室时长排行榜，后台定时线程池持久化打卡信息以及更新zset分数；\n       \n       * 了解了influxdb底层存储原理，以及时序数据的存储优势。\n     \n     \n     \n     # linux统计使用时间项目（2022.07-2022.09）\n     \n     * 项目描述：\n       \n       可以在linux平台统计各软件使用时间的开源项目，灵感来源于手机中的屏幕使用时间，未来支持其它平台。实现了查看某一个时间端各天、各小时、各软件使用时间，以及idea和vs code各项目打开时间，浏览器各网站浏览时间。主要使用了spring boot、mybatis-plus、sqlite、caffeine、netty、vue和echarts等。\n     \n     * 主要工作：\n       \n       * 使用python监听焦点窗口变化，使用netty io多路复用以及生产者消费者机制提高数据接收的能力；\n       \n       * 从历史记录表中提炼出汇总表，提高历史数据查询能力，数据量是原表的1/20；\n       \n       * 使用本地缓存caffeine提高查询效率，使用定时线程池保证数据一致性；\n     \n     * 项目优化：\n       \n       * 压缩需要缓存的数据，优化后一天的数据量仅占5.12kb内存;\n       * 仅从缓存中查询数据，使用异步方式更新缓存数据，对比sqlite查询方式从20 qps提升到3w qps。\n         \n     \n     \n     # 基于java实现raft共识算法（2023.03-2023-06）\n     \n     * 项目描述：\n       \n       要将上述项目扩展为微服务项目，必不可少会遇到分布式一致性，事务，锁等问题。本项目实现了领导者选举和日志复制模块，可解决上述问题。主要使用了sofa-bolt作为rpc通信，rocksdb作为日志存储。\n     \n     * 主要工作：\n       \n       * 按照raft论文描述，实现领导者选举模块和日志复制模块；\n       * 每个节点使用定时线程池执行心跳任务和选举任务，执行任务时，使用普通线程池模拟并行发送rpc请求，使用countdownlatch同步，进而判断所有回复中是否超过一半节点回复成功；\n       * 每个节点使用两份日志实现日志预写和日志提交，当日志复制过程超过一半节点回复成功则正式提交。\n     \n     * 项目优化： - 领导者在向跟随者并行复制日志的同时将日志写入自己的磁盘，对于客户端写请求响应时间从12ms降低到8ms。",charsets:{cjk:!0}},{title:"消息队列",frontmatter:{title:"消息队列",date:"2023-02-27T09:38:16.000Z",permalink:"/pages/9749fb/"},regularPath:"/01.Java/02.%E4%B8%AD%E9%97%B4%E4%BB%B6/00.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.html",relativePath:"01.Java/02.中间件/00.消息队列.md",key:"v-d2301728",path:"/pages/9749fb/",headers:[{level:2,title:"异步",slug:"异步",normalizedTitle:"异步",charIndex:14},{level:2,title:"解耦",slug:"解耦",normalizedTitle:"解耦",charIndex:20},{level:2,title:"削峰",slug:"削峰",normalizedTitle:"削峰",charIndex:17},{level:2,title:"缺点",slug:"缺点",normalizedTitle:"缺点",charIndex:392},{level:3,title:"系统复杂性",slug:"系统复杂性",normalizedTitle:"系统复杂性",charIndex:399},{level:3,title:"数据一致性",slug:"数据一致性",normalizedTitle:"数据一致性",charIndex:459},{level:3,title:"可用性",slug:"可用性",normalizedTitle:"可用性",charIndex:581}],headersStr:"异步 解耦 削峰 缺点 系统复杂性 数据一致性 可用性",content:"使用消息队列的三个经典场景，异步，削峰，解耦。\n\n\n# 异步\n\n就比如下单业务，对于用户而言，流程很短，下完单就完成。但是对于系统后端来说，可能流程，执行链路很长。导致用户就会存在着偏差，明明这么简单一个事情，系统给我反应这么慢。\n\n\n\n可以将业务拆分开，将一些没有顺序的流程同时做，也就是异步操作。\n\n\n\n\n# 解耦\n\n既然是将这些流程同时做，但是不能采用多线程来做。这么多业务要调用这么多接口，全部写在一块出现问题了也不好后期维护，流程中某一点出问题，又会影响到其它独立的点。\n\n用了消息队列，耦合这个问题就迎刃而解了。\n\n\n\n下单完成了，就把支付成功的消息告诉别的系统取处理，他们收到了去处理就好了。后面要接入什么系统，只需要监听这个消息即可。\n\n\n# 削峰\n\n把请求放到队列里面，然后至于每秒消费多少请求，就看自己的服务器处理能力，可能会慢一点，但不至于服务器挂了。\n\n\n# 缺点\n\n\n# 系统复杂性\n\n本来一个简单系统好好的，现在弄了一个中间件，还要维护它，消息重复消费、消息丢失、消息的顺序消费。\n\n\n# 数据一致性\n\n下单服务自己保证自己的逻辑成果处理了，成果发送了消息，但是其它系服务，成不成功得不到保证，所有服务都成功才算一次下单成功。\n\n分布式事务：把下单，优惠券，积分。。。都放在一个事务里面一样，要成功一起成功，要失败一起失败。\n\n\n# 可用性\n\n中间件毕竟是第三方软件，这个进程有可能挂了的风险。",normalizedContent:"使用消息队列的三个经典场景，异步，削峰，解耦。\n\n\n# 异步\n\n就比如下单业务，对于用户而言，流程很短，下完单就完成。但是对于系统后端来说，可能流程，执行链路很长。导致用户就会存在着偏差，明明这么简单一个事情，系统给我反应这么慢。\n\n\n\n可以将业务拆分开，将一些没有顺序的流程同时做，也就是异步操作。\n\n\n\n\n# 解耦\n\n既然是将这些流程同时做，但是不能采用多线程来做。这么多业务要调用这么多接口，全部写在一块出现问题了也不好后期维护，流程中某一点出问题，又会影响到其它独立的点。\n\n用了消息队列，耦合这个问题就迎刃而解了。\n\n\n\n下单完成了，就把支付成功的消息告诉别的系统取处理，他们收到了去处理就好了。后面要接入什么系统，只需要监听这个消息即可。\n\n\n# 削峰\n\n把请求放到队列里面，然后至于每秒消费多少请求，就看自己的服务器处理能力，可能会慢一点，但不至于服务器挂了。\n\n\n# 缺点\n\n\n# 系统复杂性\n\n本来一个简单系统好好的，现在弄了一个中间件，还要维护它，消息重复消费、消息丢失、消息的顺序消费。\n\n\n# 数据一致性\n\n下单服务自己保证自己的逻辑成果处理了，成果发送了消息，但是其它系服务，成不成功得不到保证，所有服务都成功才算一次下单成功。\n\n分布式事务：把下单，优惠券，积分。。。都放在一个事务里面一样，要成功一起成功，要失败一起失败。\n\n\n# 可用性\n\n中间件毕竟是第三方软件，这个进程有可能挂了的风险。",charsets:{cjk:!0}},{title:"ZooKeeper",frontmatter:{title:"ZooKeeper",date:"2023-02-27T08:52:28.000Z",permalink:"/pages/467ce0/"},regularPath:"/01.Java/02.%E4%B8%AD%E9%97%B4%E4%BB%B6/01.ZooKeeper.html",relativePath:"01.Java/02.中间件/01.ZooKeeper.md",key:"v-b1cae4ee",path:"/pages/467ce0/",headers:[{level:2,title:"ZoopKeeper用来干什么",slug:"zoopkeeper用来干什么",normalizedTitle:"zoopkeeper用来干什么",charIndex:2},{level:2,title:"ZoopKeeper是什么",slug:"zoopkeeper是什么",normalizedTitle:"zoopkeeper是什么",charIndex:198},{level:2,title:"监听器",slug:"监听器",normalizedTitle:"监听器",charIndex:414},{level:2,title:"统一配置管理",slug:"统一配置管理",normalizedTitle:"统一配置管理",charIndex:57},{level:2,title:"统一命名服务",slug:"统一命名服务",normalizedTitle:"统一命名服务",charIndex:64},{level:2,title:"分布式锁",slug:"分布式锁",normalizedTitle:"分布式锁",charIndex:71},{level:2,title:"集群状态",slug:"集群状态",normalizedTitle:"集群状态",charIndex:850}],headersStr:"ZoopKeeper用来干什么 ZoopKeeper是什么 监听器 统一配置管理 统一命名服务 分布式锁 集群状态",content:"# ZoopKeeper用来干什么\n\n * ZooKeeper主要服务于分布式系统，可以用ZooKeeper来做：统一配置管理、统一命名服务、分布式锁、集群管理。\n * 使用分布式系统就无法避免对节点管理的问题(需要实时感知节点的状态、对节点进行统一管理等等)，而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper作为一个能够通用解决这些问题的中间件就应运而生了。\n\n\n# ZoopKeeper是什么\n\n * ZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗树，每个节点叫做ZNode。每一个节点可以通过路径来标识，结构图如下：\n\n\n\nZnode中有两种类型的节点\n\n * 短暂/临时(Ephemeral)：当客户端和服务端断开连接后，所创建的Znode(节点)会自动删除\n * 持久(Persistent)：当客户端和服务端断开连接后，所创建的Znode(节点)不会删除\n\n\n# 监听器\n\n * 监听Znode节点的数据变化\n * 监听子节点的增减变化\n\n\n# 统一配置管理\n\n将配置文件common.yml放在ZooKeeper的Znode节点中，然后系统监听这个节点有无变更，及时响应。\n\n\n\n\n# 统一命名服务\n\n * 统一命名服务的理解其实跟域名一样，是我们为这某一部分的资源给它取一个名字，别人通过这个名字就可以拿到对应的资源\n\n\n\n\n# 分布式锁\n\n\n\n访问的时候会创建带顺序号的临时/短暂(EPHEMERAL_SEQUENTIAL)节点，比如，系统A创建了id_000000节点，系统B创建了id_000002节点，系统C创建了id_000001节点。\n\n\n\n接着，拿到/locks节点下的所有子节点(id_000000,id_000001,id_000002)，判断自己创建的是不是最小的那个节点\n\n * 如果是，则拿到锁。\n\n * * 释放锁：执行完操作后，把创建的节点给删掉\n\n * 如果不是，则监听比自己要小1的节点变化\n\n\n# 集群状态\n\n\n\n只要系统A挂了，那/groupMember/A这个节点就会删除，通过监听groupMember下的子节点，系统B和C就能够感知到系统A已经挂了。(新增也是同理)\n\n除了能够感知节点的上下线变化，ZooKeeper还可以实现动态选举Master的功能。(如果集群是主从架构模式下)\n\n原理也很简单，如果想要实现动态选举Master的功能，Znode节点的类型是带顺序号的临时节点(EPHEMERAL_SEQUENTIAL)就好了。\n\n * Zookeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的Znode节点就会删除。然后让新的最小编号作为Master，这样就可以实现动态选举的功能了。",normalizedContent:"# zoopkeeper用来干什么\n\n * zookeeper主要服务于分布式系统，可以用zookeeper来做：统一配置管理、统一命名服务、分布式锁、集群管理。\n * 使用分布式系统就无法避免对节点管理的问题(需要实时感知节点的状态、对节点进行统一管理等等)，而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，zookeeper作为一个能够通用解决这些问题的中间件就应运而生了。\n\n\n# zoopkeeper是什么\n\n * zookeeper的数据结构，跟unix文件系统非常类似，可以看做是一颗树，每个节点叫做znode。每一个节点可以通过路径来标识，结构图如下：\n\n\n\nznode中有两种类型的节点\n\n * 短暂/临时(ephemeral)：当客户端和服务端断开连接后，所创建的znode(节点)会自动删除\n * 持久(persistent)：当客户端和服务端断开连接后，所创建的znode(节点)不会删除\n\n\n# 监听器\n\n * 监听znode节点的数据变化\n * 监听子节点的增减变化\n\n\n# 统一配置管理\n\n将配置文件common.yml放在zookeeper的znode节点中，然后系统监听这个节点有无变更，及时响应。\n\n\n\n\n# 统一命名服务\n\n * 统一命名服务的理解其实跟域名一样，是我们为这某一部分的资源给它取一个名字，别人通过这个名字就可以拿到对应的资源\n\n\n\n\n# 分布式锁\n\n\n\n访问的时候会创建带顺序号的临时/短暂(ephemeral_sequential)节点，比如，系统a创建了id_000000节点，系统b创建了id_000002节点，系统c创建了id_000001节点。\n\n\n\n接着，拿到/locks节点下的所有子节点(id_000000,id_000001,id_000002)，判断自己创建的是不是最小的那个节点\n\n * 如果是，则拿到锁。\n\n * * 释放锁：执行完操作后，把创建的节点给删掉\n\n * 如果不是，则监听比自己要小1的节点变化\n\n\n# 集群状态\n\n\n\n只要系统a挂了，那/groupmember/a这个节点就会删除，通过监听groupmember下的子节点，系统b和c就能够感知到系统a已经挂了。(新增也是同理)\n\n除了能够感知节点的上下线变化，zookeeper还可以实现动态选举master的功能。(如果集群是主从架构模式下)\n\n原理也很简单，如果想要实现动态选举master的功能，znode节点的类型是带顺序号的临时节点(ephemeral_sequential)就好了。\n\n * zookeeper会每次选举最小编号的作为master，如果master挂了，自然对应的znode节点就会删除。然后让新的最小编号作为master，这样就可以实现动态选举的功能了。",charsets:{cjk:!0}},{title:"流操作",frontmatter:{title:"流操作",date:"2023-03-13T19:33:58.000Z",permalink:"/pages/4b289e/"},regularPath:"/01.Java/01.Java%E5%9F%BA%E7%A1%80/05.%E6%B5%81%E6%93%8D%E4%BD%9C.html",relativePath:"01.Java/01.Java基础/05.流操作.md",key:"v-8f05bed0",path:"/pages/4b289e/",headers:[{level:2,title:"流操作示例",slug:"流操作示例",normalizedTitle:"流操作示例",charIndex:2}],headersStr:"流操作示例",content:"# 流操作示例\n\n以下是一个使用Java 8的List流操作示例：\n\n假设我们有一个包含整数的List，我们可以使用以下流操作：\n\n 1. 过滤操作：筛选出所有大于10的数字\n\nList<Integer> numbers = Arrays.asList(1, 5, 10, 15, 20, 25);\nList<Integer> filteredNumbers = numbers.stream()\n                                        .filter(n -> n > 10)\n                                        .collect(Collectors.toList());\n\n\n 2. 映射操作：将每个数字都乘以2\n\nList<Integer> numbers = Arrays.asList(1, 5, 10, 15, 20, 25);\nList<Integer> mappedNumbers = numbers.stream()\n                                        .map(n -> n * 2)\n                                        .collect(Collectors.toList());\n\n\n 3. 排序操作：按降序排列数字\n\nList<Integer> numbers = Arrays.asList(1, 5, 10, 15, 20, 25);\nList<Integer> sortedNumbers = numbers.stream()\n                                        .sorted(Comparator.reverseOrder())\n                                        .collect(Collectors.toList());\n\n\n 4. 统计操作：获取数字的总和\n\nList<Integer> numbers = Arrays.asList(1, 5, 10, 15, 20, 25);\nint sum = numbers.stream()\n                    .mapToInt(Integer::intValue)\n                    .sum(); \n\n\n 5. 匹配操作：检查是否所有数字都大于10\n\nList<Integer> numbers = Arrays.asList(1, 5, 10, 15, 20, 25);\nboolean allGreaterThanTen = numbers.stream()\n                                        .allMatch(n -> n > 10);\n\n\n 6. 查找操作：查找第一个大于10的数字\n\nList<Integer> numbers = Arrays.asList(1, 5, 10, 15, 20, 25);\nOptional<Integer> firstGreaterThanTen = numbers.stream()\n                                                    .filter(n -> n > 10)\n                                                    .findFirst(); \n\n\n 7. 归约操作：计算数字的乘积\n\nList<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);\nint product = numbers.stream()\n                        .reduce(1, (a, b) -> a * b); \n\n\n这些示例展示了如何使用Java 8的List流操作进行常见的数据处理任务。",normalizedContent:"# 流操作示例\n\n以下是一个使用java 8的list流操作示例：\n\n假设我们有一个包含整数的list，我们可以使用以下流操作：\n\n 1. 过滤操作：筛选出所有大于10的数字\n\nlist<integer> numbers = arrays.aslist(1, 5, 10, 15, 20, 25);\nlist<integer> filterednumbers = numbers.stream()\n                                        .filter(n -> n > 10)\n                                        .collect(collectors.tolist());\n\n\n 2. 映射操作：将每个数字都乘以2\n\nlist<integer> numbers = arrays.aslist(1, 5, 10, 15, 20, 25);\nlist<integer> mappednumbers = numbers.stream()\n                                        .map(n -> n * 2)\n                                        .collect(collectors.tolist());\n\n\n 3. 排序操作：按降序排列数字\n\nlist<integer> numbers = arrays.aslist(1, 5, 10, 15, 20, 25);\nlist<integer> sortednumbers = numbers.stream()\n                                        .sorted(comparator.reverseorder())\n                                        .collect(collectors.tolist());\n\n\n 4. 统计操作：获取数字的总和\n\nlist<integer> numbers = arrays.aslist(1, 5, 10, 15, 20, 25);\nint sum = numbers.stream()\n                    .maptoint(integer::intvalue)\n                    .sum(); \n\n\n 5. 匹配操作：检查是否所有数字都大于10\n\nlist<integer> numbers = arrays.aslist(1, 5, 10, 15, 20, 25);\nboolean allgreaterthanten = numbers.stream()\n                                        .allmatch(n -> n > 10);\n\n\n 6. 查找操作：查找第一个大于10的数字\n\nlist<integer> numbers = arrays.aslist(1, 5, 10, 15, 20, 25);\noptional<integer> firstgreaterthanten = numbers.stream()\n                                                    .filter(n -> n > 10)\n                                                    .findfirst(); \n\n\n 7. 归约操作：计算数字的乘积\n\nlist<integer> numbers = arrays.aslist(1, 2, 3, 4, 5);\nint product = numbers.stream()\n                        .reduce(1, (a, b) -> a * b); \n\n\n这些示例展示了如何使用java 8的list流操作进行常见的数据处理任务。",charsets:{cjk:!0}},{title:"Kafka",frontmatter:{title:"Kafka",date:"2023-02-24T15:09:29.000Z",permalink:"/pages/11f4c8/"},regularPath:"/01.Java/02.%E4%B8%AD%E9%97%B4%E4%BB%B6/02.Kafka.html",relativePath:"01.Java/02.中间件/02.Kafka.md",key:"v-8d21212e",path:"/pages/11f4c8/",headers:[{level:2,title:"阻塞队列",slug:"阻塞队列",normalizedTitle:"阻塞队列",charIndex:2},{level:2,title:"Kafka入门",slug:"kafka入门",normalizedTitle:"kafka入门",charIndex:1276},{level:2,title:"Kafka为什么这么快",slug:"kafka为什么这么快",normalizedTitle:"kafka为什么这么快",charIndex:2126},{level:2,title:"夺命连环问",slug:"夺命连环问",normalizedTitle:"夺命连环问",charIndex:2893},{level:3,title:"说说你对Kafka的理解",slug:"说说你对kafka的理解",normalizedTitle:"说说你对kafka的理解",charIndex:2903},{level:3,title:"消息队列模型知道吗？kafka是怎么做到支持这两种模型的？",slug:"消息队列模型知道吗-kafka是怎么做到支持这两种模型的",normalizedTitle:"消息队列模型知道吗？kafka是怎么做到支持这两种模型的？",charIndex:3190},{level:3,title:"能说说kafka通信过程原理吗？",slug:"能说说kafka通信过程原理吗",normalizedTitle:"能说说kafka通信过程原理吗？",charIndex:3329},{level:3,title:"发送消息时如何选择分区的？",slug:"发送消息时如何选择分区的",normalizedTitle:"发送消息时如何选择分区的？",charIndex:3487},{level:3,title:"为什么需要分区？有什么好处？",slug:"为什么需要分区-有什么好处",normalizedTitle:"为什么需要分区？有什么好处？",charIndex:3861},{level:3,title:"详细说说消费者组和消费者重平衡？",slug:"详细说说消费者组和消费者重平衡",normalizedTitle:"详细说说消费者组和消费者重平衡？",charIndex:4007},{level:3,title:"分区分配策略？",slug:"分区分配策略",normalizedTitle:"分区分配策略？",charIndex:4189},{level:3,title:"消息传递语义剖析",slug:"消息传递语义剖析",normalizedTitle:"消息传递语义剖析",charIndex:4357},{level:3,title:"Kafka三次消息传递",slug:"kafka三次消息传递",normalizedTitle:"kafka三次消息传递",charIndex:5260},{level:3,title:"消息丢失场景",slug:"消息丢失场景",normalizedTitle:"消息丢失场景",charIndex:5499},{level:4,title:"Producer端",slug:"producer端",normalizedTitle:"producer端",charIndex:5509},{level:4,title:"Broker端",slug:"broker端",normalizedTitle:"broker端",charIndex:6150},{level:4,title:"Consumer端",slug:"consumer端",normalizedTitle:"consumer端",charIndex:6438},{level:4,title:"解决方案",slug:"解决方案",normalizedTitle:"解决方案",charIndex:7293}],headersStr:"阻塞队列 Kafka入门 Kafka为什么这么快 夺命连环问 说说你对Kafka的理解 消息队列模型知道吗？kafka是怎么做到支持这两种模型的？ 能说说kafka通信过程原理吗？ 发送消息时如何选择分区的？ 为什么需要分区？有什么好处？ 详细说说消费者组和消费者重平衡？ 分区分配策略？ 消息传递语义剖析 Kafka三次消息传递 消息丢失场景 Producer端 Broker端 Consumer端 解决方案",content:'# 阻塞队列\n\n\n\nBlockingQueue\n\n * 解决线程通信的问题\n * 阻塞方法：put、take\n\n生产者消费者模式\n\n * 生产者：产生数据的线程\n * 消费者：使用数据的线程\n\n实现类\n\n * ArrayBlockingQueue\n * LinkedBlockQueue\n * PriorityBlockingQueue，SynchronousQueue，DelayQueue等\n\n示例\n\n * 生产者线程\n\nclass Producer implements Runnable {\n    private BlockingQueue<Integer> queue;\n    public Producer(BlockingQueue<Integer> queue) {\n        this.queue = queue;\n    }\n\n    @Override\n    public void run() {\n        try {\n            for (int i = 0; i < 100; i++) {\n                Thread.sleep(20);\n                queue.put(i);\n                System.out.println(Thread.currentThread().getName() + "生产:" + queue.size());\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n}\n\n\n * 消费者线程\n\nclass Consumer implements Runnable {\n    private BlockingQueue<Integer> queue;\n    public Consumer(BlockingQueue<Integer> queue) {\n        this.queue = queue;\n    }\n\n    @Override\n    public void run() {\n        try {\n            while (true) {\n                Thread.sleep(new Random().nextInt(1000));\n                queue.take();\n                System.out.println(Thread.currentThread().getName() + "消费:" + queue.size());\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n\n\n结果\n\n\n\n\n# Kafka入门\n\n * Kafka是一个分布式的流媒体平台；\n * 应用：消息系统、日志收集、用户行为追踪、流失处理。\n\nKafka是一个消息队列，放里面放数据叫生产者，取数据叫消费者。\n\n\n\n一个消息中间件，队列不单单只有一个，然后给每个队列取个名字，叫topic。\n\n\n\n然后生产者，消费者就到指定的消息队列中存取数据就可以了。\n\n\n\n为了提高一个队列的吞吐量，Kafka会把topic分区\n\n\n\n实际上，生产者消费者是到指定topic，指定分区中存取数据\n\n\n\n一台Kafka服务器叫做Broker\n\n\n\n一个话题中的多个分区，可能存在不同的服务器上\n\n\n\nKafka将数据存放在不同的分区上，同时也会将分区备份，存在不同的broker上。备份分区只用做备份，不做读写。当某个broker挂了，那么就从其它broker中的分区作为主分区。\n\n\n\n消费者\n\n\n\n消费者可以有多个，形成一个消费者组。比如本来一个消费者要消费三个分区，那么可以通过一个消费者组，让三个消费者分别消费一个分区。\n\n * 使用消息队列不可能是单机的（必然是分布式or集群）\n\n * Kafka会将partition以消息日志的方式(落磁盘)存储起来，通过 顺序访问IO和缓存(等到一定的量或时间)才真正把数据写到磁盘上，来提高速度。\n\n * Kafka会将数据写到partition，单个partition的写入是有顺序的。如果要保证全局有序，那只能写入一个partition中。如果要消费也有序，消费者也只能有一个。\n\n * 凡是分布式就无法避免网络抖动/机器宕机等问题的发生，很有可能消费者A读取了数据，还没来得及消费，就挂掉了。Zookeeper发现消费者A挂了，让消费者B去消费原本消费者A的分区，等消费者A重连的时候，发现已经重复消费同一条数据了。(各种各样的情况，消费者超时等等都有可能…)\n   \n   如果业务上不允许重复消费的问题，最好消费者那端做业务上的校验（如果已经消费过了，就不消费了）\n\n\n# Kafka为什么这么快\n\n * 顺序写\n\n虽然说Kafka中的数据持久到到磁盘中，磁盘读写速度比不上内存读写速度。\n\n都知道完成一次磁盘io，需要经过寻道、旋转和读写数据。\n\n因为Kafka中某一个分区内的数据是有序的，队列FIFO，所以可以采用顺序写的方式进行持久化。\n\nKafka采用顺序写的方式，来省去寻道和旋转产生的时间，从而提高写入磁盘的速度。\n\n每一个分区（Partition）对应多个物理文件（Segment）。\n\n * 零拷贝\n\n消费者读取磁盘中的数据，使用传统的IO模型，需要拷贝四次\n\n\n\n零拷贝方式，减少用户态和内核态直接的切换\n\n\n\n * PageCache\n\n生产者生产消息到Broker时，先写入到page cache中，page cache存在内存当中，但不受jvm的GC管理，这样可以避免每次生产消费都需要磁盘io。\n\n\n\n * 网络模型\n\n采用基于池化思想，避免为每个连接创建线程，连接完成后将业务处理交给线程池处理。\n\n基于 IO 复用模型，多个连接共用同一个阻塞对象，不用等待所有的连接。\n\n * 批量与压缩\n\n生产者向Broker发送消息是按照批量来发送，假设带宽是10MB/s，那么发送一个10MB的消息比发送1MB的消息10次要快。\n\n多数情况下，系统的瓶颈不在磁盘IO，而是在网络IO。\n\n * 分区并发\n\nKafka的message是按topic分类存储的，topic中的数据又是按照一个一个的partition即分区存储到不同broker节点。\n\n每个partition对应了操作系统上的一个文件夹，partition实际上又是按照segment分段存储的。每次文件操作也是直接操作segment。\n\n为了进一步的查询优化，Kafka又默认为分段后的数据文件建立了索引文件。\n\n\n# 夺命连环问\n\n\n# 说说你对Kafka的理解\n\n> Kafka是一个流式数据处理平台，具有消息系统的能力，也有实时流式数据处理分析能能力，只是我们通常把它当做消息队列系统来用。\n> \n> 主要由三个方面组成，ZooKeeper、Kafka核心和存储。\n> \n> Kafka一般作为分布式系统来用，所以需要每个Kafka服务器启动时需要将自己注册到ZooKeeper中，由ZooKeeper来统一管理。\n> \n> 然后Kafka本身，有消息、话题、生产者、消费者、分片、Broker、组等等。\n> \n> 最后是存储方面，用来持久化存储Kafka的数据，都会以日志的形式最终存入到磁盘中。\n\n\n# 消息队列模型知道吗？kafka是怎么做到支持这两种模型的？\n\n> 点对点：消息只能被一个消费者消费，消费完后消息删除。\n> \n> 发布订阅：相当于广播模式，消息可以被所有消费者消费。\n> \n> 消费者组，由多个消费者组成，一个组内只会由一个消费者去消费一个分区的消息。\n\n\n# 能说说kafka通信过程原理吗？\n\n>  1. 首先Kafka Broker启动时，将自己注册到ZooKeeper中；\n>  2. 生产者根据配置的地址连接到指定的Broker，建立TCP连接；\n>  3. 发送消息；\n>  4. 消费者和协调者Broker创建TCP连接；\n>  5. 开始消费消息。\n\n\n\n\n# 发送消息时如何选择分区的？\n\n>  1. 轮询，按照顺序消息依次发送到不同的分区\n>  2. 随机，随机发送到某个分区\n> \n> 如果消息指定key，那么会根据消息的key进行hash，然后对partition分区数量取模，决定落在哪个分区上，所以，对于相同key的消息来说，总是会发送到同一个分区上，也是我们常说的消息分区有序性。\n> \n> 很常见的场景就是我们希望下单、支付消息有顺序，这样以订单ID作为key发送消息就达到了分区有序性的目的。\n> \n> 如果没有指定key，会执行默认的轮询负载均衡策略，比如第一条消息落在P0，第二条消息落在P1，然后第三条又在P1。\n> \n> 除此之外，对于一些特定的业务场景和需求，还可以通过实现Partitioner接口，重写configure和partition方法来达到自定义分区的效果。\n\n\n# 为什么需要分区？有什么好处？\n\n> 如果说不分区的话，我们发消息写数据都只能保存到一个节点上，这样的话就算这个服务器节点性能再好最终也支撑不住。\n> \n> 分区带来了负载均衡和横向扩展的能力。\n> \n> 发送消息时可以根据分区的数量存在不同的Broker上，提升了并发读写消息能力。\n\n\n# 详细说说消费者组和消费者重平衡？\n\n> 一般来说，消费者数量和所有主题分区的数量保持一致最好，消费者组可以让Kafka支持传统的两种消息队列模型。\n> \n> Kafka中有一个协调者来 完成分区的分配，而重平衡Rebalance就是指的有新消费者加入的情况，比如刚开始我们只有消费者A在消费消息，过了一段时间消费者B和C加入了，这时候分区就需要重新分配。\n\n\n# 分区分配策略？\n\n> Range\n> \n> 对同一个主题的分区，排序优先均匀分给前面的消费者，排在前面的消费者获得的消息 >= 后面的消费者。\n> \n> RoundRobin\n> \n> 轮询，按顺序以此分配给消费者。\n> \n> Sticky\n> \n> 之前这个分区 分给消费者，那么下次还是尽量分给他，避免频繁的销毁创建连接。\n\n\n# 消息传递语义剖析\n\n\n\n> 1）首先当 Producer 向 Broker 发送数据后，会进行 commit，如果commit成功，由于 Replica 副本机制的存在，则意味着消息不会丢失，但是 Producer 发送数据给 Broker 后，遇到网络问题而造成通信中断，那么 Producer 就无法准确判断该消息是否已经被提交（commit），这就可能造成 at least once 语义。\n> \n> 2）在 Kafka 0.11.0.0 之前， 如果 Producer 没有收到消息 commit 的响应结果，它只能重新发送消息，确保消息已经被正确的传输到 Broker，重新发送的时候会将消息再次写入日志中；而在 0.11.0.0 版本之后， Producer 支持幂等传递选项，保证重新发送不会导致消息在日志出现重复。为了实现这个, Broker 为 Producer 分配了一个ID，并通过每条消息的序列号进行去重。也支持了类似事务语义来保证将消息发送到多个 Topic 分区中，保证所有消息要么都写入成功，要么都失败，这个主要用在 Topic 之间的 exactly once 语义。\n> \n> 其中启用幂等传递的方法配置：enable.idempotence = true。\n> \n> 启用事务支持的方法配置：设置属性 transcational.id = "指定值"。\n> \n> 3）从 Consumer 角度来剖析, 我们知道 Offset 是由 Consumer 自己来维护的, 如果 Consumer 收到消息后更新 Offset， 这时 Consumer 异常 crash 掉， 那么新的 Consumer 接管后再次重启消费，就会造成 at most once 语义（消息会丢，但不重复）。\n> \n> 4）如果 Consumer 消费消息完成后, 再更新 Offset，如果这时 Consumer crash 掉，那么新的 Consumer 接管后重新用这个 Offset 拉取消息， 这时就会造成 at least once 语义（消息不丢，但被多次重复处理）。\n\n\n# Kafka三次消息传递\n\n> 1）Producer 端发送消息给 Kafka Broker 端。\n> \n> 2）Kafka Broker 将消息进行同步并持久化数据。\n> \n> 3）Consumer 端从Kafka Broker 将消息拉取并进行消费。\n\nKafka 只对「已提交」的消息做「最大限度的持久化保证不丢失」。\n\n已提交的数据指Producer段发送的消息已经有N个Broker成功收到了，而且至少有一个Broker存活，那么就能保证消息持久化保证不丢失。\n\n\n# 消息丢失场景\n\n# Producer端\n\n\n\n> 1）首先我们要知道一点就是Producer 端是直接与 Broker 中的 Leader Partition 交互的，所以在 Producer 端初始化中就需要通过 Partitioner 分区器从 Kafka 集群中获取到相关 Topic 对应的 Leader Partition 的元数据。\n> \n> 2）待获取到 Leader Partition 的元数据后直接将消息发送过去。\n> \n> 3）Kafka Broker 对应的 Leader Partition 收到消息会先写入 Page Cache，定时刷盘进行持久化（顺序写入磁盘）。\n> \n> 4）Follower Partition 拉取 Leader Partition 的消息并保持同 Leader Partition 数据一致，待消息拉取完毕后需要给 Leader Partition 回复 ACK 确认消息。\n> \n> 5）待 Kafka Leader 与 Follower Partition 同步完数据并收到所有 ISR 中的 Replica 副本的 ACK 后，Leader Partition 会给 Producer 回复 ACK 确认消息。\n\n丢失情况可能发生在Producer端异步发送消息给Broker\n\n * 网络原因： 由于网络抖动导致数据没有发送过去\n * **数据原因：**消息体太大超出Broker接收范围\n\n通过配置参数来确认消息是否发送成功\n\n\n\n# Broker端\n\n\n\nKafkaBroker 集群接收到数据后会将数据进行持久化存储到磁盘，为了提高吞吐量和性能，采用的是「异步批量刷盘的策略」，也就是说按照一定的消息量和间隔时间进行刷盘。首先会将数据存储到 「PageCache」 中，至于什么时候将 Cache 中的数据刷盘是由「操作系统」根据自己的策略决定或者调用 fsync 命令进行强制刷盘，如果此时 Broker 宕机 Crash 掉，且选举了一个落后 Leader Partition 很多的 Follower Partition 成为新的 Leader Partition，那么落后的消息数据就会丢失。\n\n# Consumer端\n\n\n\n> 1）Consumer 拉取数据之前跟Producer 发送数据一样, 需要通过订阅关系获取到集群元数据,找到相关 Topic 对应的 Leader Partition 的元数据。\n> \n> 2）然后 Consumer 通过 Pull 模式主动的去 Kafka 集群中拉取消息。\n> \n> 3）在这个过程中，有个消费者组的概念（不了解的可以看上面链接文章），多个 Consumer 可以组成一个消费者组即 Consumer Group，每个消费者组都有一个Group-Id。同一个 Consumer Group 中的 Consumer 可以消费同一个 Topic 下不同分区的数据，但是不会出现多个 Consumer 去消费同一个分区的数据。\n> \n> 4）拉取到消息后进行业务逻辑处理，待处理完成后，会进行 ACK 确认，即提交 Offset 消费位移进度记录。\n> \n> 5）最后 Offset 会被保存到 Kafka Broker 集群中的 __consumer_offsets 这个 Topic 中，且每个 Consumer 保存自己的 Offset 进度。\n\nConsumer拉取后消息最终是要提交Offset，那么这里就可能会丢失数据\n\n * 可能使用的「自动提交 Offset 方式」\n\n * 拉取消息后「先提交 Offset，后处理消息」，如果此时处理消息的时候异常宕机，由于 Offset 已经提交了, 待 Consumer 重启后，会从之前已提交的 Offset 下一个位置重新开始消费， 之前未处理完成的消息不会被再次处理，对于该 Consumer 来说消息就丢失了。\n\n * 拉取消息后「先处理消息，在进行提交 Offset」， 如果此时在提交之前发生异常宕机，由于没有提交成功 Offset， 待下次 Consumer 重启后还会从上次的 Offset 重新拉取消息，不会出现消息丢失的情况， 但是会出现重复消费的情况，这里只能业务自己保证幂等性。\n\n# 解决方案\n\n发送的调用方式改为异步方式\n\nFuture<RecordMetadata> send(ProducerRecord<K, V> record, Callback callback); \n\n\npublic Future<RecordMetadata> send(ProducerRecord<K, V> record, Callback callback) { \n    //intercept the record, which can be potentially modified; this method does not throw exceptions \n    ProducerRecord<K, V> interceptedRecord = this.interceptors == null ? record : this.interceptors.onSend(record); \n    return doSend(interceptedRecord, callback);}\n\n\n\n\n然后就是修改一些配置项\n\nproducer端发送消息重试次数，retries 设为最大值；\n\n重试时间retry.backoff.ms 设为300ms；\n\nunclean.leader.election.enable ，false表示不要在ISR列表外的follow选举leader，因为那些副本落后原来leader很多；\n\nreplication.factor，设置分区副本的个数，>=3；\n\nmin.insync.replicas，ISR个数，也是“已提交”个数；\n\nenable.auto.commit = false，设置消费端手动移位offset，业务自己保证幂等性。',normalizedContent:'# 阻塞队列\n\n\n\nblockingqueue\n\n * 解决线程通信的问题\n * 阻塞方法：put、take\n\n生产者消费者模式\n\n * 生产者：产生数据的线程\n * 消费者：使用数据的线程\n\n实现类\n\n * arrayblockingqueue\n * linkedblockqueue\n * priorityblockingqueue，synchronousqueue，delayqueue等\n\n示例\n\n * 生产者线程\n\nclass producer implements runnable {\n    private blockingqueue<integer> queue;\n    public producer(blockingqueue<integer> queue) {\n        this.queue = queue;\n    }\n\n    @override\n    public void run() {\n        try {\n            for (int i = 0; i < 100; i++) {\n                thread.sleep(20);\n                queue.put(i);\n                system.out.println(thread.currentthread().getname() + "生产:" + queue.size());\n            }\n        } catch (exception e) {\n            e.printstacktrace();\n        }\n    }\n\n}\n\n\n * 消费者线程\n\nclass consumer implements runnable {\n    private blockingqueue<integer> queue;\n    public consumer(blockingqueue<integer> queue) {\n        this.queue = queue;\n    }\n\n    @override\n    public void run() {\n        try {\n            while (true) {\n                thread.sleep(new random().nextint(1000));\n                queue.take();\n                system.out.println(thread.currentthread().getname() + "消费:" + queue.size());\n            }\n        } catch (exception e) {\n            e.printstacktrace();\n        }\n    }\n}\n\n\n结果\n\n\n\n\n# kafka入门\n\n * kafka是一个分布式的流媒体平台；\n * 应用：消息系统、日志收集、用户行为追踪、流失处理。\n\nkafka是一个消息队列，放里面放数据叫生产者，取数据叫消费者。\n\n\n\n一个消息中间件，队列不单单只有一个，然后给每个队列取个名字，叫topic。\n\n\n\n然后生产者，消费者就到指定的消息队列中存取数据就可以了。\n\n\n\n为了提高一个队列的吞吐量，kafka会把topic分区\n\n\n\n实际上，生产者消费者是到指定topic，指定分区中存取数据\n\n\n\n一台kafka服务器叫做broker\n\n\n\n一个话题中的多个分区，可能存在不同的服务器上\n\n\n\nkafka将数据存放在不同的分区上，同时也会将分区备份，存在不同的broker上。备份分区只用做备份，不做读写。当某个broker挂了，那么就从其它broker中的分区作为主分区。\n\n\n\n消费者\n\n\n\n消费者可以有多个，形成一个消费者组。比如本来一个消费者要消费三个分区，那么可以通过一个消费者组，让三个消费者分别消费一个分区。\n\n * 使用消息队列不可能是单机的（必然是分布式or集群）\n\n * kafka会将partition以消息日志的方式(落磁盘)存储起来，通过 顺序访问io和缓存(等到一定的量或时间)才真正把数据写到磁盘上，来提高速度。\n\n * kafka会将数据写到partition，单个partition的写入是有顺序的。如果要保证全局有序，那只能写入一个partition中。如果要消费也有序，消费者也只能有一个。\n\n * 凡是分布式就无法避免网络抖动/机器宕机等问题的发生，很有可能消费者a读取了数据，还没来得及消费，就挂掉了。zookeeper发现消费者a挂了，让消费者b去消费原本消费者a的分区，等消费者a重连的时候，发现已经重复消费同一条数据了。(各种各样的情况，消费者超时等等都有可能…)\n   \n   如果业务上不允许重复消费的问题，最好消费者那端做业务上的校验（如果已经消费过了，就不消费了）\n\n\n# kafka为什么这么快\n\n * 顺序写\n\n虽然说kafka中的数据持久到到磁盘中，磁盘读写速度比不上内存读写速度。\n\n都知道完成一次磁盘io，需要经过寻道、旋转和读写数据。\n\n因为kafka中某一个分区内的数据是有序的，队列fifo，所以可以采用顺序写的方式进行持久化。\n\nkafka采用顺序写的方式，来省去寻道和旋转产生的时间，从而提高写入磁盘的速度。\n\n每一个分区（partition）对应多个物理文件（segment）。\n\n * 零拷贝\n\n消费者读取磁盘中的数据，使用传统的io模型，需要拷贝四次\n\n\n\n零拷贝方式，减少用户态和内核态直接的切换\n\n\n\n * pagecache\n\n生产者生产消息到broker时，先写入到page cache中，page cache存在内存当中，但不受jvm的gc管理，这样可以避免每次生产消费都需要磁盘io。\n\n\n\n * 网络模型\n\n采用基于池化思想，避免为每个连接创建线程，连接完成后将业务处理交给线程池处理。\n\n基于 io 复用模型，多个连接共用同一个阻塞对象，不用等待所有的连接。\n\n * 批量与压缩\n\n生产者向broker发送消息是按照批量来发送，假设带宽是10mb/s，那么发送一个10mb的消息比发送1mb的消息10次要快。\n\n多数情况下，系统的瓶颈不在磁盘io，而是在网络io。\n\n * 分区并发\n\nkafka的message是按topic分类存储的，topic中的数据又是按照一个一个的partition即分区存储到不同broker节点。\n\n每个partition对应了操作系统上的一个文件夹，partition实际上又是按照segment分段存储的。每次文件操作也是直接操作segment。\n\n为了进一步的查询优化，kafka又默认为分段后的数据文件建立了索引文件。\n\n\n# 夺命连环问\n\n\n# 说说你对kafka的理解\n\n> kafka是一个流式数据处理平台，具有消息系统的能力，也有实时流式数据处理分析能能力，只是我们通常把它当做消息队列系统来用。\n> \n> 主要由三个方面组成，zookeeper、kafka核心和存储。\n> \n> kafka一般作为分布式系统来用，所以需要每个kafka服务器启动时需要将自己注册到zookeeper中，由zookeeper来统一管理。\n> \n> 然后kafka本身，有消息、话题、生产者、消费者、分片、broker、组等等。\n> \n> 最后是存储方面，用来持久化存储kafka的数据，都会以日志的形式最终存入到磁盘中。\n\n\n# 消息队列模型知道吗？kafka是怎么做到支持这两种模型的？\n\n> 点对点：消息只能被一个消费者消费，消费完后消息删除。\n> \n> 发布订阅：相当于广播模式，消息可以被所有消费者消费。\n> \n> 消费者组，由多个消费者组成，一个组内只会由一个消费者去消费一个分区的消息。\n\n\n# 能说说kafka通信过程原理吗？\n\n>  1. 首先kafka broker启动时，将自己注册到zookeeper中；\n>  2. 生产者根据配置的地址连接到指定的broker，建立tcp连接；\n>  3. 发送消息；\n>  4. 消费者和协调者broker创建tcp连接；\n>  5. 开始消费消息。\n\n\n\n\n# 发送消息时如何选择分区的？\n\n>  1. 轮询，按照顺序消息依次发送到不同的分区\n>  2. 随机，随机发送到某个分区\n> \n> 如果消息指定key，那么会根据消息的key进行hash，然后对partition分区数量取模，决定落在哪个分区上，所以，对于相同key的消息来说，总是会发送到同一个分区上，也是我们常说的消息分区有序性。\n> \n> 很常见的场景就是我们希望下单、支付消息有顺序，这样以订单id作为key发送消息就达到了分区有序性的目的。\n> \n> 如果没有指定key，会执行默认的轮询负载均衡策略，比如第一条消息落在p0，第二条消息落在p1，然后第三条又在p1。\n> \n> 除此之外，对于一些特定的业务场景和需求，还可以通过实现partitioner接口，重写configure和partition方法来达到自定义分区的效果。\n\n\n# 为什么需要分区？有什么好处？\n\n> 如果说不分区的话，我们发消息写数据都只能保存到一个节点上，这样的话就算这个服务器节点性能再好最终也支撑不住。\n> \n> 分区带来了负载均衡和横向扩展的能力。\n> \n> 发送消息时可以根据分区的数量存在不同的broker上，提升了并发读写消息能力。\n\n\n# 详细说说消费者组和消费者重平衡？\n\n> 一般来说，消费者数量和所有主题分区的数量保持一致最好，消费者组可以让kafka支持传统的两种消息队列模型。\n> \n> kafka中有一个协调者来 完成分区的分配，而重平衡rebalance就是指的有新消费者加入的情况，比如刚开始我们只有消费者a在消费消息，过了一段时间消费者b和c加入了，这时候分区就需要重新分配。\n\n\n# 分区分配策略？\n\n> range\n> \n> 对同一个主题的分区，排序优先均匀分给前面的消费者，排在前面的消费者获得的消息 >= 后面的消费者。\n> \n> roundrobin\n> \n> 轮询，按顺序以此分配给消费者。\n> \n> sticky\n> \n> 之前这个分区 分给消费者，那么下次还是尽量分给他，避免频繁的销毁创建连接。\n\n\n# 消息传递语义剖析\n\n\n\n> 1）首先当 producer 向 broker 发送数据后，会进行 commit，如果commit成功，由于 replica 副本机制的存在，则意味着消息不会丢失，但是 producer 发送数据给 broker 后，遇到网络问题而造成通信中断，那么 producer 就无法准确判断该消息是否已经被提交（commit），这就可能造成 at least once 语义。\n> \n> 2）在 kafka 0.11.0.0 之前， 如果 producer 没有收到消息 commit 的响应结果，它只能重新发送消息，确保消息已经被正确的传输到 broker，重新发送的时候会将消息再次写入日志中；而在 0.11.0.0 版本之后， producer 支持幂等传递选项，保证重新发送不会导致消息在日志出现重复。为了实现这个, broker 为 producer 分配了一个id，并通过每条消息的序列号进行去重。也支持了类似事务语义来保证将消息发送到多个 topic 分区中，保证所有消息要么都写入成功，要么都失败，这个主要用在 topic 之间的 exactly once 语义。\n> \n> 其中启用幂等传递的方法配置：enable.idempotence = true。\n> \n> 启用事务支持的方法配置：设置属性 transcational.id = "指定值"。\n> \n> 3）从 consumer 角度来剖析, 我们知道 offset 是由 consumer 自己来维护的, 如果 consumer 收到消息后更新 offset， 这时 consumer 异常 crash 掉， 那么新的 consumer 接管后再次重启消费，就会造成 at most once 语义（消息会丢，但不重复）。\n> \n> 4）如果 consumer 消费消息完成后, 再更新 offset，如果这时 consumer crash 掉，那么新的 consumer 接管后重新用这个 offset 拉取消息， 这时就会造成 at least once 语义（消息不丢，但被多次重复处理）。\n\n\n# kafka三次消息传递\n\n> 1）producer 端发送消息给 kafka broker 端。\n> \n> 2）kafka broker 将消息进行同步并持久化数据。\n> \n> 3）consumer 端从kafka broker 将消息拉取并进行消费。\n\nkafka 只对「已提交」的消息做「最大限度的持久化保证不丢失」。\n\n已提交的数据指producer段发送的消息已经有n个broker成功收到了，而且至少有一个broker存活，那么就能保证消息持久化保证不丢失。\n\n\n# 消息丢失场景\n\n# producer端\n\n\n\n> 1）首先我们要知道一点就是producer 端是直接与 broker 中的 leader partition 交互的，所以在 producer 端初始化中就需要通过 partitioner 分区器从 kafka 集群中获取到相关 topic 对应的 leader partition 的元数据。\n> \n> 2）待获取到 leader partition 的元数据后直接将消息发送过去。\n> \n> 3）kafka broker 对应的 leader partition 收到消息会先写入 page cache，定时刷盘进行持久化（顺序写入磁盘）。\n> \n> 4）follower partition 拉取 leader partition 的消息并保持同 leader partition 数据一致，待消息拉取完毕后需要给 leader partition 回复 ack 确认消息。\n> \n> 5）待 kafka leader 与 follower partition 同步完数据并收到所有 isr 中的 replica 副本的 ack 后，leader partition 会给 producer 回复 ack 确认消息。\n\n丢失情况可能发生在producer端异步发送消息给broker\n\n * 网络原因： 由于网络抖动导致数据没有发送过去\n * **数据原因：**消息体太大超出broker接收范围\n\n通过配置参数来确认消息是否发送成功\n\n\n\n# broker端\n\n\n\nkafkabroker 集群接收到数据后会将数据进行持久化存储到磁盘，为了提高吞吐量和性能，采用的是「异步批量刷盘的策略」，也就是说按照一定的消息量和间隔时间进行刷盘。首先会将数据存储到 「pagecache」 中，至于什么时候将 cache 中的数据刷盘是由「操作系统」根据自己的策略决定或者调用 fsync 命令进行强制刷盘，如果此时 broker 宕机 crash 掉，且选举了一个落后 leader partition 很多的 follower partition 成为新的 leader partition，那么落后的消息数据就会丢失。\n\n# consumer端\n\n\n\n> 1）consumer 拉取数据之前跟producer 发送数据一样, 需要通过订阅关系获取到集群元数据,找到相关 topic 对应的 leader partition 的元数据。\n> \n> 2）然后 consumer 通过 pull 模式主动的去 kafka 集群中拉取消息。\n> \n> 3）在这个过程中，有个消费者组的概念（不了解的可以看上面链接文章），多个 consumer 可以组成一个消费者组即 consumer group，每个消费者组都有一个group-id。同一个 consumer group 中的 consumer 可以消费同一个 topic 下不同分区的数据，但是不会出现多个 consumer 去消费同一个分区的数据。\n> \n> 4）拉取到消息后进行业务逻辑处理，待处理完成后，会进行 ack 确认，即提交 offset 消费位移进度记录。\n> \n> 5）最后 offset 会被保存到 kafka broker 集群中的 __consumer_offsets 这个 topic 中，且每个 consumer 保存自己的 offset 进度。\n\nconsumer拉取后消息最终是要提交offset，那么这里就可能会丢失数据\n\n * 可能使用的「自动提交 offset 方式」\n\n * 拉取消息后「先提交 offset，后处理消息」，如果此时处理消息的时候异常宕机，由于 offset 已经提交了, 待 consumer 重启后，会从之前已提交的 offset 下一个位置重新开始消费， 之前未处理完成的消息不会被再次处理，对于该 consumer 来说消息就丢失了。\n\n * 拉取消息后「先处理消息，在进行提交 offset」， 如果此时在提交之前发生异常宕机，由于没有提交成功 offset， 待下次 consumer 重启后还会从上次的 offset 重新拉取消息，不会出现消息丢失的情况， 但是会出现重复消费的情况，这里只能业务自己保证幂等性。\n\n# 解决方案\n\n发送的调用方式改为异步方式\n\nfuture<recordmetadata> send(producerrecord<k, v> record, callback callback); \n\n\npublic future<recordmetadata> send(producerrecord<k, v> record, callback callback) { \n    //intercept the record, which can be potentially modified; this method does not throw exceptions \n    producerrecord<k, v> interceptedrecord = this.interceptors == null ? record : this.interceptors.onsend(record); \n    return dosend(interceptedrecord, callback);}\n\n\n\n\n然后就是修改一些配置项\n\nproducer端发送消息重试次数，retries 设为最大值；\n\n重试时间retry.backoff.ms 设为300ms；\n\nunclean.leader.election.enable ，false表示不要在isr列表外的follow选举leader，因为那些副本落后原来leader很多；\n\nreplication.factor，设置分区副本的个数，>=3；\n\nmin.insync.replicas，isr个数，也是“已提交”个数；\n\nenable.auto.commit = false，设置消费端手动移位offset，业务自己保证幂等性。',charsets:{cjk:!0}},{title:"RabbitMQ",frontmatter:{title:"RabbitMQ",date:"2023-06-18T19:55:59.000Z",permalink:"/pages/2ca146/"},regularPath:"/01.Java/02.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.RabbitMQ.html",relativePath:"01.Java/02.中间件/03.RabbitMQ.md",key:"v-262abfa1",path:"/pages/2ca146/",headers:[{level:2,title:"工作模式",slug:"工作模式",normalizedTitle:"工作模式",charIndex:2},{level:2,title:"消息可靠性",slug:"消息可靠性",normalizedTitle:"消息可靠性",charIndex:492},{level:3,title:"生产者",slug:"生产者",normalizedTitle:"生产者",charIndex:15},{level:3,title:"持久化",slug:"持久化",normalizedTitle:"持久化",charIndex:1724},{level:3,title:"消费者",slug:"消费者",normalizedTitle:"消费者",charIndex:24},{level:3,title:"消费端限流",slug:"消费端限流",normalizedTitle:"消费端限流",charIndex:3054},{level:3,title:"TTL",slug:"ttl",normalizedTitle:"ttl",charIndex:3078},{level:3,title:"死信队列",slug:"死信队列",normalizedTitle:"死信队列",charIndex:3164},{level:3,title:"延迟队列",slug:"延迟队列",normalizedTitle:"延迟队列",charIndex:3287},{level:3,title:"消息可靠性保障-消息补偿",slug:"消息可靠性保障-消息补偿",normalizedTitle:"消息可靠性保障-消息补偿",charIndex:3314},{level:3,title:"消息幂等性保障",slug:"消息幂等性保障",normalizedTitle:"消息幂等性保障",charIndex:3333}],headersStr:"工作模式 消息可靠性 生产者 持久化 消费者 消费端限流 TTL 死信队列 延迟队列 消息可靠性保障-消息补偿 消息幂等性保障",content:'# 工作模式\n\n\n\n * P：生产者\n * C：消费者\n * Queue：消息队列\n * Exchange：交换机\n   * Fanout：广播\n   * Direct：定向，把消息交给指定routing key的队列\n   * Topic：通配符，把消息交给符合routing pattern（路由模式）的队列\n\n// Fanout: routingKey = ""\n// Direct: routingKey = "str"\n// Topic:  routingKey = "str.#"\n\n@Bean\npublic Binding bindQueueExchange(@Qualifier("bootQueue") Queue queue,\n                                 @Qualifier("bootExchange") Exchange exchange) {\n    return BindingBuilder.*bind*(queue).to(exchange).with(routingKey).noargs();\n}\n\n\n\n# 消息可靠性\n\n * confirm 确认模式\n * return 退回模式\n\n消息从producer到exchange，会返回一个confirmCallback。\n\n消息从exchange到Queue投递失败，会返回一个returnCallback。\n\n\n# 生产者\n\n    @Resource\n    private RabbitTemplate rabbitTemplate;\n\n    @Test\n    void testProducer() throws InterruptedException {\n        rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() {\n            @Override\n            public void confirm(CorrelationData correlationData, boolean ack, String cause) {\n                System.out.println("confirm 执行了");\n                if (ack){\n                    System.out.println(correlationData + "消息投递成功" + cause);\n                }\n                else{\n                    System.out.println(correlationData + "消息投递失败" + cause);\n                }\n            }\n        });\n        rabbitTemplate.setMandatory(true);\n        rabbitTemplate.setReturnsCallback(new RabbitTemplate.ReturnsCallback() {\n            @Override\n            public void returnedMessage(ReturnedMessage returned) {\n                System.out.println("消息路由到消息队列失败"+returned);\n            }\n        });\n        rabbitTemplate.convertAndSend( "boot_topic_exchange","boot1111.hahah", "boot mq hello!!!", new CorrelationData("1"));\n        Thread.sleep(1000);\n    }\n\n\n\n# 持久化\n\n@Configuration\npublic class RabbitConfig {\n    private static final String EXCHANGE_NAME = "boot_topic_exchange";\n    private static final String QUEUE_NAME = "boot_queue";\n\n    @Bean("bootExchange")\n    public Exchange bootExchange() {\n        return ExchangeBuilder.topicExchange(EXCHANGE_NAME).durable(true).build();\n    }\n\n    @Bean("bootQueue")\n    public Queue bootQueue() {\n        return QueueBuilder.durable(QUEUE_NAME).build();\n    }\n\n    @Bean\n    public Binding bindQueueExchange(@Qualifier("bootQueue") Queue queue,\n                                     @Qualifier("bootExchange") Exchange exchange) {\n        return BindingBuilder.bind(queue).to(exchange).with("boot.#").noargs();\n    }\n\n\n}\n\n\n\n\n# 消费者\n\n@Component\npublic class ConsumerListener {\n\n    @RabbitListener(queues = "boot_queue")\n    public void ListenerQueue(Message message, Channel channel) throws IOException, InterruptedException {\n        Thread.sleep(1000);\n        long deliveryTag = message.getMessageProperties().getDeliveryTag();\n        try {\n            System.out.println(new String(message.getBody()));\n            int a = 1/0;\n            channel.basicAck(deliveryTag, true);\n            System.out.println("message confirm.");\n        }catch (Exception e){\n            channel.basicNack(deliveryTag, true, true);\n        }\n    }\n}\n\n\n\n# 消费端限流\n\n配置prefetch属性\n\n\n# TTL\n\nTime To Live\n\nexpiration：设置消息到达存活时间后，还没有被消费，会自动被清除。\n\nx-message-ttl：对队列设置TTL。\n\n\n# 死信队列\n\n消息成为死信的三种情况：\n\n * 队列消息长度到达限制\n * 消费者拒收消息，并且不把原消息放到原消息，requeue = false\n * 消息到了过期时间\n\n死信交换机和普通的交换机没区别，同样也可以路由到绑定的队列中。\n\n\n# 延迟队列\n\n消息进入队列后不会立即被消费\n\n\n\n\n# 消息可靠性保障-消息补偿\n\n\n\n\n# 消息幂等性保障\n\n乐观锁，数据库中加一个字段，version',normalizedContent:'# 工作模式\n\n\n\n * p：生产者\n * c：消费者\n * queue：消息队列\n * exchange：交换机\n   * fanout：广播\n   * direct：定向，把消息交给指定routing key的队列\n   * topic：通配符，把消息交给符合routing pattern（路由模式）的队列\n\n// fanout: routingkey = ""\n// direct: routingkey = "str"\n// topic:  routingkey = "str.#"\n\n@bean\npublic binding bindqueueexchange(@qualifier("bootqueue") queue queue,\n                                 @qualifier("bootexchange") exchange exchange) {\n    return bindingbuilder.*bind*(queue).to(exchange).with(routingkey).noargs();\n}\n\n\n\n# 消息可靠性\n\n * confirm 确认模式\n * return 退回模式\n\n消息从producer到exchange，会返回一个confirmcallback。\n\n消息从exchange到queue投递失败，会返回一个returncallback。\n\n\n# 生产者\n\n    @resource\n    private rabbittemplate rabbittemplate;\n\n    @test\n    void testproducer() throws interruptedexception {\n        rabbittemplate.setconfirmcallback(new rabbittemplate.confirmcallback() {\n            @override\n            public void confirm(correlationdata correlationdata, boolean ack, string cause) {\n                system.out.println("confirm 执行了");\n                if (ack){\n                    system.out.println(correlationdata + "消息投递成功" + cause);\n                }\n                else{\n                    system.out.println(correlationdata + "消息投递失败" + cause);\n                }\n            }\n        });\n        rabbittemplate.setmandatory(true);\n        rabbittemplate.setreturnscallback(new rabbittemplate.returnscallback() {\n            @override\n            public void returnedmessage(returnedmessage returned) {\n                system.out.println("消息路由到消息队列失败"+returned);\n            }\n        });\n        rabbittemplate.convertandsend( "boot_topic_exchange","boot1111.hahah", "boot mq hello!!!", new correlationdata("1"));\n        thread.sleep(1000);\n    }\n\n\n\n# 持久化\n\n@configuration\npublic class rabbitconfig {\n    private static final string exchange_name = "boot_topic_exchange";\n    private static final string queue_name = "boot_queue";\n\n    @bean("bootexchange")\n    public exchange bootexchange() {\n        return exchangebuilder.topicexchange(exchange_name).durable(true).build();\n    }\n\n    @bean("bootqueue")\n    public queue bootqueue() {\n        return queuebuilder.durable(queue_name).build();\n    }\n\n    @bean\n    public binding bindqueueexchange(@qualifier("bootqueue") queue queue,\n                                     @qualifier("bootexchange") exchange exchange) {\n        return bindingbuilder.bind(queue).to(exchange).with("boot.#").noargs();\n    }\n\n\n}\n\n\n\n\n# 消费者\n\n@component\npublic class consumerlistener {\n\n    @rabbitlistener(queues = "boot_queue")\n    public void listenerqueue(message message, channel channel) throws ioexception, interruptedexception {\n        thread.sleep(1000);\n        long deliverytag = message.getmessageproperties().getdeliverytag();\n        try {\n            system.out.println(new string(message.getbody()));\n            int a = 1/0;\n            channel.basicack(deliverytag, true);\n            system.out.println("message confirm.");\n        }catch (exception e){\n            channel.basicnack(deliverytag, true, true);\n        }\n    }\n}\n\n\n\n# 消费端限流\n\n配置prefetch属性\n\n\n# ttl\n\ntime to live\n\nexpiration：设置消息到达存活时间后，还没有被消费，会自动被清除。\n\nx-message-ttl：对队列设置ttl。\n\n\n# 死信队列\n\n消息成为死信的三种情况：\n\n * 队列消息长度到达限制\n * 消费者拒收消息，并且不把原消息放到原消息，requeue = false\n * 消息到了过期时间\n\n死信交换机和普通的交换机没区别，同样也可以路由到绑定的队列中。\n\n\n# 延迟队列\n\n消息进入队列后不会立即被消费\n\n\n\n\n# 消息可靠性保障-消息补偿\n\n\n\n\n# 消息幂等性保障\n\n乐观锁，数据库中加一个字段，version',charsets:{cjk:!0}},{title:"分布式事务",frontmatter:{title:"分布式事务",date:"2023-03-01T09:00:17.000Z",permalink:"/pages/7c79c1/"},regularPath:"/01.Java/03.%E5%BE%AE%E6%9C%8D%E5%8A%A1/02.Seata.html",relativePath:"01.Java/03.微服务/02.Seata.md",key:"v-6f2e8e58",path:"/pages/7c79c1/",headers:[{level:2,title:"本地事务",slug:"本地事务",normalizedTitle:"本地事务",charIndex:2},{level:2,title:"分布式事务",slug:"分布式事务",normalizedTitle:"分布式事务",charIndex:126},{level:3,title:"CAP定理",slug:"cap定理",normalizedTitle:"cap定理",charIndex:162},{level:3,title:"BASE理论",slug:"base理论",normalizedTitle:"base理论",charIndex:443},{level:2,title:"Seata",slug:"seata",normalizedTitle:"seata",charIndex:725},{level:3,title:"XA模式",slug:"xa模式",normalizedTitle:"xa模式",charIndex:1028},{level:3,title:"AT模式",slug:"at模式",normalizedTitle:"at模式",charIndex:1096},{level:4,title:"AT与XA的区别",slug:"at与xa的区别",normalizedTitle:"at与xa的区别",charIndex:1361},{level:4,title:"AT脏写问题",slug:"at脏写问题",normalizedTitle:"at脏写问题",charIndex:1477},{level:3,title:"TCC模式",slug:"tcc模式",normalizedTitle:"tcc模式",charIndex:1066},{level:4,title:"空回滚",slug:"空回滚",normalizedTitle:"空回滚",charIndex:1863},{level:4,title:"业务悬挂",slug:"业务悬挂",normalizedTitle:"业务悬挂",charIndex:2001},{level:3,title:"SAGA模式",slug:"saga模式",normalizedTitle:"saga模式",charIndex:1138}],headersStr:"本地事务 分布式事务 CAP定理 BASE理论 Seata XA模式 AT模式 AT与XA的区别 AT脏写问题 TCC模式 空回滚 业务悬挂 SAGA模式",content:"# 本地事务\n\n满足数据库中的ACID\n\n * 原子性：事务中的所有操作，要么全部成功，要么全部失败\n * 一致性：要保证数据库内部完整性，满足约束\n * 隔离性：对同一资源操作的事务不能同时发生\n * 持久性：对数据库做的一切修改将永久保存\n\n\n# 分布式事务\n\n不是在单个服务或单个数据库架构下，产生的事务\n\n\n\n\n# CAP定理\n\n>  * Consistency（一致性）：用户访问分布式系统中的任意节点，得到的数据必须一致。\n> \n>  * Availability（可用性）：用户访问集群中任意健康节点，必须得到响应。\n> \n>  * Partition tolerance （分区容错性）：因为网络故障，分布式系统内部形成多个分区，也要对外提供服务。\n\n\n\n矛盾\n\n如果保证一致性，和可用性，那么当分布式系统中因为网络原因，有的节点无法通信，那么就会导致节点之间数据不同步，如果让数据不同步的节点不能访问，那么就不满足可用性，如果让他能访问，那么就不满足一致性。\n\n\n# BASE理论\n\n>  * Basically Available （基本可用）：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。\n>  * **Soft State（软状态）：**在一定时间内，允许出现中间状态，比如临时的不一致状态。\n>  * Eventually Consistent（最终一致性）：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。\n\nAP模式：各子事务分别执行和提交，允许出现结果不一致，然后采取弥补措施恢复数据即可，实现最终一致性。\n\nCP模式：各个子事务执行后互相等待，同时提交，同时回滚，达成强一致性。\n\n\n# Seata\n\nSeata事务管理中有三个重要的角色：\n\n>  * TC (Transaction Coordinator) - **事务协调者：**维护全局和分支事务的状态，协调全局事务提交或回滚。\n> \n>  * TM (Transaction Manager) - **事务管理器：**定义全局事务的范围、开始全局事务、提交或回滚全局事务。\n> \n>  * RM (Resource Manager) - **资源管理器：**管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。\n\n\n\nSeata基于上述架构提供了四种不同的分布式事务解决方案：\n\n>  * XA模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入\n>  * TCC模式：最终一致的分阶段事务模式，有业务侵入\n>  * AT模式：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式\n>  * SAGA模式：长事务模式，有业务侵入\n\n\n# XA模式\n\n两阶段提交\n\n一阶段：\n\n * 事务协调者通知每个事物参与者执行本地事务\n * 本地事务执行完成后报告事务执行状态给事务协调者，此时事务不提交，继续持有数据库锁\n\n二阶段：\n\n * 事务协调者基于一阶段的报告来判断下一步操作\n   * 如果一阶段都成功，则通知所有事务参与者，提交事务\n   * 如果一阶段任意一个参与者失败，则通知所有事务参与者回滚事务\n\n\n\n\n# AT模式\n\n\n\n# AT与XA的区别\n\n>  * XA模式一阶段不提交事务，锁定资源；AT模式一阶段直接提交，不锁定资源。\n>  * XA模式依赖数据库机制实现回滚；AT模式利用数据快照实现数据回滚。\n>  * XA模式强一致；AT模式最终一致\n\n# AT脏写问题\n\n\n\n解决思路就是引入了全局锁的概念。在释放DB锁之前，先拿到全局锁。避免同一时刻有另外一个事务来操作当前数据。\n\n\n\n\n# TCC模式\n\n>  * Try：资源的检测和预留；\n> \n>  * Confirm：完成资源操作业务；要求 Try 成功 Confirm 一定要能成功。\n> \n>  * Cancel：预留资源释放，可以理解为try的反向操作。\n\n\n\nTCC的优点\n\n * 一阶段完成直接提交事务，释放数据库资源，性能好\n * 相比AT模型，无需生成快照，无需使用全局锁，性能最强\n * 不依赖数据库事务，而是依赖补偿操作，可以用于非事务型数据库\n\nTCC的缺点\n\n * 有代码侵入，需要人为编写try、Confirm和Cancel接口，太麻烦\n * 软状态，事务是最终一致\n * 需要考虑Confirm和Cancel的失败情况，做好幂等处理\n\n# 空回滚\n\n当某分支事务的try阶段阻塞时，可能导致全局事务超时而触发二阶段的cancel操作。在未执行try操作时先执行了cancel操作，这时cancel不能做回滚，就是空回滚。\n\n执行cancel操作时，应当判断try是否已经执行，如果尚未执行，则应该空回滚。\n\n\n\n# 业务悬挂\n\n对于已经空回滚的业务，之前被阻塞的try操作恢复，继续执行try，就永远不可能confirm或cancel ，事务一直处于中间状态，这就是业务悬挂。\n\n执行try操作时，应当判断cancel是否已经执行过了，如果已经执行，应当阻止空回滚后的try操作，避免悬挂\n\n\n# SAGA模式\n\n分布式事务内有多个参与者，需要用户根据业务场景实现其正向操作和逆向回滚操作。\n\nSaga也分为两个阶段：\n\n * 一阶段：直接提交本地事务\n * 二阶段：成功则什么都不做；失败则通过编写补偿业务来回滚",normalizedContent:"# 本地事务\n\n满足数据库中的acid\n\n * 原子性：事务中的所有操作，要么全部成功，要么全部失败\n * 一致性：要保证数据库内部完整性，满足约束\n * 隔离性：对同一资源操作的事务不能同时发生\n * 持久性：对数据库做的一切修改将永久保存\n\n\n# 分布式事务\n\n不是在单个服务或单个数据库架构下，产生的事务\n\n\n\n\n# cap定理\n\n>  * consistency（一致性）：用户访问分布式系统中的任意节点，得到的数据必须一致。\n> \n>  * availability（可用性）：用户访问集群中任意健康节点，必须得到响应。\n> \n>  * partition tolerance （分区容错性）：因为网络故障，分布式系统内部形成多个分区，也要对外提供服务。\n\n\n\n矛盾\n\n如果保证一致性，和可用性，那么当分布式系统中因为网络原因，有的节点无法通信，那么就会导致节点之间数据不同步，如果让数据不同步的节点不能访问，那么就不满足可用性，如果让他能访问，那么就不满足一致性。\n\n\n# base理论\n\n>  * basically available （基本可用）：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。\n>  * **soft state（软状态）：**在一定时间内，允许出现中间状态，比如临时的不一致状态。\n>  * eventually consistent（最终一致性）：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。\n\nap模式：各子事务分别执行和提交，允许出现结果不一致，然后采取弥补措施恢复数据即可，实现最终一致性。\n\ncp模式：各个子事务执行后互相等待，同时提交，同时回滚，达成强一致性。\n\n\n# seata\n\nseata事务管理中有三个重要的角色：\n\n>  * tc (transaction coordinator) - **事务协调者：**维护全局和分支事务的状态，协调全局事务提交或回滚。\n> \n>  * tm (transaction manager) - **事务管理器：**定义全局事务的范围、开始全局事务、提交或回滚全局事务。\n> \n>  * rm (resource manager) - **资源管理器：**管理分支事务处理的资源，与tc交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。\n\n\n\nseata基于上述架构提供了四种不同的分布式事务解决方案：\n\n>  * xa模式：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入\n>  * tcc模式：最终一致的分阶段事务模式，有业务侵入\n>  * at模式：最终一致的分阶段事务模式，无业务侵入，也是seata的默认模式\n>  * saga模式：长事务模式，有业务侵入\n\n\n# xa模式\n\n两阶段提交\n\n一阶段：\n\n * 事务协调者通知每个事物参与者执行本地事务\n * 本地事务执行完成后报告事务执行状态给事务协调者，此时事务不提交，继续持有数据库锁\n\n二阶段：\n\n * 事务协调者基于一阶段的报告来判断下一步操作\n   * 如果一阶段都成功，则通知所有事务参与者，提交事务\n   * 如果一阶段任意一个参与者失败，则通知所有事务参与者回滚事务\n\n\n\n\n# at模式\n\n\n\n# at与xa的区别\n\n>  * xa模式一阶段不提交事务，锁定资源；at模式一阶段直接提交，不锁定资源。\n>  * xa模式依赖数据库机制实现回滚；at模式利用数据快照实现数据回滚。\n>  * xa模式强一致；at模式最终一致\n\n# at脏写问题\n\n\n\n解决思路就是引入了全局锁的概念。在释放db锁之前，先拿到全局锁。避免同一时刻有另外一个事务来操作当前数据。\n\n\n\n\n# tcc模式\n\n>  * try：资源的检测和预留；\n> \n>  * confirm：完成资源操作业务；要求 try 成功 confirm 一定要能成功。\n> \n>  * cancel：预留资源释放，可以理解为try的反向操作。\n\n\n\ntcc的优点\n\n * 一阶段完成直接提交事务，释放数据库资源，性能好\n * 相比at模型，无需生成快照，无需使用全局锁，性能最强\n * 不依赖数据库事务，而是依赖补偿操作，可以用于非事务型数据库\n\ntcc的缺点\n\n * 有代码侵入，需要人为编写try、confirm和cancel接口，太麻烦\n * 软状态，事务是最终一致\n * 需要考虑confirm和cancel的失败情况，做好幂等处理\n\n# 空回滚\n\n当某分支事务的try阶段阻塞时，可能导致全局事务超时而触发二阶段的cancel操作。在未执行try操作时先执行了cancel操作，这时cancel不能做回滚，就是空回滚。\n\n执行cancel操作时，应当判断try是否已经执行，如果尚未执行，则应该空回滚。\n\n\n\n# 业务悬挂\n\n对于已经空回滚的业务，之前被阻塞的try操作恢复，继续执行try，就永远不可能confirm或cancel ，事务一直处于中间状态，这就是业务悬挂。\n\n执行try操作时，应当判断cancel是否已经执行过了，如果已经执行，应当阻止空回滚后的try操作，避免悬挂\n\n\n# saga模式\n\n分布式事务内有多个参与者，需要用户根据业务场景实现其正向操作和逆向回滚操作。\n\nsaga也分为两个阶段：\n\n * 一阶段：直接提交本地事务\n * 二阶段：成功则什么都不做；失败则通过编写补偿业务来回滚",charsets:{cjk:!0}},{title:"限流",frontmatter:{title:"限流",date:"2023-02-28T10:15:33.000Z",permalink:"/pages/526796/"},regularPath:"/01.Java/03.%E5%BE%AE%E6%9C%8D%E5%8A%A1/01.Sentinel.html",relativePath:"01.Java/03.微服务/01.Sentinel.md",key:"v-d17c9944",path:"/pages/526796/",headers:[{level:2,title:"雪崩问题",slug:"雪崩问题",normalizedTitle:"雪崩问题",charIndex:2},{level:2,title:"Sentinel",slug:"sentinel",normalizedTitle:"sentinel",charIndex:382},{level:2,title:"隔离和降级",slug:"隔离和降级",normalizedTitle:"隔离和降级",charIndex:1020},{level:4,title:"降级",slug:"降级",normalizedTitle:"降级",charIndex:182},{level:4,title:"隔离",slug:"隔离",normalizedTitle:"隔离",charIndex:124},{level:4,title:"熔断降级",slug:"熔断降级",normalizedTitle:"熔断降级",charIndex:1263}],headersStr:"雪崩问题 Sentinel 隔离和降级 降级 隔离 熔断降级",content:"# 雪崩问题\n\n\n\n微服务调用链路中的某个服务故障，引起整个链路中的所有微服务都不可用，这就是雪崩。\n\n解决雪崩问题的常见方式：\n\n * 超时处理：设定超时时间，请求超过一定时间没有响应就返回错误消息，不会无休止等待。（缓解作用）\n\n\n\n * 线程隔离：每一个服务弄一个线程池，固定每一个服务的请求数，这样一个服务挂了，不会导致其它服务的资源也耗尽。\n\n\n\n * 降级熔断：断路器统计某一个服务中的远程调用异常的比例，如果超过一个阈值，那么就停止它对其它服务进行远程调用。\n\n\n\n * 流量控制：从源头控制流量到这个服务，预防服务一次性接收的请求过多。\n\n\n\n总结\n\n限流是对服务的保护，避免因瞬间高并发流量而导致服务故障，进而避免雪崩。是一种预防措施。\n\n超时处理、线程隔离、降级熔断是在部分服务故障时，将故障控制在一定范围，避免雪崩。是一种补救措施。\n\n\n# Sentinel\n\n隔离策略：\n\n * 线程池隔离：对每一个服务创建单独一个线程池\n\n * 信号量隔离：规定每个服务最大有几个线程，然后再去同一个线程池里拿线程。\n\n一些感念\n\n\n\n * 单机阈值：设置某个资源请求的QPS最大值，超过部分返回流量控制错误。\n\n * 流控模式：\n   \n   * 直接\n   * 关联：当/write资源访问量触发阈值时，就会对/read资源限流，避免影响/write资源。（优先处理/write）\n   \n   \n   \n   * 链路：\n\n> 例如有两条请求链路：\n> \n> /test1 --\x3e /common\n> \n> /test2 --\x3e /common\n> \n> 如果只希望统计从/test2进入到/common的请求，则可以这样配置：\n\n\n\n * 流控效果：\n   \n   * 快速失败：达到阈值后，新的请求会被立即拒绝并抛出FlowException异常。默认的处理方式。\n   * warm up：预热模式，同上，但阈值会动态变化，从一个较小值逐渐增加到最大阈值。\n   * 排队等待：让所有的请求按照先后次序排队执行，两个请求的间隔不能小于指定时长。QPS = 5，意味着每200ms处理一个队列中的请求；timeout = 2000，意味着预期等待时长超过2000ms的请求会被拒绝并抛出异常。\n\n * 热点参数限流：可能部分商品是热点商品，例如秒杀商品，我们希望这部分商品的QPS限制与其它商品不一样，高一些。\n\n\n# 隔离和降级\n\n# 降级\n\n * feignclient远程调用失败降级\n * 编写降级方法，实现FallbackFactory接口，并给spring容器管理\n * 在feign接口中的方法头添加上fallbackFactory\n\n\n\n# 隔离\n\n线程池隔离：给每个服务调用业务分配一个线程池，利用线程池本身实现隔离效果。\n\n信号量隔离：不创建线程池，而是计数器模式，记录业务使用的线程数量，达到信号量上限时，禁止新的请求。\n\nsentinel中可以配置根据线程数来控制请求。\n\n\n\n# 熔断降级\n\n * 断路器状态\n\n\n\n * 慢调用：RT超过500ms的调用是慢调用，统计最近10000ms内的请求，如果请求量超过10次，并且慢调用比例不低于0.5，则触发熔断，熔断时长为5秒。然后进入half-open状态，放行一次请求做测试。\n\n\n\n * 异常比例：统计最近1000ms内的请求，如果请求量超过10次，并且异常比例不低于0.4，则触发熔断。\n\n\n\n * 异常数：统计最近1000ms内的请求，如果请求量超过10次，并且异常数不低于2次，则触发熔断。\n\n\n\n * 授权规则：对调用方的来源做控制，有白名单和黑名单两种方式。我们允许请求从gateway到order-service，不允许浏览器访问order-service，那么白名单中就要填写网关的来源名称（origin）。\n\n\n\n * 规则持久化：控制台将配置规则推送到远程配置中心，例如Nacos。Sentinel客户端监听Nacos，获取配置变更的推送消息，完成本地配置更新。\n\n",normalizedContent:"# 雪崩问题\n\n\n\n微服务调用链路中的某个服务故障，引起整个链路中的所有微服务都不可用，这就是雪崩。\n\n解决雪崩问题的常见方式：\n\n * 超时处理：设定超时时间，请求超过一定时间没有响应就返回错误消息，不会无休止等待。（缓解作用）\n\n\n\n * 线程隔离：每一个服务弄一个线程池，固定每一个服务的请求数，这样一个服务挂了，不会导致其它服务的资源也耗尽。\n\n\n\n * 降级熔断：断路器统计某一个服务中的远程调用异常的比例，如果超过一个阈值，那么就停止它对其它服务进行远程调用。\n\n\n\n * 流量控制：从源头控制流量到这个服务，预防服务一次性接收的请求过多。\n\n\n\n总结\n\n限流是对服务的保护，避免因瞬间高并发流量而导致服务故障，进而避免雪崩。是一种预防措施。\n\n超时处理、线程隔离、降级熔断是在部分服务故障时，将故障控制在一定范围，避免雪崩。是一种补救措施。\n\n\n# sentinel\n\n隔离策略：\n\n * 线程池隔离：对每一个服务创建单独一个线程池\n\n * 信号量隔离：规定每个服务最大有几个线程，然后再去同一个线程池里拿线程。\n\n一些感念\n\n\n\n * 单机阈值：设置某个资源请求的qps最大值，超过部分返回流量控制错误。\n\n * 流控模式：\n   \n   * 直接\n   * 关联：当/write资源访问量触发阈值时，就会对/read资源限流，避免影响/write资源。（优先处理/write）\n   \n   \n   \n   * 链路：\n\n> 例如有两条请求链路：\n> \n> /test1 --\x3e /common\n> \n> /test2 --\x3e /common\n> \n> 如果只希望统计从/test2进入到/common的请求，则可以这样配置：\n\n\n\n * 流控效果：\n   \n   * 快速失败：达到阈值后，新的请求会被立即拒绝并抛出flowexception异常。默认的处理方式。\n   * warm up：预热模式，同上，但阈值会动态变化，从一个较小值逐渐增加到最大阈值。\n   * 排队等待：让所有的请求按照先后次序排队执行，两个请求的间隔不能小于指定时长。qps = 5，意味着每200ms处理一个队列中的请求；timeout = 2000，意味着预期等待时长超过2000ms的请求会被拒绝并抛出异常。\n\n * 热点参数限流：可能部分商品是热点商品，例如秒杀商品，我们希望这部分商品的qps限制与其它商品不一样，高一些。\n\n\n# 隔离和降级\n\n# 降级\n\n * feignclient远程调用失败降级\n * 编写降级方法，实现fallbackfactory接口，并给spring容器管理\n * 在feign接口中的方法头添加上fallbackfactory\n\n\n\n# 隔离\n\n线程池隔离：给每个服务调用业务分配一个线程池，利用线程池本身实现隔离效果。\n\n信号量隔离：不创建线程池，而是计数器模式，记录业务使用的线程数量，达到信号量上限时，禁止新的请求。\n\nsentinel中可以配置根据线程数来控制请求。\n\n\n\n# 熔断降级\n\n * 断路器状态\n\n\n\n * 慢调用：rt超过500ms的调用是慢调用，统计最近10000ms内的请求，如果请求量超过10次，并且慢调用比例不低于0.5，则触发熔断，熔断时长为5秒。然后进入half-open状态，放行一次请求做测试。\n\n\n\n * 异常比例：统计最近1000ms内的请求，如果请求量超过10次，并且异常比例不低于0.4，则触发熔断。\n\n\n\n * 异常数：统计最近1000ms内的请求，如果请求量超过10次，并且异常数不低于2次，则触发熔断。\n\n\n\n * 授权规则：对调用方的来源做控制，有白名单和黑名单两种方式。我们允许请求从gateway到order-service，不允许浏览器访问order-service，那么白名单中就要填写网关的来源名称（origin）。\n\n\n\n * 规则持久化：控制台将配置规则推送到远程配置中心，例如nacos。sentinel客户端监听nacos，获取配置变更的推送消息，完成本地配置更新。\n\n",charsets:{cjk:!0}},{title:"分布式缓存",frontmatter:{title:"分布式缓存",date:"2023-03-01T11:56:01.000Z",permalink:"/pages/566e96/"},regularPath:"/01.Java/03.%E5%BE%AE%E6%9C%8D%E5%8A%A1/03.Redis.html",relativePath:"01.Java/03.微服务/03.Redis.md",key:"v-2489de58",path:"/pages/566e96/",headers:[{level:2,title:"Redis持久化",slug:"redis持久化",normalizedTitle:"redis持久化",charIndex:142},{level:3,title:"RDB持久化",slug:"rdb持久化",normalizedTitle:"rdb持久化",charIndex:155},{level:3,title:"AOF持久化",slug:"aof持久化",normalizedTitle:"aof持久化",charIndex:682},{level:2,title:"Redis主从",slug:"redis主从",normalizedTitle:"redis主从",charIndex:763},{level:3,title:"全量同步",slug:"全量同步",normalizedTitle:"全量同步",charIndex:832},{level:3,title:"增量同步",slug:"增量同步",normalizedTitle:"增量同步",charIndex:1465},{level:2,title:"Redis哨兵",slug:"redis哨兵",normalizedTitle:"redis哨兵",charIndex:93},{level:3,title:"监控",slug:"监控",normalizedTitle:"监控",charIndex:1717},{level:3,title:"故障恢复",slug:"故障恢复",normalizedTitle:"故障恢复",charIndex:84},{level:2,title:"Redis分片集群",slug:"redis分片集群",normalizedTitle:"redis分片集群",charIndex:2594}],headersStr:"Redis持久化 RDB持久化 AOF持久化 Redis主从 全量同步 增量同步 Redis哨兵 监控 故障恢复 Redis分片集群",content:"基于Redis集群解决单机Redis存在的问题\n\n>  1. 数据丢失问题：实现Redis数据持久化\n>  2. 并发能力问题：搭建主从集群，实现读写分离\n>  3. 故障恢复问题：利用Redis哨兵，实现健康检测和自动恢复\n>  4. 存储能力问题：搭建分片集群，动态扩容\n\n\n# Redis持久化\n\n\n# RDB持久化\n\nRDB全称Redis Database Backup file（Redis数据备份文件），也被叫做Redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录。\n\n执行时机\n\n * 执行save命令\n\nsave命令会导致主进程执行RDB，这个过程中其它所有命令都会被阻塞。只有在数据迁移时可能用到。\n\n * 执行bgsave命令\n\n这个命令执行后会开启独立进程完成RDB，主进程可以持续处理用户请求，不受影响。\n\n * Redis停机时\n\nRedis停机时会执行一次save命令，实现RDB持久化。\n\n * 触发RDB条件时\n\nredis.conf配置触发RDB机制，可以配置多久内有多少个key发生变更，则执行bgsave命令\n\nbgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。\n\nfork采用的是copy-on-write技术：\n\n * 当主进程执行读操作时，访问共享内存；\n * 当主进程执行写操作时，则会拷贝一份数据，执行写操作。\n\n\n\n\n# AOF持久化\n\nAOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。\n\n\n\n\n# Redis主从\n\n单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离。\n\n\n\n\n# 全量同步\n\n主从第一次建立连接时，会执行全量同步，将master节点的所有数据都拷贝给slave节点，流程：\n\n\n\n * Replication Id：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid\n * offset：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。\n\n因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。\n\n因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。\n\nmaster判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。\n\nmaster会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。\n\n因此，master判断一个节点是否是第一次同步的依据，就是看replid是否一致。\n\n\n# 增量同步\n\n除了第一次做全量同步，其它大多数时候slave与master都是做增量同步。\n\n当大哥收到数据变更的命令时，以及每隔一段时间，将消息通知小弟来我这复制。\n\n\n\nrepl_baklog\n\nslave 的offset 不断追赶 master 的offset\n\n\n\n当master的offset 超过 slave的offset太多，那salve节点进行全量同步。\n\n\n# Redis哨兵\n\nRedis提供了哨兵（Sentinel）机制来实现主从集群的自动故障恢复。\n\n\n\n哨兵的作用如下：\n\n * 监控：Sentinel 会不断检查您的master和slave是否按预期工作\n * 自动故障恢复：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主\n * 通知：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端\n\n\n# 监控\n\nSentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令：\n\n•主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例主观下线。\n\n•客观下线：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好超过Sentinel实例数量的一半。\n\n\n# 故障恢复\n\n一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的：\n\n * 首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该slave节点\n * 然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举\n * 如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高\n * 最后是判断slave节点的运行id大小，越小优先级越高。\n\n当选出一个新的master后，该如何实现切换呢？\n\n流程如下：\n\n * sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master\n * sentinel给所有其它slave发送slaveof 192.168.150.101 7002 命令，让这些slave成为新master的从节点，开始从新的master上同步数据。\n * 最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点\n\n\n# Redis分片集群\n\n主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决：\n\n * 海量数据存储问题\n\n * 高并发写的问题\n\n使用分片集群可以解决上述问题，如图:\n\n\n\n分片集群特征：\n\n * 集群中有多个master，每个master保存不同数据\n\n * 每个master都可以有多个slave节点\n\n * master之间通过ping监测彼此健康状态\n\n * 客户端请求可以访问集群任意节点，最终都会被转发到正确节点",normalizedContent:"基于redis集群解决单机redis存在的问题\n\n>  1. 数据丢失问题：实现redis数据持久化\n>  2. 并发能力问题：搭建主从集群，实现读写分离\n>  3. 故障恢复问题：利用redis哨兵，实现健康检测和自动恢复\n>  4. 存储能力问题：搭建分片集群，动态扩容\n\n\n# redis持久化\n\n\n# rdb持久化\n\nrdb全称redis database backup file（redis数据备份文件），也被叫做redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。当redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为rdb文件，默认是保存在当前运行目录。\n\n执行时机\n\n * 执行save命令\n\nsave命令会导致主进程执行rdb，这个过程中其它所有命令都会被阻塞。只有在数据迁移时可能用到。\n\n * 执行bgsave命令\n\n这个命令执行后会开启独立进程完成rdb，主进程可以持续处理用户请求，不受影响。\n\n * redis停机时\n\nredis停机时会执行一次save命令，实现rdb持久化。\n\n * 触发rdb条件时\n\nredis.conf配置触发rdb机制，可以配置多久内有多少个key发生变更，则执行bgsave命令\n\nbgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 rdb 文件。\n\nfork采用的是copy-on-write技术：\n\n * 当主进程执行读操作时，访问共享内存；\n * 当主进程执行写操作时，则会拷贝一份数据，执行写操作。\n\n\n\n\n# aof持久化\n\naof全称为append only file（追加文件）。redis处理的每一个写命令都会记录在aof文件，可以看做是命令日志文件。\n\n\n\n\n# redis主从\n\n单节点redis的并发能力是有上限的，要进一步提高redis的并发能力，就需要搭建主从集群，实现读写分离。\n\n\n\n\n# 全量同步\n\n主从第一次建立连接时，会执行全量同步，将master节点的所有数据都拷贝给slave节点，流程：\n\n\n\n * replication id：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid\n * offset：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。\n\n因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。\n\n因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。\n\nmaster判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。\n\nmaster会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。\n\n因此，master判断一个节点是否是第一次同步的依据，就是看replid是否一致。\n\n\n# 增量同步\n\n除了第一次做全量同步，其它大多数时候slave与master都是做增量同步。\n\n当大哥收到数据变更的命令时，以及每隔一段时间，将消息通知小弟来我这复制。\n\n\n\nrepl_baklog\n\nslave 的offset 不断追赶 master 的offset\n\n\n\n当master的offset 超过 slave的offset太多，那salve节点进行全量同步。\n\n\n# redis哨兵\n\nredis提供了哨兵（sentinel）机制来实现主从集群的自动故障恢复。\n\n\n\n哨兵的作用如下：\n\n * 监控：sentinel 会不断检查您的master和slave是否按预期工作\n * 自动故障恢复：如果master故障，sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主\n * 通知：sentinel充当redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给redis的客户端\n\n\n# 监控\n\nsentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令：\n\n•主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例主观下线。\n\n•客观下线：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好超过sentinel实例数量的一半。\n\n\n# 故障恢复\n\n一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的：\n\n * 首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该slave节点\n * 然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举\n * 如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高\n * 最后是判断slave节点的运行id大小，越小优先级越高。\n\n当选出一个新的master后，该如何实现切换呢？\n\n流程如下：\n\n * sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master\n * sentinel给所有其它slave发送slaveof 192.168.150.101 7002 命令，让这些slave成为新master的从节点，开始从新的master上同步数据。\n * 最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点\n\n\n# redis分片集群\n\n主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决：\n\n * 海量数据存储问题\n\n * 高并发写的问题\n\n使用分片集群可以解决上述问题，如图:\n\n\n\n分片集群特征：\n\n * 集群中有多个master，每个master保存不同数据\n\n * 每个master都可以有多个slave节点\n\n * master之间通过ping监测彼此健康状态\n\n * 客户端请求可以访问集群任意节点，最终都会被转发到正确节点",charsets:{cjk:!0}},{title:"缓存同步",frontmatter:{title:"缓存同步",date:"2023-03-02T11:27:30.000Z",permalink:"/pages/663ad9/"},regularPath:"/01.Java/03.%E5%BE%AE%E6%9C%8D%E5%8A%A1/04.Canal.html",relativePath:"01.Java/03.微服务/04.Canal.md",key:"v-52136b18",path:"/pages/663ad9/",headers:[{level:2,title:"多级缓存",slug:"多级缓存",normalizedTitle:"多级缓存",charIndex:2},{level:2,title:"JVM进程缓存",slug:"jvm进程缓存",normalizedTitle:"jvm进程缓存",charIndex:341},{level:2,title:"OpenResty多级缓存",slug:"openresty多级缓存",normalizedTitle:"openresty多级缓存",charIndex:409},{level:2,title:"缓存同步",slug:"缓存同步",normalizedTitle:"缓存同步",charIndex:427},{level:3,title:"数据同步策略",slug:"数据同步策略",normalizedTitle:"数据同步策略",charIndex:529}],headersStr:"多级缓存 JVM进程缓存 OpenResty多级缓存 缓存同步 数据同步策略",content:"# 多级缓存\n\n传统的缓存策略一般是请求到达Tomcat后，先查询Redis，如果未命中则查询数据库，如图：\n\n\n\n存在下面的问题：\n\n•请求要经过Tomcat处理，Tomcat的性能成为整个系统的瓶颈\n\n•Redis缓存失效时，会对数据库产生冲击\n\n多级缓存就是充分利用请求处理的每个环节，分别添加缓存，减轻Tomcat压力，提升服务性能：\n\n * 浏览器访问静态资源时，优先读取浏览器本地缓存\n * 访问非静态资源（ajax查询数据）时，访问服务端\n * 请求到达Nginx后，优先读取Nginx本地缓存\n * 如果Nginx本地缓存未命中，则去直接查询Redis（不经过Tomcat）\n * 如果Redis查询未命中，则查询Tomcat\n * 请求进入Tomcat后，优先查询JVM进程缓存\n * 如果JVM进程缓存未命中，则查询数据库\n\n\n\n反正前面一堆缓存，数据库就是个宝宝\n\n\n# JVM进程缓存\n\n\n# OpenResty多级缓存\n\n\n# 缓存同步\n\n大多数情况下，浏览器查询到的都是缓存数据，如果缓存数据与数据库数据存在较大差异，可能会产生比较严重的后果。\n\n所以我们必须保证数据库数据、缓存数据的一致性，这就是缓存与数据库的同步。\n\n\n# 数据同步策略\n\n缓存数据同步的常见方式有三种：\n\n设置有效期：给缓存设置有效期，到期后自动删除。再次查询时更新\n\n * 优势：简单、方便\n * 缺点：时效性差，缓存过期之前可能不一致\n * 场景：更新频率较低，时效性要求低的业务\n\n同步双写：在修改数据库的同时，直接修改缓存\n\n * 优势：时效性强，缓存与数据库强一致\n * 缺点：有代码侵入，耦合度高；\n * 场景：对一致性、时效性要求较高的缓存数据\n\n**异步通知：**修改数据库时发送事件通知，相关服务监听到通知后修改缓存数据\n\n * 优势：低耦合，可以同时通知多个缓存服务\n * 缺点：时效性一般，可能存在中间不一致状态\n * 场景：时效性要求一般，有多个服务需要同步\n\n而异步实现又可以基于MQ或者Canal来实现：\n\n1）基于MQ的异步通知：\n\n\n\n解读：\n\n * 商品服务完成对数据的修改后，只需要发送一条消息到MQ中。\n * 缓存服务监听MQ消息，然后完成对缓存的更新\n\n依然有少量的代码侵入。\n\n2）基于Canal的通知\n\n\n\n解读：\n\n * 商品服务完成商品修改后，业务直接结束，没有任何代码侵入\n * Canal监听MySQL变化，当发现变化后，立即通知缓存服务\n * 缓存服务接收到canal通知，更新缓存\n\n代码零侵入",normalizedContent:"# 多级缓存\n\n传统的缓存策略一般是请求到达tomcat后，先查询redis，如果未命中则查询数据库，如图：\n\n\n\n存在下面的问题：\n\n•请求要经过tomcat处理，tomcat的性能成为整个系统的瓶颈\n\n•redis缓存失效时，会对数据库产生冲击\n\n多级缓存就是充分利用请求处理的每个环节，分别添加缓存，减轻tomcat压力，提升服务性能：\n\n * 浏览器访问静态资源时，优先读取浏览器本地缓存\n * 访问非静态资源（ajax查询数据）时，访问服务端\n * 请求到达nginx后，优先读取nginx本地缓存\n * 如果nginx本地缓存未命中，则去直接查询redis（不经过tomcat）\n * 如果redis查询未命中，则查询tomcat\n * 请求进入tomcat后，优先查询jvm进程缓存\n * 如果jvm进程缓存未命中，则查询数据库\n\n\n\n反正前面一堆缓存，数据库就是个宝宝\n\n\n# jvm进程缓存\n\n\n# openresty多级缓存\n\n\n# 缓存同步\n\n大多数情况下，浏览器查询到的都是缓存数据，如果缓存数据与数据库数据存在较大差异，可能会产生比较严重的后果。\n\n所以我们必须保证数据库数据、缓存数据的一致性，这就是缓存与数据库的同步。\n\n\n# 数据同步策略\n\n缓存数据同步的常见方式有三种：\n\n设置有效期：给缓存设置有效期，到期后自动删除。再次查询时更新\n\n * 优势：简单、方便\n * 缺点：时效性差，缓存过期之前可能不一致\n * 场景：更新频率较低，时效性要求低的业务\n\n同步双写：在修改数据库的同时，直接修改缓存\n\n * 优势：时效性强，缓存与数据库强一致\n * 缺点：有代码侵入，耦合度高；\n * 场景：对一致性、时效性要求较高的缓存数据\n\n**异步通知：**修改数据库时发送事件通知，相关服务监听到通知后修改缓存数据\n\n * 优势：低耦合，可以同时通知多个缓存服务\n * 缺点：时效性一般，可能存在中间不一致状态\n * 场景：时效性要求一般，有多个服务需要同步\n\n而异步实现又可以基于mq或者canal来实现：\n\n1）基于mq的异步通知：\n\n\n\n解读：\n\n * 商品服务完成对数据的修改后，只需要发送一条消息到mq中。\n * 缓存服务监听mq消息，然后完成对缓存的更新\n\n依然有少量的代码侵入。\n\n2）基于canal的通知\n\n\n\n解读：\n\n * 商品服务完成商品修改后，业务直接结束，没有任何代码侵入\n * canal监听mysql变化，当发现变化后，立即通知缓存服务\n * 缓存服务接收到canal通知，更新缓存\n\n代码零侵入",charsets:{cjk:!0}},{title:"常见面试题",frontmatter:{title:"常见面试题",date:"2023-03-02T15:18:04.000Z",permalink:"/pages/78eabe/"},regularPath:"/01.Java/03.%E5%BE%AE%E6%9C%8D%E5%8A%A1/05.%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98.html",relativePath:"01.Java/03.微服务/05.常见面试题.md",key:"v-ec24f742",path:"/pages/78eabe/",headers:[{level:2,title:"1.1.SpringCloud常见组件有哪些？",slug:"_1-1-springcloud常见组件有哪些",normalizedTitle:"1.1.springcloud常见组件有哪些？",charIndex:23},{level:2,title:"1.2.Nacos的服务注册表结构是怎样的？",slug:"_1-2-nacos的服务注册表结构是怎样的",normalizedTitle:"1.2.nacos的服务注册表结构是怎样的？",charIndex:281},{level:2,title:"1.3.Nacos如何支撑阿里内部数十万服务注册压力？",slug:"_1-3-nacos如何支撑阿里内部数十万服务注册压力",normalizedTitle:"1.3.nacos如何支撑阿里内部数十万服务注册压力？",charIndex:730},{level:2,title:"1.4.Nacos如何避免并发读写冲突问题？",slug:"_1-4-nacos如何避免并发读写冲突问题",normalizedTitle:"1.4.nacos如何避免并发读写冲突问题？",charIndex:892},{level:2,title:"1.5.Nacos与Eureka的区别有哪些？",slug:"_1-5-nacos与eureka的区别有哪些",normalizedTitle:"1.5.nacos与eureka的区别有哪些？",charIndex:1075},{level:2,title:"1.6.Sentinel的限流与Gateway的限流有什么差别？",slug:"_1-6-sentinel的限流与gateway的限流有什么差别",normalizedTitle:"1.6.sentinel的限流与gateway的限流有什么差别？",charIndex:1385},{level:2,title:"1.7.Sentinel的线程隔离与Hystix的线程隔离有什么差别?",slug:"_1-7-sentinel的线程隔离与hystix的线程隔离有什么差别",normalizedTitle:"1.7.sentinel的线程隔离与hystix的线程隔离有什么差别?",charIndex:1597},{level:2,title:"2.1.你们为什么选择了RabbitMQ而不是其它的MQ？",slug:"_2-1-你们为什么选择了rabbitmq而不是其它的mq",normalizedTitle:"2.1.你们为什么选择了rabbitmq而不是其它的mq？",charIndex:1809},{level:2,title:"2.2.RabbitMQ如何确保消息的不丢失？",slug:"_2-2-rabbitmq如何确保消息的不丢失",normalizedTitle:"2.2.rabbitmq如何确保消息的不丢失？",charIndex:2202},{level:2,title:"2.3.RabbitMQ如何避免消息堆积？",slug:"_2-3-rabbitmq如何避免消息堆积",normalizedTitle:"2.3.rabbitmq如何避免消息堆积？",charIndex:3343},{level:2,title:"2.4.RabbitMQ如何保证消息的有序性？",slug:"_2-4-rabbitmq如何保证消息的有序性",normalizedTitle:"2.4.rabbitmq如何保证消息的有序性？",charIndex:3898},{level:2,title:"2.5.如何防止MQ消息被重复消费？",slug:"_2-5-如何防止mq消息被重复消费",normalizedTitle:"2.5.如何防止mq消息被重复消费？",charIndex:4116},{level:2,title:"2.6.如何保证RabbitMQ的高可用？",slug:"_2-6-如何保证rabbitmq的高可用",normalizedTitle:"2.6.如何保证rabbitmq的高可用？",charIndex:4391},{level:2,title:"2.7.使用MQ可以解决那些问题？",slug:"_2-7-使用mq可以解决那些问题",normalizedTitle:"2.7.使用mq可以解决那些问题？",charIndex:4512},{level:2,title:"3.1.Redis与Memcache的区别？",slug:"_3-1-redis与memcache的区别",normalizedTitle:"3.1.redis与memcache的区别？",charIndex:4764},{level:2,title:"3.2.Redis的单线程问题",slug:"_3-2-redis的单线程问题",normalizedTitle:"3.2.redis的单线程问题",charIndex:5119},{level:2,title:"3.2.Redis的持久化方案由哪些？",slug:"_3-2-redis的持久化方案由哪些",normalizedTitle:"3.2.redis的持久化方案由哪些？",charIndex:5373},{level:2,title:"3.3.Redis的集群方式有哪些？",slug:"_3-3-redis的集群方式有哪些",normalizedTitle:"3.3.redis的集群方式有哪些？",charIndex:7732},{level:2,title:"3.4.Redis的常用数据类型有哪些？",slug:"_3-4-redis的常用数据类型有哪些",normalizedTitle:"3.4.redis的常用数据类型有哪些？",charIndex:8682},{level:2,title:"3.5.聊一下Redis事务机制",slug:"_3-5-聊一下redis事务机制",normalizedTitle:"3.5.聊一下redis事务机制",charIndex:8881},{level:2,title:"3.6.Redis的Key过期策略",slug:"_3-6-redis的key过期策略",normalizedTitle:"3.6.redis的key过期策略",charIndex:10303},{level:3,title:"参考资料：",slug:"参考资料",normalizedTitle:"参考资料：",charIndex:10325},{level:4,title:"为什么需要内存回收？",slug:"为什么需要内存回收",normalizedTitle:"为什么需要内存回收？",charIndex:10334},{level:4,title:"过期删除策略",slug:"过期删除策略",normalizedTitle:"过期删除策略",charIndex:10542},{level:4,title:"内存淘汰策略",slug:"内存淘汰策略",normalizedTitle:"内存淘汰策略",charIndex:10549},{level:3,title:"面试话术：",slug:"面试话术",normalizedTitle:"面试话术：",charIndex:5161},{level:2,title:"3.7.Redis在项目中的哪些地方有用到?",slug:"_3-7-redis在项目中的哪些地方有用到",normalizedTitle:"3.7.redis在项目中的哪些地方有用到?",charIndex:12481},{level:2,title:"3.8.Redis的缓存击穿、缓存雪崩、缓存穿透",slug:"_3-8-redis的缓存击穿、缓存雪崩、缓存穿透",normalizedTitle:"3.8.redis的缓存击穿、缓存雪崩、缓存穿透",charIndex:12890},{level:3,title:"1）缓存穿透",slug:"_1-缓存穿透",normalizedTitle:"1）缓存穿透",charIndex:12919},{level:3,title:"2）缓存击穿",slug:"_2-缓存击穿",normalizedTitle:"2）缓存击穿",charIndex:13706},{level:3,title:"3）缓存雪崩",slug:"_3-缓存雪崩",normalizedTitle:"3）缓存雪崩",charIndex:14378},{level:2,title:"3.9.缓存冷热数据分离",slug:"_3-9-缓存冷热数据分离",normalizedTitle:"3.9.缓存冷热数据分离",charIndex:14746},{level:2,title:"3.10.Redis实现分布式锁",slug:"_3-10-redis实现分布式锁",normalizedTitle:"3.10.redis实现分布式锁",charIndex:15253},{level:3,title:"1）最基本的分布式锁：",slug:"_1-最基本的分布式锁",normalizedTitle:"1）最基本的分布式锁：",charIndex:15400},{level:3,title:"2）可重入分布式锁",slug:"_2-可重入分布式锁",normalizedTitle:"2）可重入分布式锁",charIndex:15914},{level:3,title:"3）高可用的锁",slug:"_3-高可用的锁",normalizedTitle:"3）高可用的锁",charIndex:17597},{level:2,title:"3.11.如何实现数据库与缓存数据一致？",slug:"_3-11-如何实现数据库与缓存数据一致",normalizedTitle:"3.11.如何实现数据库与缓存数据一致？",charIndex:18568}],headersStr:"1.1.SpringCloud常见组件有哪些？ 1.2.Nacos的服务注册表结构是怎样的？ 1.3.Nacos如何支撑阿里内部数十万服务注册压力？ 1.4.Nacos如何避免并发读写冲突问题？ 1.5.Nacos与Eureka的区别有哪些？ 1.6.Sentinel的限流与Gateway的限流有什么差别？ 1.7.Sentinel的线程隔离与Hystix的线程隔离有什么差别? 2.1.你们为什么选择了RabbitMQ而不是其它的MQ？ 2.2.RabbitMQ如何确保消息的不丢失？ 2.3.RabbitMQ如何避免消息堆积？ 2.4.RabbitMQ如何保证消息的有序性？ 2.5.如何防止MQ消息被重复消费？ 2.6.如何保证RabbitMQ的高可用？ 2.7.使用MQ可以解决那些问题？ 3.1.Redis与Memcache的区别？ 3.2.Redis的单线程问题 3.2.Redis的持久化方案由哪些？ 3.3.Redis的集群方式有哪些？ 3.4.Redis的常用数据类型有哪些？ 3.5.聊一下Redis事务机制 3.6.Redis的Key过期策略 参考资料： 为什么需要内存回收？ 过期删除策略 内存淘汰策略 面试话术： 3.7.Redis在项目中的哪些地方有用到? 3.8.Redis的缓存击穿、缓存雪崩、缓存穿透 1）缓存穿透 2）缓存击穿 3）缓存雪崩 3.9.缓存冷热数据分离 3.10.Redis实现分布式锁 1）最基本的分布式锁： 2）可重入分布式锁 3）高可用的锁 3.11.如何实现数据库与缓存数据一致？",content:"# 常见面试题\n\n\n# 1.微服务篇\n\n\n# 1.1.SpringCloud常见组件有哪些？\n\n问题说明：这个题目主要考察对SpringCloud的组件基本了解\n\n难易程度：简单\n\n参考话术：\n\nSpringCloud包含的组件很多，有很多功能是重复的。其中最常用组件包括：\n\n•注册中心组件：Eureka、Nacos等\n\n•负载均衡组件：Ribbon\n\n•远程调用组件：OpenFeign\n\n•网关组件：Zuul、Gateway\n\n•服务保护组件：Hystrix、Sentinel\n\n•服务配置管理组件：SpringCloudConfig、Nacos\n\n\n# 1.2.Nacos的服务注册表结构是怎样的？\n\n问题说明：考察对Nacos数据分级结构的了解，以及Nacos源码的掌握情况\n\n难易程度：一般\n\n参考话术：\n\nNacos采用了数据的分级存储模型，最外层是Namespace，用来隔离环境。然后是Group，用来对服务分组。接下来就是服务（Service）了，一个服务包含多个实例，但是可能处于不同机房，因此Service下有多个集群（Cluster），Cluster下是不同的实例（Instance）。\n\n对应到Java代码中，Nacos采用了一个多层的Map来表示。结构为Map<String, Map<String, Service>>，其中最外层Map的key就是namespaceId，值是一个Map。内层Map的key是group拼接serviceName，值是Service对象。Service对象内部又是一个Map，key是集群名称，值是Cluster对象。而Cluster对象内部维护了Instance的集合。\n\n如图：\n\n\n\n\n# 1.3.Nacos如何支撑阿里内部数十万服务注册压力？\n\n问题说明：考察对Nacos源码的掌握情况\n\n难易程度：难\n\n参考话术：\n\nNacos内部接收到注册的请求时，不会立即写数据，而是将服务注册的任务放入一个阻塞队列就立即响应给客户端。然后利用线程池读取阻塞队列中的任务，异步来完成实例更新，从而提高并发写能力。\n\n\n# 1.4.Nacos如何避免并发读写冲突问题？\n\n问题说明：考察对Nacos源码的掌握情况\n\n难易程度：难\n\n参考话术：\n\nNacos在更新实例列表时，会采用CopyOnWrite技术，首先将旧的实例列表拷贝一份，然后更新拷贝的实例列表，再用更新后的实例列表来覆盖旧的实例列表。\n\n这样在更新的过程中，就不会对读实例列表的请求产生影响，也不会出现脏读问题了。\n\n\n# 1.5.Nacos与Eureka的区别有哪些？\n\n问题说明：考察对Nacos、Eureka的底层实现的掌握情况\n\n难易程度：难\n\n参考话术：\n\nNacos与Eureka有相同点，也有不同之处，可以从以下几点来描述：\n\n * 接口方式：Nacos与Eureka都对外暴露了Rest风格的API接口，用来实现服务注册、发现等功能\n * 实例类型：Nacos的实例有永久和临时实例之分；而Eureka只支持临时实例\n * 健康检测：Nacos对临时实例采用心跳模式检测，对永久实例采用主动请求来检测；Eureka只支持心跳模式\n * 服务发现：Nacos支持定时拉取和订阅推送两种模式；Eureka只支持定时拉取模式\n\n\n# 1.6.Sentinel的限流与Gateway的限流有什么差别？\n\n问题说明：考察对限流算法的掌握情况\n\n难易程度：难\n\n参考话术：\n\n限流算法常见的有三种实现：滑动时间窗口、令牌桶算法、漏桶算法。Gateway则采用了基于Redis实现的令牌桶算法。\n\n而Sentinel内部却比较复杂：\n\n * 默认限流模式是基于滑动时间窗口算法\n * 排队等待的限流模式则基于漏桶算法\n * 而热点参数限流则是基于令牌桶算法\n\n\n# 1.7.Sentinel的线程隔离与Hystix的线程隔离有什么差别?\n\n问题说明：考察对线程隔离方案的掌握情况\n\n难易程度：一般\n\n参考话术：\n\nHystix默认是基于线程池实现的线程隔离，每一个被隔离的业务都要创建一个独立的线程池，线程过多会带来额外的CPU开销，性能一般，但是隔离性更强。\n\nSentinel是基于信号量（计数器）实现的线程隔离，不用创建线程池，性能较好，但是隔离性一般。\n\n\n# 2.MQ篇\n\n\n# 2.1.你们为什么选择了RabbitMQ而不是其它的MQ？\n\n如图：\n\n\n\n话术：\n\nkafka是以吞吐量高而闻名，不过其数据稳定性一般，而且无法保证消息有序性。我们公司的日志收集也有使用，业务模块中则使用的RabbitMQ。\n\n阿里巴巴的RocketMQ基于Kafka的原理，弥补了Kafka的缺点，继承了其高吞吐的优势，其客户端目前以Java为主。但是我们担心阿里巴巴开源产品的稳定性，所以就没有使用。\n\nRabbitMQ基于面向并发的语言Erlang开发，吞吐量不如Kafka，但是对我们公司来讲够用了。而且消息可靠性较好，并且消息延迟极低，集群搭建比较方便。支持多种协议，并且有各种语言的客户端，比较灵活。Spring对RabbitMQ的支持也比较好，使用起来比较方便，比较符合我们公司的需求。\n\n综合考虑我们公司的并发需求以及稳定性需求，我们选择了RabbitMQ。\n\n\n# 2.2.RabbitMQ如何确保消息的不丢失？\n\n话术：\n\nRabbitMQ针对消息传递过程中可能发生问题的各个地方，给出了针对性的解决方案：\n\n * 生产者发送消息时可能因为网络问题导致消息没有到达交换机：\n   * RabbitMQ提供了publisher confirm机制\n     * 生产者发送消息后，可以编写ConfirmCallback函数\n     * 消息成功到达交换机后，RabbitMQ会调用ConfirmCallback通知消息的发送者，返回ACK\n     * 消息如果未到达交换机，RabbitMQ也会调用ConfirmCallback通知消息的发送者，返回NACK\n     * 消息超时未发送成功也会抛出异常\n * 消息到达交换机后，如果未能到达队列，也会导致消息丢失：\n   * RabbitMQ提供了publisher return机制\n     * 生产者可以定义ReturnCallback函数\n     * 消息到达交换机，未到达队列，RabbitMQ会调用ReturnCallback通知发送者，告知失败原因\n * 消息到达队列后，MQ宕机也可能导致丢失消息：\n   * RabbitMQ提供了持久化功能，集群的主从备份功能\n     * 消息持久化，RabbitMQ会将交换机、队列、消息持久化到磁盘，宕机重启可以恢复消息\n     * 镜像集群，仲裁队列，都可以提供主从备份功能，主节点宕机，从节点会自动切换为主，数据依然在\n * 消息投递给消费者后，如果消费者处理不当，也可能导致消息丢失\n   * SpringAMQP基于RabbitMQ提供了消费者确认机制、消费者重试机制，消费者失败处理策略：\n     * 消费者的确认机制：\n       * 消费者处理消息成功，未出现异常时，Spring返回ACK给RabbitMQ，消息才被移除\n       * 消费者处理消息失败，抛出异常，宕机，Spring返回NACK或者不返回结果，消息不被异常\n     * 消费者重试机制：\n       * 默认情况下，消费者处理失败时，消息会再次回到MQ队列，然后投递给其它消费者。Spring提供的消费者重试机制，则是在处理失败后不返回NACK，而是直接在消费者本地重试。多次重试都失败后，则按照消费者失败处理策略来处理消息。避免了消息频繁入队带来的额外压力。\n     * 消费者失败策略：\n       * 当消费者多次本地重试失败时，消息默认会丢弃。\n       * Spring提供了Republish策略，在多次重试都失败，耗尽重试次数后，将消息重新投递给指定的异常交换机，并且会携带上异常栈信息，帮助定位问题。\n\n\n# 2.3.RabbitMQ如何避免消息堆积？\n\n话术：\n\n消息堆积问题产生的原因往往是因为消息发送的速度超过了消费者消息处理的速度。因此解决方案无外乎以下三点：\n\n * 提高消费者处理速度\n * 增加更多消费者\n * 增加队列消息存储上限\n\n1）提高消费者处理速度\n\n消费者处理速度是由业务代码决定的，所以我们能做的事情包括：\n\n * 尽可能优化业务代码，提高业务性能\n * 接收到消息后，开启线程池，并发处理多个消息\n\n优点：成本低，改改代码即可\n\n缺点：开启线程池会带来额外的性能开销，对于高频、低时延的任务不合适。推荐任务执行周期较长的业务。\n\n2）增加更多消费者\n\n一个队列绑定多个消费者，共同争抢任务，自然可以提供消息处理的速度。\n\n优点：能用钱解决的问题都不是问题。实现简单粗暴\n\n缺点：问题是没有钱。成本太高\n\n3）增加队列消息存储上限\n\n在RabbitMQ的1.8版本后，加入了新的队列模式：Lazy Queue\n\n这种队列不会将消息保存在内存中，而是在收到消息后直接写入磁盘中，理论上没有存储上限。可以解决消息堆积问题。\n\n优点：磁盘存储更安全；存储无上限；避免内存存储带来的Page Out问题，性能更稳定；\n\n缺点：磁盘存储受到IO性能的限制，消息时效性不如内存模式，但影响不大。\n\n\n# 2.4.RabbitMQ如何保证消息的有序性？\n\n话术：\n\n其实RabbitMQ是队列存储，天然具备先进先出的特点，只要消息的发送是有序的，那么理论上接收也是有序的。不过当一个队列绑定了多个消费者时，可能出现消息轮询投递给消费者的情况，而消费者的处理顺序就无法保证了。\n\n因此，要保证消息的有序性，需要做的下面几点：\n\n * 保证消息发送的有序性\n * 保证一组有序的消息都发送到同一个队列\n * 保证一个队列只包含一个消费者\n\n\n# 2.5.如何防止MQ消息被重复消费？\n\n话术：\n\n消息重复消费的原因多种多样，不可避免。所以只能从消费者端入手，只要能保证消息处理的幂等性就可以确保消息不被重复消费。\n\n而幂等性的保证又有很多方案：\n\n * 给每一条消息都添加一个唯一id，在本地记录消息表及消息状态，处理消息时基于数据库表的id唯一性做判断\n * 同样是记录消息表，利用消息状态字段实现基于乐观锁的判断，保证幂等\n * 基于业务本身的幂等性。比如根据id的删除、查询业务天生幂等；新增、修改等业务可以考虑基于数据库id唯一性、或者乐观锁机制确保幂等。本质与消息表方案类似。\n\n\n# 2.6.如何保证RabbitMQ的高可用？\n\n话术：\n\n要实现RabbitMQ的高可用无外乎下面两点：\n\n * 做好交换机、队列、消息的持久化\n * 搭建RabbitMQ的镜像集群，做好主从备份。当然也可以使用仲裁队列代替镜像集群。\n\n\n# 2.7.使用MQ可以解决那些问题？\n\n话术：\n\nRabbitMQ能解决的问题很多，例如：\n\n * 解耦合：将几个业务关联的微服务调用修改为基于MQ的异步通知，可以解除微服务之间的业务耦合。同时还提高了业务性能。\n * 流量削峰：将突发的业务请求放入MQ中，作为缓冲区。后端的业务根据自己的处理能力从MQ中获取消息，逐个处理任务。流量曲线变的平滑很多\n * 延迟队列：基于RabbitMQ的死信队列或者DelayExchange插件，可以实现消息发送后，延迟接收的效果。\n\n\n# 3.Redis篇\n\n\n# 3.1.Redis与Memcache的区别？\n\n * redis支持更丰富的数据类型（支持更复杂的应用场景）：Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。\n * Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中。\n * 集群模式：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的.\n * Redis使用单线程：Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。\n\n\n\n\n# 3.2.Redis的单线程问题\n\n面试官：Redis采用单线程，如何保证高并发？\n\n面试话术：\n\nRedis快的主要原因是：\n\n 1. 完全基于内存\n 2. 数据结构简单，对数据操作也简单\n 3. 使用多路 I/O 复用模型，充分利用CPU资源\n\n面试官：这样做的好处是什么？\n\n面试话术：\n\n单线程优势有下面几点：\n\n * 代码更清晰，处理逻辑更简单\n * 不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为锁而导致的性能消耗\n * 不存在多进程或者多线程导致的CPU切换，充分利用CPU资源\n\n\n# 3.2.Redis的持久化方案由哪些？\n\n相关资料：\n\n1）RDB 持久化\n\nRDB持久化可以使用save或bgsave，为了不阻塞主进程业务，一般都使用bgsave，流程：\n\n * Redis 进程会 fork 出一个子进程（与父进程内存数据一致）。\n * 父进程继续处理客户端请求命令\n * 由子进程将内存中的所有数据写入到一个临时的 RDB 文件中。\n * 完成写入操作之后，旧的 RDB 文件会被新的 RDB 文件替换掉。\n\n下面是一些和 RDB 持久化相关的配置：\n\n * save 60 10000：如果在 60 秒内有 10000 个 key 发生改变，那就执行 RDB 持久化。\n * stop-writes-on-bgsave-error yes：如果 Redis 执行 RDB 持久化失败（常见于操作系统内存不足），那么 Redis 将不再接受 client 写入数据的请求。\n * rdbcompression yes：当生成 RDB 文件时，同时进行压缩。\n * dbfilename dump.rdb：将 RDB 文件命名为 dump.rdb。\n * dir /var/lib/redis：将 RDB 文件保存在/var/lib/redis目录下。\n\n当然在实践中，我们通常会将stop-writes-on-bgsave-error设置为false，同时让监控系统在 Redis 执行 RDB 持久化失败时发送告警，以便人工介入解决，而不是粗暴地拒绝 client 的写入请求。\n\nRDB持久化的优点：\n\n * RDB持久化文件小，Redis数据恢复时速度快\n * 子进程不影响父进程，父进程可以持续处理客户端命令\n * 子进程fork时采用copy-on-write方式，大多数情况下，没有太多的内存消耗，效率比较好。\n\nRDB 持久化的缺点：\n\n * 子进程fork时采用copy-on-write方式，如果Redis此时写操作较多，可能导致额外的内存占用，甚至内存溢出\n * RDB文件压缩会减小文件体积，但通过时会对CPU有额外的消耗\n * 如果业务场景很看重数据的持久性 (durability)，那么不应该采用 RDB 持久化。譬如说，如果 Redis 每 5 分钟执行一次 RDB 持久化，要是 Redis 意外奔溃了，那么最多会丢失 5 分钟的数据。\n\n2）AOF 持久化\n\n可以使用appendonly yes配置项来开启 AOF 持久化。Redis 执行 AOF 持久化时，会将接收到的写命令追加到 AOF 文件的末尾，因此 Redis 只要对 AOF 文件中的命令进行回放，就可以将数据库还原到原先的状态。 　　与 RDB 持久化相比，AOF 持久化的一个明显优势就是，它可以提高数据的持久性 (durability)。因为在 AOF 模式下，Redis 每次接收到 client 的写命令，就会将命令write()到 AOF 文件末尾。 　　然而，在 Linux 中，将数据write()到文件后，数据并不会立即刷新到磁盘，而会先暂存在 OS 的文件系统缓冲区。在合适的时机，OS 才会将缓冲区的数据刷新到磁盘（如果需要将文件内容刷新到磁盘，可以调用fsync()或fdatasync()）。 　　通过appendfsync配置项，可以控制 Redis 将命令同步到磁盘的频率：\n\n * always：每次 Redis 将命令write()到 AOF 文件时，都会调用fsync()，将命令刷新到磁盘。这可以保证最好的数据持久性，但却会给系统带来极大的开销。\n * no：Redis 只将命令write()到 AOF 文件。这会让 OS 决定何时将命令刷新到磁盘。\n * everysec：除了将命令write()到 AOF 文件，Redis 还会每秒执行一次fsync()。在实践中，推荐使用这种设置，一定程度上可以保证数据持久性，又不会明显降低 Redis 性能。\n\n然而，AOF 持久化并不是没有缺点的：Redis 会不断将接收到的写命令追加到 AOF 文件中，导致 AOF 文件越来越大。过大的 AOF 文件会消耗磁盘空间，并且导致 Redis 重启时更加缓慢。为了解决这个问题，在适当情况下，Redis 会对 AOF 文件进行重写，去除文件中冗余的命令，以减小 AOF 文件的体积。在重写 AOF 文件期间， Redis 会启动一个子进程，由子进程负责对 AOF 文件进行重写。 　　可以通过下面两个配置项，控制 Redis 重写 AOF 文件的频率：\n\n * auto-aof-rewrite-min-size 64mb\n * auto-aof-rewrite-percentage 100\n\n上面两个配置的作用：当 AOF 文件的体积大于 64MB，并且 AOF 文件的体积比上一次重写之后的体积大了至少一倍，那么 Redis 就会执行 AOF 重写。\n\n优点：\n\n * 持久化频率高，数据可靠性高\n * 没有额外的内存或CPU消耗\n\n缺点：\n\n * 文件体积大\n * 文件大导致服务数据恢复时效率较低\n\n面试话术：\n\nRedis 提供了两种数据持久化的方式，一种是 RDB，另一种是 AOF。默认情况下，Redis 使用的是 RDB 持久化。\n\nRDB持久化文件体积较小，但是保存数据的频率一般较低，可靠性差，容易丢失数据。另外RDB写数据时会采用Fork函数拷贝主进程，可能有额外的内存消耗，文件压缩也会有额外的CPU消耗。\n\nROF持久化可以做到每秒钟持久化一次，可靠性高。但是持久化文件体积较大，导致数据恢复时读取文件时间较长，效率略低\n\n\n# 3.3.Redis的集群方式有哪些？\n\n面试话术：\n\nRedis集群可以分为主从集群和分片集群两类。\n\n主从集群一般一主多从，主库用来写数据，从库用来读数据。结合哨兵，可以再主库宕机时从新选主，目的是保证Redis的高可用。\n\n分片集群是数据分片，我们会让多个Redis节点组成集群，并将16383个插槽分到不同的节点上。存储数据时利用对key做hash运算，得到插槽值后存储到对应的节点即可。因为存储数据面向的是插槽而非节点本身，因此可以做到集群动态伸缩。目的是让Redis能存储更多数据。\n\n1）主从集群\n\n主从集群，也是读写分离集群。一般都是一主多从方式。\n\nRedis 的复制（replication）功能允许用户根据一个 Redis 服务器来创建任意多个该服务器的复制品，其中被复制的服务器为主服务器（master），而通过复制创建出来的服务器复制品则为从服务器（slave）。\n\n只要主从服务器之间的网络连接正常，主从服务器两者会具有相同的数据，主服务器就会一直将发生在自己身上的数据更新同步 给从服务器，从而一直保证主从服务器的数据相同。\n\n * 写数据时只能通过主节点完成\n * 读数据可以从任何节点完成\n * 如果配置了哨兵节点，当master宕机时，哨兵会从salve节点选出一个新的主。\n\n主从集群分两种：\n\n\n\n带有哨兵的集群：\n\n\n\n2）分片集群\n\n主从集群中，每个节点都要保存所有信息，容易形成木桶效应。并且当数据量较大时，单个机器无法满足需求。此时我们就要使用分片集群了。\n\n\n\n集群特征：\n\n * 每个节点都保存不同数据\n\n * 所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽.\n\n * 节点的fail是通过集群中超过半数的节点检测失效时才生效.\n\n * 客户端与redis节点直连,不需要中间proxy层连接集群中任何一个可用节点都可以访问到数据\n\n * redis-cluster把所有的物理节点映射到[0-16383]slot（插槽）上，实现动态伸缩\n\n为了保证Redis中每个节点的高可用，我们还可以给每个节点创建replication（slave节点），如图：\n\n\n\n出现故障时，主从可以及时切换：\n\n\n\n\n# 3.4.Redis的常用数据类型有哪些？\n\n支持多种类型的数据结构，主要区别是value存储的数据格式不同：\n\n * string：最基本的数据类型，二进制安全的字符串，最大512M。\n\n * list：按照添加顺序保持顺序的字符串列表。\n\n * set：无序的字符串集合，不存在重复的元素。\n\n * sorted set：已排序的字符串集合。\n\n * hash：key-value对格式\n\n\n# 3.5.聊一下Redis事务机制\n\n相关资料：\n\n参考：http://redisdoc.com/topic/transaction.html\n\nRedis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的。Redis会将一个事务中的所有命令序列化，然后按顺序执行。但是Redis事务不支持回滚操作，命令运行出错后，正确的命令会继续执行。\n\n * MULTI: 用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个待执行命令队列中\n * EXEC：按顺序执行命令队列内的所有命令。返回所有命令的返回值。事务执行过程中，Redis不会执行其它事务的命令。\n * DISCARD：清空命令队列，并放弃执行事务， 并且客户端会从事务状态中退出\n * WATCH：Redis的乐观锁机制，利用compare-and-set（CAS）原理，可以监控一个或多个键，一旦其中有一个键被修改，之后的事务就不会执行\n\n使用事务时可能会遇上以下两种错误：\n\n * 执行 EXEC 之前，入队的命令可能会出错。比如说，命令可能会产生语法错误（参数数量错误，参数名错误，等等），或者其他更严重的错误，比如内存不足（如果服务器使用 maxmemory 设置了最大内存限制的话）。\n   * Redis 2.6.5 开始，服务器会对命令入队失败的情况进行记录，并在客户端调用 EXEC 命令时，拒绝执行并自动放弃这个事务。\n * 命令可能在 EXEC 调用之后失败。举个例子，事务中的命令可能处理了错误类型的键，比如将列表命令用在了字符串键上面，诸如此类。\n   * 即使事务中有某个/某些命令在执行时产生了错误， 事务中的其他命令仍然会继续执行，不会回滚。\n\n为什么 Redis 不支持回滚（roll back）？\n\n以下是这种做法的优点：\n\n * Redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。\n * 因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。\n\n鉴于没有任何机制能避免程序员自己造成的错误， 并且这类错误通常不会在生产环境中出现， 所以 Redis 选择了更简单、更快速的无回滚方式来处理事务。\n\n面试话术：\n\nRedis事务其实是把一系列Redis命令放入队列，然后批量执行，执行过程中不会有其它事务来打断。不过与关系型数据库的事务不同，Redis事务不支持回滚操作，事务中某个命令执行失败，其它命令依然会执行。\n\n为了弥补不能回滚的问题，Redis会在事务入队时就检查命令，如果命令异常则会放弃整个事务。\n\n因此，只要程序员编程是正确的，理论上说Redis会正确执行所有事务，无需回滚。\n\n面试官：如果事务执行一半的时候Redis宕机怎么办？\n\nRedis有持久化机制，因为可靠性问题，我们一般使用AOF持久化。事务的所有命令也会写入AOF文件，但是如果在执行EXEC命令之前，Redis已经宕机，则AOF文件中事务不完整。使用 redis-check-aof 程序可以移除 AOF 文件中不完整事务的信息，确保服务器可以顺利启动。\n\n\n# 3.6.Redis的Key过期策略\n\n\n# 参考资料：\n\n# 为什么需要内存回收？\n\n * 1、在Redis中，set指令可以指定key的过期时间，当过期时间到达以后，key就失效了；\n * 2、Redis是基于内存操作的，所有的数据都是保存在内存中，一台机器的内存是有限且很宝贵的。\n\n基于以上两点，为了保证Redis能继续提供可靠的服务，Redis需要一种机制清理掉不常用的、无效的、多余的数据，失效后的数据需要及时清理，这就需要内存回收了。\n\nRedis的内存回收主要分为过期删除策略和内存淘汰策略两部分。\n\n# 过期删除策略\n\n删除达到过期时间的key。\n\n * 1）定时删除\n\n对于每一个设置了过期时间的key都会创建一个定时器，一旦到达过期时间就立即删除。该策略可以立即清除过期的数据，对内存较友好，但是缺点是占用了大量的CPU资源去处理过期的数据，会影响Redis的吞吐量和响应时间。\n\n * 2）惰性删除\n\n当访问一个key时，才判断该key是否过期，过期则删除。该策略能最大限度地节省CPU资源，但是对内存却十分不友好。有一种极端的情况是可能出现大量的过期key没有被再次访问，因此不会被清除，导致占用了大量的内存。\n\n> 在计算机科学中，懒惰删除（英文：lazy deletion）指的是从一个散列表（也称哈希表）中删除元素的一种方法。在这个方法中，删除仅仅是指标记一个元素被删除，而不是整个清除它。被删除的位点在插入时被当作空元素，在搜索之时被当作已占据。\n\n * 3）定期删除\n\n每隔一段时间，扫描Redis中过期key字典，并清除部分过期的key。该策略是前两者的一个折中方案，还可以通过调整定时扫描的时间间隔和每次扫描的限定耗时，在不同情况下使得CPU和内存资源达到最优的平衡效果。\n\n在Redis中，同时使用了定期删除和惰性删除。不过Redis定期删除采用的是随机抽取的方式删除部分Key，因此不能保证过期key 100%的删除。\n\nRedis结合了定期删除和惰性删除，基本上能很好的处理过期数据的清理，但是实际上还是有点问题的，如果过期key较多，定期删除漏掉了一部分，而且也没有及时去查，即没有走惰性删除，那么就会有大量的过期key堆积在内存中，导致redis内存耗尽，当内存耗尽之后，有新的key到来会发生什么事呢？是直接抛弃还是其他措施呢？有什么办法可以接受更多的key？\n\n# 内存淘汰策略\n\nRedis的内存淘汰策略，是指内存达到maxmemory极限时，使用某种算法来决定清理掉哪些数据，以保证新数据的存入。\n\nRedis的内存淘汰机制包括：\n\n * noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错。\n * allkeys-lru：当内存不足以容纳新写入数据时，在键空间（server.db[i].dict）中，移除最近最少使用的 key（这个是最常用的）。\n * allkeys-random：当内存不足以容纳新写入数据时，在键空间（server.db[i].dict）中，随机移除某个 key。\n * volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（server.db[i].expires）中，移除最近最少使用的 key。\n * volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（server.db[i].expires）中，随机移除某个 key。\n * volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（server.db[i].expires）中，有更早过期时间的 key 优先移除。\n\n> 在配置文件中，通过maxmemory-policy可以配置要使用哪一个淘汰机制。\n\n什么时候会进行淘汰？\n\nRedis会在每一次处理命令的时候（processCommand函数调用freeMemoryIfNeeded）判断当前redis是否达到了内存的最大限制，如果达到限制，则使用对应的算法去处理需要删除的key。\n\n在淘汰key时，Redis默认最常用的是LRU算法（Latest Recently Used）。Redis通过在每一个redisObject保存lru属性来保存key最近的访问时间，在实现LRU算法时直接读取key的lru属性。\n\n具体实现时，Redis遍历每一个db，从每一个db中随机抽取一批样本key，默认是3个key，再从这3个key中，删除最近最少使用的key。\n\n\n# 面试话术：\n\nRedis过期策略包含定期删除和惰性删除两部分。定期删除是在Redis内部有一个定时任务，会定期删除一些过期的key。惰性删除是当用户查询某个Key时，会检查这个Key是否已经过期，如果没过期则返回用户，如果过期则删除。\n\n但是这两个策略都无法保证过期key一定删除，漏网之鱼越来越多，还可能导致内存溢出。当发生内存不足问题时，Redis还会做内存回收。内存回收采用LRU策略，就是最近最少使用。其原理就是记录每个Key的最近使用时间，内存回收时，随机抽取一些Key，比较其使用时间，把最老的几个删除。\n\nRedis的逻辑是：最近使用过的，很可能再次被使用\n\n\n# 3.7.Redis在项目中的哪些地方有用到?\n\n（1）共享session\n\n在分布式系统下，服务会部署在不同的tomcat，因此多个tomcat的session无法共享，以前存储在session中的数据无法实现共享，可以用redis代替session，解决分布式系统间数据共享问题。\n\n（2）数据缓存\n\nRedis采用内存存储，读写效率较高。我们可以把数据库的访问频率高的热点数据存储到redis中，这样用户请求时优先从redis中读取，减少数据库压力，提高并发能力。\n\n（3）异步队列\n\nReids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。而且Redis中还有pub/sub这样的专用结构，用于1对N的消息通信模式。\n\n（4）分布式锁\n\nRedis中的乐观锁机制，可以帮助我们实现分布式锁的效果，用于解决分布式系统下的多线程安全问题\n\n\n# 3.8.Redis的缓存击穿、缓存雪崩、缓存穿透\n\n\n# 1）缓存穿透\n\n参考资料：\n\n * 什么是缓存穿透\n   \n   * 正常情况下，我们去查询数据都是存在。那么请求去查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。这种查询不存在数据的现象我们称为缓存穿透。\n\n * 穿透带来的问题\n   \n   * 试想一下，如果有黑客会对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库去查询。可能会导致你的数据库由于压力过大而宕掉。\n\n * 解决办法\n   \n   * 缓存空值：之所以会发生穿透，就是因为缓存中没有存储这些空数据的key。从而导致每次查询都到数据库去了。那么我们就可以为这些key对应的值设置为null 丢到缓存里面去。后面再出现查询这个key 的请求的时候，直接返回null 。这样，就不用在到数据库中去走一圈了，但是别忘了设置过期时间。\n   * BloomFilter（布隆过滤）：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。在缓存之前在加一层 BloomFilter ，在查询的时候先去 BloomFilter 去查询 key 是否存在，如果不存在就直接返回，存在再走查缓存 -> 查 DB。\n\n话术：\n\n缓存穿透有两种解决方案：其一是把不存在的key设置null值到缓存中。其二是使用布隆过滤器，在查询缓存前先通过布隆过滤器判断key是否存在，存在再去查询缓存。\n\n设置null值可能被恶意针对，攻击者使用大量不存在的不重复key ，那么方案一就会缓存大量不存在key数据。此时我们还可以对Key规定格式模板，然后对不存在的key做正则规范匹配，如果完全不符合就不用存null值到redis，而是直接返回错误。\n\n\n# 2）缓存击穿\n\n相关资料：\n\n * 什么是缓存击穿？\n\nkey可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题。\n\n当这个key在失效的瞬间，redis查询失败，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。\n\n * 解决方案：\n   * 使用互斥锁(mutex key)：mutex，就是互斥。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用Redis的SETNX去set一个互斥key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现互斥的效果。\n   * 软过期：也就是逻辑过期，不使用redis提供的过期时间，而是业务层在数据中存储过期时间信息。查询时由业务程序判断是否过期，如果数据即将过期时，将缓存的时效延长，程序可以派遣一个线程去数据库中获取最新的数据，其他线程这时看到延长了的过期时间，就会继续使用旧数据，等派遣的线程获取最新数据后再更新缓存。\n\n推荐使用互斥锁，因为软过期会有业务逻辑侵入和额外的判断。\n\n面试话术：\n\n缓存击穿主要担心的是某个Key过期，更新缓存时引起对数据库的突发高并发访问。因此我们可以在更新缓存时采用互斥锁控制，只允许一个线程去更新缓存，其它线程等待并重新读取缓存。例如Redis的setnx命令就能实现互斥效果。\n\n\n# 3）缓存雪崩\n\n相关资料：\n\n缓存雪崩，是指在某一个时间段，缓存集中过期失效。对这批数据的访问查询，都落到了数据库上，对于数据库而言，就会产生周期性的压力波峰。\n\n解决方案：\n\n * 数据分类分批处理：采取不同分类数据，缓存不同周期\n * 相同分类数据：采用固定时长加随机数方式设置缓存\n * 热点数据缓存时间长一些，冷门数据缓存时间短一些\n * 避免redis节点宕机引起雪崩，搭建主从集群，保证高可用\n\n面试话术：\n\n解决缓存雪崩问题的关键是让缓存Key的过期时间分散。因此我们可以把数据按照业务分类，然后设置不同过期时间。相同业务类型的key，设置固定时长加随机数。尽可能保证每个Key的过期时间都不相同。\n\n另外，Redis宕机也可能导致缓存雪崩，因此我们还要搭建Redis主从集群及哨兵监控，保证Redis的高可用。\n\n\n# 3.9.缓存冷热数据分离\n\n背景资料：\n\nRedis使用的是内存存储，当需要海量数据存储时，成本非常高。\n\n经过调研发现，当前主流DDR3内存和主流SATA SSD的单位成本价格差距大概在20倍左右，为了优化redis机器综合成本，我们考虑实现基于热度统计 的数据分级存储及数据在RAM/FLASH之间的动态交换，从而大幅度降低成本，达到性能与成本的高平衡。\n\n基本思路：基于key访问次数(LFU)的热度统计算法识别出热点数据，并将热点数据保留在redis中，对于无访问/访问次数少的数据则转存到SSD上，如果SSD上的key再次变热，则重新将其加载到redis内存中。\n\n目前流行的高性能磁盘存储，并且遵循Redis协议的方案包括：\n\n * SSDB：http://ssdb.io/zh_cn/\n * RocksDB：https://rocksdb.org.cn/\n\n因此，我们就需要在应用程序与缓存服务之间引入代理，实现Redis和SSD之间的切换，如图：\n\n\n\n这样的代理方案阿里云提供的就有。当然也有一些开源方案，例如：https://github.com/JingchengLi/swapdb\n\n\n# 3.10.Redis实现分布式锁\n\n分布式锁要满足的条件：\n\n * 多进程互斥：同一时刻，只有一个进程可以获取锁\n * 保证锁可以释放：任务结束或出现异常，锁一定要释放，避免死锁\n * 阻塞锁（可选）：获取锁失败时可否重试\n * 重入锁（可选）：获取锁的代码递归调用时，依然可以获取锁\n\n\n# 1）最基本的分布式锁：\n\n利用Redis的setnx命令，这个命令的特征时如果多次执行，只有第一次执行会成功，可以实现互斥的效果。但是为了保证服务宕机时也可以释放锁，需要利用expire命令给锁设置一个有效期\n\nsetnx lock thread-01 # 尝试获取锁\nexpire lock 10 # 设置有效期\n\n\n面试官问题1：如果expire之前服务宕机怎么办？\n\n要保证setnx和expire命令的原子性。redis的set命令可以满足：\n\nset key value [NX] [EX time] \n\n\n需要添加nx和ex的选项：\n\n * NX：与setnx一致，第一次执行成功\n * EX：设置过期时间\n\n面试官问题2：释放锁的时候，如果自己的锁已经过期了，此时会出现安全漏洞，如何解决？\n\n在锁中存储当前进程和线程标识，释放锁时对锁的标识判断，如果是自己的则删除，不是则放弃操作。\n\n但是这两步操作要保证原子性，需要通过Lua脚本来实现。\n\nif redis.call(\"get\",KEYS[1]) == ARGV[1] then\n    redis.call(\"del\",KEYS[1])\nend\n\n\n\n# 2）可重入分布式锁\n\n如果有重入的需求，则除了在锁中记录进程标识，还要记录重试次数，流程如下：\n\n\n\n下面我们假设锁的key为“lock”，hashKey是当前线程的id：“threadId”，锁自动释放时间假设为20\n\n获取锁的步骤：\n\n * 1、判断lock是否存在 EXISTS lock\n   * 存在，说明有人获取锁了，下面判断是不是自己的锁\n     * 判断当前线程id作为hashKey是否存在：HEXISTS lock threadId\n       * 不存在，说明锁已经有了，且不是自己获取的，锁获取失败，end\n       * 存在，说明是自己获取的锁，重入次数+1：HINCRBY lock threadId 1，去到步骤3\n   * 2、不存在，说明可以获取锁，HSET key threadId 1\n   * 3、设置锁自动释放时间，EXPIRE lock 20\n\n释放锁的步骤：\n\n * 1、判断当前线程id作为hashKey是否存在：HEXISTS lock threadId\n   * 不存在，说明锁已经失效，不用管了\n   * 存在，说明锁还在，重入次数减1：HINCRBY lock threadId -1，获取新的重入次数\n * 2、判断重入次数是否为0：\n   * 为0，说明锁全部释放，删除key：DEL lock\n   * 大于0，说明锁还在使用，重置有效时间：EXPIRE lock 20\n\n对应的Lua脚本如下：\n\n首先是获取锁：\n\nlocal key = KEYS[1]; -- 锁的key\nlocal threadId = ARGV[1]; -- 线程唯一标识\nlocal releaseTime = ARGV[2]; -- 锁的自动释放时间\n\nif(redis.call('exists', key) == 0) then -- 判断是否存在\n\tredis.call('hset', key, threadId, '1'); -- 不存在, 获取锁\n\tredis.call('expire', key, releaseTime); -- 设置有效期\n\treturn 1; -- 返回结果\nend;\n\nif(redis.call('hexists', key, threadId) == 1) then -- 锁已经存在，判断threadId是否是自己\t\n\tredis.call('hincrby', key, threadId, '1'); -- 不存在, 获取锁，重入次数+1\n\tredis.call('expire', key, releaseTime); -- 设置有效期\n\treturn 1; -- 返回结果\nend;\nreturn 0; -- 代码走到这里,说明获取锁的不是自己，获取锁失败\n\n\n然后是释放锁：\n\nlocal key = KEYS[1]; -- 锁的key\nlocal threadId = ARGV[1]; -- 线程唯一标识\nlocal releaseTime = ARGV[2]; -- 锁的自动释放时间\n\nif (redis.call('HEXISTS', key, threadId) == 0) then -- 判断当前锁是否还是被自己持有\n    return nil; -- 如果已经不是自己，则直接返回\nend;\nlocal count = redis.call('HINCRBY', key, threadId, -1); -- 是自己的锁，则重入次数-1\n\nif (count > 0) then -- 判断是否重入次数是否已经为0\n    redis.call('EXPIRE', key, releaseTime); -- 大于0说明不能释放锁，重置有效期然后返回\n    return nil;\nelse\n    redis.call('DEL', key); -- 等于0说明可以释放锁，直接删除\n    return nil;\nend;\n\n\n\n# 3）高可用的锁\n\n面试官问题：redis分布式锁依赖与redis，如果redis宕机则锁失效。如何解决？\n\n此时大多数同学会回答说：搭建主从集群，做数据备份。\n\n这样就进入了陷阱，因为面试官的下一个问题就来了：\n\n面试官问题：如果搭建主从集群做数据备份时，进程A获取锁，master还没有把数据备份到slave，master宕机，slave升级为master，此时原来锁失效，其它进程也可以获取锁，出现安全问题。如何解决？\n\n关于这个问题，Redis官网给出了解决方案，使用RedLock思路可以解决：\n\n> 在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。之前我们已经描述了在Redis单实例下怎么安全地获取和释放锁。我们确保将在每（N)个实例上使用此方法获取和释放锁。在这个样例中，我们假设有5个Redis master节点，这是一个比较合理的设置，所以我们需要在5台机器上面或者5台虚拟机上面运行这些实例，这样保证他们不会同时都宕掉。\n> \n> 为了取到锁，客户端应该执行以下操作:\n> \n>  1. 获取当前Unix时间，以毫秒为单位。\n>  2. 依次尝试从N个实例，使用相同的key和随机值获取锁。在步骤2，当向Redis设置锁时,客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试另外一个Redis实例。\n>  3. 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。\n>  4. 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。\n>  5. 如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功）。\n\n\n# 3.11.如何实现数据库与缓存数据一致？\n\n面试话术：\n\n实现方案有下面几种：\n\n * 本地缓存同步：当前微服务的数据库数据与缓存数据同步，可以直接在数据库修改时加入对Redis的修改逻辑，保证一致。\n * 跨服务缓存同步：服务A调用了服务B，并对查询结果缓存。服务B数据库修改，可以通过MQ通知服务A，服务A修改Redis缓存数据\n * 通用方案：使用Canal框架，伪装成MySQL的salve节点，监听MySQL的binLog变化，然后修改Redis缓存数据",normalizedContent:"# 常见面试题\n\n\n# 1.微服务篇\n\n\n# 1.1.springcloud常见组件有哪些？\n\n问题说明：这个题目主要考察对springcloud的组件基本了解\n\n难易程度：简单\n\n参考话术：\n\nspringcloud包含的组件很多，有很多功能是重复的。其中最常用组件包括：\n\n•注册中心组件：eureka、nacos等\n\n•负载均衡组件：ribbon\n\n•远程调用组件：openfeign\n\n•网关组件：zuul、gateway\n\n•服务保护组件：hystrix、sentinel\n\n•服务配置管理组件：springcloudconfig、nacos\n\n\n# 1.2.nacos的服务注册表结构是怎样的？\n\n问题说明：考察对nacos数据分级结构的了解，以及nacos源码的掌握情况\n\n难易程度：一般\n\n参考话术：\n\nnacos采用了数据的分级存储模型，最外层是namespace，用来隔离环境。然后是group，用来对服务分组。接下来就是服务（service）了，一个服务包含多个实例，但是可能处于不同机房，因此service下有多个集群（cluster），cluster下是不同的实例（instance）。\n\n对应到java代码中，nacos采用了一个多层的map来表示。结构为map<string, map<string, service>>，其中最外层map的key就是namespaceid，值是一个map。内层map的key是group拼接servicename，值是service对象。service对象内部又是一个map，key是集群名称，值是cluster对象。而cluster对象内部维护了instance的集合。\n\n如图：\n\n\n\n\n# 1.3.nacos如何支撑阿里内部数十万服务注册压力？\n\n问题说明：考察对nacos源码的掌握情况\n\n难易程度：难\n\n参考话术：\n\nnacos内部接收到注册的请求时，不会立即写数据，而是将服务注册的任务放入一个阻塞队列就立即响应给客户端。然后利用线程池读取阻塞队列中的任务，异步来完成实例更新，从而提高并发写能力。\n\n\n# 1.4.nacos如何避免并发读写冲突问题？\n\n问题说明：考察对nacos源码的掌握情况\n\n难易程度：难\n\n参考话术：\n\nnacos在更新实例列表时，会采用copyonwrite技术，首先将旧的实例列表拷贝一份，然后更新拷贝的实例列表，再用更新后的实例列表来覆盖旧的实例列表。\n\n这样在更新的过程中，就不会对读实例列表的请求产生影响，也不会出现脏读问题了。\n\n\n# 1.5.nacos与eureka的区别有哪些？\n\n问题说明：考察对nacos、eureka的底层实现的掌握情况\n\n难易程度：难\n\n参考话术：\n\nnacos与eureka有相同点，也有不同之处，可以从以下几点来描述：\n\n * 接口方式：nacos与eureka都对外暴露了rest风格的api接口，用来实现服务注册、发现等功能\n * 实例类型：nacos的实例有永久和临时实例之分；而eureka只支持临时实例\n * 健康检测：nacos对临时实例采用心跳模式检测，对永久实例采用主动请求来检测；eureka只支持心跳模式\n * 服务发现：nacos支持定时拉取和订阅推送两种模式；eureka只支持定时拉取模式\n\n\n# 1.6.sentinel的限流与gateway的限流有什么差别？\n\n问题说明：考察对限流算法的掌握情况\n\n难易程度：难\n\n参考话术：\n\n限流算法常见的有三种实现：滑动时间窗口、令牌桶算法、漏桶算法。gateway则采用了基于redis实现的令牌桶算法。\n\n而sentinel内部却比较复杂：\n\n * 默认限流模式是基于滑动时间窗口算法\n * 排队等待的限流模式则基于漏桶算法\n * 而热点参数限流则是基于令牌桶算法\n\n\n# 1.7.sentinel的线程隔离与hystix的线程隔离有什么差别?\n\n问题说明：考察对线程隔离方案的掌握情况\n\n难易程度：一般\n\n参考话术：\n\nhystix默认是基于线程池实现的线程隔离，每一个被隔离的业务都要创建一个独立的线程池，线程过多会带来额外的cpu开销，性能一般，但是隔离性更强。\n\nsentinel是基于信号量（计数器）实现的线程隔离，不用创建线程池，性能较好，但是隔离性一般。\n\n\n# 2.mq篇\n\n\n# 2.1.你们为什么选择了rabbitmq而不是其它的mq？\n\n如图：\n\n\n\n话术：\n\nkafka是以吞吐量高而闻名，不过其数据稳定性一般，而且无法保证消息有序性。我们公司的日志收集也有使用，业务模块中则使用的rabbitmq。\n\n阿里巴巴的rocketmq基于kafka的原理，弥补了kafka的缺点，继承了其高吞吐的优势，其客户端目前以java为主。但是我们担心阿里巴巴开源产品的稳定性，所以就没有使用。\n\nrabbitmq基于面向并发的语言erlang开发，吞吐量不如kafka，但是对我们公司来讲够用了。而且消息可靠性较好，并且消息延迟极低，集群搭建比较方便。支持多种协议，并且有各种语言的客户端，比较灵活。spring对rabbitmq的支持也比较好，使用起来比较方便，比较符合我们公司的需求。\n\n综合考虑我们公司的并发需求以及稳定性需求，我们选择了rabbitmq。\n\n\n# 2.2.rabbitmq如何确保消息的不丢失？\n\n话术：\n\nrabbitmq针对消息传递过程中可能发生问题的各个地方，给出了针对性的解决方案：\n\n * 生产者发送消息时可能因为网络问题导致消息没有到达交换机：\n   * rabbitmq提供了publisher confirm机制\n     * 生产者发送消息后，可以编写confirmcallback函数\n     * 消息成功到达交换机后，rabbitmq会调用confirmcallback通知消息的发送者，返回ack\n     * 消息如果未到达交换机，rabbitmq也会调用confirmcallback通知消息的发送者，返回nack\n     * 消息超时未发送成功也会抛出异常\n * 消息到达交换机后，如果未能到达队列，也会导致消息丢失：\n   * rabbitmq提供了publisher return机制\n     * 生产者可以定义returncallback函数\n     * 消息到达交换机，未到达队列，rabbitmq会调用returncallback通知发送者，告知失败原因\n * 消息到达队列后，mq宕机也可能导致丢失消息：\n   * rabbitmq提供了持久化功能，集群的主从备份功能\n     * 消息持久化，rabbitmq会将交换机、队列、消息持久化到磁盘，宕机重启可以恢复消息\n     * 镜像集群，仲裁队列，都可以提供主从备份功能，主节点宕机，从节点会自动切换为主，数据依然在\n * 消息投递给消费者后，如果消费者处理不当，也可能导致消息丢失\n   * springamqp基于rabbitmq提供了消费者确认机制、消费者重试机制，消费者失败处理策略：\n     * 消费者的确认机制：\n       * 消费者处理消息成功，未出现异常时，spring返回ack给rabbitmq，消息才被移除\n       * 消费者处理消息失败，抛出异常，宕机，spring返回nack或者不返回结果，消息不被异常\n     * 消费者重试机制：\n       * 默认情况下，消费者处理失败时，消息会再次回到mq队列，然后投递给其它消费者。spring提供的消费者重试机制，则是在处理失败后不返回nack，而是直接在消费者本地重试。多次重试都失败后，则按照消费者失败处理策略来处理消息。避免了消息频繁入队带来的额外压力。\n     * 消费者失败策略：\n       * 当消费者多次本地重试失败时，消息默认会丢弃。\n       * spring提供了republish策略，在多次重试都失败，耗尽重试次数后，将消息重新投递给指定的异常交换机，并且会携带上异常栈信息，帮助定位问题。\n\n\n# 2.3.rabbitmq如何避免消息堆积？\n\n话术：\n\n消息堆积问题产生的原因往往是因为消息发送的速度超过了消费者消息处理的速度。因此解决方案无外乎以下三点：\n\n * 提高消费者处理速度\n * 增加更多消费者\n * 增加队列消息存储上限\n\n1）提高消费者处理速度\n\n消费者处理速度是由业务代码决定的，所以我们能做的事情包括：\n\n * 尽可能优化业务代码，提高业务性能\n * 接收到消息后，开启线程池，并发处理多个消息\n\n优点：成本低，改改代码即可\n\n缺点：开启线程池会带来额外的性能开销，对于高频、低时延的任务不合适。推荐任务执行周期较长的业务。\n\n2）增加更多消费者\n\n一个队列绑定多个消费者，共同争抢任务，自然可以提供消息处理的速度。\n\n优点：能用钱解决的问题都不是问题。实现简单粗暴\n\n缺点：问题是没有钱。成本太高\n\n3）增加队列消息存储上限\n\n在rabbitmq的1.8版本后，加入了新的队列模式：lazy queue\n\n这种队列不会将消息保存在内存中，而是在收到消息后直接写入磁盘中，理论上没有存储上限。可以解决消息堆积问题。\n\n优点：磁盘存储更安全；存储无上限；避免内存存储带来的page out问题，性能更稳定；\n\n缺点：磁盘存储受到io性能的限制，消息时效性不如内存模式，但影响不大。\n\n\n# 2.4.rabbitmq如何保证消息的有序性？\n\n话术：\n\n其实rabbitmq是队列存储，天然具备先进先出的特点，只要消息的发送是有序的，那么理论上接收也是有序的。不过当一个队列绑定了多个消费者时，可能出现消息轮询投递给消费者的情况，而消费者的处理顺序就无法保证了。\n\n因此，要保证消息的有序性，需要做的下面几点：\n\n * 保证消息发送的有序性\n * 保证一组有序的消息都发送到同一个队列\n * 保证一个队列只包含一个消费者\n\n\n# 2.5.如何防止mq消息被重复消费？\n\n话术：\n\n消息重复消费的原因多种多样，不可避免。所以只能从消费者端入手，只要能保证消息处理的幂等性就可以确保消息不被重复消费。\n\n而幂等性的保证又有很多方案：\n\n * 给每一条消息都添加一个唯一id，在本地记录消息表及消息状态，处理消息时基于数据库表的id唯一性做判断\n * 同样是记录消息表，利用消息状态字段实现基于乐观锁的判断，保证幂等\n * 基于业务本身的幂等性。比如根据id的删除、查询业务天生幂等；新增、修改等业务可以考虑基于数据库id唯一性、或者乐观锁机制确保幂等。本质与消息表方案类似。\n\n\n# 2.6.如何保证rabbitmq的高可用？\n\n话术：\n\n要实现rabbitmq的高可用无外乎下面两点：\n\n * 做好交换机、队列、消息的持久化\n * 搭建rabbitmq的镜像集群，做好主从备份。当然也可以使用仲裁队列代替镜像集群。\n\n\n# 2.7.使用mq可以解决那些问题？\n\n话术：\n\nrabbitmq能解决的问题很多，例如：\n\n * 解耦合：将几个业务关联的微服务调用修改为基于mq的异步通知，可以解除微服务之间的业务耦合。同时还提高了业务性能。\n * 流量削峰：将突发的业务请求放入mq中，作为缓冲区。后端的业务根据自己的处理能力从mq中获取消息，逐个处理任务。流量曲线变的平滑很多\n * 延迟队列：基于rabbitmq的死信队列或者delayexchange插件，可以实现消息发送后，延迟接收的效果。\n\n\n# 3.redis篇\n\n\n# 3.1.redis与memcache的区别？\n\n * redis支持更丰富的数据类型（支持更复杂的应用场景）：redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，string。\n * redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而memecache把数据全部存在内存之中。\n * 集群模式：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的.\n * redis使用单线程：memcached是多线程，非阻塞io复用的网络模型；redis使用单线程的多路 io 复用模型。\n\n\n\n\n# 3.2.redis的单线程问题\n\n面试官：redis采用单线程，如何保证高并发？\n\n面试话术：\n\nredis快的主要原因是：\n\n 1. 完全基于内存\n 2. 数据结构简单，对数据操作也简单\n 3. 使用多路 i/o 复用模型，充分利用cpu资源\n\n面试官：这样做的好处是什么？\n\n面试话术：\n\n单线程优势有下面几点：\n\n * 代码更清晰，处理逻辑更简单\n * 不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为锁而导致的性能消耗\n * 不存在多进程或者多线程导致的cpu切换，充分利用cpu资源\n\n\n# 3.2.redis的持久化方案由哪些？\n\n相关资料：\n\n1）rdb 持久化\n\nrdb持久化可以使用save或bgsave，为了不阻塞主进程业务，一般都使用bgsave，流程：\n\n * redis 进程会 fork 出一个子进程（与父进程内存数据一致）。\n * 父进程继续处理客户端请求命令\n * 由子进程将内存中的所有数据写入到一个临时的 rdb 文件中。\n * 完成写入操作之后，旧的 rdb 文件会被新的 rdb 文件替换掉。\n\n下面是一些和 rdb 持久化相关的配置：\n\n * save 60 10000：如果在 60 秒内有 10000 个 key 发生改变，那就执行 rdb 持久化。\n * stop-writes-on-bgsave-error yes：如果 redis 执行 rdb 持久化失败（常见于操作系统内存不足），那么 redis 将不再接受 client 写入数据的请求。\n * rdbcompression yes：当生成 rdb 文件时，同时进行压缩。\n * dbfilename dump.rdb：将 rdb 文件命名为 dump.rdb。\n * dir /var/lib/redis：将 rdb 文件保存在/var/lib/redis目录下。\n\n当然在实践中，我们通常会将stop-writes-on-bgsave-error设置为false，同时让监控系统在 redis 执行 rdb 持久化失败时发送告警，以便人工介入解决，而不是粗暴地拒绝 client 的写入请求。\n\nrdb持久化的优点：\n\n * rdb持久化文件小，redis数据恢复时速度快\n * 子进程不影响父进程，父进程可以持续处理客户端命令\n * 子进程fork时采用copy-on-write方式，大多数情况下，没有太多的内存消耗，效率比较好。\n\nrdb 持久化的缺点：\n\n * 子进程fork时采用copy-on-write方式，如果redis此时写操作较多，可能导致额外的内存占用，甚至内存溢出\n * rdb文件压缩会减小文件体积，但通过时会对cpu有额外的消耗\n * 如果业务场景很看重数据的持久性 (durability)，那么不应该采用 rdb 持久化。譬如说，如果 redis 每 5 分钟执行一次 rdb 持久化，要是 redis 意外奔溃了，那么最多会丢失 5 分钟的数据。\n\n2）aof 持久化\n\n可以使用appendonly yes配置项来开启 aof 持久化。redis 执行 aof 持久化时，会将接收到的写命令追加到 aof 文件的末尾，因此 redis 只要对 aof 文件中的命令进行回放，就可以将数据库还原到原先的状态。 　　与 rdb 持久化相比，aof 持久化的一个明显优势就是，它可以提高数据的持久性 (durability)。因为在 aof 模式下，redis 每次接收到 client 的写命令，就会将命令write()到 aof 文件末尾。 　　然而，在 linux 中，将数据write()到文件后，数据并不会立即刷新到磁盘，而会先暂存在 os 的文件系统缓冲区。在合适的时机，os 才会将缓冲区的数据刷新到磁盘（如果需要将文件内容刷新到磁盘，可以调用fsync()或fdatasync()）。 　　通过appendfsync配置项，可以控制 redis 将命令同步到磁盘的频率：\n\n * always：每次 redis 将命令write()到 aof 文件时，都会调用fsync()，将命令刷新到磁盘。这可以保证最好的数据持久性，但却会给系统带来极大的开销。\n * no：redis 只将命令write()到 aof 文件。这会让 os 决定何时将命令刷新到磁盘。\n * everysec：除了将命令write()到 aof 文件，redis 还会每秒执行一次fsync()。在实践中，推荐使用这种设置，一定程度上可以保证数据持久性，又不会明显降低 redis 性能。\n\n然而，aof 持久化并不是没有缺点的：redis 会不断将接收到的写命令追加到 aof 文件中，导致 aof 文件越来越大。过大的 aof 文件会消耗磁盘空间，并且导致 redis 重启时更加缓慢。为了解决这个问题，在适当情况下，redis 会对 aof 文件进行重写，去除文件中冗余的命令，以减小 aof 文件的体积。在重写 aof 文件期间， redis 会启动一个子进程，由子进程负责对 aof 文件进行重写。 　　可以通过下面两个配置项，控制 redis 重写 aof 文件的频率：\n\n * auto-aof-rewrite-min-size 64mb\n * auto-aof-rewrite-percentage 100\n\n上面两个配置的作用：当 aof 文件的体积大于 64mb，并且 aof 文件的体积比上一次重写之后的体积大了至少一倍，那么 redis 就会执行 aof 重写。\n\n优点：\n\n * 持久化频率高，数据可靠性高\n * 没有额外的内存或cpu消耗\n\n缺点：\n\n * 文件体积大\n * 文件大导致服务数据恢复时效率较低\n\n面试话术：\n\nredis 提供了两种数据持久化的方式，一种是 rdb，另一种是 aof。默认情况下，redis 使用的是 rdb 持久化。\n\nrdb持久化文件体积较小，但是保存数据的频率一般较低，可靠性差，容易丢失数据。另外rdb写数据时会采用fork函数拷贝主进程，可能有额外的内存消耗，文件压缩也会有额外的cpu消耗。\n\nrof持久化可以做到每秒钟持久化一次，可靠性高。但是持久化文件体积较大，导致数据恢复时读取文件时间较长，效率略低\n\n\n# 3.3.redis的集群方式有哪些？\n\n面试话术：\n\nredis集群可以分为主从集群和分片集群两类。\n\n主从集群一般一主多从，主库用来写数据，从库用来读数据。结合哨兵，可以再主库宕机时从新选主，目的是保证redis的高可用。\n\n分片集群是数据分片，我们会让多个redis节点组成集群，并将16383个插槽分到不同的节点上。存储数据时利用对key做hash运算，得到插槽值后存储到对应的节点即可。因为存储数据面向的是插槽而非节点本身，因此可以做到集群动态伸缩。目的是让redis能存储更多数据。\n\n1）主从集群\n\n主从集群，也是读写分离集群。一般都是一主多从方式。\n\nredis 的复制（replication）功能允许用户根据一个 redis 服务器来创建任意多个该服务器的复制品，其中被复制的服务器为主服务器（master），而通过复制创建出来的服务器复制品则为从服务器（slave）。\n\n只要主从服务器之间的网络连接正常，主从服务器两者会具有相同的数据，主服务器就会一直将发生在自己身上的数据更新同步 给从服务器，从而一直保证主从服务器的数据相同。\n\n * 写数据时只能通过主节点完成\n * 读数据可以从任何节点完成\n * 如果配置了哨兵节点，当master宕机时，哨兵会从salve节点选出一个新的主。\n\n主从集群分两种：\n\n\n\n带有哨兵的集群：\n\n\n\n2）分片集群\n\n主从集群中，每个节点都要保存所有信息，容易形成木桶效应。并且当数据量较大时，单个机器无法满足需求。此时我们就要使用分片集群了。\n\n\n\n集群特征：\n\n * 每个节点都保存不同数据\n\n * 所有的redis节点彼此互联(ping-pong机制),内部使用二进制协议优化传输速度和带宽.\n\n * 节点的fail是通过集群中超过半数的节点检测失效时才生效.\n\n * 客户端与redis节点直连,不需要中间proxy层连接集群中任何一个可用节点都可以访问到数据\n\n * redis-cluster把所有的物理节点映射到[0-16383]slot（插槽）上，实现动态伸缩\n\n为了保证redis中每个节点的高可用，我们还可以给每个节点创建replication（slave节点），如图：\n\n\n\n出现故障时，主从可以及时切换：\n\n\n\n\n# 3.4.redis的常用数据类型有哪些？\n\n支持多种类型的数据结构，主要区别是value存储的数据格式不同：\n\n * string：最基本的数据类型，二进制安全的字符串，最大512m。\n\n * list：按照添加顺序保持顺序的字符串列表。\n\n * set：无序的字符串集合，不存在重复的元素。\n\n * sorted set：已排序的字符串集合。\n\n * hash：key-value对格式\n\n\n# 3.5.聊一下redis事务机制\n\n相关资料：\n\n参考：http://redisdoc.com/topic/transaction.html\n\nredis事务功能是通过multi、exec、discard和watch 四个原语实现的。redis会将一个事务中的所有命令序列化，然后按顺序执行。但是redis事务不支持回滚操作，命令运行出错后，正确的命令会继续执行。\n\n * multi: 用于开启一个事务，它总是返回ok。 multi执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个待执行命令队列中\n * exec：按顺序执行命令队列内的所有命令。返回所有命令的返回值。事务执行过程中，redis不会执行其它事务的命令。\n * discard：清空命令队列，并放弃执行事务， 并且客户端会从事务状态中退出\n * watch：redis的乐观锁机制，利用compare-and-set（cas）原理，可以监控一个或多个键，一旦其中有一个键被修改，之后的事务就不会执行\n\n使用事务时可能会遇上以下两种错误：\n\n * 执行 exec 之前，入队的命令可能会出错。比如说，命令可能会产生语法错误（参数数量错误，参数名错误，等等），或者其他更严重的错误，比如内存不足（如果服务器使用 maxmemory 设置了最大内存限制的话）。\n   * redis 2.6.5 开始，服务器会对命令入队失败的情况进行记录，并在客户端调用 exec 命令时，拒绝执行并自动放弃这个事务。\n * 命令可能在 exec 调用之后失败。举个例子，事务中的命令可能处理了错误类型的键，比如将列表命令用在了字符串键上面，诸如此类。\n   * 即使事务中有某个/某些命令在执行时产生了错误， 事务中的其他命令仍然会继续执行，不会回滚。\n\n为什么 redis 不支持回滚（roll back）？\n\n以下是这种做法的优点：\n\n * redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。\n * 因为不需要对回滚进行支持，所以 redis 的内部可以保持简单且快速。\n\n鉴于没有任何机制能避免程序员自己造成的错误， 并且这类错误通常不会在生产环境中出现， 所以 redis 选择了更简单、更快速的无回滚方式来处理事务。\n\n面试话术：\n\nredis事务其实是把一系列redis命令放入队列，然后批量执行，执行过程中不会有其它事务来打断。不过与关系型数据库的事务不同，redis事务不支持回滚操作，事务中某个命令执行失败，其它命令依然会执行。\n\n为了弥补不能回滚的问题，redis会在事务入队时就检查命令，如果命令异常则会放弃整个事务。\n\n因此，只要程序员编程是正确的，理论上说redis会正确执行所有事务，无需回滚。\n\n面试官：如果事务执行一半的时候redis宕机怎么办？\n\nredis有持久化机制，因为可靠性问题，我们一般使用aof持久化。事务的所有命令也会写入aof文件，但是如果在执行exec命令之前，redis已经宕机，则aof文件中事务不完整。使用 redis-check-aof 程序可以移除 aof 文件中不完整事务的信息，确保服务器可以顺利启动。\n\n\n# 3.6.redis的key过期策略\n\n\n# 参考资料：\n\n# 为什么需要内存回收？\n\n * 1、在redis中，set指令可以指定key的过期时间，当过期时间到达以后，key就失效了；\n * 2、redis是基于内存操作的，所有的数据都是保存在内存中，一台机器的内存是有限且很宝贵的。\n\n基于以上两点，为了保证redis能继续提供可靠的服务，redis需要一种机制清理掉不常用的、无效的、多余的数据，失效后的数据需要及时清理，这就需要内存回收了。\n\nredis的内存回收主要分为过期删除策略和内存淘汰策略两部分。\n\n# 过期删除策略\n\n删除达到过期时间的key。\n\n * 1）定时删除\n\n对于每一个设置了过期时间的key都会创建一个定时器，一旦到达过期时间就立即删除。该策略可以立即清除过期的数据，对内存较友好，但是缺点是占用了大量的cpu资源去处理过期的数据，会影响redis的吞吐量和响应时间。\n\n * 2）惰性删除\n\n当访问一个key时，才判断该key是否过期，过期则删除。该策略能最大限度地节省cpu资源，但是对内存却十分不友好。有一种极端的情况是可能出现大量的过期key没有被再次访问，因此不会被清除，导致占用了大量的内存。\n\n> 在计算机科学中，懒惰删除（英文：lazy deletion）指的是从一个散列表（也称哈希表）中删除元素的一种方法。在这个方法中，删除仅仅是指标记一个元素被删除，而不是整个清除它。被删除的位点在插入时被当作空元素，在搜索之时被当作已占据。\n\n * 3）定期删除\n\n每隔一段时间，扫描redis中过期key字典，并清除部分过期的key。该策略是前两者的一个折中方案，还可以通过调整定时扫描的时间间隔和每次扫描的限定耗时，在不同情况下使得cpu和内存资源达到最优的平衡效果。\n\n在redis中，同时使用了定期删除和惰性删除。不过redis定期删除采用的是随机抽取的方式删除部分key，因此不能保证过期key 100%的删除。\n\nredis结合了定期删除和惰性删除，基本上能很好的处理过期数据的清理，但是实际上还是有点问题的，如果过期key较多，定期删除漏掉了一部分，而且也没有及时去查，即没有走惰性删除，那么就会有大量的过期key堆积在内存中，导致redis内存耗尽，当内存耗尽之后，有新的key到来会发生什么事呢？是直接抛弃还是其他措施呢？有什么办法可以接受更多的key？\n\n# 内存淘汰策略\n\nredis的内存淘汰策略，是指内存达到maxmemory极限时，使用某种算法来决定清理掉哪些数据，以保证新数据的存入。\n\nredis的内存淘汰机制包括：\n\n * noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错。\n * allkeys-lru：当内存不足以容纳新写入数据时，在键空间（server.db[i].dict）中，移除最近最少使用的 key（这个是最常用的）。\n * allkeys-random：当内存不足以容纳新写入数据时，在键空间（server.db[i].dict）中，随机移除某个 key。\n * volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（server.db[i].expires）中，移除最近最少使用的 key。\n * volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（server.db[i].expires）中，随机移除某个 key。\n * volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（server.db[i].expires）中，有更早过期时间的 key 优先移除。\n\n> 在配置文件中，通过maxmemory-policy可以配置要使用哪一个淘汰机制。\n\n什么时候会进行淘汰？\n\nredis会在每一次处理命令的时候（processcommand函数调用freememoryifneeded）判断当前redis是否达到了内存的最大限制，如果达到限制，则使用对应的算法去处理需要删除的key。\n\n在淘汰key时，redis默认最常用的是lru算法（latest recently used）。redis通过在每一个redisobject保存lru属性来保存key最近的访问时间，在实现lru算法时直接读取key的lru属性。\n\n具体实现时，redis遍历每一个db，从每一个db中随机抽取一批样本key，默认是3个key，再从这3个key中，删除最近最少使用的key。\n\n\n# 面试话术：\n\nredis过期策略包含定期删除和惰性删除两部分。定期删除是在redis内部有一个定时任务，会定期删除一些过期的key。惰性删除是当用户查询某个key时，会检查这个key是否已经过期，如果没过期则返回用户，如果过期则删除。\n\n但是这两个策略都无法保证过期key一定删除，漏网之鱼越来越多，还可能导致内存溢出。当发生内存不足问题时，redis还会做内存回收。内存回收采用lru策略，就是最近最少使用。其原理就是记录每个key的最近使用时间，内存回收时，随机抽取一些key，比较其使用时间，把最老的几个删除。\n\nredis的逻辑是：最近使用过的，很可能再次被使用\n\n\n# 3.7.redis在项目中的哪些地方有用到?\n\n（1）共享session\n\n在分布式系统下，服务会部署在不同的tomcat，因此多个tomcat的session无法共享，以前存储在session中的数据无法实现共享，可以用redis代替session，解决分布式系统间数据共享问题。\n\n（2）数据缓存\n\nredis采用内存存储，读写效率较高。我们可以把数据库的访问频率高的热点数据存储到redis中，这样用户请求时优先从redis中读取，减少数据库压力，提高并发能力。\n\n（3）异步队列\n\nreids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得redis能作为一个很好的消息队列平台来使用。而且redis中还有pub/sub这样的专用结构，用于1对n的消息通信模式。\n\n（4）分布式锁\n\nredis中的乐观锁机制，可以帮助我们实现分布式锁的效果，用于解决分布式系统下的多线程安全问题\n\n\n# 3.8.redis的缓存击穿、缓存雪崩、缓存穿透\n\n\n# 1）缓存穿透\n\n参考资料：\n\n * 什么是缓存穿透\n   \n   * 正常情况下，我们去查询数据都是存在。那么请求去查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。这种查询不存在数据的现象我们称为缓存穿透。\n\n * 穿透带来的问题\n   \n   * 试想一下，如果有黑客会对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库去查询。可能会导致你的数据库由于压力过大而宕掉。\n\n * 解决办法\n   \n   * 缓存空值：之所以会发生穿透，就是因为缓存中没有存储这些空数据的key。从而导致每次查询都到数据库去了。那么我们就可以为这些key对应的值设置为null 丢到缓存里面去。后面再出现查询这个key 的请求的时候，直接返回null 。这样，就不用在到数据库中去走一圈了，但是别忘了设置过期时间。\n   * bloomfilter（布隆过滤）：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。在缓存之前在加一层 bloomfilter ，在查询的时候先去 bloomfilter 去查询 key 是否存在，如果不存在就直接返回，存在再走查缓存 -> 查 db。\n\n话术：\n\n缓存穿透有两种解决方案：其一是把不存在的key设置null值到缓存中。其二是使用布隆过滤器，在查询缓存前先通过布隆过滤器判断key是否存在，存在再去查询缓存。\n\n设置null值可能被恶意针对，攻击者使用大量不存在的不重复key ，那么方案一就会缓存大量不存在key数据。此时我们还可以对key规定格式模板，然后对不存在的key做正则规范匹配，如果完全不符合就不用存null值到redis，而是直接返回错误。\n\n\n# 2）缓存击穿\n\n相关资料：\n\n * 什么是缓存击穿？\n\nkey可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题。\n\n当这个key在失效的瞬间，redis查询失败，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。\n\n * 解决方案：\n   * 使用互斥锁(mutex key)：mutex，就是互斥。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用redis的setnx去set一个互斥key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。setnx，是「set if not exists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现互斥的效果。\n   * 软过期：也就是逻辑过期，不使用redis提供的过期时间，而是业务层在数据中存储过期时间信息。查询时由业务程序判断是否过期，如果数据即将过期时，将缓存的时效延长，程序可以派遣一个线程去数据库中获取最新的数据，其他线程这时看到延长了的过期时间，就会继续使用旧数据，等派遣的线程获取最新数据后再更新缓存。\n\n推荐使用互斥锁，因为软过期会有业务逻辑侵入和额外的判断。\n\n面试话术：\n\n缓存击穿主要担心的是某个key过期，更新缓存时引起对数据库的突发高并发访问。因此我们可以在更新缓存时采用互斥锁控制，只允许一个线程去更新缓存，其它线程等待并重新读取缓存。例如redis的setnx命令就能实现互斥效果。\n\n\n# 3）缓存雪崩\n\n相关资料：\n\n缓存雪崩，是指在某一个时间段，缓存集中过期失效。对这批数据的访问查询，都落到了数据库上，对于数据库而言，就会产生周期性的压力波峰。\n\n解决方案：\n\n * 数据分类分批处理：采取不同分类数据，缓存不同周期\n * 相同分类数据：采用固定时长加随机数方式设置缓存\n * 热点数据缓存时间长一些，冷门数据缓存时间短一些\n * 避免redis节点宕机引起雪崩，搭建主从集群，保证高可用\n\n面试话术：\n\n解决缓存雪崩问题的关键是让缓存key的过期时间分散。因此我们可以把数据按照业务分类，然后设置不同过期时间。相同业务类型的key，设置固定时长加随机数。尽可能保证每个key的过期时间都不相同。\n\n另外，redis宕机也可能导致缓存雪崩，因此我们还要搭建redis主从集群及哨兵监控，保证redis的高可用。\n\n\n# 3.9.缓存冷热数据分离\n\n背景资料：\n\nredis使用的是内存存储，当需要海量数据存储时，成本非常高。\n\n经过调研发现，当前主流ddr3内存和主流sata ssd的单位成本价格差距大概在20倍左右，为了优化redis机器综合成本，我们考虑实现基于热度统计 的数据分级存储及数据在ram/flash之间的动态交换，从而大幅度降低成本，达到性能与成本的高平衡。\n\n基本思路：基于key访问次数(lfu)的热度统计算法识别出热点数据，并将热点数据保留在redis中，对于无访问/访问次数少的数据则转存到ssd上，如果ssd上的key再次变热，则重新将其加载到redis内存中。\n\n目前流行的高性能磁盘存储，并且遵循redis协议的方案包括：\n\n * ssdb：http://ssdb.io/zh_cn/\n * rocksdb：https://rocksdb.org.cn/\n\n因此，我们就需要在应用程序与缓存服务之间引入代理，实现redis和ssd之间的切换，如图：\n\n\n\n这样的代理方案阿里云提供的就有。当然也有一些开源方案，例如：https://github.com/jingchengli/swapdb\n\n\n# 3.10.redis实现分布式锁\n\n分布式锁要满足的条件：\n\n * 多进程互斥：同一时刻，只有一个进程可以获取锁\n * 保证锁可以释放：任务结束或出现异常，锁一定要释放，避免死锁\n * 阻塞锁（可选）：获取锁失败时可否重试\n * 重入锁（可选）：获取锁的代码递归调用时，依然可以获取锁\n\n\n# 1）最基本的分布式锁：\n\n利用redis的setnx命令，这个命令的特征时如果多次执行，只有第一次执行会成功，可以实现互斥的效果。但是为了保证服务宕机时也可以释放锁，需要利用expire命令给锁设置一个有效期\n\nsetnx lock thread-01 # 尝试获取锁\nexpire lock 10 # 设置有效期\n\n\n面试官问题1：如果expire之前服务宕机怎么办？\n\n要保证setnx和expire命令的原子性。redis的set命令可以满足：\n\nset key value [nx] [ex time] \n\n\n需要添加nx和ex的选项：\n\n * nx：与setnx一致，第一次执行成功\n * ex：设置过期时间\n\n面试官问题2：释放锁的时候，如果自己的锁已经过期了，此时会出现安全漏洞，如何解决？\n\n在锁中存储当前进程和线程标识，释放锁时对锁的标识判断，如果是自己的则删除，不是则放弃操作。\n\n但是这两步操作要保证原子性，需要通过lua脚本来实现。\n\nif redis.call(\"get\",keys[1]) == argv[1] then\n    redis.call(\"del\",keys[1])\nend\n\n\n\n# 2）可重入分布式锁\n\n如果有重入的需求，则除了在锁中记录进程标识，还要记录重试次数，流程如下：\n\n\n\n下面我们假设锁的key为“lock”，hashkey是当前线程的id：“threadid”，锁自动释放时间假设为20\n\n获取锁的步骤：\n\n * 1、判断lock是否存在 exists lock\n   * 存在，说明有人获取锁了，下面判断是不是自己的锁\n     * 判断当前线程id作为hashkey是否存在：hexists lock threadid\n       * 不存在，说明锁已经有了，且不是自己获取的，锁获取失败，end\n       * 存在，说明是自己获取的锁，重入次数+1：hincrby lock threadid 1，去到步骤3\n   * 2、不存在，说明可以获取锁，hset key threadid 1\n   * 3、设置锁自动释放时间，expire lock 20\n\n释放锁的步骤：\n\n * 1、判断当前线程id作为hashkey是否存在：hexists lock threadid\n   * 不存在，说明锁已经失效，不用管了\n   * 存在，说明锁还在，重入次数减1：hincrby lock threadid -1，获取新的重入次数\n * 2、判断重入次数是否为0：\n   * 为0，说明锁全部释放，删除key：del lock\n   * 大于0，说明锁还在使用，重置有效时间：expire lock 20\n\n对应的lua脚本如下：\n\n首先是获取锁：\n\nlocal key = keys[1]; -- 锁的key\nlocal threadid = argv[1]; -- 线程唯一标识\nlocal releasetime = argv[2]; -- 锁的自动释放时间\n\nif(redis.call('exists', key) == 0) then -- 判断是否存在\n\tredis.call('hset', key, threadid, '1'); -- 不存在, 获取锁\n\tredis.call('expire', key, releasetime); -- 设置有效期\n\treturn 1; -- 返回结果\nend;\n\nif(redis.call('hexists', key, threadid) == 1) then -- 锁已经存在，判断threadid是否是自己\t\n\tredis.call('hincrby', key, threadid, '1'); -- 不存在, 获取锁，重入次数+1\n\tredis.call('expire', key, releasetime); -- 设置有效期\n\treturn 1; -- 返回结果\nend;\nreturn 0; -- 代码走到这里,说明获取锁的不是自己，获取锁失败\n\n\n然后是释放锁：\n\nlocal key = keys[1]; -- 锁的key\nlocal threadid = argv[1]; -- 线程唯一标识\nlocal releasetime = argv[2]; -- 锁的自动释放时间\n\nif (redis.call('hexists', key, threadid) == 0) then -- 判断当前锁是否还是被自己持有\n    return nil; -- 如果已经不是自己，则直接返回\nend;\nlocal count = redis.call('hincrby', key, threadid, -1); -- 是自己的锁，则重入次数-1\n\nif (count > 0) then -- 判断是否重入次数是否已经为0\n    redis.call('expire', key, releasetime); -- 大于0说明不能释放锁，重置有效期然后返回\n    return nil;\nelse\n    redis.call('del', key); -- 等于0说明可以释放锁，直接删除\n    return nil;\nend;\n\n\n\n# 3）高可用的锁\n\n面试官问题：redis分布式锁依赖与redis，如果redis宕机则锁失效。如何解决？\n\n此时大多数同学会回答说：搭建主从集群，做数据备份。\n\n这样就进入了陷阱，因为面试官的下一个问题就来了：\n\n面试官问题：如果搭建主从集群做数据备份时，进程a获取锁，master还没有把数据备份到slave，master宕机，slave升级为master，此时原来锁失效，其它进程也可以获取锁，出现安全问题。如何解决？\n\n关于这个问题，redis官网给出了解决方案，使用redlock思路可以解决：\n\n> 在redis的分布式环境中，我们假设有n个redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。之前我们已经描述了在redis单实例下怎么安全地获取和释放锁。我们确保将在每（n)个实例上使用此方法获取和释放锁。在这个样例中，我们假设有5个redis master节点，这是一个比较合理的设置，所以我们需要在5台机器上面或者5台虚拟机上面运行这些实例，这样保证他们不会同时都宕掉。\n> \n> 为了取到锁，客户端应该执行以下操作:\n> \n>  1. 获取当前unix时间，以毫秒为单位。\n>  2. 依次尝试从n个实例，使用相同的key和随机值获取锁。在步骤2，当向redis设置锁时,客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试另外一个redis实例。\n>  3. 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（这里是3个节点）的redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。\n>  4. 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。\n>  5. 如果因为某些原因，获取锁失败（没有在至少n/2+1个redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的redis实例上进行解锁（即便某些redis实例根本就没有加锁成功）。\n\n\n# 3.11.如何实现数据库与缓存数据一致？\n\n面试话术：\n\n实现方案有下面几种：\n\n * 本地缓存同步：当前微服务的数据库数据与缓存数据同步，可以直接在数据库修改时加入对redis的修改逻辑，保证一致。\n * 跨服务缓存同步：服务a调用了服务b，并对查询结果缓存。服务b数据库修改，可以通过mq通知服务a，服务a修改redis缓存数据\n * 通用方案：使用canal框架，伪装成mysql的salve节点，监听mysql的binlog变化，然后修改redis缓存数据",charsets:{cjk:!0}},{title:"Spring",frontmatter:{title:"Spring",date:"2023-03-02T15:16:23.000Z",permalink:"/pages/23ed38/"},regularPath:"/01.Java/04.%E6%A1%86%E6%9E%B6/01.spring.html",relativePath:"01.Java/04.框架/01.spring.md",key:"v-2fe1c292",path:"/pages/23ed38/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"Spring Boot 自动装配简易理解",frontmatter:{title:"Spring Boot 自动装配简易理解",date:"2023-03-09T22:22:55.000Z",permalink:"/pages/418390/"},regularPath:"/01.Java/04.%E6%A1%86%E6%9E%B6/03.springbooteasy.html",relativePath:"01.Java/04.框架/03.springbooteasy.md",key:"v-3ad03cd2",path:"/pages/418390/",headers:[{level:2,title:"预热",slug:"预热",normalizedTitle:"预热",charIndex:2},{level:2,title:"再预热",slug:"再预热",normalizedTitle:"再预热",charIndex:1183},{level:3,title:"BeanDefinition",slug:"beandefinition",normalizedTitle:"beandefinition",charIndex:3116},{level:3,title:"BeanDefinition中的属性",slug:"beandefinition中的属性",normalizedTitle:"beandefinition中的属性",charIndex:3220},{level:2,title:"自动装配",slug:"自动装配",normalizedTitle:"自动装配",charIndex:3451},{level:2,title:"ChatGPT",slug:"chatgpt",normalizedTitle:"chatgpt",charIndex:4136},{level:3,title:"springboot 自动装配原理",slug:"springboot-自动装配原理",normalizedTitle:"springboot 自动装配原理",charIndex:4148},{level:3,title:"springboot 自动装配源码分析",slug:"springboot-自动装配源码分析",normalizedTitle:"springboot 自动装配源码分析",charIndex:4991},{level:3,title:"springboot 中的BeanDefinition怎么理解",slug:"springboot-中的beandefinition怎么理解",normalizedTitle:"springboot 中的beandefinition怎么理解",charIndex:6132},{level:3,title:"如何理解BeanDefinition 中的 autowireMode属性",slug:"如何理解beandefinition-中的-autowiremode属性",normalizedTitle:"如何理解beandefinition 中的 autowiremode属性",charIndex:7122},{level:3,title:"BeanDefinition中的ConstructorArgumentValues属性使用方式",slug:"beandefinition中的constructorargumentvalues属性使用方式",normalizedTitle:"beandefinition中的constructorargumentvalues属性使用方式",charIndex:8079},{level:3,title:"SpringApplication中的setListeners怎么理解",slug:"springapplication中的setlisteners怎么理解",normalizedTitle:"springapplication中的setlisteners怎么理解",charIndex:9494},{level:3,title:"SpringApplication中的setInitializers怎么理解",slug:"springapplication中的setinitializers怎么理解",normalizedTitle:"springapplication中的setinitializers怎么理解",charIndex:10741}],headersStr:"预热 再预热 BeanDefinition BeanDefinition中的属性 自动装配 ChatGPT springboot 自动装配原理 springboot 自动装配源码分析 springboot 中的BeanDefinition怎么理解 如何理解BeanDefinition 中的 autowireMode属性 BeanDefinition中的ConstructorArgumentValues属性使用方式 SpringApplication中的setListeners怎么理解 SpringApplication中的setInitializers怎么理解",content:'# 预热\n\n@Data\n@NoArgsConstructor\n@AllArgsConstructor\npublic class Person {\n    private String name;\n    private Integer age;\n    private Boolean sex;\n}\n\n\n配置Bean\n\n 1. 通过配置文件，setter注入\n\n\x3c!-- 手动配置bean对象 --\x3e\n<bean id="person" class="pojo.Person">\n    <property name="name" value="dzzhyk"/>\n    <property name="age" value="20"/>\n    <property name="sex" value="true"/>\n</bean>\n\n\n 2. 通过配置文件，构造器注入\n\n\x3c!-- 使用构造器 --\x3e\n<bean id="person" class="pojo.Person">\n    <constructor-arg index="0" type="java.lang.String" value="dzzhyk" />\n    <constructor-arg index="1" type="java.lang.Integer" value="20"/>\n    <constructor-arg index="2" type="java.lang.Boolean" value="true"/>\n</bean>\n\n\n 3. 通过注解，属性注入\n\n@Component\npublic class Person {\n    \n    @Value("dzzhyk")\n    private String name;\n    @Value("20")\n    private Integer age;\n    @Value("true")\n    private Boolean sex;\n}\n\n\n测试以上三种方案，都可以获得Bean\n\npublic class TestVersion {\n    @Test\n    public void test(){\n        ApplicationContext ac = new ClassPathXmlApplicationContext("applicationContext.xml");\n        Person person = ac.getBean("person", Person.class);\n        System.out.println(person);\n    }\n}\n\n\n结果\n\nPerson(name=dzzhyk, age=20, sex=true)\n\n\n\n# 再预热\n\n扩展一下这个类\n\npublic class Car {\n    private String brand;\n    private Integer price;\n}\n\npublic class Dog {\n    private String name;\n    private Integer age;\n}\n\npublic class Person {\n    private String name;\n    private Integer age;\n    private Boolean sex;\n    private Dog dog;\n    private Car car;\n}\n\n\n\n1. 基于XML配置\n\n<bean id="person" class="pojo.Person">\n    <property name="name" value="dzzhyk"/>\n    <property name="age" value="20"/>\n    <property name="sex" value="true"/>\n    <property name="dog" ref="dog"/>\n    <property name="car" ref="car"/>\n</bean>\n\n<bean id="dog" class="pojo.Dog">\n    <property name="name" value="旺财"/>\n    <property name="age" value="5" />\n</bean>\n\n<bean id="car" class="pojo.Car">\n    <property name="brand" value="奥迪双钻"/>\n    <property name="price" value="100000"/>\n</bean>\n\n\n\n使用ClassPathXmlApplicationContext容器\n\n/**\n * 使用XML配置\n */\npublic class TestVersion1 {\n    @Test\n    public void test(){\n        ClassPathXmlApplicationContext ca = new ClassPathXmlApplicationContext("applicationContext.xml");\n        Person person = ca.getBean("person", Person.class);\n        System.out.println(person);\n    }\n}\n\n\n\n2. 基于配置类配置\n\n@Configuration\n@ComponentScan\npublic class PersonConfig {\n\n    @Bean\n    public Person person(Dog dog, Car car){\n        return new Person("dzzhyk", 20, true, dog, car);\n    }\n\n    @Bean\n    public Dog dog(){\n        return new Dog("旺财", 5);\n    }\n\n    @Bean\n    public Car car(){\n        return new Car("奥迪双钻", 100000);\n    }\n}\n\n\n\n使用AnnotationConfigApplicationContext容器\n\n/**\n * 使用JavaConfig配置\n */\npublic class TestVersion2 {\n    @Test\n    public void test(){\n        AnnotationConfigApplicationContext ac = new AnnotationConfigApplicationContext(PersonConfig.class);\n        Person person = ac.getBean("person", Person.class);\n        System.out.println(person);\n    }\n}\n\n\n\n结果\n\nPerson(name=dzzhyk, age=20, sex=true, dog=Dog(name=旺财, age=5), car=Car(brand=奥迪双钻, price=100000))\n\n\n\n# BeanDefinition\n\n是描述Spring 容器中Bean的元数据对象，被存放一个map容器中\n\nBeanDefinitionMap<beanName, BeanDefinition>\n\n\n\n\n\n# BeanDefinition中的属性\n\n\n\n重点以下三个成员\n\nprivate volatile Object beanClass;\nprivate int autowireMode = AUTOWIRE_NO;\nprivate ConstructorArgumentValues constructorArgumentValues;\n\n\nBeanClass\n\n这个属性定义了这个BeanDefinition 是属于哪个class\n\nautowireMode\n\n自动装配模式\n\n * AUTOWIRE_NO\n * AUTOWIRE_BY_NAME\n * AUTOWIRE_BY_TYPE\n * AUTOWIRE_CONSTRUCTOR\n\n@Component\npublic class A {\n    @Value("我是AAA")\n    private String name;\n    // A的BeanDefinition开启了自动装配, 才可以使用该为A注入属性\n    @Autowired\n    private B b;\n}\n\n\n在BeanFactoryPostProcessor中做文章\n\ndefA.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_NAME);\n\n\nconstructorArgumentValues\n\nSpring在实例化对象时使用的是对象的默认空参构造器\n\n在BeanFactoryPostProcessor中做文章\n\nConstructorArgumentValues args = new ConstructorArgumentValues();\n// 在BeanDefinition中设置实例化对象时,调用哪个构造函数, 设置构造函数中第i个位置，的值\nargs.addIndexedArgumentValue(0, "我指定的姓名");\nargs.addIndexedArgumentValue(1, 20);\ndefStu.setConstructorArgumentValues(args);\n\n\n\n\n# 自动装配\n\n\n\n\n# ChatGPT\n\n\n# springboot 自动装配原理\n\nSpring Boot 自动装配是基于 Spring Framework 的自动装配机制，通过使用 @EnableAutoConfiguration 注解来实现。@EnableAutoConfiguration 注解会自动扫描当前类路径下的所有 jar 包，根据约定的规则和条件，自动配置需要的 Bean，并将其注入到 Spring 容器中。\n\nSpring Boot 自动装配的原理可以概括为以下几个步骤：\n\n 1. Spring Boot 在启动时会扫描所有 jar 包，并根据约定的规则和条件，自动配置需要的 Bean。\n\n 2. Spring Boot 会根据当前项目中的依赖关系，优先使用项目中已经存在的 Bean。\n\n 3. Spring Boot 会根据配置文件中的配置，覆盖自动配置的默认值。\n\n 4. Spring Boot 会根据条件判断，决定是否需要自动配置某些 Bean。\n\n 5. Spring Boot 会将所有自动配置的 Bean 注入到 Spring 容器中，供其他组件使用。\n\nSpring Boot 自动装配的规则和条件是由 Spring Boot Starter 模块中的 META-INF/spring.factories 文件中的配置来定义的。该文件中定义了一个或多个自动配置类，每个自动配置类都会根据特定的规则和条件，自动配置相应的 Bean。\n\n在自动装配过程中，如果需要手动配置某些 Bean，可以使用 @Configuration 注解来定义一个配置类，并使用 @Bean 注解来定义需要手动配置的 Bean。手动配置的 Bean 会覆盖自动配置的默认值。\n\n总的来说，Spring Boot 自动装配的原理是在 Spring Framework 的自动装配机制的基础上，通过约定的规则和条件，自动配置需要的 Bean，并将其注入到 Spring 容器中，从而简化了应用程序的开发和部署。\n\n\n# springboot 自动装配源码分析\n\nSpring Boot 自动装配的源码分析主要涉及以下几个方面：\n\n 1. @EnableAutoConfiguration 注解的实现\n\n@EnableAutoConfiguration 是 Spring Boot 自动装配的核心注解，它的作用是开启自动装配功能。@EnableAutoConfiguration 注解的实现基于 Spring Framework 的自动装配机制，它会自动扫描当前类路径下的所有 jar 包，根据约定的规则和条件，自动配置需要的 Bean。具体实现可以参考 AutoConfigurationImportSelector 类。\n\n 2. 自动配置类的实现\n\n自动配置类是实现自动装配功能的关键，它们是根据约定的规则和条件，自动配置需要的 Bean。自动配置类通常使用 @Configuration 注解来标识，并使用 @ConditionalOnClass、@ConditionalOnMissingBean、@ConditionalOnProperty 等条件注解来控制自动配置的行为。具体实现可以参考 Spring Boot Starter 模块中的 META-INF/spring.factories 文件中的配置。\n\n 3. Spring Boot Starter 的实现\n\nSpring Boot Starter 是一种可复用的、可配置的依赖关系，它可以将多个相关的依赖项打包成一个单独的模块，从而简化应用程序的开发和部署。Spring Boot Starter 的实现通常包括以下几个方面：自动配置类、依赖管理、插件管理、属性配置等。具体实现可以参考 Spring Boot Starter 模块中的 pom.xml 文件和 META-INF/spring.factories 文件中的配置。\n\n 4. 自动装配的优先级和顺序\n\n在自动装配过程中，Spring Boot 会根据当前项目中的依赖关系，优先使用项目中已经存在的 Bean。如果存在多个自动配置类可以配置同一个 Bean，那么 Spring Boot 会根据自动配置类的优先级和顺序来决定使用哪个自动配置类。具体实现可以参考 AutoConfigurationImportSelector 类中的方法。\n\n总的来说，Spring Boot 自动装配的源码分析需要深入了解 Spring Framework 的自动装配机制和条件注解的使用方法，同时还需要了解 Spring Boot Starter 的实现和自动装配的优先级和顺序。只有在深入了解这些内容的基础上，才能更好地理解和使用 Spring Boot 自动装配功能。\n\n\n# springboot 中的BeanDefinition怎么理解\n\n在 Spring Boot 中，BeanDefinition 是用来描述 Spring 容器中 Bean 的元数据对象。BeanDefinition 中包含了 Bean 的类名、属性值、构造函数参数值等信息，它定义了 Bean 的类型、作用域、生命周期等属性，是 Spring 容器中 Bean 的重要组成部分。\n\nBeanDefinition 可以通过两种方式进行定义：\n\n 1. 通过 XML 配置文件定义 BeanDefinition。\n\n 2. 通过 Java 代码定义 BeanDefinition。\n\n在 Spring Boot 中，通常使用 Java 代码来定义 BeanDefinition。可以通过 @Bean 注解、@Component 注解、@Configuration 注解等方式来定义 BeanDefinition。其中，@Bean 注解是最常用的方式，它可以在任何 Java 类中定义 BeanDefinition，并将其注入到 Spring 容器中。\n\n例如，下面是一个使用 @Bean 注解定义 BeanDefinition 的示例：\n\n@Configuration\npublic class AppConfig {\n    @Bean\n    public UserService userService() {\n        return new UserServiceImpl();\n    }\n}\n\n\n在上面的示例中，@Configuration 注解表示该类是一个配置类，@Bean 注解表示该方法返回的对象是一个 Bean。Spring Boot 会根据该 Bean 的类型、作用域、生命周期等属性，创建对应的 BeanDefinition，并将其注入到 Spring 容器中。\n\n总的来说，BeanDefinition 是描述 Spring 容器中 Bean 的元数据对象，它定义了 Bean 的类型、作用域、生命周期等属性，并可以通过 @Bean 注解、@Component 注解、@Configuration 注解等方式进行定义。了解 BeanDefinition 的概念和定义方式，可以更好地理解和使用 Spring Boot 中的 Bean 容器。\n\n\n# 如何理解BeanDefinition 中的 autowireMode属性\n\nBeanDefinition 中的 autowireMode 属性是用来指定自动装配模式的。自动装配模式指的是 Spring 容器在进行自动装配时，如何确定要注入哪个 Bean。\n\nBeanDefinition 中的 autowireMode 属性有以下几个取值：\n\n 1. AUTOWIRE_NO：不进行自动装配，需要手动指定依赖关系。\n\n 2. AUTOWIRE_BY_NAME：根据 Bean 的名称进行自动装配，要求依赖的 Bean 名称必须和属性名称一致。\n\n 3. AUTOWIRE_BY_TYPE：根据 Bean 的类型进行自动装配，要求依赖的 Bean 类型必须和属性类型一致。\n\n 4. AUTOWIRE_CONSTRUCTOR：通过构造函数进行自动装配，要求依赖的 Bean 类型必须和构造函数参数类型一致。\n\n 5. AUTOWIRE_AUTODETECT：自动检测自动装配模式，根据属性类型和名称进行自动装配。\n\n例如，下面是一个使用 @Autowired 注解进行自动装配的示例：\n\n@Component\npublic class UserController {\n    @Autowired\n    private UserService userService;\n}\n\n\n在上面的示例中，@Autowired 注解表示要对 userService 属性进行自动装配。如果 BeanDefinition 中的 autowireMode 属性为 AUTOWIRE_BY_NAME，则需要保证 UserService 的名称和属性名称一致；如果 BeanDefinition 中的 autowireMode 属性为 AUTOWIRE_BY_TYPE，则需要保证 UserService 的类型和属性类型一致。\n\n总的来说，BeanDefinition 中的 autowireMode 属性是用来指定自动装配模式的，它决定了 Spring 容器在进行自动装配时如何确定要注入哪个 Bean。了解 autowireMode 属性的取值和作用，可以更好地理解和使用 Spring Boot 中的自动装配功能。\n\n\n# BeanDefinition中的ConstructorArgumentValues属性使用方式\n\nBeanDefinition 中的 ConstructorArgumentValues 属性是用来指定 Bean 的构造函数参数的。它可以通过以下两种方式进行设置：\n\n 1. 使用 index 属性指定构造函数参数的位置，使用 value 属性指定构造函数参数的值。例如：\n\n<bean id="user" class="com.example.User">\n    <constructor-arg index="0" value="张三"/>\n    <constructor-arg index="1" value="30"/>\n</bean>\n\n\n在上面的示例中，index 属性指定了构造函数参数的位置，value 属性指定了构造函数参数的值。\n\n 2. 使用 name 属性指定构造函数参数的名称，使用 ref 属性指定构造函数参数的引用。例如：\n\n<bean id="user" class="com.example.User">\n    <constructor-arg name="name" value="张三"/>\n    <constructor-arg name="age" ref="ageBean"/>\n</bean>\n\n<bean id="ageBean" class="java.lang.Integer">\n    <constructor-arg value="30"/>\n</bean>\n\n\n在上面的示例中，name 属性指定了构造函数参数的名称，value 属性指定了构造函数参数的值，ref 属性指定了构造函数参数的引用。\n\n除了 XML 配置文件之外，还可以使用 Java 代码来设置 ConstructorArgumentValues 属性。例如：\n\n@Configuration\npublic class AppConfig {\n    @Bean\n    public User user() {\n        ConstructorArgumentValues constructorArgumentValues = new ConstructorArgumentValues();\n        constructorArgumentValues.addIndexedArgumentValue(0, "张三");\n        constructorArgumentValues.addIndexedArgumentValue(1, 30);\n        return new User(constructorArgumentValues);\n    }\n}\n\n\n在上面的示例中，使用 ConstructorArgumentValues 对象来设置构造函数参数的值，addIndexedArgumentValue() 方法指定了构造函数参数的位置和值。\n\n总的来说，ConstructorArgumentValues 属性是用来指定 Bean 的构造函数参数的，可以通过 XML 配置文件或 Java 代码进行设置。了解 ConstructorArgumentValues 的使用方式，可以更好地理解和使用 Spring Boot 中的 Bean 容器。\n\n\n# SpringApplication中的setListeners怎么理解\n\nSpringApplication 中的 setListeners() 方法是用来设置 Spring Boot 应用程序的监听器的。Spring Boot 应用程序的监听器是一种特殊的 Bean，它可以监听 Spring Boot 应用程序的生命周期事件，并在事件发生时执行相应的逻辑。\n\nSpring Boot 应用程序的监听器可以分为以下几种类型：\n\n 1. ApplicationStartingEvent 监听器：在 Spring Boot 应用程序启动之前执行。\n\n 2. ApplicationEnvironmentPreparedEvent 监听器：在 Spring Boot 应用程序环境准备完成之后执行。\n\n 3. ApplicationPreparedEvent 监听器：在 Spring Boot 应用程序准备完成之后执行。\n\n 4. ApplicationStartedEvent 监听器：在 Spring Boot 应用程序启动完成之后执行。\n\n 5. ApplicationReadyEvent 监听器：在 Spring Boot 应用程序准备好接收请求之后执行。\n\n 6. ApplicationFailedEvent 监听器：在 Spring Boot 应用程序启动失败时执行。\n\n使用 setListeners() 方法可以向 Spring Boot 应用程序添加自定义的监听器，以实现一些特定的业务逻辑。例如，下面是一个使用 setListeners() 方法添加 ApplicationStartedEvent 监听器的示例：\n\n@SpringBootApplication\npublic class MyApp {\n    public static void main(String[] args) {\n        SpringApplication app = new SpringApplication(MyApp.class);\n        app.setListeners(Collections.singletonList(new MyApplicationStartedEventListener()));\n        app.run(args);\n    }\n}\n\n\n在上面的示例中，使用 setListeners() 方法向 Spring Boot 应用程序添加了一个自定义的 ApplicationStartedEvent 监听器 MyApplicationStartedEventListener。\n\n总的来说，setListeners() 方法是用来设置 Spring Boot 应用程序的监听器的。了解 setListeners() 方法的使用方式和 Spring Boot 应用程序的监听器类型，可以更好地实现一些特定的业务逻辑。\n\n\n# SpringApplication中的setInitializers怎么理解\n\nSpringApplication 中的 setInitializers() 方法是用来设置 Spring Boot 应用程序的初始化器的。Spring Boot 应用程序的初始化器是一种特殊的 Bean，它可以在 Spring Boot 应用程序启动之前执行一些初始化逻辑。\n\nSpring Boot 应用程序的初始化器可以分为以下几种类型：\n\n 1. ApplicationContextInitializer：在 Spring 应用程序上下文创建之前执行。\n\n 2. ApplicationListener：在 Spring Boot 应用程序启动之前执行。\n\n使用 setInitializers() 方法，可以向 Spring Boot 应用程序添加自定义的初始化器，以实现一些特定的业务逻辑。例如，下面是一个使用 setInitializers() 方法添加 ApplicationContextInitializer 的示例：\n\n@SpringBootApplication\npublic class MyApp {\n    public static void main(String[] args) {\n        SpringApplication app = new SpringApplication(MyApp.class);\n        app.setInitializers(Collections.singletonList(new MyApplicationContextInitializer()));\n        app.run(args);\n    }\n}\n\n\n在上面的示例中，使用 setInitializers() 方法向 Spring Boot 应用程序添加了一个自定义的 ApplicationContextInitializer。\n\n总的来说，setInitializers() 方法是用来设置 Spring Boot 应用程序的初始化器的。了解 setInitializers() 方法的使用方式和 Spring Boot 应用程序的初始化器类型，可以更好地实现一些特定的业务逻辑。',normalizedContent:'# 预热\n\n@data\n@noargsconstructor\n@allargsconstructor\npublic class person {\n    private string name;\n    private integer age;\n    private boolean sex;\n}\n\n\n配置bean\n\n 1. 通过配置文件，setter注入\n\n\x3c!-- 手动配置bean对象 --\x3e\n<bean id="person" class="pojo.person">\n    <property name="name" value="dzzhyk"/>\n    <property name="age" value="20"/>\n    <property name="sex" value="true"/>\n</bean>\n\n\n 2. 通过配置文件，构造器注入\n\n\x3c!-- 使用构造器 --\x3e\n<bean id="person" class="pojo.person">\n    <constructor-arg index="0" type="java.lang.string" value="dzzhyk" />\n    <constructor-arg index="1" type="java.lang.integer" value="20"/>\n    <constructor-arg index="2" type="java.lang.boolean" value="true"/>\n</bean>\n\n\n 3. 通过注解，属性注入\n\n@component\npublic class person {\n    \n    @value("dzzhyk")\n    private string name;\n    @value("20")\n    private integer age;\n    @value("true")\n    private boolean sex;\n}\n\n\n测试以上三种方案，都可以获得bean\n\npublic class testversion {\n    @test\n    public void test(){\n        applicationcontext ac = new classpathxmlapplicationcontext("applicationcontext.xml");\n        person person = ac.getbean("person", person.class);\n        system.out.println(person);\n    }\n}\n\n\n结果\n\nperson(name=dzzhyk, age=20, sex=true)\n\n\n\n# 再预热\n\n扩展一下这个类\n\npublic class car {\n    private string brand;\n    private integer price;\n}\n\npublic class dog {\n    private string name;\n    private integer age;\n}\n\npublic class person {\n    private string name;\n    private integer age;\n    private boolean sex;\n    private dog dog;\n    private car car;\n}\n\n\n\n1. 基于xml配置\n\n<bean id="person" class="pojo.person">\n    <property name="name" value="dzzhyk"/>\n    <property name="age" value="20"/>\n    <property name="sex" value="true"/>\n    <property name="dog" ref="dog"/>\n    <property name="car" ref="car"/>\n</bean>\n\n<bean id="dog" class="pojo.dog">\n    <property name="name" value="旺财"/>\n    <property name="age" value="5" />\n</bean>\n\n<bean id="car" class="pojo.car">\n    <property name="brand" value="奥迪双钻"/>\n    <property name="price" value="100000"/>\n</bean>\n\n\n\n使用classpathxmlapplicationcontext容器\n\n/**\n * 使用xml配置\n */\npublic class testversion1 {\n    @test\n    public void test(){\n        classpathxmlapplicationcontext ca = new classpathxmlapplicationcontext("applicationcontext.xml");\n        person person = ca.getbean("person", person.class);\n        system.out.println(person);\n    }\n}\n\n\n\n2. 基于配置类配置\n\n@configuration\n@componentscan\npublic class personconfig {\n\n    @bean\n    public person person(dog dog, car car){\n        return new person("dzzhyk", 20, true, dog, car);\n    }\n\n    @bean\n    public dog dog(){\n        return new dog("旺财", 5);\n    }\n\n    @bean\n    public car car(){\n        return new car("奥迪双钻", 100000);\n    }\n}\n\n\n\n使用annotationconfigapplicationcontext容器\n\n/**\n * 使用javaconfig配置\n */\npublic class testversion2 {\n    @test\n    public void test(){\n        annotationconfigapplicationcontext ac = new annotationconfigapplicationcontext(personconfig.class);\n        person person = ac.getbean("person", person.class);\n        system.out.println(person);\n    }\n}\n\n\n\n结果\n\nperson(name=dzzhyk, age=20, sex=true, dog=dog(name=旺财, age=5), car=car(brand=奥迪双钻, price=100000))\n\n\n\n# beandefinition\n\n是描述spring 容器中bean的元数据对象，被存放一个map容器中\n\nbeandefinitionmap<beanname, beandefinition>\n\n\n\n\n\n# beandefinition中的属性\n\n\n\n重点以下三个成员\n\nprivate volatile object beanclass;\nprivate int autowiremode = autowire_no;\nprivate constructorargumentvalues constructorargumentvalues;\n\n\nbeanclass\n\n这个属性定义了这个beandefinition 是属于哪个class\n\nautowiremode\n\n自动装配模式\n\n * autowire_no\n * autowire_by_name\n * autowire_by_type\n * autowire_constructor\n\n@component\npublic class a {\n    @value("我是aaa")\n    private string name;\n    // a的beandefinition开启了自动装配, 才可以使用该为a注入属性\n    @autowired\n    private b b;\n}\n\n\n在beanfactorypostprocessor中做文章\n\ndefa.setautowiremode(abstractbeandefinition.autowire_by_name);\n\n\nconstructorargumentvalues\n\nspring在实例化对象时使用的是对象的默认空参构造器\n\n在beanfactorypostprocessor中做文章\n\nconstructorargumentvalues args = new constructorargumentvalues();\n// 在beandefinition中设置实例化对象时,调用哪个构造函数, 设置构造函数中第i个位置，的值\nargs.addindexedargumentvalue(0, "我指定的姓名");\nargs.addindexedargumentvalue(1, 20);\ndefstu.setconstructorargumentvalues(args);\n\n\n\n\n# 自动装配\n\n\n\n\n# chatgpt\n\n\n# springboot 自动装配原理\n\nspring boot 自动装配是基于 spring framework 的自动装配机制，通过使用 @enableautoconfiguration 注解来实现。@enableautoconfiguration 注解会自动扫描当前类路径下的所有 jar 包，根据约定的规则和条件，自动配置需要的 bean，并将其注入到 spring 容器中。\n\nspring boot 自动装配的原理可以概括为以下几个步骤：\n\n 1. spring boot 在启动时会扫描所有 jar 包，并根据约定的规则和条件，自动配置需要的 bean。\n\n 2. spring boot 会根据当前项目中的依赖关系，优先使用项目中已经存在的 bean。\n\n 3. spring boot 会根据配置文件中的配置，覆盖自动配置的默认值。\n\n 4. spring boot 会根据条件判断，决定是否需要自动配置某些 bean。\n\n 5. spring boot 会将所有自动配置的 bean 注入到 spring 容器中，供其他组件使用。\n\nspring boot 自动装配的规则和条件是由 spring boot starter 模块中的 meta-inf/spring.factories 文件中的配置来定义的。该文件中定义了一个或多个自动配置类，每个自动配置类都会根据特定的规则和条件，自动配置相应的 bean。\n\n在自动装配过程中，如果需要手动配置某些 bean，可以使用 @configuration 注解来定义一个配置类，并使用 @bean 注解来定义需要手动配置的 bean。手动配置的 bean 会覆盖自动配置的默认值。\n\n总的来说，spring boot 自动装配的原理是在 spring framework 的自动装配机制的基础上，通过约定的规则和条件，自动配置需要的 bean，并将其注入到 spring 容器中，从而简化了应用程序的开发和部署。\n\n\n# springboot 自动装配源码分析\n\nspring boot 自动装配的源码分析主要涉及以下几个方面：\n\n 1. @enableautoconfiguration 注解的实现\n\n@enableautoconfiguration 是 spring boot 自动装配的核心注解，它的作用是开启自动装配功能。@enableautoconfiguration 注解的实现基于 spring framework 的自动装配机制，它会自动扫描当前类路径下的所有 jar 包，根据约定的规则和条件，自动配置需要的 bean。具体实现可以参考 autoconfigurationimportselector 类。\n\n 2. 自动配置类的实现\n\n自动配置类是实现自动装配功能的关键，它们是根据约定的规则和条件，自动配置需要的 bean。自动配置类通常使用 @configuration 注解来标识，并使用 @conditionalonclass、@conditionalonmissingbean、@conditionalonproperty 等条件注解来控制自动配置的行为。具体实现可以参考 spring boot starter 模块中的 meta-inf/spring.factories 文件中的配置。\n\n 3. spring boot starter 的实现\n\nspring boot starter 是一种可复用的、可配置的依赖关系，它可以将多个相关的依赖项打包成一个单独的模块，从而简化应用程序的开发和部署。spring boot starter 的实现通常包括以下几个方面：自动配置类、依赖管理、插件管理、属性配置等。具体实现可以参考 spring boot starter 模块中的 pom.xml 文件和 meta-inf/spring.factories 文件中的配置。\n\n 4. 自动装配的优先级和顺序\n\n在自动装配过程中，spring boot 会根据当前项目中的依赖关系，优先使用项目中已经存在的 bean。如果存在多个自动配置类可以配置同一个 bean，那么 spring boot 会根据自动配置类的优先级和顺序来决定使用哪个自动配置类。具体实现可以参考 autoconfigurationimportselector 类中的方法。\n\n总的来说，spring boot 自动装配的源码分析需要深入了解 spring framework 的自动装配机制和条件注解的使用方法，同时还需要了解 spring boot starter 的实现和自动装配的优先级和顺序。只有在深入了解这些内容的基础上，才能更好地理解和使用 spring boot 自动装配功能。\n\n\n# springboot 中的beandefinition怎么理解\n\n在 spring boot 中，beandefinition 是用来描述 spring 容器中 bean 的元数据对象。beandefinition 中包含了 bean 的类名、属性值、构造函数参数值等信息，它定义了 bean 的类型、作用域、生命周期等属性，是 spring 容器中 bean 的重要组成部分。\n\nbeandefinition 可以通过两种方式进行定义：\n\n 1. 通过 xml 配置文件定义 beandefinition。\n\n 2. 通过 java 代码定义 beandefinition。\n\n在 spring boot 中，通常使用 java 代码来定义 beandefinition。可以通过 @bean 注解、@component 注解、@configuration 注解等方式来定义 beandefinition。其中，@bean 注解是最常用的方式，它可以在任何 java 类中定义 beandefinition，并将其注入到 spring 容器中。\n\n例如，下面是一个使用 @bean 注解定义 beandefinition 的示例：\n\n@configuration\npublic class appconfig {\n    @bean\n    public userservice userservice() {\n        return new userserviceimpl();\n    }\n}\n\n\n在上面的示例中，@configuration 注解表示该类是一个配置类，@bean 注解表示该方法返回的对象是一个 bean。spring boot 会根据该 bean 的类型、作用域、生命周期等属性，创建对应的 beandefinition，并将其注入到 spring 容器中。\n\n总的来说，beandefinition 是描述 spring 容器中 bean 的元数据对象，它定义了 bean 的类型、作用域、生命周期等属性，并可以通过 @bean 注解、@component 注解、@configuration 注解等方式进行定义。了解 beandefinition 的概念和定义方式，可以更好地理解和使用 spring boot 中的 bean 容器。\n\n\n# 如何理解beandefinition 中的 autowiremode属性\n\nbeandefinition 中的 autowiremode 属性是用来指定自动装配模式的。自动装配模式指的是 spring 容器在进行自动装配时，如何确定要注入哪个 bean。\n\nbeandefinition 中的 autowiremode 属性有以下几个取值：\n\n 1. autowire_no：不进行自动装配，需要手动指定依赖关系。\n\n 2. autowire_by_name：根据 bean 的名称进行自动装配，要求依赖的 bean 名称必须和属性名称一致。\n\n 3. autowire_by_type：根据 bean 的类型进行自动装配，要求依赖的 bean 类型必须和属性类型一致。\n\n 4. autowire_constructor：通过构造函数进行自动装配，要求依赖的 bean 类型必须和构造函数参数类型一致。\n\n 5. autowire_autodetect：自动检测自动装配模式，根据属性类型和名称进行自动装配。\n\n例如，下面是一个使用 @autowired 注解进行自动装配的示例：\n\n@component\npublic class usercontroller {\n    @autowired\n    private userservice userservice;\n}\n\n\n在上面的示例中，@autowired 注解表示要对 userservice 属性进行自动装配。如果 beandefinition 中的 autowiremode 属性为 autowire_by_name，则需要保证 userservice 的名称和属性名称一致；如果 beandefinition 中的 autowiremode 属性为 autowire_by_type，则需要保证 userservice 的类型和属性类型一致。\n\n总的来说，beandefinition 中的 autowiremode 属性是用来指定自动装配模式的，它决定了 spring 容器在进行自动装配时如何确定要注入哪个 bean。了解 autowiremode 属性的取值和作用，可以更好地理解和使用 spring boot 中的自动装配功能。\n\n\n# beandefinition中的constructorargumentvalues属性使用方式\n\nbeandefinition 中的 constructorargumentvalues 属性是用来指定 bean 的构造函数参数的。它可以通过以下两种方式进行设置：\n\n 1. 使用 index 属性指定构造函数参数的位置，使用 value 属性指定构造函数参数的值。例如：\n\n<bean id="user" class="com.example.user">\n    <constructor-arg index="0" value="张三"/>\n    <constructor-arg index="1" value="30"/>\n</bean>\n\n\n在上面的示例中，index 属性指定了构造函数参数的位置，value 属性指定了构造函数参数的值。\n\n 2. 使用 name 属性指定构造函数参数的名称，使用 ref 属性指定构造函数参数的引用。例如：\n\n<bean id="user" class="com.example.user">\n    <constructor-arg name="name" value="张三"/>\n    <constructor-arg name="age" ref="agebean"/>\n</bean>\n\n<bean id="agebean" class="java.lang.integer">\n    <constructor-arg value="30"/>\n</bean>\n\n\n在上面的示例中，name 属性指定了构造函数参数的名称，value 属性指定了构造函数参数的值，ref 属性指定了构造函数参数的引用。\n\n除了 xml 配置文件之外，还可以使用 java 代码来设置 constructorargumentvalues 属性。例如：\n\n@configuration\npublic class appconfig {\n    @bean\n    public user user() {\n        constructorargumentvalues constructorargumentvalues = new constructorargumentvalues();\n        constructorargumentvalues.addindexedargumentvalue(0, "张三");\n        constructorargumentvalues.addindexedargumentvalue(1, 30);\n        return new user(constructorargumentvalues);\n    }\n}\n\n\n在上面的示例中，使用 constructorargumentvalues 对象来设置构造函数参数的值，addindexedargumentvalue() 方法指定了构造函数参数的位置和值。\n\n总的来说，constructorargumentvalues 属性是用来指定 bean 的构造函数参数的，可以通过 xml 配置文件或 java 代码进行设置。了解 constructorargumentvalues 的使用方式，可以更好地理解和使用 spring boot 中的 bean 容器。\n\n\n# springapplication中的setlisteners怎么理解\n\nspringapplication 中的 setlisteners() 方法是用来设置 spring boot 应用程序的监听器的。spring boot 应用程序的监听器是一种特殊的 bean，它可以监听 spring boot 应用程序的生命周期事件，并在事件发生时执行相应的逻辑。\n\nspring boot 应用程序的监听器可以分为以下几种类型：\n\n 1. applicationstartingevent 监听器：在 spring boot 应用程序启动之前执行。\n\n 2. applicationenvironmentpreparedevent 监听器：在 spring boot 应用程序环境准备完成之后执行。\n\n 3. applicationpreparedevent 监听器：在 spring boot 应用程序准备完成之后执行。\n\n 4. applicationstartedevent 监听器：在 spring boot 应用程序启动完成之后执行。\n\n 5. applicationreadyevent 监听器：在 spring boot 应用程序准备好接收请求之后执行。\n\n 6. applicationfailedevent 监听器：在 spring boot 应用程序启动失败时执行。\n\n使用 setlisteners() 方法可以向 spring boot 应用程序添加自定义的监听器，以实现一些特定的业务逻辑。例如，下面是一个使用 setlisteners() 方法添加 applicationstartedevent 监听器的示例：\n\n@springbootapplication\npublic class myapp {\n    public static void main(string[] args) {\n        springapplication app = new springapplication(myapp.class);\n        app.setlisteners(collections.singletonlist(new myapplicationstartedeventlistener()));\n        app.run(args);\n    }\n}\n\n\n在上面的示例中，使用 setlisteners() 方法向 spring boot 应用程序添加了一个自定义的 applicationstartedevent 监听器 myapplicationstartedeventlistener。\n\n总的来说，setlisteners() 方法是用来设置 spring boot 应用程序的监听器的。了解 setlisteners() 方法的使用方式和 spring boot 应用程序的监听器类型，可以更好地实现一些特定的业务逻辑。\n\n\n# springapplication中的setinitializers怎么理解\n\nspringapplication 中的 setinitializers() 方法是用来设置 spring boot 应用程序的初始化器的。spring boot 应用程序的初始化器是一种特殊的 bean，它可以在 spring boot 应用程序启动之前执行一些初始化逻辑。\n\nspring boot 应用程序的初始化器可以分为以下几种类型：\n\n 1. applicationcontextinitializer：在 spring 应用程序上下文创建之前执行。\n\n 2. applicationlistener：在 spring boot 应用程序启动之前执行。\n\n使用 setinitializers() 方法，可以向 spring boot 应用程序添加自定义的初始化器，以实现一些特定的业务逻辑。例如，下面是一个使用 setinitializers() 方法添加 applicationcontextinitializer 的示例：\n\n@springbootapplication\npublic class myapp {\n    public static void main(string[] args) {\n        springapplication app = new springapplication(myapp.class);\n        app.setinitializers(collections.singletonlist(new myapplicationcontextinitializer()));\n        app.run(args);\n    }\n}\n\n\n在上面的示例中，使用 setinitializers() 方法向 spring boot 应用程序添加了一个自定义的 applicationcontextinitializer。\n\n总的来说，setinitializers() 方法是用来设置 spring boot 应用程序的初始化器的。了解 setinitializers() 方法的使用方式和 spring boot 应用程序的初始化器类型，可以更好地实现一些特定的业务逻辑。',charsets:{cjk:!0}},{title:"Controller接收请求方式",frontmatter:{title:"Controller接收请求方式",date:"2023-08-10T10:44:49.000Z",permalink:"/pages/4ce008/"},regularPath:"/01.Java/04.%E6%A1%86%E6%9E%B6/04.Controller.html",relativePath:"01.Java/04.框架/04.Controller.md",key:"v-f8ca3edc",path:"/pages/4ce008/",headers:[{level:2,title:"Get",slug:"get",normalizedTitle:"get",charIndex:2},{level:2,title:"Post",slug:"post",normalizedTitle:"post",charIndex:617},{level:3,title:"form-data数据",slug:"form-data数据",normalizedTitle:"form-data数据",charIndex:626},{level:3,title:"json数据",slug:"json数据",normalizedTitle:"json数据",charIndex:828}],headersStr:"Get Post form-data数据 json数据",content:'# Get\n\n使用 / 拼接\n\nhttp://localhost:8088/testGetUrl/2/23\n\n\n@GetMapping("/testGetUrl/{id}/{age}")\npublic String testGetUrl(@PathVariable("id") String id, @PathVariable("age") String age){\n    System.out.println(id);\n    System.out.println(age);\n    return id;\n}\n\n\n----------------------------------------\n\n使用 ？拼接\n\nhttp://localhost:8088/testGetUrl?id=2&age=23\n\n\n@GetMapping("/testGetUrl")\npublic String testGet1(String id, String age){\n    System.out.println(id);\n    return id;\n}\n\n\n@GetMapping("/testGetUrl")\npublic String testGet2(TestDto testDto){\n    System.out.println(testDto);\n    return testDto.toString();\n}\n\n\n\n# Post\n\n\n# form-data数据\n\n\n\n@PostMapping("/testPost")\npublic String testPost(Integer id, Integer age){\n    return "ok";\n}\n\n\n@PostMapping("/testPost")\npublic String testPost(TestDto testDto){\n    return "ok";\n}\n\n\n\n# json数据\n\n\n\n@PostMapping("/testPost")\npublic String testPost(@RequestBody TestDto testDto){\n    return "ok";\n}\n',normalizedContent:'# get\n\n使用 / 拼接\n\nhttp://localhost:8088/testgeturl/2/23\n\n\n@getmapping("/testgeturl/{id}/{age}")\npublic string testgeturl(@pathvariable("id") string id, @pathvariable("age") string age){\n    system.out.println(id);\n    system.out.println(age);\n    return id;\n}\n\n\n----------------------------------------\n\n使用 ？拼接\n\nhttp://localhost:8088/testgeturl?id=2&age=23\n\n\n@getmapping("/testgeturl")\npublic string testget1(string id, string age){\n    system.out.println(id);\n    return id;\n}\n\n\n@getmapping("/testgeturl")\npublic string testget2(testdto testdto){\n    system.out.println(testdto);\n    return testdto.tostring();\n}\n\n\n\n# post\n\n\n# form-data数据\n\n\n\n@postmapping("/testpost")\npublic string testpost(integer id, integer age){\n    return "ok";\n}\n\n\n@postmapping("/testpost")\npublic string testpost(testdto testdto){\n    return "ok";\n}\n\n\n\n# json数据\n\n\n\n@postmapping("/testpost")\npublic string testpost(@requestbody testdto testdto){\n    return "ok";\n}\n',charsets:{cjk:!0}},{title:"NIO",frontmatter:{title:"NIO",date:"2023-05-05T19:43:35.000Z",permalink:"/pages/533bbc/"},regularPath:"/01.Java/04.%E6%A1%86%E6%9E%B6/10.NIO.html",relativePath:"01.Java/04.框架/10.NIO.md",key:"v-6ab22c04",path:"/pages/533bbc/",headers:[{level:2,title:"Channel",slug:"channel",normalizedTitle:"channel",charIndex:2},{level:2,title:"ByteBuffer",slug:"bytebuffer",normalizedTitle:"bytebuffer",charIndex:93},{level:3,title:"读取文件",slug:"读取文件",normalizedTitle:"读取文件",charIndex:108},{level:3,title:"ByteBuffer结构",slug:"bytebuffer结构",normalizedTitle:"bytebuffer结构",charIndex:722},{level:3,title:"创建ByteBuffer",slug:"创建bytebuffer",normalizedTitle:"创建bytebuffer",charIndex:1225},{level:3,title:"读写",slug:"读写",normalizedTitle:"读写",charIndex:29},{level:4,title:"向 buffer 写入数据",slug:"向-buffer-写入数据",normalizedTitle:"向 buffer 写入数据",charIndex:1332},{level:4,title:"从 buffer 读取数据",slug:"从-buffer-读取数据",normalizedTitle:"从 buffer 读取数据",charIndex:1467},{level:3,title:"ByteBuffer与字符串相互转换",slug:"bytebuffer与字符串相互转换",normalizedTitle:"bytebuffer与字符串相互转换",charIndex:1721},{level:3,title:"黏包&半包",slug:"黏包-半包",normalizedTitle:"黏包&amp;半包",charIndex:null},{level:3,title:"FileChannel",slug:"filechannel",normalizedTitle:"filechannel",charIndex:145},{level:2,title:"网络编程",slug:"网络编程",normalizedTitle:"网络编程",charIndex:2913},{level:3,title:"阻塞模式",slug:"阻塞模式",normalizedTitle:"阻塞模式",charIndex:2922},{level:3,title:"非阻塞",slug:"非阻塞",normalizedTitle:"非阻塞",charIndex:3944},{level:3,title:"Selector",slug:"selector",normalizedTitle:"selector",charIndex:4917},{level:4,title:"创建",slug:"创建",normalizedTitle:"创建",charIndex:1225},{level:4,title:"绑定事件",slug:"绑定事件",normalizedTitle:"绑定事件",charIndex:5007},{level:4,title:"处理read事件",slug:"处理read事件",normalizedTitle:"处理read事件",charIndex:5918},{level:4,title:"处理边界问题",slug:"处理边界问题",normalizedTitle:"处理边界问题",charIndex:7490},{level:4,title:"处理write事件",slug:"处理write事件",normalizedTitle:"处理write事件",charIndex:11052},{level:3,title:"多线程优化",slug:"多线程优化",normalizedTitle:"多线程优化",charIndex:13225}],headersStr:"Channel ByteBuffer 读取文件 ByteBuffer结构 创建ByteBuffer 读写 向 buffer 写入数据 从 buffer 读取数据 ByteBuffer与字符串相互转换 黏包&半包 FileChannel 网络编程 阻塞模式 非阻塞 Selector 创建 绑定事件 处理read事件 处理边界问题 处理write事件 多线程优化",content:'# Channel\n\nChannel类似于stream，是读写数据的双向通道。\n\ngraph LR\nchannel --\x3e buffer\nbuffer --\x3e channel\n\n\n\n# ByteBuffer\n\n\n# 读取文件\n\ndata.txt\n\n1234567890abc\n\n\ntry (FileChannel channel = new FileInputStream("data.txt").getChannel()) {\n    ByteBuffer buffer = ByteBuffer.allocate(10);\n    while (true) {\n        // 返回这次读取到的数据字节数\n        // channel -> buffer\n        int len = channel.read(buffer);\n        log.debug("读取到的字节数 {}", len);\n        if (len == -1) {\n            break;\n        }\n\n        // 切换到读模式\n        buffer.flip();\n        while (buffer.hasRemaining()) {\n            byte b = buffer.get();\n            log.debug("实际字节 {}", (char) b);\n        }\n        // 切换到写模式\n        buffer.clear();\n    }\n} \ncatch (IOException e) {\n}\n\n\n\n# ByteBuffer结构\n\n三个重要属性\n\n * Capacity\n * Position\n * Limit\n\n开始时，Position指向开头，Limit和Capacity指向Buffer末尾\n\n\n\n----------------------------------------\n\n写模式下\n\nPosition指针指向下一个写的位置，Limit和Capacity指向Buffer末尾\n\n\n\n----------------------------------------\n\n读模式下\n\nPosition指向第一个数据，Limit指向可读数据的末尾，Capacity指向Buffer末尾\n\n\n\nbuffer.filp()操作从写模式切换至读模式\n\nlimit = position;\nposition = 0;\n\n\nbuffer.clear()操作从读模式切换至写模式\n\nposition = 0;\nlimit = capacity;\n\n\nbuffer.compact()操作从读模式切换至写模式\n\nposition = limit - position;\nlimit = capacity;\n\n\n\n# 创建ByteBuffer\n\nByteBuffer.allocate(16);\t\t// 在Java堆内存中申请内存\nByteBuffer.AllocateDirect(16);\t// 直接内存\n\n\n\n# 读写\n\n# 向 buffer 写入数据\n\n有两种办法\n\n * 调用 channel 的 read 方法\n * 调用 buffer 自己的 put 方法\n\nint readBytes = channel.read(buf);\n\n\n和\n\nbuf.put((byte)127);\n\n\n# 从 buffer 读取数据\n\n同样有两种办法\n\n * 调用 channel 的 write 方法\n * 调用 buffer 自己的 get 方法\n\nint writeBytes = channel.write(buf);\n\n\n和\n\nbyte b = buf.get();\n\n\nget 方法会让 position 读指针向后走，如果想重复读取数据\n\n * 可以调用 rewind 方法将 position 重新置为 0\n * 或者调用 get(int i) 方法获取索引 i 的内容，它不会移动读指针\n\n\n# ByteBuffer与字符串相互转换\n\n待补充。\n\n\n# 黏包&半包\n\n网络上有多条数据发送给服务端，数据之间使用 \\n 进行分隔 但由于某种原因这些数据在接收时，被进行了重新组合，例如原始数据有3条为\n\n * Hello,world\\n\n * I\'m zhangsan\\n\n * How are you?\\n\n\n变成了下面的两个 byteBuffer (黏包，半包)\n\n * Hello,world\\nI\'m zhangsan\\nHo\n * w are you?\\n\n\n原因\n\n在网络通信中，数据的传送将多条消息合并在一块效率更高，所以会导致黏包现象，\n\n又因为服务器中的buffer大小，超过部分会截断，所以会出现半包现象。\n\n解决办法，按\\n分隔数据\n\npublic static void main(String[] args) {\n    ByteBuffer source = ByteBuffer.allocate(32);\n    //                     11            24\n    source.put("Hello,world\\nI\'m zhangsan\\nHo".getBytes());\n    split(source);\n\n    source.put("w are you?\\nhaha!\\n".getBytes());\n    split(source);\n}\n\nprivate static void split(ByteBuffer source) {\n    source.flip();\n    int oldLimit = source.limit();\n    for (int i = 0; i < oldLimit; i++) {\n        if (source.get(i) == \'\\n\') {\n            System.out.println(i);\n            ByteBuffer target = ByteBuffer.allocate(i + 1 - source.position());\n            // 0 ~ limit\n            source.limit(i + 1);\n            target.put(source); // 从source 读，向 target 写\n            debugAll(target);\n            source.limit(oldLimit);\n        }\n    }\n    source.compact();\n}\n\n\n\n# FileChannel\n\n零拷贝 transferTo(position, size, target);\n\n\n# 网络编程\n\n\n# 阻塞模式\n\n服务器端\n\n// 使用 nio 来理解阻塞模式, 单线程\n// 0. ByteBuffer\nByteBuffer buffer = ByteBuffer.allocate(16);\n// 1. 创建了服务器\nServerSocketChannel ssc = ServerSocketChannel.open();\n\n// 2. 绑定监听端口 \nssc.bind(new InetSocketAddress(8080));\n\n// 3. 连接集合\nList<SocketChannel> channels = new ArrayList<>();\nwhile (true) {\n    // 4. accept 建立与客户端连接， SocketChannel 用来与客户端之间通信\n    log.debug("connecting...");\n    SocketChannel sc = ssc.accept(); // 阻塞方法，线程停止运行\n    log.debug("connected... {}", sc);\n    channels.add(sc);\n    for (SocketChannel channel : channels) {\n        // 5. 接收客户端发送的数据\n        log.debug("before read... {}", channel);\n        channel.read(buffer); // 阻塞方法，线程停止运行\n        buffer.flip();\n        debugRead(buffer);\n        buffer.clear();\n        log.debug("after read...{}", channel);\n    }\n}\n\n\n客户端\n\nSocketChannel sc = SocketChannel.open();\nsc.connect(new InetSocketAddress("localhost", 8080));\nSystem.out.println("waiting...");\n\n\n问题\n\nwhile循环中每次循环开始阻塞在等待新连接；\n\n连接建立完成后，阻塞在read数据；\n\n等待新连接过程中，不能读取已经建立连接的客户端发过来的数据\n\n等待读取数据时，不能建立新连接\n\n\n# 非阻塞\n\n// 使用 nio 来理解非阻塞模式, 单线程\n// 0. ByteBuffer\nByteBuffer buffer = ByteBuffer.allocate(16);\n// 1. 创建了服务器\nServerSocketChannel ssc = ServerSocketChannel.open();\nssc.configureBlocking(false); // 非阻塞模式\n// 2. 绑定监听端口\nssc.bind(new InetSocketAddress(8080));\n// 3. 连接集合\nList<SocketChannel> channels = new ArrayList<>();\nwhile (true) {\n    // 4. accept 建立与客户端连接， SocketChannel 用来与客户端之间通信\n    SocketChannel sc = ssc.accept(); // 非阻塞，线程还会继续运行，如果没有连接建立，但sc是null\n    if (sc != null) {\n        log.debug("connected... {}", sc);\n        sc.configureBlocking(false); // 非阻塞模式\n        channels.add(sc);\n    }\n    for (SocketChannel channel : channels) {\n        // 5. 接收客户端发送的数据\n        int read = channel.read(buffer);// 非阻塞，线程仍然会继续运行，如果没有读到数据，read 返回 0\n        if (read > 0) {\n            buffer.flip();\n            debugRead(buffer);\n            buffer.clear();\n            log.debug("after read...{}", channel);\n        }\n    }\n}\n\n\n等待连接和读取数据互不干扰\n\n在每次循环中没有阻塞方法让CPU停下来，反复执行\n\nCPU做了很多无用功\n\n\n# Selector\n\n一个线程就可以监控多个channel的事件，事件发生时才去处理\n\n# 创建\n\nSelector selector = Selector.open();\n\n\n# 绑定事件\n\nchannel.configureBlocking(false);\nSelectionKey key = channel.register(selector, 绑定事件);\n\n\n * channel 必须工作在非阻塞模式\n * FileChannel 没有非阻塞模式，因此不能配合 selector 一起使用\n * 绑定的事件类型可以有\n   * connect - 客户端连接成功时触发\n   * accept - 服务器端成功接受连接时触发\n   * read - 数据可读入时触发，有因为接收能力弱，数据暂不能读入的情况\n   * write - 数据可写出时触发，有因为发送能力弱，数据暂不能写出的情况\n\nSelector selector = Selector.open();\nServerSocketChannel ssc = ServerSocketChannel.open();\nchannel.configureBlocking(false);\n\nSelectionKey sscKey = ssc.register(selector, 0, null);\n// 只关注accept事件\nsscKey.interestOps(SelectionKey.OP_ACCEPT);\n\nssc.bind(new InetSocketAddress(8080));\nwhile(true){\n    // 没有事件发生时阻塞\n\tselector.select();\n    Iterator<SelectionKey> iter = selector.selectedKeys().iterator();\n    while(iter.hasNext()){\n        SelectionKey key = iter.next();\n        ServerSocketChannel channel = (ServerSocketChannel)key.channel();\n        SocketChannel sc = channel.accept();\n    }\n}\n\n\n# 处理read事件\n\ntry (ServerSocketChannel channel = ServerSocketChannel.open()) {\n    channel.bind(new InetSocketAddress(7070));\n    System.out.println(channel);\n    Selector selector = Selector.open();\n    channel.configureBlocking(false);\n    channel.register(selector, SelectionKey.OP_ACCEPT);\n\n    while (true) {\n        int count = selector.select();\n        log.debug("select count: {}", count);\n        // 获取所有事件\n        Set<SelectionKey> keys = selector.selectedKeys();\n\n        // 遍历所有事件，逐一处理\n        Iterator<SelectionKey> iter = keys.iterator();\n        while (iter.hasNext()) {\n            SelectionKey key = iter.next();\n            // 判断事件类型\n            if (key.isAcceptable()) {\n                ServerSocketChannel c = (ServerSocketChannel) key.channel();\n                // 必须处理\n                SocketChannel sc = c.accept();\n                sc.configureBlocking(false);\n                sc.register(selector, SelectionKey.OP_READ);\n                log.debug("连接已建立: {}", sc);\n            } else if (key.isReadable()) {\n                SocketChannel sc = (SocketChannel) key.channel();\n                ByteBuffer buffer = ByteBuffer.allocate(128);\n                int read = sc.read(buffer);\n                if(read == -1) {\n                    key.cancel();\n                    sc.close();\n                } else {\n                    buffer.flip();\n                    debugAll(buffer);\n                }\n            }\n            // 处理完毕，必须将事件移除\n            iter.remove();\n        }\n    }\n} catch (IOException e) {\n    e.printStackTrace();\n}\n\n\n断开连接会触发read事件\n\n# 处理边界问题\n\n缓冲区大小小于channel中的数据大小，那么将会读取多次，如果都是往一个buffer里存，那么后面读的就会覆盖前面读的。\n\n解决办法\n\n约定一条消息的末尾为\\n，只有读取到\\n时，才将buffer中的数据读取出来。\n\n在写模式情况下，如果position和limit相等，那么代表这个buffer没有读到一个完整的消息。\n\n这时需要将其buffer扩容，然后用这个buffer再去读channel中的数据。\n\nprivate static void split(ByteBuffer source) {\n    source.flip();\n    for (int i = 0; i < source.limit(); i++) {\n        // 找到一条完整消息\n        if (source.get(i) == \'\\n\') {\n            int length = i + 1 - source.position();\n            // 把这条完整消息存入新的 ByteBuffer\n            ByteBuffer target = ByteBuffer.allocate(length);\n            // 从 source 读，向 target 写\n            for (int j = 0; j < length; j++) {\n                target.put(source.get());\n            }\n            debugAll(target);\n        }\n    }\n    source.compact(); // 0123456789abcdef  position 16 limit 16\n}\n\npublic static void main(String[] args) throws IOException {\n    // 1. 创建 selector, 管理多个 channel\n    Selector selector = Selector.open();\n    ServerSocketChannel ssc = ServerSocketChannel.open();\n    ssc.configureBlocking(false);\n    // 2. 建立 selector 和 channel 的联系（注册）\n    // SelectionKey 就是将来事件发生后，通过它可以知道事件和哪个channel的事件\n    SelectionKey sscKey = ssc.register(selector, 0, null);\n    // key 只关注 accept 事件\n    sscKey.interestOps(SelectionKey.OP_ACCEPT);\n    log.debug("sscKey:{}", sscKey);\n    ssc.bind(new InetSocketAddress(8080));\n    while (true) {\n        // 3. select 方法, 没有事件发生，线程阻塞，有事件，线程才会恢复运行\n        // select 在事件未处理时，它不会阻塞, 事件发生后要么处理，要么取消，不能置之不理\n        selector.select();\n        // 4. 处理事件, selectedKeys 内部包含了所有发生的事件\n        Iterator<SelectionKey> iter = selector.selectedKeys().iterator(); // accept, read\n        while (iter.hasNext()) {\n            SelectionKey key = iter.next();\n            // 处理key 时，要从 selectedKeys 集合中删除，否则下次处理就会有问题\n            iter.remove();\n            log.debug("key: {}", key);\n            // 5. 区分事件类型\n            if (key.isAcceptable()) { // 如果是 accept\n                ServerSocketChannel channel = (ServerSocketChannel) key.channel();\n                SocketChannel sc = channel.accept();\n                sc.configureBlocking(false);\n                ByteBuffer buffer = ByteBuffer.allocate(16); // attachment\n                // 将一个 byteBuffer 作为附件关联到 selectionKey 上\n                SelectionKey scKey = sc.register(selector, 0, buffer);\n                scKey.interestOps(SelectionKey.OP_READ);\n                log.debug("{}", sc);\n                log.debug("scKey:{}", scKey);\n            } else if (key.isReadable()) { // 如果是 read\n                try {\n                    SocketChannel channel = (SocketChannel) key.channel(); // 拿到触发事件的channel\n                    // 获取 selectionKey 上关联的附件\n                    ByteBuffer buffer = (ByteBuffer) key.attachment();\n                    int read = channel.read(buffer); // 如果是正常断开，read 的方法的返回值是 -1\n                    if(read == -1) {\n                        key.cancel();\n                    } else {\n                        split(buffer);\n                        // 需要扩容\n                        if (buffer.position() == buffer.limit()) {\n                            ByteBuffer newBuffer = ByteBuffer.allocate(buffer.capacity() * 2);\n                            buffer.flip();\n                            newBuffer.put(buffer); // 0123456789abcdef3333\\n\n                            key.attach(newBuffer);\n                        }\n                    }\n\n                } catch (IOException e) {\n                    e.printStackTrace();\n                    key.cancel();  // 因为客户端断开了,因此需要将 key 取消（从 selector 的 keys 集合中真正删除 key）\n                }\n            }\n        }\n    }\n}\n\n\n# 处理write事件\n\n出现一次写不下的情形，将数据附加到SelectionKey中，以便于这个key再次触发时，将剩下的数据继续写入到channel中。\n\n提示\n\nisWritable()方法的不取决于事件，取决于channel通道中是否可以写入数据。所以建议写完数据后，需要将可写事件取消关注，否则会一直轮询可写事件。\n\n\npublic static void main(String[] args) throws IOException {\n    ServerSocketChannel ssc = ServerSocketChannel.open();\n    ssc.configureBlocking(false);\n    ssc.bind(new InetSocketAddress(8080));\n\n    Selector selector = Selector.open();\n    ssc.register(selector, SelectionKey.OP_ACCEPT);\n\n    while(true) {\n        selector.select();\n\n        Iterator<SelectionKey> iter = selector.selectedKeys().iterator();\n        while (iter.hasNext()) {\n            SelectionKey key = iter.next();\n            iter.remove();\n            if (key.isAcceptable()) {\n                SocketChannel sc = ssc.accept();\n                sc.configureBlocking(false);\n                SelectionKey sckey = sc.register(selector, SelectionKey.OP_READ);\n                // 1. 向客户端发送内容\n                StringBuilder sb = new StringBuilder();\n                for (int i = 0; i < 3000000; i++) {\n                    sb.append("a");\n                }\n                ByteBuffer buffer = Charset.defaultCharset().encode(sb.toString());\n                int write = sc.write(buffer);\n                // 3. write 表示实际写了多少字节\n                System.out.println("实际写入字节:" + write);\n                // 4. 如果有剩余未读字节，才需要关注写事件\n                if (buffer.hasRemaining()) {\n                    // read 1  write 4\n                    // 在原有关注事件的基础上，多关注 写事件\n                    sckey.interestOps(sckey.interestOps() + SelectionKey.OP_WRITE);\n                    // 把 buffer 作为附件加入 sckey\n                    sckey.attach(buffer);\n                }\n            } else if (key.isWritable()) {\n                ByteBuffer buffer = (ByteBuffer) key.attachment();\n                SocketChannel sc = (SocketChannel) key.channel();\n                int write = sc.write(buffer);\n                System.out.println("实际写入字节:" + write);\n                if (!buffer.hasRemaining()) { // 写完了\n                    key.interestOps(key.interestOps() - SelectionKey.OP_WRITE);\n                    key.attach(null);\n                }\n            }\n        }\n    }\n}\n    \n\n\n\n# 多线程优化\n\n> 在单线程中，一个selector监听多个事件，但是只能同时处理一个事件\n\n分两组选择器\n\n * 处理accept事件\n * 处理read和write事件\n\npublic class ChannelDemo7 {\n    public static void main(String[] args) throws IOException {\n        new BossEventLoop().register();\n    }\n\n\n    @Slf4j\n    static class BossEventLoop implements Runnable {\n        private Selector boss;\n        private WorkerEventLoop[] workers;\n        private volatile boolean start = false;\n        AtomicInteger index = new AtomicInteger();\n\n        public void register() throws IOException {\n            if (!start) {\n                ServerSocketChannel ssc = ServerSocketChannel.open();\n                ssc.bind(new InetSocketAddress(8080));\n                ssc.configureBlocking(false);\n                boss = Selector.open();\n                SelectionKey ssckey = ssc.register(boss, 0, null);\n                ssckey.interestOps(SelectionKey.OP_ACCEPT);\n                workers = initEventLoops();\n                new Thread(this, "boss").start();\n                log.debug("boss start...");\n                start = true;\n            }\n        }\n\n        public WorkerEventLoop[] initEventLoops() {\n//        EventLoop[] eventLoops = new EventLoop[Runtime.getRuntime().availableProcessors()];\n            WorkerEventLoop[] workerEventLoops = new WorkerEventLoop[2];\n            for (int i = 0; i < workerEventLoops.length; i++) {\n                workerEventLoops[i] = new WorkerEventLoop(i);\n            }\n            return workerEventLoops;\n        }\n\n        @Override\n        public void run() {\n            while (true) {\n                try {\n                    boss.select();\n                    Iterator<SelectionKey> iter = boss.selectedKeys().iterator();\n                    while (iter.hasNext()) {\n                        SelectionKey key = iter.next();\n                        iter.remove();\n                        if (key.isAcceptable()) {\n                            ServerSocketChannel c = (ServerSocketChannel) key.channel();\n                            SocketChannel sc = c.accept();\n                            sc.configureBlocking(false);\n                            log.debug("{} connected", sc.getRemoteAddress());\n                            workers[index.getAndIncrement() % workers.length].register(sc);\n                        }\n                    }\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n    }\n\n    @Slf4j\n    static class WorkerEventLoop implements Runnable {\n        private Selector worker;\n        private volatile boolean start = false;\n        private int index;\n\n        private final ConcurrentLinkedQueue<Runnable> tasks = new ConcurrentLinkedQueue<>();\n\n        public WorkerEventLoop(int index) {\n            this.index = index;\n        }\n\n        public void register(SocketChannel sc) throws IOException {\n            if (!start) {\n                worker = Selector.open();\n                new Thread(this, "worker-" + index).start();\n                start = true;\n            }\n            tasks.add(() -> {\n                try {\n                    SelectionKey sckey = sc.register(worker, 0, null);\n                    sckey.interestOps(SelectionKey.OP_READ);\n                    worker.selectNow();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            });\n            worker.wakeup();\n        }\n\n        @Override\n        public void run() {\n            while (true) {\n                try {\n                    worker.select();\n                    Runnable task = tasks.poll();\n                    if (task != null) {\n                        task.run();\n                    }\n                    Set<SelectionKey> keys = worker.selectedKeys();\n                    Iterator<SelectionKey> iter = keys.iterator();\n                    while (iter.hasNext()) {\n                        SelectionKey key = iter.next();\n                        if (key.isReadable()) {\n                            SocketChannel sc = (SocketChannel) key.channel();\n                            ByteBuffer buffer = ByteBuffer.allocate(128);\n                            try {\n                                int read = sc.read(buffer);\n                                if (read == -1) {\n                                    key.cancel();\n                                    sc.close();\n                                } else {\n                                    buffer.flip();\n                                    log.debug("{} message:", sc.getRemoteAddress());\n                                    debugAll(buffer);\n                                }\n                            } catch (IOException e) {\n                                e.printStackTrace();\n                                key.cancel();\n                                sc.close();\n                            }\n                        }\n                        iter.remove();\n                    }\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n    }\n}\n\n\n注意\n\n确保在select()方法阻塞前已经关注对应的事件，否则会一直阻塞',normalizedContent:'# channel\n\nchannel类似于stream，是读写数据的双向通道。\n\ngraph lr\nchannel --\x3e buffer\nbuffer --\x3e channel\n\n\n\n# bytebuffer\n\n\n# 读取文件\n\ndata.txt\n\n1234567890abc\n\n\ntry (filechannel channel = new fileinputstream("data.txt").getchannel()) {\n    bytebuffer buffer = bytebuffer.allocate(10);\n    while (true) {\n        // 返回这次读取到的数据字节数\n        // channel -> buffer\n        int len = channel.read(buffer);\n        log.debug("读取到的字节数 {}", len);\n        if (len == -1) {\n            break;\n        }\n\n        // 切换到读模式\n        buffer.flip();\n        while (buffer.hasremaining()) {\n            byte b = buffer.get();\n            log.debug("实际字节 {}", (char) b);\n        }\n        // 切换到写模式\n        buffer.clear();\n    }\n} \ncatch (ioexception e) {\n}\n\n\n\n# bytebuffer结构\n\n三个重要属性\n\n * capacity\n * position\n * limit\n\n开始时，position指向开头，limit和capacity指向buffer末尾\n\n\n\n----------------------------------------\n\n写模式下\n\nposition指针指向下一个写的位置，limit和capacity指向buffer末尾\n\n\n\n----------------------------------------\n\n读模式下\n\nposition指向第一个数据，limit指向可读数据的末尾，capacity指向buffer末尾\n\n\n\nbuffer.filp()操作从写模式切换至读模式\n\nlimit = position;\nposition = 0;\n\n\nbuffer.clear()操作从读模式切换至写模式\n\nposition = 0;\nlimit = capacity;\n\n\nbuffer.compact()操作从读模式切换至写模式\n\nposition = limit - position;\nlimit = capacity;\n\n\n\n# 创建bytebuffer\n\nbytebuffer.allocate(16);\t\t// 在java堆内存中申请内存\nbytebuffer.allocatedirect(16);\t// 直接内存\n\n\n\n# 读写\n\n# 向 buffer 写入数据\n\n有两种办法\n\n * 调用 channel 的 read 方法\n * 调用 buffer 自己的 put 方法\n\nint readbytes = channel.read(buf);\n\n\n和\n\nbuf.put((byte)127);\n\n\n# 从 buffer 读取数据\n\n同样有两种办法\n\n * 调用 channel 的 write 方法\n * 调用 buffer 自己的 get 方法\n\nint writebytes = channel.write(buf);\n\n\n和\n\nbyte b = buf.get();\n\n\nget 方法会让 position 读指针向后走，如果想重复读取数据\n\n * 可以调用 rewind 方法将 position 重新置为 0\n * 或者调用 get(int i) 方法获取索引 i 的内容，它不会移动读指针\n\n\n# bytebuffer与字符串相互转换\n\n待补充。\n\n\n# 黏包&半包\n\n网络上有多条数据发送给服务端，数据之间使用 \\n 进行分隔 但由于某种原因这些数据在接收时，被进行了重新组合，例如原始数据有3条为\n\n * hello,world\\n\n * i\'m zhangsan\\n\n * how are you?\\n\n\n变成了下面的两个 bytebuffer (黏包，半包)\n\n * hello,world\\ni\'m zhangsan\\nho\n * w are you?\\n\n\n原因\n\n在网络通信中，数据的传送将多条消息合并在一块效率更高，所以会导致黏包现象，\n\n又因为服务器中的buffer大小，超过部分会截断，所以会出现半包现象。\n\n解决办法，按\\n分隔数据\n\npublic static void main(string[] args) {\n    bytebuffer source = bytebuffer.allocate(32);\n    //                     11            24\n    source.put("hello,world\\ni\'m zhangsan\\nho".getbytes());\n    split(source);\n\n    source.put("w are you?\\nhaha!\\n".getbytes());\n    split(source);\n}\n\nprivate static void split(bytebuffer source) {\n    source.flip();\n    int oldlimit = source.limit();\n    for (int i = 0; i < oldlimit; i++) {\n        if (source.get(i) == \'\\n\') {\n            system.out.println(i);\n            bytebuffer target = bytebuffer.allocate(i + 1 - source.position());\n            // 0 ~ limit\n            source.limit(i + 1);\n            target.put(source); // 从source 读，向 target 写\n            debugall(target);\n            source.limit(oldlimit);\n        }\n    }\n    source.compact();\n}\n\n\n\n# filechannel\n\n零拷贝 transferto(position, size, target);\n\n\n# 网络编程\n\n\n# 阻塞模式\n\n服务器端\n\n// 使用 nio 来理解阻塞模式, 单线程\n// 0. bytebuffer\nbytebuffer buffer = bytebuffer.allocate(16);\n// 1. 创建了服务器\nserversocketchannel ssc = serversocketchannel.open();\n\n// 2. 绑定监听端口 \nssc.bind(new inetsocketaddress(8080));\n\n// 3. 连接集合\nlist<socketchannel> channels = new arraylist<>();\nwhile (true) {\n    // 4. accept 建立与客户端连接， socketchannel 用来与客户端之间通信\n    log.debug("connecting...");\n    socketchannel sc = ssc.accept(); // 阻塞方法，线程停止运行\n    log.debug("connected... {}", sc);\n    channels.add(sc);\n    for (socketchannel channel : channels) {\n        // 5. 接收客户端发送的数据\n        log.debug("before read... {}", channel);\n        channel.read(buffer); // 阻塞方法，线程停止运行\n        buffer.flip();\n        debugread(buffer);\n        buffer.clear();\n        log.debug("after read...{}", channel);\n    }\n}\n\n\n客户端\n\nsocketchannel sc = socketchannel.open();\nsc.connect(new inetsocketaddress("localhost", 8080));\nsystem.out.println("waiting...");\n\n\n问题\n\nwhile循环中每次循环开始阻塞在等待新连接；\n\n连接建立完成后，阻塞在read数据；\n\n等待新连接过程中，不能读取已经建立连接的客户端发过来的数据\n\n等待读取数据时，不能建立新连接\n\n\n# 非阻塞\n\n// 使用 nio 来理解非阻塞模式, 单线程\n// 0. bytebuffer\nbytebuffer buffer = bytebuffer.allocate(16);\n// 1. 创建了服务器\nserversocketchannel ssc = serversocketchannel.open();\nssc.configureblocking(false); // 非阻塞模式\n// 2. 绑定监听端口\nssc.bind(new inetsocketaddress(8080));\n// 3. 连接集合\nlist<socketchannel> channels = new arraylist<>();\nwhile (true) {\n    // 4. accept 建立与客户端连接， socketchannel 用来与客户端之间通信\n    socketchannel sc = ssc.accept(); // 非阻塞，线程还会继续运行，如果没有连接建立，但sc是null\n    if (sc != null) {\n        log.debug("connected... {}", sc);\n        sc.configureblocking(false); // 非阻塞模式\n        channels.add(sc);\n    }\n    for (socketchannel channel : channels) {\n        // 5. 接收客户端发送的数据\n        int read = channel.read(buffer);// 非阻塞，线程仍然会继续运行，如果没有读到数据，read 返回 0\n        if (read > 0) {\n            buffer.flip();\n            debugread(buffer);\n            buffer.clear();\n            log.debug("after read...{}", channel);\n        }\n    }\n}\n\n\n等待连接和读取数据互不干扰\n\n在每次循环中没有阻塞方法让cpu停下来，反复执行\n\ncpu做了很多无用功\n\n\n# selector\n\n一个线程就可以监控多个channel的事件，事件发生时才去处理\n\n# 创建\n\nselector selector = selector.open();\n\n\n# 绑定事件\n\nchannel.configureblocking(false);\nselectionkey key = channel.register(selector, 绑定事件);\n\n\n * channel 必须工作在非阻塞模式\n * filechannel 没有非阻塞模式，因此不能配合 selector 一起使用\n * 绑定的事件类型可以有\n   * connect - 客户端连接成功时触发\n   * accept - 服务器端成功接受连接时触发\n   * read - 数据可读入时触发，有因为接收能力弱，数据暂不能读入的情况\n   * write - 数据可写出时触发，有因为发送能力弱，数据暂不能写出的情况\n\nselector selector = selector.open();\nserversocketchannel ssc = serversocketchannel.open();\nchannel.configureblocking(false);\n\nselectionkey ssckey = ssc.register(selector, 0, null);\n// 只关注accept事件\nssckey.interestops(selectionkey.op_accept);\n\nssc.bind(new inetsocketaddress(8080));\nwhile(true){\n    // 没有事件发生时阻塞\n\tselector.select();\n    iterator<selectionkey> iter = selector.selectedkeys().iterator();\n    while(iter.hasnext()){\n        selectionkey key = iter.next();\n        serversocketchannel channel = (serversocketchannel)key.channel();\n        socketchannel sc = channel.accept();\n    }\n}\n\n\n# 处理read事件\n\ntry (serversocketchannel channel = serversocketchannel.open()) {\n    channel.bind(new inetsocketaddress(7070));\n    system.out.println(channel);\n    selector selector = selector.open();\n    channel.configureblocking(false);\n    channel.register(selector, selectionkey.op_accept);\n\n    while (true) {\n        int count = selector.select();\n        log.debug("select count: {}", count);\n        // 获取所有事件\n        set<selectionkey> keys = selector.selectedkeys();\n\n        // 遍历所有事件，逐一处理\n        iterator<selectionkey> iter = keys.iterator();\n        while (iter.hasnext()) {\n            selectionkey key = iter.next();\n            // 判断事件类型\n            if (key.isacceptable()) {\n                serversocketchannel c = (serversocketchannel) key.channel();\n                // 必须处理\n                socketchannel sc = c.accept();\n                sc.configureblocking(false);\n                sc.register(selector, selectionkey.op_read);\n                log.debug("连接已建立: {}", sc);\n            } else if (key.isreadable()) {\n                socketchannel sc = (socketchannel) key.channel();\n                bytebuffer buffer = bytebuffer.allocate(128);\n                int read = sc.read(buffer);\n                if(read == -1) {\n                    key.cancel();\n                    sc.close();\n                } else {\n                    buffer.flip();\n                    debugall(buffer);\n                }\n            }\n            // 处理完毕，必须将事件移除\n            iter.remove();\n        }\n    }\n} catch (ioexception e) {\n    e.printstacktrace();\n}\n\n\n断开连接会触发read事件\n\n# 处理边界问题\n\n缓冲区大小小于channel中的数据大小，那么将会读取多次，如果都是往一个buffer里存，那么后面读的就会覆盖前面读的。\n\n解决办法\n\n约定一条消息的末尾为\\n，只有读取到\\n时，才将buffer中的数据读取出来。\n\n在写模式情况下，如果position和limit相等，那么代表这个buffer没有读到一个完整的消息。\n\n这时需要将其buffer扩容，然后用这个buffer再去读channel中的数据。\n\nprivate static void split(bytebuffer source) {\n    source.flip();\n    for (int i = 0; i < source.limit(); i++) {\n        // 找到一条完整消息\n        if (source.get(i) == \'\\n\') {\n            int length = i + 1 - source.position();\n            // 把这条完整消息存入新的 bytebuffer\n            bytebuffer target = bytebuffer.allocate(length);\n            // 从 source 读，向 target 写\n            for (int j = 0; j < length; j++) {\n                target.put(source.get());\n            }\n            debugall(target);\n        }\n    }\n    source.compact(); // 0123456789abcdef  position 16 limit 16\n}\n\npublic static void main(string[] args) throws ioexception {\n    // 1. 创建 selector, 管理多个 channel\n    selector selector = selector.open();\n    serversocketchannel ssc = serversocketchannel.open();\n    ssc.configureblocking(false);\n    // 2. 建立 selector 和 channel 的联系（注册）\n    // selectionkey 就是将来事件发生后，通过它可以知道事件和哪个channel的事件\n    selectionkey ssckey = ssc.register(selector, 0, null);\n    // key 只关注 accept 事件\n    ssckey.interestops(selectionkey.op_accept);\n    log.debug("ssckey:{}", ssckey);\n    ssc.bind(new inetsocketaddress(8080));\n    while (true) {\n        // 3. select 方法, 没有事件发生，线程阻塞，有事件，线程才会恢复运行\n        // select 在事件未处理时，它不会阻塞, 事件发生后要么处理，要么取消，不能置之不理\n        selector.select();\n        // 4. 处理事件, selectedkeys 内部包含了所有发生的事件\n        iterator<selectionkey> iter = selector.selectedkeys().iterator(); // accept, read\n        while (iter.hasnext()) {\n            selectionkey key = iter.next();\n            // 处理key 时，要从 selectedkeys 集合中删除，否则下次处理就会有问题\n            iter.remove();\n            log.debug("key: {}", key);\n            // 5. 区分事件类型\n            if (key.isacceptable()) { // 如果是 accept\n                serversocketchannel channel = (serversocketchannel) key.channel();\n                socketchannel sc = channel.accept();\n                sc.configureblocking(false);\n                bytebuffer buffer = bytebuffer.allocate(16); // attachment\n                // 将一个 bytebuffer 作为附件关联到 selectionkey 上\n                selectionkey sckey = sc.register(selector, 0, buffer);\n                sckey.interestops(selectionkey.op_read);\n                log.debug("{}", sc);\n                log.debug("sckey:{}", sckey);\n            } else if (key.isreadable()) { // 如果是 read\n                try {\n                    socketchannel channel = (socketchannel) key.channel(); // 拿到触发事件的channel\n                    // 获取 selectionkey 上关联的附件\n                    bytebuffer buffer = (bytebuffer) key.attachment();\n                    int read = channel.read(buffer); // 如果是正常断开，read 的方法的返回值是 -1\n                    if(read == -1) {\n                        key.cancel();\n                    } else {\n                        split(buffer);\n                        // 需要扩容\n                        if (buffer.position() == buffer.limit()) {\n                            bytebuffer newbuffer = bytebuffer.allocate(buffer.capacity() * 2);\n                            buffer.flip();\n                            newbuffer.put(buffer); // 0123456789abcdef3333\\n\n                            key.attach(newbuffer);\n                        }\n                    }\n\n                } catch (ioexception e) {\n                    e.printstacktrace();\n                    key.cancel();  // 因为客户端断开了,因此需要将 key 取消（从 selector 的 keys 集合中真正删除 key）\n                }\n            }\n        }\n    }\n}\n\n\n# 处理write事件\n\n出现一次写不下的情形，将数据附加到selectionkey中，以便于这个key再次触发时，将剩下的数据继续写入到channel中。\n\n提示\n\niswritable()方法的不取决于事件，取决于channel通道中是否可以写入数据。所以建议写完数据后，需要将可写事件取消关注，否则会一直轮询可写事件。\n\n\npublic static void main(string[] args) throws ioexception {\n    serversocketchannel ssc = serversocketchannel.open();\n    ssc.configureblocking(false);\n    ssc.bind(new inetsocketaddress(8080));\n\n    selector selector = selector.open();\n    ssc.register(selector, selectionkey.op_accept);\n\n    while(true) {\n        selector.select();\n\n        iterator<selectionkey> iter = selector.selectedkeys().iterator();\n        while (iter.hasnext()) {\n            selectionkey key = iter.next();\n            iter.remove();\n            if (key.isacceptable()) {\n                socketchannel sc = ssc.accept();\n                sc.configureblocking(false);\n                selectionkey sckey = sc.register(selector, selectionkey.op_read);\n                // 1. 向客户端发送内容\n                stringbuilder sb = new stringbuilder();\n                for (int i = 0; i < 3000000; i++) {\n                    sb.append("a");\n                }\n                bytebuffer buffer = charset.defaultcharset().encode(sb.tostring());\n                int write = sc.write(buffer);\n                // 3. write 表示实际写了多少字节\n                system.out.println("实际写入字节:" + write);\n                // 4. 如果有剩余未读字节，才需要关注写事件\n                if (buffer.hasremaining()) {\n                    // read 1  write 4\n                    // 在原有关注事件的基础上，多关注 写事件\n                    sckey.interestops(sckey.interestops() + selectionkey.op_write);\n                    // 把 buffer 作为附件加入 sckey\n                    sckey.attach(buffer);\n                }\n            } else if (key.iswritable()) {\n                bytebuffer buffer = (bytebuffer) key.attachment();\n                socketchannel sc = (socketchannel) key.channel();\n                int write = sc.write(buffer);\n                system.out.println("实际写入字节:" + write);\n                if (!buffer.hasremaining()) { // 写完了\n                    key.interestops(key.interestops() - selectionkey.op_write);\n                    key.attach(null);\n                }\n            }\n        }\n    }\n}\n    \n\n\n\n# 多线程优化\n\n> 在单线程中，一个selector监听多个事件，但是只能同时处理一个事件\n\n分两组选择器\n\n * 处理accept事件\n * 处理read和write事件\n\npublic class channeldemo7 {\n    public static void main(string[] args) throws ioexception {\n        new bosseventloop().register();\n    }\n\n\n    @slf4j\n    static class bosseventloop implements runnable {\n        private selector boss;\n        private workereventloop[] workers;\n        private volatile boolean start = false;\n        atomicinteger index = new atomicinteger();\n\n        public void register() throws ioexception {\n            if (!start) {\n                serversocketchannel ssc = serversocketchannel.open();\n                ssc.bind(new inetsocketaddress(8080));\n                ssc.configureblocking(false);\n                boss = selector.open();\n                selectionkey ssckey = ssc.register(boss, 0, null);\n                ssckey.interestops(selectionkey.op_accept);\n                workers = initeventloops();\n                new thread(this, "boss").start();\n                log.debug("boss start...");\n                start = true;\n            }\n        }\n\n        public workereventloop[] initeventloops() {\n//        eventloop[] eventloops = new eventloop[runtime.getruntime().availableprocessors()];\n            workereventloop[] workereventloops = new workereventloop[2];\n            for (int i = 0; i < workereventloops.length; i++) {\n                workereventloops[i] = new workereventloop(i);\n            }\n            return workereventloops;\n        }\n\n        @override\n        public void run() {\n            while (true) {\n                try {\n                    boss.select();\n                    iterator<selectionkey> iter = boss.selectedkeys().iterator();\n                    while (iter.hasnext()) {\n                        selectionkey key = iter.next();\n                        iter.remove();\n                        if (key.isacceptable()) {\n                            serversocketchannel c = (serversocketchannel) key.channel();\n                            socketchannel sc = c.accept();\n                            sc.configureblocking(false);\n                            log.debug("{} connected", sc.getremoteaddress());\n                            workers[index.getandincrement() % workers.length].register(sc);\n                        }\n                    }\n                } catch (ioexception e) {\n                    e.printstacktrace();\n                }\n            }\n        }\n    }\n\n    @slf4j\n    static class workereventloop implements runnable {\n        private selector worker;\n        private volatile boolean start = false;\n        private int index;\n\n        private final concurrentlinkedqueue<runnable> tasks = new concurrentlinkedqueue<>();\n\n        public workereventloop(int index) {\n            this.index = index;\n        }\n\n        public void register(socketchannel sc) throws ioexception {\n            if (!start) {\n                worker = selector.open();\n                new thread(this, "worker-" + index).start();\n                start = true;\n            }\n            tasks.add(() -> {\n                try {\n                    selectionkey sckey = sc.register(worker, 0, null);\n                    sckey.interestops(selectionkey.op_read);\n                    worker.selectnow();\n                } catch (ioexception e) {\n                    e.printstacktrace();\n                }\n            });\n            worker.wakeup();\n        }\n\n        @override\n        public void run() {\n            while (true) {\n                try {\n                    worker.select();\n                    runnable task = tasks.poll();\n                    if (task != null) {\n                        task.run();\n                    }\n                    set<selectionkey> keys = worker.selectedkeys();\n                    iterator<selectionkey> iter = keys.iterator();\n                    while (iter.hasnext()) {\n                        selectionkey key = iter.next();\n                        if (key.isreadable()) {\n                            socketchannel sc = (socketchannel) key.channel();\n                            bytebuffer buffer = bytebuffer.allocate(128);\n                            try {\n                                int read = sc.read(buffer);\n                                if (read == -1) {\n                                    key.cancel();\n                                    sc.close();\n                                } else {\n                                    buffer.flip();\n                                    log.debug("{} message:", sc.getremoteaddress());\n                                    debugall(buffer);\n                                }\n                            } catch (ioexception e) {\n                                e.printstacktrace();\n                                key.cancel();\n                                sc.close();\n                            }\n                        }\n                        iter.remove();\n                    }\n                } catch (ioexception e) {\n                    e.printstacktrace();\n                }\n            }\n        }\n    }\n}\n\n\n注意\n\n确保在select()方法阻塞前已经关注对应的事件，否则会一直阻塞',charsets:{cjk:!0}},{title:"Netty",frontmatter:{title:"Netty",date:"2023-06-07T19:10:18.000Z",permalink:"/pages/20bd69/"},regularPath:"/01.Java/04.%E6%A1%86%E6%9E%B6/11.Netty.html",relativePath:"01.Java/04.框架/11.Netty.md",key:"v-58dee060",path:"/pages/20bd69/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"MySQL函数",frontmatter:{title:"MySQL函数",date:"2023-03-06T09:42:02.000Z",permalink:"/pages/e60c12/"},regularPath:"/01.Java/05.%E6%95%B0%E6%8D%AE%E5%BA%93/03.MySQL%E5%87%BD%E6%95%B0.html",relativePath:"01.Java/05.数据库/03.MySQL函数.md",key:"v-6ecce798",path:"/pages/e60c12/",headers:[{level:3,title:"数学函数",slug:"数学函数",normalizedTitle:"数学函数",charIndex:2},{level:3,title:"聚合函数",slug:"聚合函数",normalizedTitle:"聚合函数",charIndex:608},{level:3,title:"字符串函数",slug:"字符串函数",normalizedTitle:"字符串函数",charIndex:843},{level:3,title:"日期控制函数",slug:"日期控制函数",normalizedTitle:"日期控制函数",charIndex:1846},{level:3,title:"控制流函数",slug:"控制流函数",normalizedTitle:"控制流函数",charIndex:3595},{level:3,title:"格式化函数",slug:"格式化函数",normalizedTitle:"格式化函数",charIndex:5765},{level:3,title:"类型转化函数",slug:"类型转化函数",normalizedTitle:"类型转化函数",charIndex:6356},{level:3,title:"系统信息函数",slug:"系统信息函数",normalizedTitle:"系统信息函数",charIndex:6586},{level:3,title:"开窗函数",slug:"开窗函数",normalizedTitle:"开窗函数",charIndex:6996}],headersStr:"数学函数 聚合函数 字符串函数 日期控制函数 控制流函数 格式化函数 类型转化函数 系统信息函数 开窗函数",content:"# 数学函数\n\nABS(x)         --返回x的绝对值 \nBIN(x)         --返回x的二进制（OCT返回八进制，HEX返回十六进制） \nCEILING(x)     --返回大于x的最小整数值 \nEXP(x)         --返回值e（自然对数的底）的x次方 \nFLOOR(x)       --返回小于x的最大整数值 \nGREATEST(x1,x2,...,xn) \n                --返回集合中最大的值 \nLEAST(x1,x2,...,xn)    \n                --返回集合中最小的值 \nLN(x)           --返回x的自然对数 \nLOG(x,y)        --返回x的以y为底的对数 \nMOD(x,y)        --返回x/y的模（余数） \nPI()            --返回pi的值（圆周率） \nRAND()          --返回０到１内的随机值,可以通过提供一个参数(种子)使RAND()随机数生成器生成一个指定的值。 \nROUND(x,y)      --返回参数x的四舍五入的有y位小数的值 \nSIGN(x)         --返回代表数字x的符号的值 \nSQRT(x)         --返回一个数的平方根 \nTRUNCATE(x,y)   --返回数字x截短为y位小数的结果 \n\n\n\n# 聚合函数\n\nAVG(X)            --返回指定列的平均值 \nCOUNT(X)          --返回指定列中非NULL值的个数 \nMIN(X)            --返回指定列的最小值 \nMAX(X)            --返回指定列的最大值 \nSUM(X)            --返回指定列的所有值之和 \nGROUP_CONCAT(X)   --将group by产生的同一个分组中的值连接起来，返回一个字符串结果。非常有用 \n\n\n\n# 字符串函数\n\nASCII(char)        --返回字符的ASCII码值 \nBIT_LENGTH(str)    --返回字符串的比特长度 \nCONCAT(s1,s2...,sn)  \n                   --将s1,s2...,sn连接成字符串 \nCONCAT_WS(sep,s1,s2...,sn) \n                   --将s1,s2...,sn连接成字符串，并用sep字符间隔 \nINSERT(str,x,y,instr)  \n                   --将字符串str从第x位置开始，y个字符长的子串替换为字符串instr，返回结果 \nFIND_IN_SET(str,list) \n                   --分析逗号分隔的list列表，如果发现str，返回str在list中的位置 \nLCASE(str)或LOWER(str)  \n                   --返回将字符串str中所有字符改变为小写后的结果 \nLEFT(str,x)        --返回字符串str中最左边的x个字符 \nLENGTH(s)          --返回字符串str中的字符数 \nLTRIM(str)         --从字符串str中切掉开头的空格 \nPOSITION(substr,str)  \n                   --返回子串substr在字符串str中第一次出现的位置 \nQUOTE(str)         --用反斜杠转义str中的单引号 \nREPEAT(str,srchstr,rplcstr) \n                   --返回字符串str重复x次的结果 \nREVERSE(str)       --返回颠倒字符串str的结果 \nRIGHT(str,x)       --返回字符串str中最右边的x个字符 \nRTRIM(str)         --返回字符串str尾部的空格 \nSTRCMP(s1,s2)      --比较字符串s1和s2 \nTRIM(str)          --去除字符串首部和尾部的所有空格 \nUCASE(str)或UPPER(str)  \n                   --返回将字符串str中所有字符转变为大写后的结果 \n\n\n\n# 日期控制函数\n\nCURDATE()或CURRENT_DATE()  \n                   --返回当前的日期 \nCURTIME()或CURRENT_TIME()  \n                   --返回当前的时间 \nDATE_ADD(date,INTERVAL int keyword) \n                   --返回日期date加上间隔时间int的结果(int必须按照关键字进行格式化) \n例如 \nSELECT DATE_ADD(CURRENT_DATE,INTERVAL 6 MONTH); \n \nDATE_FORMAT(date,fmt)   \n                   --依照指定的fmt格式格式化日期date值 \nDATE_SUB(date,INTERVAL int keyword) \n                   --返回日期date加上间隔时间int的结果(int必须按照关键字进行格式化) \n例如 \nSELECT DATE_SUB(CURRENT_DATE,INTERVAL 6 MONTH); \n \nDAYOFWEEK(date)    --返回date所代表的一星期中的第几天(1~7) \nDAYOFMONTH(date)   --返回date是一个月的第几天(1~31) \nDAYOFYEAR(date)    --返回date是一年的第几天(1~366) \nDAYNAME(date)      --返回date的星期名，如：SELECT DAYNAME(CURRENT_DATE); \nFROM_UNIXTIME(ts,fmt)   \n                   --根据指定的fmt格式，格式化UNIX时间戳ts \nHOUR(time)         --返回time的小时值(0~23) \nMINUTE(time)       --返回time的分钟值(0~59) \nMONTH(date)        --返回date的月份值(1~12) \nMONTHNAME(date)    --返回date的月份名，如：SELECT MONTHNAME(CURRENT_DATE); \nNOW()              --返回当前的日期和时间 \nQUARTER(date)      --返回date在一年中的季度(1~4) \n例如 \nSELECT QUARTER(CURRENT_DATE); \n \nWEEK(date)         --返回日期date为一年中第几周(0~53) \nYEAR(date)         --返回日期date的年份(1000~9999) \n例如，获取当前系统时间 \nSELECT FROM_UNIXTIME(UNIX_TIMESTAMP()); \nSELECT EXTRACT(YEAR_MONTH FROM CURRENT_DATE); \nSELECT EXTRACT(DAY_SECOND FROM CURRENT_DATE); \nSELECT EXTRACT(HOUR_MINUTE FROM CURRENT_DATE); \n \n返回两个日期值之间的差值(月数) \nSELECT PERIOD_DIFF(200302,199802); \n \n在Mysql中计算年龄： \nSELECT DATE_FORMAT(FROM_DAYS(TO_DAYS(NOW())-TO_DAYS(birthday)),'%Y')+0 AS age FROM employee; \n这样，如果Brithday是未来的年月日的话，计算结果为0。 \n下面的SQL语句计算员工的绝对年龄，即当Birthday是未来的日期时，将得到负值。 \nSELECT DATE_FORMAT(NOW(), '%Y')  \n- DATE_FORMAT(birthday, '%Y')  \n-(DATE_FORMAT(NOW(), '00-%m-%d')  \n< DATE_FORMAT(birthday, '00-%m-%d')) AS age from employee \n\n\n\n# 控制流函数\n\nCASE WHEN [test1] THEN [result1]...ELSE [default] END  \n                    --如果test1是真，则返回result1，否则返回default \nCASE [test] WHEN [val1] THEN [result]...ELSE [default] END   \n                    --如果test和valN相等，则返回result，否则返回default \nIF(test,t,f)        --如果test是真，返回t；否则返回f \nIFNULL(arg1,arg2)   --如果arg1不是空，返回arg1，否则返回arg2 \nNULLIF(arg1,arg2)   --如果arg1=arg2返回NULL；否则返回arg1 \n \n这些函数的第一个是IFNULL()，它有两个参数，并且对第一个参数进行判断。 \n如果第一个参数不是NULL，函数就会向调用者返回第一个参数； \n如果是NULL,将返回第二个参数。 \n例如 \nSELECT IFNULL(1,2),  \nIFNULL(NULL,10), \nIFNULL(4*NULL,'false'); \n \nNULLIF()函数将会检验提供的两个参数是否相等，如果相等，则返回NULL， \n如果不相等，就返回第一个参数。 \n例如 \nSELECT  NULLIF(1,1), \n NULLIF('A','B'), \n NULLIF(2+3,4+1); \n \nMySQL的IF()函数也可以建立一个简单的条件测试， \n这个函数有三个参数，第一个是要被判断的表达式， \n如果表达式为真，IF()将会返回第二个参数， \n如果为假，IF()将会返回第三个参数。 \n例如 \nSELECT IF(1<10,2,3),IF(56>100,'true','false'); \nIF()函数在只有两种可能结果时才适合使用。 \n然而，在现实世界中，我们可能发现在条件测试中会需要多个分支。 \n在这种情况下，它和PHP及Perl语言的switch-case条件例程一样。 \n \nCASE函数的格式有些复杂，通常如下所示： \nCASE [expression to be evaluated] \nWHEN [val 1] THEN [result 1] \nWHEN [val 2] THEN [result 2] \nWHEN [val 3] THEN [result 3] \n...... \nWHEN [val n] THEN [result n] \nELSE [default result] \nEND \n这里，第一个参数是要被判断的值或表达式，接下来的是一系列的WHEN-THEN块， \n每一块的第一个参数指定要比较的值，如果为真，就返回结果。 \n所有的WHEN-THEN块将以ELSE块结束，当END结束了所有外部的CASE块时， \n如果前面的每一个块都不匹配就会返回ELSE块指定的默认结果。 \n如果没有指定ELSE块，而且所有的WHEN-THEN比较都不是真，MySQL将会返回NULL。 \nCASE函数还有另外一种句法，有时使用起来非常方便，如下： \nCASE \nWHEN [conditional test 1] THEN [result 1] \nWHEN [conditional test 2] THEN [result 2] \nELSE [default result] \nEND \n这种条件下，返回的结果取决于相应的条件测试是否为真。 \n例如： \nSELECT  CASE 'green' \n      WHEN 'red' THEN 'stop' \n      WHEN 'green' THEN 'go' END; \n \nSELECT CASE  9  \nWHEN 1 THEN 'a' \nWHEN 2 THEN 'b' ELSE 'N/A' END; \n \nSELECT CASE WHEN (2+2)=4 THEN 'OK'  \nWHEN (2+2)<>4 THEN 'not OK' END AS STATUS; \n \nSELECT Name,IF((IsActive = 1),'已激活','未激活') AS RESULT  \nFROM UserLoginInfo; \n \nSELECT fname,lname,(math+sci+lit) AS total, \nCASE WHEN (math+sci+lit) < 50 THEN 'D' \n     WHEN (math+sci+lit) BETWEEN 50 AND 150 THEN 'C' \n     WHEN (math+sci+lit) BETWEEN 151 AND 250 THEN 'B' \nELSE 'A' END AS grade FROM marks ; \n \nSELECT IF(ENCRYPT('sue','ts')=upass,'allow','deny') AS LoginResult \nFROM users WHERE uname = 'sue'; \n\n\n\n# 格式化函数\n\nDATE_FORMAT(date,fmt)   \n                  -- 依照字符串fmt格式化日期date值 \nFORMAT(x,y)       -- 把x格式化为以逗号隔开的数字序列，y是结果的小数位数 \nINET_ATON(ip)     -- 返回IP地址的数字表示 \nINET_NTOA(num)    -- 返回数字所代表的IP地址 \nTIME_FORMAT(time,fmt)    \n                  --依照字符串fmt格式化时间time值 \n-- 其中最简单的是FORMAT()函数， \n-- 它可以把大的数值格式化为以逗号间隔的易读的序列。 \n-- 例如\nSELECT FORMAT(34234.34323432,3) ; \nSELECT DATE_FORMAT(NOW(),'%W,%D %M %Y %r') ; \nSELECT DATE_FORMAT(NOW(),'%Y-%m-%d') ; \nSELECT DATE_FORMAT(19990330,'%Y-%m-%d') ; \nSELECT DATE_FORMAT(NOW(),'%h:%i %p') ; \nSELECT INET_ATON('10.122.89.47') ; \nSELECT INET_NTOA(175790383) ; \n\n\n\n# 类型转化函数\n\n-- 为了进行数据类型转化，MySQL提供了CAST()函数， \n-- 它可以把一个值转化为指定的数据类型。 \n-- 类型有：BINARY,CHAR,DATE,TIME,DATETIME,SIGNED,UNSIGNED \n-- 例如 \nSELECT CAST(NOW() AS SIGNED INTEGER),CURDATE()+0; \nSELECT 'f'=BINARY 'F','f'=CAST('F' AS BINARY); \n\n\n\n# 系统信息函数\n\nDATABASE()         --返回当前数据库名 \nBENCHMARK(count,expr)    \n                   --将表达式expr重复运行count次 \nCONNECTION_ID()    --返回当前客户的连接ID \nFOUND_ROWS()       --返回最后一个SELECT查询进行检索的总行数 \nUSER()或SYSTEM_USER()   \n                   --返回当前登陆用户名 \nVERSION()          --返回MySQL服务器的版本 \n例如 \nSELECT DATABASE(),VERSION(),USER(); \nSELECTBENCHMARK(9999999,LOG(RAND()*PI())); \n--该例中,MySQL计算LOG(RAND()*PI())表达式9999999次。 \n\n\n\n# 开窗函数\n\nROW_NUMBER() OVER()  --排序：1,2,3,4 \nRANK() OVER() --排序：1,1,3,3,5 \nDENSE_RANK() OVER()  --排序：1,1,2,2,3,4 \nNTILE() OVER() --将有序数据分为N组，记录等级数 \nLAG(expr,n) OVER() --返回当前行的前N行的expr的值 \nLEAD(expr,n) OVER()  --返回当前行 后N行的expr的值 \n",normalizedContent:"# 数学函数\n\nabs(x)         --返回x的绝对值 \nbin(x)         --返回x的二进制（oct返回八进制，hex返回十六进制） \nceiling(x)     --返回大于x的最小整数值 \nexp(x)         --返回值e（自然对数的底）的x次方 \nfloor(x)       --返回小于x的最大整数值 \ngreatest(x1,x2,...,xn) \n                --返回集合中最大的值 \nleast(x1,x2,...,xn)    \n                --返回集合中最小的值 \nln(x)           --返回x的自然对数 \nlog(x,y)        --返回x的以y为底的对数 \nmod(x,y)        --返回x/y的模（余数） \npi()            --返回pi的值（圆周率） \nrand()          --返回０到１内的随机值,可以通过提供一个参数(种子)使rand()随机数生成器生成一个指定的值。 \nround(x,y)      --返回参数x的四舍五入的有y位小数的值 \nsign(x)         --返回代表数字x的符号的值 \nsqrt(x)         --返回一个数的平方根 \ntruncate(x,y)   --返回数字x截短为y位小数的结果 \n\n\n\n# 聚合函数\n\navg(x)            --返回指定列的平均值 \ncount(x)          --返回指定列中非null值的个数 \nmin(x)            --返回指定列的最小值 \nmax(x)            --返回指定列的最大值 \nsum(x)            --返回指定列的所有值之和 \ngroup_concat(x)   --将group by产生的同一个分组中的值连接起来，返回一个字符串结果。非常有用 \n\n\n\n# 字符串函数\n\nascii(char)        --返回字符的ascii码值 \nbit_length(str)    --返回字符串的比特长度 \nconcat(s1,s2...,sn)  \n                   --将s1,s2...,sn连接成字符串 \nconcat_ws(sep,s1,s2...,sn) \n                   --将s1,s2...,sn连接成字符串，并用sep字符间隔 \ninsert(str,x,y,instr)  \n                   --将字符串str从第x位置开始，y个字符长的子串替换为字符串instr，返回结果 \nfind_in_set(str,list) \n                   --分析逗号分隔的list列表，如果发现str，返回str在list中的位置 \nlcase(str)或lower(str)  \n                   --返回将字符串str中所有字符改变为小写后的结果 \nleft(str,x)        --返回字符串str中最左边的x个字符 \nlength(s)          --返回字符串str中的字符数 \nltrim(str)         --从字符串str中切掉开头的空格 \nposition(substr,str)  \n                   --返回子串substr在字符串str中第一次出现的位置 \nquote(str)         --用反斜杠转义str中的单引号 \nrepeat(str,srchstr,rplcstr) \n                   --返回字符串str重复x次的结果 \nreverse(str)       --返回颠倒字符串str的结果 \nright(str,x)       --返回字符串str中最右边的x个字符 \nrtrim(str)         --返回字符串str尾部的空格 \nstrcmp(s1,s2)      --比较字符串s1和s2 \ntrim(str)          --去除字符串首部和尾部的所有空格 \nucase(str)或upper(str)  \n                   --返回将字符串str中所有字符转变为大写后的结果 \n\n\n\n# 日期控制函数\n\ncurdate()或current_date()  \n                   --返回当前的日期 \ncurtime()或current_time()  \n                   --返回当前的时间 \ndate_add(date,interval int keyword) \n                   --返回日期date加上间隔时间int的结果(int必须按照关键字进行格式化) \n例如 \nselect date_add(current_date,interval 6 month); \n \ndate_format(date,fmt)   \n                   --依照指定的fmt格式格式化日期date值 \ndate_sub(date,interval int keyword) \n                   --返回日期date加上间隔时间int的结果(int必须按照关键字进行格式化) \n例如 \nselect date_sub(current_date,interval 6 month); \n \ndayofweek(date)    --返回date所代表的一星期中的第几天(1~7) \ndayofmonth(date)   --返回date是一个月的第几天(1~31) \ndayofyear(date)    --返回date是一年的第几天(1~366) \ndayname(date)      --返回date的星期名，如：select dayname(current_date); \nfrom_unixtime(ts,fmt)   \n                   --根据指定的fmt格式，格式化unix时间戳ts \nhour(time)         --返回time的小时值(0~23) \nminute(time)       --返回time的分钟值(0~59) \nmonth(date)        --返回date的月份值(1~12) \nmonthname(date)    --返回date的月份名，如：select monthname(current_date); \nnow()              --返回当前的日期和时间 \nquarter(date)      --返回date在一年中的季度(1~4) \n例如 \nselect quarter(current_date); \n \nweek(date)         --返回日期date为一年中第几周(0~53) \nyear(date)         --返回日期date的年份(1000~9999) \n例如，获取当前系统时间 \nselect from_unixtime(unix_timestamp()); \nselect extract(year_month from current_date); \nselect extract(day_second from current_date); \nselect extract(hour_minute from current_date); \n \n返回两个日期值之间的差值(月数) \nselect period_diff(200302,199802); \n \n在mysql中计算年龄： \nselect date_format(from_days(to_days(now())-to_days(birthday)),'%y')+0 as age from employee; \n这样，如果brithday是未来的年月日的话，计算结果为0。 \n下面的sql语句计算员工的绝对年龄，即当birthday是未来的日期时，将得到负值。 \nselect date_format(now(), '%y')  \n- date_format(birthday, '%y')  \n-(date_format(now(), '00-%m-%d')  \n< date_format(birthday, '00-%m-%d')) as age from employee \n\n\n\n# 控制流函数\n\ncase when [test1] then [result1]...else [default] end  \n                    --如果test1是真，则返回result1，否则返回default \ncase [test] when [val1] then [result]...else [default] end   \n                    --如果test和valn相等，则返回result，否则返回default \nif(test,t,f)        --如果test是真，返回t；否则返回f \nifnull(arg1,arg2)   --如果arg1不是空，返回arg1，否则返回arg2 \nnullif(arg1,arg2)   --如果arg1=arg2返回null；否则返回arg1 \n \n这些函数的第一个是ifnull()，它有两个参数，并且对第一个参数进行判断。 \n如果第一个参数不是null，函数就会向调用者返回第一个参数； \n如果是null,将返回第二个参数。 \n例如 \nselect ifnull(1,2),  \nifnull(null,10), \nifnull(4*null,'false'); \n \nnullif()函数将会检验提供的两个参数是否相等，如果相等，则返回null， \n如果不相等，就返回第一个参数。 \n例如 \nselect  nullif(1,1), \n nullif('a','b'), \n nullif(2+3,4+1); \n \nmysql的if()函数也可以建立一个简单的条件测试， \n这个函数有三个参数，第一个是要被判断的表达式， \n如果表达式为真，if()将会返回第二个参数， \n如果为假，if()将会返回第三个参数。 \n例如 \nselect if(1<10,2,3),if(56>100,'true','false'); \nif()函数在只有两种可能结果时才适合使用。 \n然而，在现实世界中，我们可能发现在条件测试中会需要多个分支。 \n在这种情况下，它和php及perl语言的switch-case条件例程一样。 \n \ncase函数的格式有些复杂，通常如下所示： \ncase [expression to be evaluated] \nwhen [val 1] then [result 1] \nwhen [val 2] then [result 2] \nwhen [val 3] then [result 3] \n...... \nwhen [val n] then [result n] \nelse [default result] \nend \n这里，第一个参数是要被判断的值或表达式，接下来的是一系列的when-then块， \n每一块的第一个参数指定要比较的值，如果为真，就返回结果。 \n所有的when-then块将以else块结束，当end结束了所有外部的case块时， \n如果前面的每一个块都不匹配就会返回else块指定的默认结果。 \n如果没有指定else块，而且所有的when-then比较都不是真，mysql将会返回null。 \ncase函数还有另外一种句法，有时使用起来非常方便，如下： \ncase \nwhen [conditional test 1] then [result 1] \nwhen [conditional test 2] then [result 2] \nelse [default result] \nend \n这种条件下，返回的结果取决于相应的条件测试是否为真。 \n例如： \nselect  case 'green' \n      when 'red' then 'stop' \n      when 'green' then 'go' end; \n \nselect case  9  \nwhen 1 then 'a' \nwhen 2 then 'b' else 'n/a' end; \n \nselect case when (2+2)=4 then 'ok'  \nwhen (2+2)<>4 then 'not ok' end as status; \n \nselect name,if((isactive = 1),'已激活','未激活') as result  \nfrom userlogininfo; \n \nselect fname,lname,(math+sci+lit) as total, \ncase when (math+sci+lit) < 50 then 'd' \n     when (math+sci+lit) between 50 and 150 then 'c' \n     when (math+sci+lit) between 151 and 250 then 'b' \nelse 'a' end as grade from marks ; \n \nselect if(encrypt('sue','ts')=upass,'allow','deny') as loginresult \nfrom users where uname = 'sue'; \n\n\n\n# 格式化函数\n\ndate_format(date,fmt)   \n                  -- 依照字符串fmt格式化日期date值 \nformat(x,y)       -- 把x格式化为以逗号隔开的数字序列，y是结果的小数位数 \ninet_aton(ip)     -- 返回ip地址的数字表示 \ninet_ntoa(num)    -- 返回数字所代表的ip地址 \ntime_format(time,fmt)    \n                  --依照字符串fmt格式化时间time值 \n-- 其中最简单的是format()函数， \n-- 它可以把大的数值格式化为以逗号间隔的易读的序列。 \n-- 例如\nselect format(34234.34323432,3) ; \nselect date_format(now(),'%w,%d %m %y %r') ; \nselect date_format(now(),'%y-%m-%d') ; \nselect date_format(19990330,'%y-%m-%d') ; \nselect date_format(now(),'%h:%i %p') ; \nselect inet_aton('10.122.89.47') ; \nselect inet_ntoa(175790383) ; \n\n\n\n# 类型转化函数\n\n-- 为了进行数据类型转化，mysql提供了cast()函数， \n-- 它可以把一个值转化为指定的数据类型。 \n-- 类型有：binary,char,date,time,datetime,signed,unsigned \n-- 例如 \nselect cast(now() as signed integer),curdate()+0; \nselect 'f'=binary 'f','f'=cast('f' as binary); \n\n\n\n# 系统信息函数\n\ndatabase()         --返回当前数据库名 \nbenchmark(count,expr)    \n                   --将表达式expr重复运行count次 \nconnection_id()    --返回当前客户的连接id \nfound_rows()       --返回最后一个select查询进行检索的总行数 \nuser()或system_user()   \n                   --返回当前登陆用户名 \nversion()          --返回mysql服务器的版本 \n例如 \nselect database(),version(),user(); \nselectbenchmark(9999999,log(rand()*pi())); \n--该例中,mysql计算log(rand()*pi())表达式9999999次。 \n\n\n\n# 开窗函数\n\nrow_number() over()  --排序：1,2,3,4 \nrank() over() --排序：1,1,3,3,5 \ndense_rank() over()  --排序：1,1,2,2,3,4 \nntile() over() --将有序数据分为n组，记录等级数 \nlag(expr,n) over() --返回当前行的前n行的expr的值 \nlead(expr,n) over()  --返回当前行 后n行的expr的值 \n",charsets:{cjk:!0}},{title:"MySQL基础",frontmatter:{title:"MySQL基础",date:"2023-03-03T09:39:47.000Z",permalink:"/pages/c7801c/"},regularPath:"/01.Java/05.%E6%95%B0%E6%8D%AE%E5%BA%93/01.MySQL%E5%9F%BA%E7%A1%80.html",relativePath:"01.Java/05.数据库/01.MySQL基础.md",key:"v-062906bf",path:"/pages/c7801c/",headers:[{level:2,title:"MySQL执行流程",slug:"mysql执行流程",normalizedTitle:"mysql执行流程",charIndex:2},{level:2,title:"存储引擎",slug:"存储引擎",normalizedTitle:"存储引擎",charIndex:163},{level:3,title:"InnoDB和MyISAM对比",slug:"innodb和myisam对比",normalizedTitle:"innodb和myisam对比",charIndex:255},{level:3,title:"InnoDB",slug:"innodb",normalizedTitle:"innodb",charIndex:255},{level:4,title:"内存架构",slug:"内存架构",normalizedTitle:"内存架构",charIndex:634},{level:4,title:"磁盘架构",slug:"磁盘架构",normalizedTitle:"磁盘架构",charIndex:1138},{level:2,title:"索引",slug:"索引",normalizedTitle:"索引",charIndex:233},{level:2,title:"查询性能优化",slug:"查询性能优化",normalizedTitle:"查询性能优化",charIndex:1284},{level:2,title:"事务",slug:"事务",normalizedTitle:"事务",charIndex:330}],headersStr:"MySQL执行流程 存储引擎 InnoDB和MyISAM对比 InnoDB 内存架构 磁盘架构 索引 查询性能优化 事务",content:"# MySQL执行流程\n\n\n\n * 连接器：管理客户端登录，用户身份验证；\n * 缓存：执行查询语句时候，先查询缓存；\n * 分析器：（解析器）将SQL语句中关键字进行解析，生成一颗对应的“语法树”，来判断语法是否正确；\n * 优化器：将语法树转换成执行计划，并生成MySQL认为最好的执行计划；\n * 执行器：执行过程，调用存储引擎提供的api，来执行执行计划，执行之前进行权限验证，表、数据库、操作是否符合权限；\n * 存储引擎：定义MySQL中数据的存储机制、索引和锁机制等。\n\n\n# 存储引擎\n\n\n# InnoDB和MyISAM对比\n\n 1. InnoDB 支持行级别的锁粒度，MyISAM 不支持，只支持表级别的锁粒度。\n 2. MyISAM 不提供事务支持。InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别。\n 3. MyISAM 不支持外键，而 InnoDB 支持。\n 4. MyISAM 不支持 MVVC，而 InnoDB 支持。\n 5. 虽然 MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。\n 6. MyISAM 不支持数据库异常崩溃后的安全恢复，而 InnoDB 支持。\n 7. InnoDB 的性能比 MyISAM 更强大。\n\n\n# InnoDB\n\n存储引擎决定了MySQL会怎样存储引擎，怎样读取和写入数据，也很大程度决定了MySQL的读写性能和数据可靠性。\n\n# 内存架构\n\n * InnoDB In-Memory Structures\n * InnoDb On-Disk Structures\n\n\n\nBuffer Pool\n\nMySQL不会直接去修改磁盘的数据，因为这样做太慢了，MySQL会先改内存，然后记录redo log，等有空了再刷磁盘，如果内存里没有数据，就去磁盘load。\n\nBuffer Pool采用基于LRU的算法来管理内存：\n\n\n\nChange Buffer\n\n如果要修改MySQL的数据，并且包含该数据的页不在内存中，那么先把修改记到一个Change Buffer的地方，同时记录redo log，然后延迟将页面加载到内存中\n\n * merge：Change Buffer -> Buffer Pool\n * purge：Buffer Pool -> Disk\n\nAdaptive Hash Index\n\nMySQL索引，不管是内存的还是磁盘的，都是B+树，B+树的查找次数取决于树的深度。空间换时间的方法，MySQL会自动评估这张表建立这个索引是否值得。\n\nLog Buffer\n\nLog Buffer 里的redo log，会被刷到磁盘里\n\n# 磁盘架构\n\n\n\n表空间\n\n * The System Tablespace\n * File-Per-Table Tablespaces\n * General Tablespace\n * Undo Tablespaces\n * Temporary Tablespaces\n\n\n# 索引\n\n\n# 查询性能优化\n\n\n# 事务",normalizedContent:"# mysql执行流程\n\n\n\n * 连接器：管理客户端登录，用户身份验证；\n * 缓存：执行查询语句时候，先查询缓存；\n * 分析器：（解析器）将sql语句中关键字进行解析，生成一颗对应的“语法树”，来判断语法是否正确；\n * 优化器：将语法树转换成执行计划，并生成mysql认为最好的执行计划；\n * 执行器：执行过程，调用存储引擎提供的api，来执行执行计划，执行之前进行权限验证，表、数据库、操作是否符合权限；\n * 存储引擎：定义mysql中数据的存储机制、索引和锁机制等。\n\n\n# 存储引擎\n\n\n# innodb和myisam对比\n\n 1. innodb 支持行级别的锁粒度，myisam 不支持，只支持表级别的锁粒度。\n 2. myisam 不提供事务支持。innodb 提供事务支持，实现了 sql 标准定义了四个隔离级别。\n 3. myisam 不支持外键，而 innodb 支持。\n 4. myisam 不支持 mvvc，而 innodb 支持。\n 5. 虽然 myisam 引擎和 innodb 引擎都是使用 b+tree 作为索引结构，但是两者的实现方式不太一样。\n 6. myisam 不支持数据库异常崩溃后的安全恢复，而 innodb 支持。\n 7. innodb 的性能比 myisam 更强大。\n\n\n# innodb\n\n存储引擎决定了mysql会怎样存储引擎，怎样读取和写入数据，也很大程度决定了mysql的读写性能和数据可靠性。\n\n# 内存架构\n\n * innodb in-memory structures\n * innodb on-disk structures\n\n\n\nbuffer pool\n\nmysql不会直接去修改磁盘的数据，因为这样做太慢了，mysql会先改内存，然后记录redo log，等有空了再刷磁盘，如果内存里没有数据，就去磁盘load。\n\nbuffer pool采用基于lru的算法来管理内存：\n\n\n\nchange buffer\n\n如果要修改mysql的数据，并且包含该数据的页不在内存中，那么先把修改记到一个change buffer的地方，同时记录redo log，然后延迟将页面加载到内存中\n\n * merge：change buffer -> buffer pool\n * purge：buffer pool -> disk\n\nadaptive hash index\n\nmysql索引，不管是内存的还是磁盘的，都是b+树，b+树的查找次数取决于树的深度。空间换时间的方法，mysql会自动评估这张表建立这个索引是否值得。\n\nlog buffer\n\nlog buffer 里的redo log，会被刷到磁盘里\n\n# 磁盘架构\n\n\n\n表空间\n\n * the system tablespace\n * file-per-table tablespaces\n * general tablespace\n * undo tablespaces\n * temporary tablespaces\n\n\n# 索引\n\n\n# 查询性能优化\n\n\n# 事务",charsets:{cjk:!0}},{title:"《MySQL是怎么运行的》",frontmatter:{title:"《MySQL是怎么运行的》",date:"2023-03-03T21:28:30.000Z",permalink:"/pages/e0425d/"},regularPath:"/01.Java/05.%E6%95%B0%E6%8D%AE%E5%BA%93/02.MySQL%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%90%E8%A1%8C%E7%9A%84.html",relativePath:"01.Java/05.数据库/02.MySQL是怎么运行的.md",key:"v-3f7f455b",path:"/pages/e0425d/",headers:[{level:2,title:"第0章 楔子",slug:"第0章-楔子",normalizedTitle:"第0章 楔子",charIndex:18},{level:2,title:"第1章\t装作自己是个小白",slug:"第1章装作自己是个小白",normalizedTitle:"第1章\t装作自己是个小白",charIndex:null},{level:2,title:"第2章\t启动选项和系统变量",slug:"第2章启动选项和系统变量",normalizedTitle:"第2章\t启动选项和系统变量",charIndex:null},{level:2,title:"第3章\t字符集和比较规则",slug:"第3章字符集和比较规则",normalizedTitle:"第3章\t字符集和比较规则",charIndex:null},{level:2,title:"第4章\tInnoDB记录存储结构",slug:"第4章innodb记录存储结构",normalizedTitle:"第4章\tinnodb记录存储结构",charIndex:null},{level:2,title:"第5章 InnoDB数据页结构",slug:"第5章-innodb数据页结构",normalizedTitle:"第5章 innodb数据页结构",charIndex:970},{level:2,title:"第6章 B+树索引",slug:"第6章-b-树索引",normalizedTitle:"第6章 b+树索引",charIndex:2897},{level:2,title:"第7章 B+树索引的应用",slug:"第7章-b-树索引的应用",normalizedTitle:"第7章 b+树索引的应用",charIndex:3430},{level:2,title:"第8章 数据的家",slug:"第8章-数据的家",normalizedTitle:"第8章 数据的家",charIndex:4194},{level:2,title:"第9章 InnoDB的表空间",slug:"第9章-innodb的表空间",normalizedTitle:"第9章 innodb的表空间",charIndex:4549},{level:2,title:"第10章 单表访问方式",slug:"第10章-单表访问方式",normalizedTitle:"第10章 单表访问方式",charIndex:4568},{level:2,title:"第11章 连接的原理",slug:"第11章-连接的原理",normalizedTitle:"第11章 连接的原理",charIndex:4584},{level:2,title:"第12章 基于成本的优化",slug:"第12章-基于成本的优化",normalizedTitle:"第12章 基于成本的优化",charIndex:4888},{level:3,title:"成本",slug:"成本",normalizedTitle:"成本",charIndex:3872},{level:3,title:"基于成本的优化步骤",slug:"基于成本的优化步骤",normalizedTitle:"基于成本的优化步骤",charIndex:5104},{level:3,title:"基于索引统计数据的成本计算",slug:"基于索引统计数据的成本计算",normalizedTitle:"基于索引统计数据的成本计算",charIndex:5204},{level:3,title:"连接查询的成本",slug:"连接查询的成本",normalizedTitle:"连接查询的成本",charIndex:5397},{level:4,title:"条件过滤",slug:"条件过滤",normalizedTitle:"条件过滤",charIndex:5408},{level:4,title:"两表连接的成本分析",slug:"两表连接的成本分析",normalizedTitle:"两表连接的成本分析",charIndex:5609},{level:4,title:"多表连接的成本分析",slug:"多表连接的成本分析",normalizedTitle:"多表连接的成本分析",charIndex:5730},{level:3,title:"调节成本常数",slug:"调节成本常数",normalizedTitle:"调节成本常数",charIndex:5842},{level:2,title:"第13章 InnoDB统计数据是如何收集的",slug:"第13章-innodb统计数据是如何收集的",normalizedTitle:"第13章 innodb统计数据是如何收集的",charIndex:5938},{level:2,title:"第14章 基于规则的优化",slug:"第14章-基于规则的优化",normalizedTitle:"第14章 基于规则的优化",charIndex:5964},{level:3,title:"一些简单的优化",slug:"一些简单的优化",normalizedTitle:"一些简单的优化",charIndex:5981},{level:3,title:"常量表检测",slug:"常量表检测",normalizedTitle:"常量表检测",charIndex:6160},{level:3,title:"外连接消除",slug:"外连接消除",normalizedTitle:"外连接消除",charIndex:6249},{level:3,title:"子查询MySQL执行过程",slug:"子查询mysql执行过程",normalizedTitle:"子查询mysql执行过程",charIndex:6397},{level:4,title:"不相关标量子查询",slug:"不相关标量子查询",normalizedTitle:"不相关标量子查询",charIndex:6413},{level:4,title:"相关标量子查询",slug:"相关标量子查询",normalizedTitle:"相关标量子查询",charIndex:6414},{level:4,title:"IN子查询的优化",slug:"in子查询的优化",normalizedTitle:"in子查询的优化",charIndex:6803},{level:4,title:"将子查询转换为semi-join",slug:"将子查询转换为semi-join",normalizedTitle:"将子查询转换为semi-join",charIndex:7169},{level:2,title:"第15章 EXPLAIN详解",slug:"第15章-explain详解",normalizedTitle:"第15章 explain详解",charIndex:8540},{level:3,title:"执行输出中各列",slug:"执行输出中各列",normalizedTitle:"执行输出中各列",charIndex:8617},{level:4,title:"table",slug:"table",normalizedTitle:"table",charIndex:4062},{level:4,title:"id",slug:"id",normalizedTitle:"id",charIndex:4514},{level:4,title:"select_type",slug:"select-type",normalizedTitle:"select_type",charIndex:8781},{level:4,title:"type",slug:"type",normalizedTitle:"type",charIndex:2024},{level:4,title:"possible_keys和key",slug:"possible-keys和key",normalizedTitle:"possible_keys和key",charIndex:15798},{level:4,title:"key_len",slug:"key-len",normalizedTitle:"key_len",charIndex:8846},{level:4,title:"ref",slug:"ref",normalizedTitle:"ref",charIndex:8856},{level:4,title:"rows",slug:"rows",normalizedTitle:"rows",charIndex:8863},{level:4,title:"filtered",slug:"filtered",normalizedTitle:"filtered",charIndex:8870},{level:2,title:"第16章 optimizer trace的神奇功效",slug:"第16章-optimizer-trace的神奇功效",normalizedTitle:"第16章 optimizer trace的神奇功效",charIndex:15969},{level:2,title:"第17章 InnoDB的Buffer Pool",slug:"第17章-innodb的buffer-pool",normalizedTitle:"第17章 innodb的buffer pool",charIndex:15999},{level:2,title:"第18章 事务",slug:"第18章-事务",normalizedTitle:"第18章 事务",charIndex:16391},{level:2,title:"第19章 redo日志",slug:"第19章-redo日志",normalizedTitle:"第19章 redo日志",charIndex:16425},{level:2,title:"第20章 undo日志",slug:"第20章-undo日志",normalizedTitle:"第20章 undo日志",charIndex:16441},{level:2,title:"第21章 事务隔离级别和MVCC",slug:"第21章-事务隔离级别和mvcc",normalizedTitle:"第21章 事务隔离级别和mvcc",charIndex:16457},{level:2,title:"第22章 锁",slug:"第22章-锁",normalizedTitle:"第22章 锁",charIndex:16478}],headersStr:"第0章 楔子 第1章\t装作自己是个小白 第2章\t启动选项和系统变量 第3章\t字符集和比较规则 第4章\tInnoDB记录存储结构 第5章 InnoDB数据页结构 第6章 B+树索引 第7章 B+树索引的应用 第8章 数据的家 第9章 InnoDB的表空间 第10章 单表访问方式 第11章 连接的原理 第12章 基于成本的优化 成本 基于成本的优化步骤 基于索引统计数据的成本计算 连接查询的成本 条件过滤 两表连接的成本分析 多表连接的成本分析 调节成本常数 第13章 InnoDB统计数据是如何收集的 第14章 基于规则的优化 一些简单的优化 常量表检测 外连接消除 子查询MySQL执行过程 不相关标量子查询 相关标量子查询 IN子查询的优化 将子查询转换为semi-join 第15章 EXPLAIN详解 执行输出中各列 table id select_type type possible_keys和key key_len ref rows filtered 第16章 optimizer trace的神奇功效 第17章 InnoDB的Buffer Pool 第18章 事务 第19章 redo日志 第20章 undo日志 第21章 事务隔离级别和MVCC 第22章 锁",content:"都说这本书好，我倒要去看看\n\n\n# 第0章 楔子\n\n叫我逐章学习，不要跳着阅读\n\n\n# 第1章 装作自己是个小白\n\n介绍了一番MySQL客户端，服务器模式，客户端连接服务器方式。\n\n服务器处理客户端请求，具体步骤和MySQL执行过程一样。MySQL执行流程\n\n\n# 第2章 启动选项和系统变量\n\n没看\n\n\n# 第3章 字符集和比较规则\n\n字符集\n\n我们知道，计算机中实际存储的是二进制数据，那它是怎么存储字符串呢？当然是建立字符与二进制数据的映射关系了。\n\n * 把哪些字符映射成二进制数据\n * 字符映射到二进制数据叫编码，反之叫解码\n\n比较规则\n\n不区分大小写，全部转为大写或者小写\n\nMySQL中的字符集\n\n * utf8mb3: “阉割”过的utf8，使用1-3字节表示字符；\n * utf8ub4: 正宗的utf8，使用1-4字节表示字符。\n\nMySQL中的比较规则\n\n * utf8_general_ci: ci（case insensitive）不区分大小写。\n\n\n# 第4章 InnoDB记录存储结构\n\n页是InnoDB中磁盘和内存交互的基本单位，也是InnoDB管理存储空间的基本单位，默认大小为16KB。也就是说，一次从磁盘中读取内容到内存中是16KB，从内容写到磁盘，也是16KB。\n\nCOMPACT行格式（额外信息，真实数据）\n\n      变长字段长度列表   NULL值列表   记录头信息   列1的值   列2的值   ...   列N的值\n记录1   01 03 04   00                                    \n记录2   03 04      06                                    \n\n变长字段长度列表\n\n列名   存储内容     内容长度（十六进制）\nc1   'aaaa'   0x04\nc3   'bbb'    0x03\nc4   'd'      0x01\n\n那么就逆序存储变长字段的长度\n\nNULL值列表\n\n如果一个表中有9个值允许为NULL的列，则这个记录的NULL值列表部分需要2个字节表示，这个数据中的每一位代表真实数据是否为NULL。\n\n如c3, c4位NULL，则值位0x110 也就是06。\n\n\n# 第5章 InnoDB数据页结构\n\n页是InnoDB管理存储空间的基本单位，一个页的大小一般是16KB。InnoDB为了不同的目的设计了多种不同类型的页，这里介绍存放记录的页，数据页（索引页）。\n\nInnoDB数据页结构\n\n名称                   中文名             占用空间大小   简单描述\nFile Header          文件头部            38字节     页的一些通用信息\nPage Header          页面头部            56字节     数据页专有的一些信息\nInfimum + Supremum   页面中的最小记录和最大记录   26字节     两个虚拟的记录\nUser Records         用户记录            不确定      用户存储的记录内容\nFree Space           空闲空间            不确定      页中尚未使用的空间\nPage Directory       页目录             不确定      页中某些记录的相对位置\nFile Trailer         文件尾部            8字节      校验页是否完整\n\n用户记录\n\n我们自己存储的数据一开始在Free Space部分，随后将这部分划分到User Records中，当Free Space全部用完时，代表这个页使用完了。如果有新的记录插入，就需要去申请新的页了。\n\n上一章的行记录格式中的 记录头信息\n\n\n\n记录头信息\n\n名称             大小(比特〕   描述\n预留位 1          1        没有使用\n预留位 2          1        没有使用\ndeleted_flag   1        标记该记录是否被删除\nmin_rec_flag   1        B+ 树中每层非叶子节点中的 最小的目录项记录都会添加该标记\nn_owned        4        一个页面中的记录会被分成若干个组,每个组中有一个记录是\"带头大哥其余的记录都是\"小弟\"，\"带头大哥\"记录的\n                        n_owned值代表该组中所有的记录条数，\"小弟\"记录的 n_owned 值都为 0\nheap_no        13       表示当前记录在页面堆中的相对位置\nrecord_type    3        表示当前记录的类型 。0 表示普通记录，1 表示 B+ 树非叶节点的目录项记录 . 2 表示 Infimum 记录 ，3\n                        表示 Supremum 记录\nnext record    16       表示下一条记录的相对位置\n\n页目录\n\n\n\n要找主键值为x的记录，通过二分法确定该记录所在分组对应的槽，然后找到该槽所在分组中主键值最小的那条记录，然后通过记录的next_record属性遍历该槽所在的组中的各个记录。\n\n页面的头部\n\n存储数据页中的记录状态信息，比如数据页中已经存储了多少条记录、Free Space在页面中的地址偏移量、页目录中存储了多少个槽等。\n\n文件头部\n\n存放各种页的信息，比如这个页的编号是多少，上一页下一页是谁。\n\n文件尾部\n\n * 前4字节代表页的校验和，验证该页是否完整\n * 后4字节代表页面被最后修改时对应的LSN的后4字节\n\n总结\n\n每个记录的头信息中都有一个 next record 属性 ,从而可以 使页 中的 所有记录串联成一个单向链表.\n\nlnnoDB 会把页中的记录划分为若干个组,每个组的最后一个记录的地址偏移量作为一个槽,存放在 Page Directory 中一个槽占用 2 字节.在一个页中根据主键查找记录是非常快的,分为两步.\n\n 1. 通过 二分法确定该记录所在分 组对应的槽,并找到该糟所在分组中主键值最小的那条记录。\n\n 2. 通过记录的 next record 属性遍历该槽所在的组中 的各个记录.每个数据页的 File Header 部分 都有上 一个页和下一个页的编号,所以所有的数据页会组成一个双向链表。\n\n在将页从内存刷新到磁盘时 , 为了保证页的完整性 ,页首 和 **页尾 **都会存储页中数据的校验和，以及页面最 后修改时对应 的 LSN 值 (页尾只会存 储 LSN 值的后 4 字节) . 如果页首和页尾的校验和以及 LSN 值校验不成功 , 就说明刷新期间出现了问题。\n\n\n# 第6章 B+树索引\n\n各个数据页可以组成一个双向链表，数据页中每条记录会按照主键值从小到大组成一个单向链表。每个数据页会生成一个页目录，通过页目录二分法找到对应的槽，再去顺序遍历槽对应的分组中的记录。\n\n\n\n存放页目录的页，复用原来的数据页，所以记录中的记录头信息record_type，用来标记是用户记录还是目录项。存放页目录的页，中的记录只存放两个值，主键值与对应的页号。\n\n\n\n聚簇索引\n\n使用记录主键值的大小进行记录和页的排序\n\n 1. 页内的节点按照主键值大小排成一个单向链表，页内的节点分成若干个组，每组中最大主键值当成一个槽；\n 2. 存放页目录的页，根据主键值大小排成双向链表；\n 3. 存放用户记录的页，根据主键值大小排成双向链表；\n\nB+树的叶子节点存储的是完整的用户记录。\n\n二级索引\n\n存放页目录的页中的记录只存放多个值，主键值，索引值与对应的页号。叶子节点包含索引值与主键值，再生成一颗B+树，但叶子节点不包含完整记录，找到叶子节点对应的主键值，再到主键索引中查找完整记录，需要进行一次回表操作；\n\n联合索引\n\n存放页目录的页中的记录只存放多个值，主键值，n个索引值与对应的页号。\n\nMyISAM中的索引，都是二级索引，其它类似。\n\n\n# 第7章 B+树索引的应用\n\n每个索引都对应一颗B+树。B+树分为好多层，最下边一层是叶子节点，其余是内节点。所有用户记录都存储在B+树的叶子结点，所有目录项记录都存储在内节点。\n\nInnoDB存储引擎会自动为主键简历聚簇索引，聚簇索引的叶子节点包含完整的用户记录。但是建立的二级索引中的叶子节点只包含主键和索引列，若需要查找到非索引列，则需要拿到主键值，到聚簇索引中再查找一次，简称回表。\n\n聚簇索引和二级索引示意图\n\n\n\n\n\n扫描区间和边界条件分析\n\n索引在空间和时间上都会“拖后腿”\n\n * 空间上的代价\n\n每建立一个索引，都要为它建立一颗B+树。每一颗B+树的每一个节点都是一个数据页（一个节点中包含多条记录，还包含一些其它信息）。\n\n * 时间上的代价\n   \n   因为索引列的值是有序的关系，如果新插入的数据，有可能会造成页面分裂、页面回收、还要维护索引列中的排序关系。\n   \n   在执行查询语句前，首先要生成一个执行计划。MySQL会分析使用不同索引执行查询所需要的成本，索引越多分析的时间越长。\n\n扫描区间和边界分析\n\n去翻书吧。\n\n更好的创建索引和使用索引\n\n 1. 只为用于搜索、排序或分组的列创建索引\n 2. 考虑索引列中不重复值的个数\n 3. 索引列的类型尽量小\n 4. 为列前缀建立索引，节省空间\n 5. 索引覆盖，只查询索引列，避免回表\n 6. 让索引列以列名的形式在搜索条件中单独出现\n\nselect * from single_table where key2 * 2 < 4;  #不适用索引，全表扫描\nselect * from single_table where key2  < 4/2;   \n\n\n 7. 新插入记录时主键大小对效率的影响，忽大忽小的插入可能会造成页面分裂\n\n\n# 第8章 数据的家\n\nMySQL 服务器程序在启动时会到数据目录中加载数据,运行过程中产生的数据也会被存储到数据目录中系统变量也扭曲表明了数据目录的路径。\n\n每个数据库都对应着数据目录下的一个子目录，该子目录中包含一个名为 db.opt 的文件这个文件包含了该数据库的一些属性，比如该数据库的字符集和比较规则等。\n\n对于InnoDB 存储引擎来说 :\n\n * 如果使用系统表空间存储表中的数据,那么只会在该表所在数据库对应的子目录下创建一个名为\"表名 frm\" 的文件,表中的数据会存储在系统表空间对应的文件中；\n * 如果使用独立表空间存储表中的数据，那么会在该表所在数据库对应的子目录下创建一个名为\"表名.frm\"的文件和一个名为\"表名.idb\"的文件，表中的数据会存储这个\"表名.idb\"文件中。\n\n\n# 第9章 InnoDB的表空间\n\n\n# 第10章 单表访问方式\n\n\n# 第11章 连接的原理\n\n从本质上说，连接就是将多个表的数据查询出来依次匹配，组成一个结果集返回。如果没有过滤条件，产生的结果集那么就是笛卡尔积。\n\nMySQL中分为内连接和外连接，内连接也就是取匹配中的交集，外连接就是，被驱动表中有没有数据匹配与驱动表匹配，都保留驱动表中的数据，内连接则不保存。\n\n嵌套循环连接算法是值驱动表只访问一次，对于每一条驱动表中的数据，都会访问一次被驱动表。因此设计了Join Buffer（连接缓冲区）存放于内存，把驱动表中查询出来的数据放到缓冲区中，然后对于查询被驱动表中的每一条数据，都与缓冲区中的数据进行匹配。这样，就假如缓冲区足够大，那么只需访问一次被驱动表。\n\n\n# 第12章 基于成本的优化\n\n\n# 成本\n\n * I/O成本：当查询表中的记录时，需要把数据或者索引加载到内存中，然后再进行操作。这个从磁盘到内存的加载过程损耗的时间成为I/O成本。\n * CPU成本：读取记录以及检测记录是否满足对应的搜索条件、对结果集进行排序等这些操作损耗的时间称为CPU成本。\n\n对于InnoDB存储引擎来说，读取一个页面花费的成本默认是1.0；读取以及检测一条记录是否符合搜索条件的成本默认是0.2。\n\n\n# 基于成本的优化步骤\n\n 1. 根据搜索条件，找出所有可能使用的索引\n 2. 计算全表扫描的代价\n 3. 计算使用不同索引执行查询的代价\n 4. 对比各种执行方案的代价，找出成本最低的那个方案\n\n\n# 基于索引统计数据的成本计算\n\n每张表都有一个对应的统计表，来记录这张表的信息。比如有个索引统计数据，index statistics，show index from 表名，统计索引列中的各种信息，有一个比较重要的信息，Cardinality，表示该列中不重复值的数量。根据这个属性，可以计算出在某一列中一个值平均出现了多少次，大约重复次数等于函数初一Cardinality值。\n\n\n# 连接查询的成本\n\n# 条件过滤\n\n因为在连接查询中，驱动表会被访问一次，被驱动表可能会被访问多次。所以，对于两表连接查询来说，它的查询成本由两部分构成：\n\n * 单词查询驱动表的成本\n * 多次查询被驱动表的成本\n\n驱动表的记录条数成为扇出（fanout），然后呢，就要计算扇出值。\n\n对于那些条件中没有使用的索引列的数据，完全靠猜测来计算符合条件的记录条数，对于有索引列，那么通过Cardinality来猜测条数。\n\n# 两表连接的成本分析\n\n连接查询的总成本=单词访问驱动表的成本 + 驱动表的扇出值*单词访问被驱动表的成本\n\n所以也需要考虑最优的表连接顺序，优化的重点就是后面那个大头：\n\n * 尽量减少驱动表的扇出值\n * 访问被驱动表的成本要尽量底\n\n# 多表连接的成本分析\n\nn张表的连接方式就有n!种连接方式，通过一些启发式规则来分析多表连接的成本，比如\n\n * 提前结束某种连接顺序的成本评估\n * 防止无穷无尽地分析各种连接顺序的成本，只分析小于一定的连接表数量\n\n\n# 调节成本常数\n\n有两张表，engine_cost，server_cost\n\n在server层进行连接管理、查询缓存、语法解析、查询优化等操作；\n\n在存储引擎层执行具体的数据存取操作。\n\n\n# 第13章 InnoDB统计数据是如何收集的\n\n\n# 第14章 基于规则的优化\n\n\n# 一些简单的优化\n\n * 移除不必要的括号\n * 常量传递\n\na = 5 AND b > a\n\n\na = 5 AND b > 5\n\n\n * 等值传递\n\n * 移除没用的条件\n\n * 表达式计算\n\n * HAVING字句和WHERE字句的合并，如果没用出现SUM、MAC等聚集函数以及GROUP BY字句，优化器就把HAVING字句和WHERE字句合并\n\n\n# 常量表检测\n\n这两种查询话费的时间特别少\n\n * 查询的表中一条记录没有，或者只有一条记录（根据统计信息（但不准确））\n * 使用主键等值匹配或者唯一二级索引列等值匹配\n\n\n# 外连接消除\n\n在被驱动表中没有找到符合条件的记录，就会加入一条NULL值的记录到结果集中。如果在where条件中拒绝空值，这时候的查询结果是等价于内连接的，那么就可以将外连接转换为内连接。\n\n转为内连接的好处是，优化器可以评估不同连接顺序的成本，进而选出成本最低的那种连接顺序进行查询。\n\n\n# 子查询MySQL执行过程\n\n# 不相关标量子查询\n\nSELECT * FROM s1 \n    WHERE key1 = (SELECT common_field FROM s2 WHERE key3 = 'a' LIMIT 1);\n\n\n * 先单独执行子查询SELECT common_field FROM s2 WHERE key3 = 'a' LIMIT 1\n * 将上一步子查询的结果作为外层循环的条件\n\n# 相关标量子查询\n\nSELECT * FROM s1 WHERE \n    key1 = (SELECT common_field FROM s2 WHERE s1.key3 = s2.key3 LIMIT 1);\n\n\n * 从外循环取出一条记录\n * 获取上一步的记录所需的列，然后执行子查询\n * 如果符合条件，查出子查询的结果\n * 再将子查询的结果拼接到外层查询的WHERE子句中\n\n# IN子查询的优化\n\nSELECT * FROM s1 \n    WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = 'a');\n\n\n将IN后面的子查询结果，写入到一个临时表中（物化表）materialized_table\n\n那么就相当于有两张表，就有一下两种考虑\n\n * 从原表s1的角度看待，先获取s1表中的一条记录，然后判断这条记录是否存在于物化表中。\n * 从物化表看待，先获取物化表中的值，然后判断s1表中是否有这个值的记录。\n\n也就是说，可以相当于是一个内连接，等价于\n\nSELECT s1.* FROM s1 INNER JOIN materialized_table ON key1 = m_val;\n\n\n是内连接，那么优化器就会评估它们的连接顺序。\n\n# 将子查询转换为semi-join\n\n直接将子查询转换为连接。\n\n对于这样一个查询\n\nSELECT * FROM s1 \n    WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = 'a');\n\n\n尝试将其转换为连接\n\nSELECT s1.* FROM s1 INNER JOIN s2 \n    ON s1.key1 = s2.common_field \n    WHERE s2.key3 = 'a';\n\n\n这个查询的结果集是s1的记录，如果对于表s1的某条记录来说，s2表中有多条s1.key1=s2.common_field，那么s1的这条记录会加入多次到结果集中，这一种情况与原来的查询等价，原来的查询只关心是否存在记录满足s1.key1=s2.common_field二不关心具体有多少条记录与之匹配。\n\n半连接\n\n * Table pullout（子查询中的表上拉）\n   \n   当子查询的查询列表是只有主键或者唯一索引列时\n   \n   SELECT * FROM s1 \n       WHERE key2 IN (SELECT key2 FROM s2 WHERE key3 = 'a');\n   \n   \n   可以转换为\n   \n   SELECT s1.* FROM s1 INNER JOIN s2 \n       ON s1.key2 = s2.key2 \n       WHERE s2.key3 = 'a';\n   \n   \n   因为唯一索引或主键不存在有多条记录与之匹配\n\n * DuplicateWeedout execution strategy （重复值消除）\n   \n   SELECT * FROM s1 \n       WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = 'a');\n   \n   \n   可以创建一个临时表\n   \n   CREATE TABLE tmp (\n       id PRIMARY KEY\n   );\n   \n   \n   这样，如果要将s1的某条记录加入到结果集中，那先将该条记录的id插入到临时表中，如果插入成功，那可以将该条记录加入到结果集。\n\n半连接适用条件\n\nSELECT ... FROM outer_tables \n    WHERE expr IN (SELECT ... FROM inner_tables ...) AND ...\n\n\n如果IN子查询不符合转换为semi-join的条件，那么查询优化器再二选一\n\n * 先将子查询物化之后再执行查询\n * 执行IN to EXISTS转换\n\nIN to EXISTS转换\n\nouter_expr IN (SELECT inner_expr FROM ... WHERE subquery_where)\n\n\n转换为\n\nEXISTS (SELECT inner_expr FROM ... WHERE subquery_where AND outer_expr=inner_expr)\n\n\n转换为EXISTS的好处是，子查询可能可以用上索引\n\n看到这里脑子嗡嗡的~\n\n\n# 第15章 EXPLAIN详解\n\n一条查询语句在经过MySQL的查询优化器后，会基于成本或规则进行优化，可以通EXPLAIN来查看具体的执行计划。\n\n\n# 执行输出中各列\n\nmysql> EXPLAIN SELECT * FROM s1;\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+\n|  1 | SIMPLE      | s1    | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 9688 |   100.00 | NULL  |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+\n1 row in set, 1 warning (0.00 sec)\n\n\n# table\n\n无论查询语句中包含多少个表，最终都会对每个表进行单表查询\n\n# id\n\n一个大的查询可以拆分成多个SELECT，每一个SELECT对应一个id。\n\n对于连接查询因为是同一个SELECT子句，所以查询的两个表是同一个id值。\n\nmysql> EXPLAIN SELECT * FROM s1 INNER JOIN s2;\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                                 |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+\n|  1 | SIMPLE      | s1    | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 9688 |   100.00 | NULL                                  |\n|  1 | SIMPLE      | s2    | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 9954 |   100.00 | Using join buffer (Block Nested Loop) |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+\n2 rows in set, 1 warning (0.01 sec)\n\n\n对于联合查询或者子查询，则会分配多个唯一id值。\n\nmysql> EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2) OR key3 = 'a';\n+----+-------------+-------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\n| id | select_type | table | partitions | type  | possible_keys | key      | key_len | ref  | rows | filtered | Extra       |\n+----+-------------+-------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\n|  1 | PRIMARY     | s1    | NULL       | ALL   | idx_key3      | NULL     | NULL    | NULL | 9688 |   100.00 | Using where |\n|  2 | SUBQUERY    | s2    | NULL       | index | idx_key1      | idx_key1 | 303     | NULL | 9954 |   100.00 | Using index |\n+----+-------------+-------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\n2 rows in set, 1 warning (0.02 sec)\n\n\n# select_type\n\n一个大的SELECT可以拆分成多个小SELECT，对每一个`SELECT分配角色。\n\n * SIMPLE\n\n不包含UNION或者子查询的查询都算作SIMPLE类型\n\nmysql> EXPLAIN SELECT * FROM s1;\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+\n|  1 | SIMPLE      | s1    | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 9688 |   100.00 | NULL  |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+\n1 row in set, 1 warning (0.00 sec)\n\n\n * PRIVATE\n\n包含UNION，或者子查询的查询，其中最左边的表就是PRIVATE\n\nmysql> EXPLAIN SELECT * FROM s1 UNION SELECT * FROM s2;\n+----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+\n| id | select_type  | table      | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra           |\n+----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+\n|  1 | PRIMARY      | s1         | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 9688 |   100.00 | NULL            |\n|  2 | UNION        | s2         | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 9954 |   100.00 | NULL            |\n| NULL | UNION RESULT | <union1,2> | NULL       | ALL  | NULL          | NULL | NULL    | NULL | NULL |     NULL | Using temporary |\n+----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+\n3 rows in set, 1 warning (0.00 sec)\n\n\n * UNION\n\n上边，除了最左边的s1，其它都是UNION\n\n * UNION RESULT\n\n上边，需要将两个查询的结果集合并，这里就是存放到一个临时表中，并去重。\n\n * SUBQUERY\n\n包含子查询的查询，不能转为对应的semi-join，并且是不相关子查询\n\n * DEPENDENT SUBQUERY\n\n相关子查询\n\n * DEPENDENT UNION\n * DERIVED\n\n派生表\n\nmysql> EXPLAIN SELECT * FROM (SELECT key1, count(*) as c FROM s1 GROUP BY key1) AS derived_s1 where c > 1;\n+----+-------------+------------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\n| id | select_type | table      | partitions | type  | possible_keys | key      | key_len | ref  | rows | filtered | Extra       |\n+----+-------------+------------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\n|  1 | PRIMARY     | <derived2> | NULL       | ALL   | NULL          | NULL     | NULL    | NULL | 9688 |    33.33 | Using where |\n|  2 | DERIVED     | s1         | NULL       | index | idx_key1      | idx_key1 | 303     | NULL | 9688 |   100.00 | Using index |\n+----+-------------+------------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\n2 rows in set, 1 warning (0.00 sec)\n\n\n * MATERIALIZED\n\n物化表\n\nmysql> EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2);\n+----+--------------+-------------+------------+--------+---------------+------------+---------+-------------------+------+----------+-------------+\n| id | select_type  | table       | partitions | type   | possible_keys | key        | key_len | ref               | rows | filtered | Extra       |\n+----+--------------+-------------+------------+--------+---------------+------------+---------+-------------------+------+----------+-------------+\n|  1 | SIMPLE       | s1          | NULL       | ALL    | idx_key1      | NULL       | NULL    | NULL              | 9688 |   100.00 | Using where |\n|  1 | SIMPLE       | <subquery2> | NULL       | eq_ref | <auto_key>    | <auto_key> | 303     | xiaohaizi.s1.key1 |    1 |   100.00 | NULL        |\n|  2 | MATERIALIZED | s2          | NULL       | index  | idx_key1      | idx_key1   | 303     | NULL              | 9954 |   100.00 | Using index |\n+----+--------------+-------------+------------+--------+---------------+------------+---------+-------------------+------+----------+-------------+\n3 rows in set, 1 warning (0.01 sec)\n\n\n# type\n\nTYPE              类型\nsystem            对于统计精确的引擎，表中仅含一条记录\nconst             单表访问，主键或者唯一二级索引列与等值匹配\neq_ref            连接查询，被驱动表通过主键或者唯一二级索引列与等值匹配\nref               普通的二级索引列与等值匹配\nfulltext          全文索引\nref_or_null       普通的二级索引列与等值匹配，包含NULL\nindex_merge       索引合并\nunique_subquery   连接查询，被驱动表使用eq_ref\nindex_subquery    连接查询，被驱动表使用ref\nrange             使用索引获取某些范围区间\nindex             需要扫描索引上的所有数据\nALL               全表扫描\n\n# possible_keys和key\n\n可能使用到的索引，和实际用到的索引\n\n# key_len\n\n# ref\n\n使用索引列等值匹配去执行查询时，展示与什么进行等值匹配，与某个常数const，某一列，某个函数。\n\n# rows\n\n预计需要扫描的行数\n\n# filtered\n\n过滤条件后，还剩多少记录，1~100%。\n\n未完待续。。。\n\n\n# 第16章 optimizer trace的神奇功效\n\n\n# 第17章 InnoDB的Buffer Pool\n\n磁盘太慢，用内存作为缓存，不至于每次都访问磁盘。\n\nBuffer Poll是向操作系统申请的连续内存，一个个的chunk组成，每个chunk由控制块和缓存页组成，控制块那肯定就是存放一些缓存页的信息，上一页，下一页，锁啥的。\n\n那在内存中弄了一个这样的玩意，那肯定就有这些问题\n\n咋知道缓存中是否加载了某一页，使用表空间号 + 页号作为key，缓存页作为value，建立哈希表。\n\n缓存中修改了页（脏页），加入到flush链表，等待时机刷入磁盘。\n\nBuffer Poll满了怎么办，采用LRU链表，LRU链表分为young区和old区，新加入的数据，放到LRU的old头，在间隔一定时间外访问，就会吧他送到young头。没有足够的空闲缓存页，首先淘汰old中的页。\n\n少于1G缓存数据，不建议搞多个Buffer Poll。\n\n\n# 第18章 事务\n\nACID，原子性，一致性，隔离性，持久性\n\n\n# 第19章 redo日志\n\n\n# 第20章 undo日志\n\n\n# 第21章 事务隔离级别和MVCC\n\n\n# 第22章 锁",normalizedContent:"都说这本书好，我倒要去看看\n\n\n# 第0章 楔子\n\n叫我逐章学习，不要跳着阅读\n\n\n# 第1章 装作自己是个小白\n\n介绍了一番mysql客户端，服务器模式，客户端连接服务器方式。\n\n服务器处理客户端请求，具体步骤和mysql执行过程一样。mysql执行流程\n\n\n# 第2章 启动选项和系统变量\n\n没看\n\n\n# 第3章 字符集和比较规则\n\n字符集\n\n我们知道，计算机中实际存储的是二进制数据，那它是怎么存储字符串呢？当然是建立字符与二进制数据的映射关系了。\n\n * 把哪些字符映射成二进制数据\n * 字符映射到二进制数据叫编码，反之叫解码\n\n比较规则\n\n不区分大小写，全部转为大写或者小写\n\nmysql中的字符集\n\n * utf8mb3: “阉割”过的utf8，使用1-3字节表示字符；\n * utf8ub4: 正宗的utf8，使用1-4字节表示字符。\n\nmysql中的比较规则\n\n * utf8_general_ci: ci（case insensitive）不区分大小写。\n\n\n# 第4章 innodb记录存储结构\n\n页是innodb中磁盘和内存交互的基本单位，也是innodb管理存储空间的基本单位，默认大小为16kb。也就是说，一次从磁盘中读取内容到内存中是16kb，从内容写到磁盘，也是16kb。\n\ncompact行格式（额外信息，真实数据）\n\n      变长字段长度列表   null值列表   记录头信息   列1的值   列2的值   ...   列n的值\n记录1   01 03 04   00                                    \n记录2   03 04      06                                    \n\n变长字段长度列表\n\n列名   存储内容     内容长度（十六进制）\nc1   'aaaa'   0x04\nc3   'bbb'    0x03\nc4   'd'      0x01\n\n那么就逆序存储变长字段的长度\n\nnull值列表\n\n如果一个表中有9个值允许为null的列，则这个记录的null值列表部分需要2个字节表示，这个数据中的每一位代表真实数据是否为null。\n\n如c3, c4位null，则值位0x110 也就是06。\n\n\n# 第5章 innodb数据页结构\n\n页是innodb管理存储空间的基本单位，一个页的大小一般是16kb。innodb为了不同的目的设计了多种不同类型的页，这里介绍存放记录的页，数据页（索引页）。\n\ninnodb数据页结构\n\n名称                   中文名             占用空间大小   简单描述\nfile header          文件头部            38字节     页的一些通用信息\npage header          页面头部            56字节     数据页专有的一些信息\ninfimum + supremum   页面中的最小记录和最大记录   26字节     两个虚拟的记录\nuser records         用户记录            不确定      用户存储的记录内容\nfree space           空闲空间            不确定      页中尚未使用的空间\npage directory       页目录             不确定      页中某些记录的相对位置\nfile trailer         文件尾部            8字节      校验页是否完整\n\n用户记录\n\n我们自己存储的数据一开始在free space部分，随后将这部分划分到user records中，当free space全部用完时，代表这个页使用完了。如果有新的记录插入，就需要去申请新的页了。\n\n上一章的行记录格式中的 记录头信息\n\n\n\n记录头信息\n\n名称             大小(比特〕   描述\n预留位 1          1        没有使用\n预留位 2          1        没有使用\ndeleted_flag   1        标记该记录是否被删除\nmin_rec_flag   1        b+ 树中每层非叶子节点中的 最小的目录项记录都会添加该标记\nn_owned        4        一个页面中的记录会被分成若干个组,每个组中有一个记录是\"带头大哥其余的记录都是\"小弟\"，\"带头大哥\"记录的\n                        n_owned值代表该组中所有的记录条数，\"小弟\"记录的 n_owned 值都为 0\nheap_no        13       表示当前记录在页面堆中的相对位置\nrecord_type    3        表示当前记录的类型 。0 表示普通记录，1 表示 b+ 树非叶节点的目录项记录 . 2 表示 infimum 记录 ，3\n                        表示 supremum 记录\nnext record    16       表示下一条记录的相对位置\n\n页目录\n\n\n\n要找主键值为x的记录，通过二分法确定该记录所在分组对应的槽，然后找到该槽所在分组中主键值最小的那条记录，然后通过记录的next_record属性遍历该槽所在的组中的各个记录。\n\n页面的头部\n\n存储数据页中的记录状态信息，比如数据页中已经存储了多少条记录、free space在页面中的地址偏移量、页目录中存储了多少个槽等。\n\n文件头部\n\n存放各种页的信息，比如这个页的编号是多少，上一页下一页是谁。\n\n文件尾部\n\n * 前4字节代表页的校验和，验证该页是否完整\n * 后4字节代表页面被最后修改时对应的lsn的后4字节\n\n总结\n\n每个记录的头信息中都有一个 next record 属性 ,从而可以 使页 中的 所有记录串联成一个单向链表.\n\nlnnodb 会把页中的记录划分为若干个组,每个组的最后一个记录的地址偏移量作为一个槽,存放在 page directory 中一个槽占用 2 字节.在一个页中根据主键查找记录是非常快的,分为两步.\n\n 1. 通过 二分法确定该记录所在分 组对应的槽,并找到该糟所在分组中主键值最小的那条记录。\n\n 2. 通过记录的 next record 属性遍历该槽所在的组中 的各个记录.每个数据页的 file header 部分 都有上 一个页和下一个页的编号,所以所有的数据页会组成一个双向链表。\n\n在将页从内存刷新到磁盘时 , 为了保证页的完整性 ,页首 和 **页尾 **都会存储页中数据的校验和，以及页面最 后修改时对应 的 lsn 值 (页尾只会存 储 lsn 值的后 4 字节) . 如果页首和页尾的校验和以及 lsn 值校验不成功 , 就说明刷新期间出现了问题。\n\n\n# 第6章 b+树索引\n\n各个数据页可以组成一个双向链表，数据页中每条记录会按照主键值从小到大组成一个单向链表。每个数据页会生成一个页目录，通过页目录二分法找到对应的槽，再去顺序遍历槽对应的分组中的记录。\n\n\n\n存放页目录的页，复用原来的数据页，所以记录中的记录头信息record_type，用来标记是用户记录还是目录项。存放页目录的页，中的记录只存放两个值，主键值与对应的页号。\n\n\n\n聚簇索引\n\n使用记录主键值的大小进行记录和页的排序\n\n 1. 页内的节点按照主键值大小排成一个单向链表，页内的节点分成若干个组，每组中最大主键值当成一个槽；\n 2. 存放页目录的页，根据主键值大小排成双向链表；\n 3. 存放用户记录的页，根据主键值大小排成双向链表；\n\nb+树的叶子节点存储的是完整的用户记录。\n\n二级索引\n\n存放页目录的页中的记录只存放多个值，主键值，索引值与对应的页号。叶子节点包含索引值与主键值，再生成一颗b+树，但叶子节点不包含完整记录，找到叶子节点对应的主键值，再到主键索引中查找完整记录，需要进行一次回表操作；\n\n联合索引\n\n存放页目录的页中的记录只存放多个值，主键值，n个索引值与对应的页号。\n\nmyisam中的索引，都是二级索引，其它类似。\n\n\n# 第7章 b+树索引的应用\n\n每个索引都对应一颗b+树。b+树分为好多层，最下边一层是叶子节点，其余是内节点。所有用户记录都存储在b+树的叶子结点，所有目录项记录都存储在内节点。\n\ninnodb存储引擎会自动为主键简历聚簇索引，聚簇索引的叶子节点包含完整的用户记录。但是建立的二级索引中的叶子节点只包含主键和索引列，若需要查找到非索引列，则需要拿到主键值，到聚簇索引中再查找一次，简称回表。\n\n聚簇索引和二级索引示意图\n\n\n\n\n\n扫描区间和边界条件分析\n\n索引在空间和时间上都会“拖后腿”\n\n * 空间上的代价\n\n每建立一个索引，都要为它建立一颗b+树。每一颗b+树的每一个节点都是一个数据页（一个节点中包含多条记录，还包含一些其它信息）。\n\n * 时间上的代价\n   \n   因为索引列的值是有序的关系，如果新插入的数据，有可能会造成页面分裂、页面回收、还要维护索引列中的排序关系。\n   \n   在执行查询语句前，首先要生成一个执行计划。mysql会分析使用不同索引执行查询所需要的成本，索引越多分析的时间越长。\n\n扫描区间和边界分析\n\n去翻书吧。\n\n更好的创建索引和使用索引\n\n 1. 只为用于搜索、排序或分组的列创建索引\n 2. 考虑索引列中不重复值的个数\n 3. 索引列的类型尽量小\n 4. 为列前缀建立索引，节省空间\n 5. 索引覆盖，只查询索引列，避免回表\n 6. 让索引列以列名的形式在搜索条件中单独出现\n\nselect * from single_table where key2 * 2 < 4;  #不适用索引，全表扫描\nselect * from single_table where key2  < 4/2;   \n\n\n 7. 新插入记录时主键大小对效率的影响，忽大忽小的插入可能会造成页面分裂\n\n\n# 第8章 数据的家\n\nmysql 服务器程序在启动时会到数据目录中加载数据,运行过程中产生的数据也会被存储到数据目录中系统变量也扭曲表明了数据目录的路径。\n\n每个数据库都对应着数据目录下的一个子目录，该子目录中包含一个名为 db.opt 的文件这个文件包含了该数据库的一些属性，比如该数据库的字符集和比较规则等。\n\n对于innodb 存储引擎来说 :\n\n * 如果使用系统表空间存储表中的数据,那么只会在该表所在数据库对应的子目录下创建一个名为\"表名 frm\" 的文件,表中的数据会存储在系统表空间对应的文件中；\n * 如果使用独立表空间存储表中的数据，那么会在该表所在数据库对应的子目录下创建一个名为\"表名.frm\"的文件和一个名为\"表名.idb\"的文件，表中的数据会存储这个\"表名.idb\"文件中。\n\n\n# 第9章 innodb的表空间\n\n\n# 第10章 单表访问方式\n\n\n# 第11章 连接的原理\n\n从本质上说，连接就是将多个表的数据查询出来依次匹配，组成一个结果集返回。如果没有过滤条件，产生的结果集那么就是笛卡尔积。\n\nmysql中分为内连接和外连接，内连接也就是取匹配中的交集，外连接就是，被驱动表中有没有数据匹配与驱动表匹配，都保留驱动表中的数据，内连接则不保存。\n\n嵌套循环连接算法是值驱动表只访问一次，对于每一条驱动表中的数据，都会访问一次被驱动表。因此设计了join buffer（连接缓冲区）存放于内存，把驱动表中查询出来的数据放到缓冲区中，然后对于查询被驱动表中的每一条数据，都与缓冲区中的数据进行匹配。这样，就假如缓冲区足够大，那么只需访问一次被驱动表。\n\n\n# 第12章 基于成本的优化\n\n\n# 成本\n\n * i/o成本：当查询表中的记录时，需要把数据或者索引加载到内存中，然后再进行操作。这个从磁盘到内存的加载过程损耗的时间成为i/o成本。\n * cpu成本：读取记录以及检测记录是否满足对应的搜索条件、对结果集进行排序等这些操作损耗的时间称为cpu成本。\n\n对于innodb存储引擎来说，读取一个页面花费的成本默认是1.0；读取以及检测一条记录是否符合搜索条件的成本默认是0.2。\n\n\n# 基于成本的优化步骤\n\n 1. 根据搜索条件，找出所有可能使用的索引\n 2. 计算全表扫描的代价\n 3. 计算使用不同索引执行查询的代价\n 4. 对比各种执行方案的代价，找出成本最低的那个方案\n\n\n# 基于索引统计数据的成本计算\n\n每张表都有一个对应的统计表，来记录这张表的信息。比如有个索引统计数据，index statistics，show index from 表名，统计索引列中的各种信息，有一个比较重要的信息，cardinality，表示该列中不重复值的数量。根据这个属性，可以计算出在某一列中一个值平均出现了多少次，大约重复次数等于函数初一cardinality值。\n\n\n# 连接查询的成本\n\n# 条件过滤\n\n因为在连接查询中，驱动表会被访问一次，被驱动表可能会被访问多次。所以，对于两表连接查询来说，它的查询成本由两部分构成：\n\n * 单词查询驱动表的成本\n * 多次查询被驱动表的成本\n\n驱动表的记录条数成为扇出（fanout），然后呢，就要计算扇出值。\n\n对于那些条件中没有使用的索引列的数据，完全靠猜测来计算符合条件的记录条数，对于有索引列，那么通过cardinality来猜测条数。\n\n# 两表连接的成本分析\n\n连接查询的总成本=单词访问驱动表的成本 + 驱动表的扇出值*单词访问被驱动表的成本\n\n所以也需要考虑最优的表连接顺序，优化的重点就是后面那个大头：\n\n * 尽量减少驱动表的扇出值\n * 访问被驱动表的成本要尽量底\n\n# 多表连接的成本分析\n\nn张表的连接方式就有n!种连接方式，通过一些启发式规则来分析多表连接的成本，比如\n\n * 提前结束某种连接顺序的成本评估\n * 防止无穷无尽地分析各种连接顺序的成本，只分析小于一定的连接表数量\n\n\n# 调节成本常数\n\n有两张表，engine_cost，server_cost\n\n在server层进行连接管理、查询缓存、语法解析、查询优化等操作；\n\n在存储引擎层执行具体的数据存取操作。\n\n\n# 第13章 innodb统计数据是如何收集的\n\n\n# 第14章 基于规则的优化\n\n\n# 一些简单的优化\n\n * 移除不必要的括号\n * 常量传递\n\na = 5 and b > a\n\n\na = 5 and b > 5\n\n\n * 等值传递\n\n * 移除没用的条件\n\n * 表达式计算\n\n * having字句和where字句的合并，如果没用出现sum、mac等聚集函数以及group by字句，优化器就把having字句和where字句合并\n\n\n# 常量表检测\n\n这两种查询话费的时间特别少\n\n * 查询的表中一条记录没有，或者只有一条记录（根据统计信息（但不准确））\n * 使用主键等值匹配或者唯一二级索引列等值匹配\n\n\n# 外连接消除\n\n在被驱动表中没有找到符合条件的记录，就会加入一条null值的记录到结果集中。如果在where条件中拒绝空值，这时候的查询结果是等价于内连接的，那么就可以将外连接转换为内连接。\n\n转为内连接的好处是，优化器可以评估不同连接顺序的成本，进而选出成本最低的那种连接顺序进行查询。\n\n\n# 子查询mysql执行过程\n\n# 不相关标量子查询\n\nselect * from s1 \n    where key1 = (select common_field from s2 where key3 = 'a' limit 1);\n\n\n * 先单独执行子查询select common_field from s2 where key3 = 'a' limit 1\n * 将上一步子查询的结果作为外层循环的条件\n\n# 相关标量子查询\n\nselect * from s1 where \n    key1 = (select common_field from s2 where s1.key3 = s2.key3 limit 1);\n\n\n * 从外循环取出一条记录\n * 获取上一步的记录所需的列，然后执行子查询\n * 如果符合条件，查出子查询的结果\n * 再将子查询的结果拼接到外层查询的where子句中\n\n# in子查询的优化\n\nselect * from s1 \n    where key1 in (select common_field from s2 where key3 = 'a');\n\n\n将in后面的子查询结果，写入到一个临时表中（物化表）materialized_table\n\n那么就相当于有两张表，就有一下两种考虑\n\n * 从原表s1的角度看待，先获取s1表中的一条记录，然后判断这条记录是否存在于物化表中。\n * 从物化表看待，先获取物化表中的值，然后判断s1表中是否有这个值的记录。\n\n也就是说，可以相当于是一个内连接，等价于\n\nselect s1.* from s1 inner join materialized_table on key1 = m_val;\n\n\n是内连接，那么优化器就会评估它们的连接顺序。\n\n# 将子查询转换为semi-join\n\n直接将子查询转换为连接。\n\n对于这样一个查询\n\nselect * from s1 \n    where key1 in (select common_field from s2 where key3 = 'a');\n\n\n尝试将其转换为连接\n\nselect s1.* from s1 inner join s2 \n    on s1.key1 = s2.common_field \n    where s2.key3 = 'a';\n\n\n这个查询的结果集是s1的记录，如果对于表s1的某条记录来说，s2表中有多条s1.key1=s2.common_field，那么s1的这条记录会加入多次到结果集中，这一种情况与原来的查询等价，原来的查询只关心是否存在记录满足s1.key1=s2.common_field二不关心具体有多少条记录与之匹配。\n\n半连接\n\n * table pullout（子查询中的表上拉）\n   \n   当子查询的查询列表是只有主键或者唯一索引列时\n   \n   select * from s1 \n       where key2 in (select key2 from s2 where key3 = 'a');\n   \n   \n   可以转换为\n   \n   select s1.* from s1 inner join s2 \n       on s1.key2 = s2.key2 \n       where s2.key3 = 'a';\n   \n   \n   因为唯一索引或主键不存在有多条记录与之匹配\n\n * duplicateweedout execution strategy （重复值消除）\n   \n   select * from s1 \n       where key1 in (select common_field from s2 where key3 = 'a');\n   \n   \n   可以创建一个临时表\n   \n   create table tmp (\n       id primary key\n   );\n   \n   \n   这样，如果要将s1的某条记录加入到结果集中，那先将该条记录的id插入到临时表中，如果插入成功，那可以将该条记录加入到结果集。\n\n半连接适用条件\n\nselect ... from outer_tables \n    where expr in (select ... from inner_tables ...) and ...\n\n\n如果in子查询不符合转换为semi-join的条件，那么查询优化器再二选一\n\n * 先将子查询物化之后再执行查询\n * 执行in to exists转换\n\nin to exists转换\n\nouter_expr in (select inner_expr from ... where subquery_where)\n\n\n转换为\n\nexists (select inner_expr from ... where subquery_where and outer_expr=inner_expr)\n\n\n转换为exists的好处是，子查询可能可以用上索引\n\n看到这里脑子嗡嗡的~\n\n\n# 第15章 explain详解\n\n一条查询语句在经过mysql的查询优化器后，会基于成本或规则进行优化，可以通explain来查看具体的执行计划。\n\n\n# 执行输出中各列\n\nmysql> explain select * from s1;\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | extra |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+\n|  1 | simple      | s1    | null       | all  | null          | null | null    | null | 9688 |   100.00 | null  |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+\n1 row in set, 1 warning (0.00 sec)\n\n\n# table\n\n无论查询语句中包含多少个表，最终都会对每个表进行单表查询\n\n# id\n\n一个大的查询可以拆分成多个select，每一个select对应一个id。\n\n对于连接查询因为是同一个select子句，所以查询的两个表是同一个id值。\n\nmysql> explain select * from s1 inner join s2;\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | extra                                 |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+\n|  1 | simple      | s1    | null       | all  | null          | null | null    | null | 9688 |   100.00 | null                                  |\n|  1 | simple      | s2    | null       | all  | null          | null | null    | null | 9954 |   100.00 | using join buffer (block nested loop) |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+\n2 rows in set, 1 warning (0.01 sec)\n\n\n对于联合查询或者子查询，则会分配多个唯一id值。\n\nmysql> explain select * from s1 where key1 in (select key1 from s2) or key3 = 'a';\n+----+-------------+-------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\n| id | select_type | table | partitions | type  | possible_keys | key      | key_len | ref  | rows | filtered | extra       |\n+----+-------------+-------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\n|  1 | primary     | s1    | null       | all   | idx_key3      | null     | null    | null | 9688 |   100.00 | using where |\n|  2 | subquery    | s2    | null       | index | idx_key1      | idx_key1 | 303     | null | 9954 |   100.00 | using index |\n+----+-------------+-------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\n2 rows in set, 1 warning (0.02 sec)\n\n\n# select_type\n\n一个大的select可以拆分成多个小select，对每一个`select分配角色。\n\n * simple\n\n不包含union或者子查询的查询都算作simple类型\n\nmysql> explain select * from s1;\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+\n| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | extra |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+\n|  1 | simple      | s1    | null       | all  | null          | null | null    | null | 9688 |   100.00 | null  |\n+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+\n1 row in set, 1 warning (0.00 sec)\n\n\n * private\n\n包含union，或者子查询的查询，其中最左边的表就是private\n\nmysql> explain select * from s1 union select * from s2;\n+----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+\n| id | select_type  | table      | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | extra           |\n+----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+\n|  1 | primary      | s1         | null       | all  | null          | null | null    | null | 9688 |   100.00 | null            |\n|  2 | union        | s2         | null       | all  | null          | null | null    | null | 9954 |   100.00 | null            |\n| null | union result | <union1,2> | null       | all  | null          | null | null    | null | null |     null | using temporary |\n+----+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+\n3 rows in set, 1 warning (0.00 sec)\n\n\n * union\n\n上边，除了最左边的s1，其它都是union\n\n * union result\n\n上边，需要将两个查询的结果集合并，这里就是存放到一个临时表中，并去重。\n\n * subquery\n\n包含子查询的查询，不能转为对应的semi-join，并且是不相关子查询\n\n * dependent subquery\n\n相关子查询\n\n * dependent union\n * derived\n\n派生表\n\nmysql> explain select * from (select key1, count(*) as c from s1 group by key1) as derived_s1 where c > 1;\n+----+-------------+------------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\n| id | select_type | table      | partitions | type  | possible_keys | key      | key_len | ref  | rows | filtered | extra       |\n+----+-------------+------------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\n|  1 | primary     | <derived2> | null       | all   | null          | null     | null    | null | 9688 |    33.33 | using where |\n|  2 | derived     | s1         | null       | index | idx_key1      | idx_key1 | 303     | null | 9688 |   100.00 | using index |\n+----+-------------+------------+------------+-------+---------------+----------+---------+------+------+----------+-------------+\n2 rows in set, 1 warning (0.00 sec)\n\n\n * materialized\n\n物化表\n\nmysql> explain select * from s1 where key1 in (select key1 from s2);\n+----+--------------+-------------+------------+--------+---------------+------------+---------+-------------------+------+----------+-------------+\n| id | select_type  | table       | partitions | type   | possible_keys | key        | key_len | ref               | rows | filtered | extra       |\n+----+--------------+-------------+------------+--------+---------------+------------+---------+-------------------+------+----------+-------------+\n|  1 | simple       | s1          | null       | all    | idx_key1      | null       | null    | null              | 9688 |   100.00 | using where |\n|  1 | simple       | <subquery2> | null       | eq_ref | <auto_key>    | <auto_key> | 303     | xiaohaizi.s1.key1 |    1 |   100.00 | null        |\n|  2 | materialized | s2          | null       | index  | idx_key1      | idx_key1   | 303     | null              | 9954 |   100.00 | using index |\n+----+--------------+-------------+------------+--------+---------------+------------+---------+-------------------+------+----------+-------------+\n3 rows in set, 1 warning (0.01 sec)\n\n\n# type\n\ntype              类型\nsystem            对于统计精确的引擎，表中仅含一条记录\nconst             单表访问，主键或者唯一二级索引列与等值匹配\neq_ref            连接查询，被驱动表通过主键或者唯一二级索引列与等值匹配\nref               普通的二级索引列与等值匹配\nfulltext          全文索引\nref_or_null       普通的二级索引列与等值匹配，包含null\nindex_merge       索引合并\nunique_subquery   连接查询，被驱动表使用eq_ref\nindex_subquery    连接查询，被驱动表使用ref\nrange             使用索引获取某些范围区间\nindex             需要扫描索引上的所有数据\nall               全表扫描\n\n# possible_keys和key\n\n可能使用到的索引，和实际用到的索引\n\n# key_len\n\n# ref\n\n使用索引列等值匹配去执行查询时，展示与什么进行等值匹配，与某个常数const，某一列，某个函数。\n\n# rows\n\n预计需要扫描的行数\n\n# filtered\n\n过滤条件后，还剩多少记录，1~100%。\n\n未完待续。。。\n\n\n# 第16章 optimizer trace的神奇功效\n\n\n# 第17章 innodb的buffer pool\n\n磁盘太慢，用内存作为缓存，不至于每次都访问磁盘。\n\nbuffer poll是向操作系统申请的连续内存，一个个的chunk组成，每个chunk由控制块和缓存页组成，控制块那肯定就是存放一些缓存页的信息，上一页，下一页，锁啥的。\n\n那在内存中弄了一个这样的玩意，那肯定就有这些问题\n\n咋知道缓存中是否加载了某一页，使用表空间号 + 页号作为key，缓存页作为value，建立哈希表。\n\n缓存中修改了页（脏页），加入到flush链表，等待时机刷入磁盘。\n\nbuffer poll满了怎么办，采用lru链表，lru链表分为young区和old区，新加入的数据，放到lru的old头，在间隔一定时间外访问，就会吧他送到young头。没有足够的空闲缓存页，首先淘汰old中的页。\n\n少于1g缓存数据，不建议搞多个buffer poll。\n\n\n# 第18章 事务\n\nacid，原子性，一致性，隔离性，持久性\n\n\n# 第19章 redo日志\n\n\n# 第20章 undo日志\n\n\n# 第21章 事务隔离级别和mvcc\n\n\n# 第22章 锁",charsets:{cjk:!0}},{title:"MySQL易忘点",frontmatter:{title:"MySQL易忘点",date:"2023-03-06T14:53:40.000Z",permalink:"/pages/c38f55/"},regularPath:"/01.Java/05.%E6%95%B0%E6%8D%AE%E5%BA%93/04.MySQL%E6%98%93%E5%BF%98%E7%82%B9.html",relativePath:"01.Java/05.数据库/04.MySQL易忘点.md",key:"v-611dc400",path:"/pages/c38f55/",headers:[{level:2,title:"GROUP BY",slug:"group-by",normalizedTitle:"group by",charIndex:2},{level:2,title:"JOIN",slug:"join",normalizedTitle:"join",charIndex:1033},{level:2,title:"UNION",slug:"union",normalizedTitle:"union",charIndex:2382}],headersStr:"GROUP BY JOIN UNION",content:"# GROUP BY\n\ngroup by语法可以根据给定数据列的每个成员对查询结果进行分组统计，最终得到一个分组汇总表。\n\nSELECT子句中的列名必须为分组列或列函数。列函数对于GROUP BY子句定义的每个组各返回一个结果。\n\n可应用限定条件进行分组，以便系统仅对满足条件的组返回结果。\n\nSELECT col_1, col_2, MAX(col_3) AS alis -- 分组后使用聚合函数作用与组内的数据\nFROM tab\nWHERE col_1 > 'xxx'\nGROUP BY col_1, col_2 -- 把列1，列2 看成一个整体，分组\nhaving col_1 > 'xxx' -- 在每一组中进行筛选\nORDER BY col_1, col_2\n\n\nTable: Employees\n\nROLE       NAME         BUILDING   YEARS_EMPLOYED\nEngineer   Becky A.     1e         4\nEngineer   Dan B.       1e         2\nEngineer   Sharon F.    1e         6\nEngineer   Dan M.       1e         4\nEngineer   Malcom S.    1e         1\nArtist     Tylar S.     2w         2\nArtist     Sherman D.   2w         8\nArtist     Jakob J.     2w         6\nArtist     Lillia A.    2w         7\nArtist     Brandon J.   2w         7\nManager    Scott K.     1e         9\nManager    Shirlee M.   1e         3\nManager    Daria O.     2w         6\n\n计算Engineer的总工作年限\n\nROLE       YEARS\nEngineer   17\n\nSELECT role, SUM(Years_employed) Years FROM employees\nGROUP BY role\nHAVING role='Engineer'\n\n\n\n# JOIN\n\nOrderItems表\n\nPROD_ID   ORDER_NUM\nBR01      a0001\nBR01      a0002\nBR02      a0003\nBR02      a0013\n\nOrders表\n\nORDER_NUM   CUST_ID   ORDER_DATE\na0001       cust10    2022-01-01 00:00:00\na0002       cust1     2022-01-01 00:01:00\na0003       cust1     2022-01-02 00:00:00\na0013       cust2     2022-01-01 00:20:00\n\n确定哪些订单（在 OrderItems 中）购买了 prod_id 为 \"BR01\" 的产品，然后从 Orders 表中返回每个产品对应的顾客 ID（cust_id）和订单日期（order_date），按订购日期对结果进行升序排序。\n\n结果\n\nCUST_ID   ORDER_DATE\ncust10    2022-01-01 00:00:00\ncust1     2022-01-01 00:01:00\n\nwhere\n\nselect cust_id, order_date\nfrom Orders o, OrderItems oi\nwhere prod_id = 'BR01' and o.order_num = oi.order_num\norder by order_date\n\n\n子查询\n\nselect cust_id, order_date from Orders\nwhere order_num in (\n  select order_num from OrderItems\n  where prod_id = 'BR01'\n)\norder by order_date;\n\n\n左连接\n\nselect cust_id,order_date\nfrom Orders o\nleft join OrderItems oi \non o.order_num = oi.order_num\nwhere prod_id = 'BR01'\norder by order_date;\n\n\n自然连接\n\nselect cust_id, order_date\nfrom Orders\nnatural join OrderItems\nwhere prod_id = 'BR01'\norder by  order_date;\n\n\n内连接\n\nselect cust_id, order_date\nfrom Orders o\ninner JOIN OrderItems oi\non o.order_num = oi.order_num and  prod_id = 'BR01'\norder by order_date;\n\n\n自然连接 using\n\nselect cust_id, order_date\nfrom Orders\njoin OrderItems using(order_num)\nwhere prod_id = 'BR01'\norder by order_date;\n\n\n\n# UNION\n\n * union--连接表，对行操作。\n * union--将两个表做行拼接，同时自动删除重复的行。\n * union all---将两个表做行拼接，保留重复的行\n\n表OrderItems包含订单产品信息，字段prod_id代表产品id、quantity代表产品数量\n\nPROD_ID   QUANTITY\na0001     105\na0002     100\na0002     200\na0013     1121\na0003     10\na0003     19\na0003     5\nBNBG      10002\n\n【问题】\n\n将两个 SELECT 语句结合起来，以便从 OrderItems表中检索产品 id（prod_id）和 quantity。其中，一个 SELECT 语句过滤数量为 100 的行，另一个 SELECT 语句过滤 id 以 BNBG 开头的产品，最后按产品 id 对结果进行升序排序。\n\n【示例结果】\n\n返回产品id prod_id和产品数量quantity\n\nPROD_ID   QUANTITY\na0002     100\nBNBG      10002\n\nselect prod_id, quantity\nfrom OrderItems\nwhere quantity=100\nunion \nselect prod_id, quantity\nfrom OrderItems\nwhere prod_id like 'BNBG%'\norder by prod_id\n",normalizedContent:"# group by\n\ngroup by语法可以根据给定数据列的每个成员对查询结果进行分组统计，最终得到一个分组汇总表。\n\nselect子句中的列名必须为分组列或列函数。列函数对于group by子句定义的每个组各返回一个结果。\n\n可应用限定条件进行分组，以便系统仅对满足条件的组返回结果。\n\nselect col_1, col_2, max(col_3) as alis -- 分组后使用聚合函数作用与组内的数据\nfrom tab\nwhere col_1 > 'xxx'\ngroup by col_1, col_2 -- 把列1，列2 看成一个整体，分组\nhaving col_1 > 'xxx' -- 在每一组中进行筛选\norder by col_1, col_2\n\n\ntable: employees\n\nrole       name         building   years_employed\nengineer   becky a.     1e         4\nengineer   dan b.       1e         2\nengineer   sharon f.    1e         6\nengineer   dan m.       1e         4\nengineer   malcom s.    1e         1\nartist     tylar s.     2w         2\nartist     sherman d.   2w         8\nartist     jakob j.     2w         6\nartist     lillia a.    2w         7\nartist     brandon j.   2w         7\nmanager    scott k.     1e         9\nmanager    shirlee m.   1e         3\nmanager    daria o.     2w         6\n\n计算engineer的总工作年限\n\nrole       years\nengineer   17\n\nselect role, sum(years_employed) years from employees\ngroup by role\nhaving role='engineer'\n\n\n\n# join\n\norderitems表\n\nprod_id   order_num\nbr01      a0001\nbr01      a0002\nbr02      a0003\nbr02      a0013\n\norders表\n\norder_num   cust_id   order_date\na0001       cust10    2022-01-01 00:00:00\na0002       cust1     2022-01-01 00:01:00\na0003       cust1     2022-01-02 00:00:00\na0013       cust2     2022-01-01 00:20:00\n\n确定哪些订单（在 orderitems 中）购买了 prod_id 为 \"br01\" 的产品，然后从 orders 表中返回每个产品对应的顾客 id（cust_id）和订单日期（order_date），按订购日期对结果进行升序排序。\n\n结果\n\ncust_id   order_date\ncust10    2022-01-01 00:00:00\ncust1     2022-01-01 00:01:00\n\nwhere\n\nselect cust_id, order_date\nfrom orders o, orderitems oi\nwhere prod_id = 'br01' and o.order_num = oi.order_num\norder by order_date\n\n\n子查询\n\nselect cust_id, order_date from orders\nwhere order_num in (\n  select order_num from orderitems\n  where prod_id = 'br01'\n)\norder by order_date;\n\n\n左连接\n\nselect cust_id,order_date\nfrom orders o\nleft join orderitems oi \non o.order_num = oi.order_num\nwhere prod_id = 'br01'\norder by order_date;\n\n\n自然连接\n\nselect cust_id, order_date\nfrom orders\nnatural join orderitems\nwhere prod_id = 'br01'\norder by  order_date;\n\n\n内连接\n\nselect cust_id, order_date\nfrom orders o\ninner join orderitems oi\non o.order_num = oi.order_num and  prod_id = 'br01'\norder by order_date;\n\n\n自然连接 using\n\nselect cust_id, order_date\nfrom orders\njoin orderitems using(order_num)\nwhere prod_id = 'br01'\norder by order_date;\n\n\n\n# union\n\n * union--连接表，对行操作。\n * union--将两个表做行拼接，同时自动删除重复的行。\n * union all---将两个表做行拼接，保留重复的行\n\n表orderitems包含订单产品信息，字段prod_id代表产品id、quantity代表产品数量\n\nprod_id   quantity\na0001     105\na0002     100\na0002     200\na0013     1121\na0003     10\na0003     19\na0003     5\nbnbg      10002\n\n【问题】\n\n将两个 select 语句结合起来，以便从 orderitems表中检索产品 id（prod_id）和 quantity。其中，一个 select 语句过滤数量为 100 的行，另一个 select 语句过滤 id 以 bnbg 开头的产品，最后按产品 id 对结果进行升序排序。\n\n【示例结果】\n\n返回产品id prod_id和产品数量quantity\n\nprod_id   quantity\na0002     100\nbnbg      10002\n\nselect prod_id, quantity\nfrom orderitems\nwhere quantity=100\nunion \nselect prod_id, quantity\nfrom orderitems\nwhere prod_id like 'bnbg%'\norder by prod_id\n",charsets:{cjk:!0}},{title:"锁",frontmatter:{title:"锁",date:"2023-05-28T17:35:15.000Z",permalink:"/pages/8d8ba3/"},regularPath:"/01.Java/05.%E6%95%B0%E6%8D%AE%E5%BA%93/07.MySQL%E9%94%81.html",relativePath:"01.Java/05.数据库/07.MySQL锁.md",key:"v-0d1fe552",path:"/pages/8d8ba3/",headers:[{level:2,title:"全局锁",slug:"全局锁",normalizedTitle:"全局锁",charIndex:25},{level:2,title:"表锁",slug:"表锁",normalizedTitle:"表锁",charIndex:95},{level:2,title:"行锁",slug:"行锁",normalizedTitle:"行锁",charIndex:513},{level:3,title:"Gap Locks：",slug:"gap-locks",normalizedTitle:"gap locks：",charIndex:553},{level:3,title:"Next-Key Locks：",slug:"next-key-locks",normalizedTitle:"next-key locks：",charIndex:694},{level:3,title:"插入意向锁：",slug:"插入意向锁",normalizedTitle:"插入意向锁：",charIndex:729},{level:3,title:"隐式锁",slug:"隐式锁",normalizedTitle:"隐式锁",charIndex:794}],headersStr:"全局锁 表锁 行锁 Gap Locks： Next-Key Locks： 插入意向锁： 隐式锁",content:"锁，固然是用来解决并发事务出现的问题的。\n\n\n# 全局锁\n\n同时需要备份多个表的数据，仅仅锁一张表是不够的，但是又比较鸡肋。\n\n数据库备份，采用Read View方式进行备份即可。\n\n\n# 表锁\n\n也就是正常理解的写锁和读锁，如果某事务要对表获取读锁，那就得确保该表中所有的记录都没有写锁。加表锁之前先遍历一遍表中的记录？遍历是不可能遍历的，这辈子都不可能遍历。\n\n意向锁\n\n所以这样设计，事务想对某条记录上加锁时，先在表上加个意向锁。加意向锁并不关心这表先前有没有加过意向锁。释放记录上的锁时，同时释放自己加在表上的意向锁。\n\n这样新事务来想对表加锁，那么判断这表上有没有意向锁，如果有相应的意向锁，那么就会获取表锁失败，阻塞。\n\n----------------------------------------\n\nAUTO-INC自增锁\n\n对于自增的列，系统会自动赋值。\n\n * 采用AUTO-INC锁，执行插入语句时就在表上加一个AUTO-INC锁，分配自增的值，等执行完插入语句时把锁释放。\n * 有一个轻量级锁，在给插入SQL语句生成自增值后，遍释放锁，无需等插入语句执行完。一般用在已知要插入多少条记录。\n\n\n# 行锁\n\n每一行记录后，会附加一个锁结构信息，用来表示该记录中锁的信息。\n\n\n# Gap Locks：\n\n因为先前的MVCC方案和加锁方案均不能有效解决幻读现象。\n\n对于插入记录时，按照主键顺序，判断插入位置的下一条记录中是否有Gap锁，如果有，则加入失败。\n\n\n\n如果想在（20，正无穷）范围加Gap锁，那么，就在最后记录所在页的伪记录中加Gap锁\n\n\n\n\n# Next-Key Locks：\n\n普通的锁，和Gap锁结合体\n\n\n# 插入意向锁：\n\n他想规定事务在等待时候也在内存中生成一个锁结构，表明有事务想在某个间隙中插入新记录，但是现在在等待。\n\n\n\n\n# 隐式锁\n\n一般情况插入记录过程中不会加锁，所以插入记录过程，其它的事务可能想获取该记录写锁或读锁，会出现脏读或者脏写，那该怎么办？\n\n根据事务id，如果有事务想对某条记录加锁，先判断该记录上的trx_id，如果该trx_id代表的事务在活跃状态，那么就帮它创建一个锁结构，is_waiting是false，然后再给自己创建锁结构，is_waiting是true。",normalizedContent:"锁，固然是用来解决并发事务出现的问题的。\n\n\n# 全局锁\n\n同时需要备份多个表的数据，仅仅锁一张表是不够的，但是又比较鸡肋。\n\n数据库备份，采用read view方式进行备份即可。\n\n\n# 表锁\n\n也就是正常理解的写锁和读锁，如果某事务要对表获取读锁，那就得确保该表中所有的记录都没有写锁。加表锁之前先遍历一遍表中的记录？遍历是不可能遍历的，这辈子都不可能遍历。\n\n意向锁\n\n所以这样设计，事务想对某条记录上加锁时，先在表上加个意向锁。加意向锁并不关心这表先前有没有加过意向锁。释放记录上的锁时，同时释放自己加在表上的意向锁。\n\n这样新事务来想对表加锁，那么判断这表上有没有意向锁，如果有相应的意向锁，那么就会获取表锁失败，阻塞。\n\n----------------------------------------\n\nauto-inc自增锁\n\n对于自增的列，系统会自动赋值。\n\n * 采用auto-inc锁，执行插入语句时就在表上加一个auto-inc锁，分配自增的值，等执行完插入语句时把锁释放。\n * 有一个轻量级锁，在给插入sql语句生成自增值后，遍释放锁，无需等插入语句执行完。一般用在已知要插入多少条记录。\n\n\n# 行锁\n\n每一行记录后，会附加一个锁结构信息，用来表示该记录中锁的信息。\n\n\n# gap locks：\n\n因为先前的mvcc方案和加锁方案均不能有效解决幻读现象。\n\n对于插入记录时，按照主键顺序，判断插入位置的下一条记录中是否有gap锁，如果有，则加入失败。\n\n\n\n如果想在（20，正无穷）范围加gap锁，那么，就在最后记录所在页的伪记录中加gap锁\n\n\n\n\n# next-key locks：\n\n普通的锁，和gap锁结合体\n\n\n# 插入意向锁：\n\n他想规定事务在等待时候也在内存中生成一个锁结构，表明有事务想在某个间隙中插入新记录，但是现在在等待。\n\n\n\n\n# 隐式锁\n\n一般情况插入记录过程中不会加锁，所以插入记录过程，其它的事务可能想获取该记录写锁或读锁，会出现脏读或者脏写，那该怎么办？\n\n根据事务id，如果有事务想对某条记录加锁，先判断该记录上的trx_id，如果该trx_id代表的事务在活跃状态，那么就帮它创建一个锁结构，is_waiting是false，然后再给自己创建锁结构，is_waiting是true。",charsets:{cjk:!0}},{title:"在Ubuntu上统计软件使用时长",frontmatter:{title:"在Ubuntu上统计软件使用时长",date:"2023-05-25T16:26:13.000Z",permalink:"/pages/361d44/"},regularPath:"/01.Java/06.%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/01.statistics.html",relativePath:"01.Java/06.项目记录/01.statistics.md",key:"v-33c9c057",path:"/pages/361d44/",headers:[{level:2,title:"2023/6/21 日志",slug:"_2023-6-21-日志",normalizedTitle:"2023/6/21 日志",charIndex:2},{level:2,title:"2023/6/16 日志",slug:"_2023-6-16-日志",normalizedTitle:"2023/6/16 日志",charIndex:21},{level:3,title:"使用本地缓存",slug:"使用本地缓存",normalizedTitle:"使用本地缓存",charIndex:143},{level:2,title:"2023/6/12 更新",slug:"_2023-6-12-更新",normalizedTitle:"2023/6/12 更新",charIndex:1829},{level:2,title:"项目架构",slug:"项目架构",normalizedTitle:"项目架构",charIndex:1947},{level:2,title:"展示",slug:"展示",normalizedTitle:"展示",charIndex:2033},{level:2,title:"MySQL表结构",slug:"mysql表结构",normalizedTitle:"mysql表结构",charIndex:2044},{level:2,title:"查询",slug:"查询",normalizedTitle:"查询",charIndex:41},{level:2,title:"优化查询",slug:"优化查询",normalizedTitle:"优化查询",charIndex:3134}],headersStr:"2023/6/21 日志 2023/6/16 日志 使用本地缓存 2023/6/12 更新 项目架构 展示 MySQL表结构 查询 优化查询",content:'# 2023/6/21 日志\n\n\n\n\n# 2023/6/16 日志\n\n优化了数据库查询性能，从原来的全表扫描，到都用上了索引。\n\n单个接口性能 20 QPS ---\x3e 400 QPS\n\n使用caffeine后缓存后\n\n单个接口性能 400 QPS ---\x3e 6000 QPS。\n\n\n# 使用本地缓存\n\n接口                                   返回数据\ngetSevenTimes/2023-06-15             总的运行时间\ngetAppRunningTimeOneDay/2023-06-15   app的运行时间\ngetRunningTimeByHour/2023-06-15      各个小时的运行时间\n\n这里都有重叠的地方，不需要都建立缓存。保存每个app每个小时的运行时间。\n\napp的个数，我不超过10个，按10个算。按一天休息8小时，最多有16个小时是运行了电脑，要保存每个app每个小时的运行时间即可，一天的数据量是160，每个数据是app名称（假设31字节），时间（1字节），一个数据32字节，一天数据5.12KB，一年的数据不到2MB。\n\n// 8点，app1运行120秒\nappHoursCache = {\n    "date1": {\n        "hour1": {{"app1": 120}, {"app2", 350}, {"app3", 23}},\n        "hour2": {{"app1": 120}, {"app2", 350}, {"app3", 23}}\n    } \n    "date2": {\n        "hour1": {{"app1": 120}, {"app2", 350}, {"app3", 23}},\n        "hour2": {{"app1": 120}, {"app2", 350}, {"app3", 23}}\n    } \n}\n\n\n接口                                           返回数据\ngetVscodeRunningTime/2023-06-08_2023-06-15   返回VScode的各个项目运行时间\ngetIdeaRunningTime/2023-06-08_2023-06-15     返回Idea各个项目的运行时间\ngetChromeTime/2023-06-08_2023-06-15          返回Chrome各个网址的浏览时间\n\n这三个数据都没有重叠的地方，需要分别建立缓存。\n\n分别保存每一天各个项目的运行时间，或者各个网址。\n\n对于当天的缓存数据每十分钟更新一次，凡是过去，皆为序章，对于过往的缓存数据不作处理。\n\nvsCodeCache = {\n    "date1": {"project1": "time1", "project2": "time2"},\n    "date2": {"project1": "time1", "project2": "time2"},\n    ...\n}\n    \nideaCache = {\n    date1: {"project1": "time1", "project2": "time2"},\n    date2: {"project1": "time1", "project2": "time2"},\n    ...\n}\n\n\ntitles = {\n    "date1": ["title1", "title2", "title3",...],\n    "date2": ["title1", "title2", "title3",...],\n    ...\n}\n\nchromeTitleToUrl = {\n    "title1": "url1",\n    "title2": "url1",\n    "title3": "url4",\n    ...\n}\t\t\n\n\n更新当日缓存\n\n每1分钟更新当日数据。线程池，定时任务\n\n更新最新数据（待完成）\n\n使用netty监听Python端发送过来的数据，将其汇总，每隔一段时间使用消息队列发布消息，消费者拿到消息后，存到MySQL，和添加到缓存。\n\n当缓存中没数据，所有请求都会访问MySQL\n\n加锁，只让一个请求去写入缓存\n\n\n# 2023/6/12 更新\n\n使用Chrome api来获取网站的图标\n\nhttps://www.google.com/s2/favicons?domain=google.com\n\n读取Chrome浏览器的History文件\n\n\n\n\n# 项目架构\n\n\n\nPython发送数据格式\n\n * xid X11窗口id\n * title 窗口标题\n * app 激活窗口的软件名称\n * time 激活时间戳\n\n\n# 展示\n\n\n\n\n\n\n# MySQL表结构\n\nCREATE TABLE statistics_time\n(\n    id           INT PRIMARY KEY AUTO_INCREMENT,\n    app          VARCHAR(255) NOT NULL,\n    title        VARCHAR(255),\n    start_time   INT          NOT NULL,\n    end_time     INT          NOT NULL,\n    running_time INT\n);\n\n\n\n# 查询\n\n这种查询方式虽然简单，但是对于数据库而言，查询语句均为All，全表扫描。\n\n查询范围天的运行时间\n\nSELECT DATE(DATE_FORMAT(FROM_UNIXTIME(start_time), \'%Y-%m-%d\')) AS time_hour,\n       SUM(running_time)                                        AS total_running_time\nFROM statistics_time\nWHERE DATE(DATE_FORMAT(FROM_UNIXTIME(start_time), \'%Y-%m-%d\')) >= \'2023-04-25\'\n  AND DATE(DATE_FORMAT(FROM_UNIXTIME(start_time), \'%Y-%m-%d\')) <= \'2023-04-27\'\nGROUP BY time_hour;\n\n\n查询范围天的各app运行时间\n\nSELECT DATE(DATE_FORMAT(FROM_UNIXTIME(start_time), \'%Y-%m-%d\')) AS time_hour,\n       app,\n       SUM(running_time)                                        AS total_running_time\nFROM statistics_time\nWHERE DATE(DATE_FORMAT(FROM_UNIXTIME(start_time), \'%Y-%m-%d\')) >= \'2023-04-25\'\n  AND DATE(DATE_FORMAT(FROM_UNIXTIME(start_time), \'%Y-%m-%d\')) <= \'2023-04-27\'\nGROUP BY time_hour, app;\n\n\n\n# 优化查询\n\n在业务层进行一下数据处理，仅根据时间戳进行查询，不进行日期格式转换，执行的单表查询类型为range。\n\n查询范围时间内总的运行时间\n\nSELECT running_time as total_running_time\nFROM statistics_time\nWHERE start_time >= 1685004118\n  AND end_time <= 1685011373;\n\n\n查询范围天的各app运行时间\n\nSELECT app, sum(running_time) as total_running_time\nFROM statistics_time\nWHERE start_time >= 1685000118\n  AND end_time <= 1685011373\ngroup by app;\n',normalizedContent:'# 2023/6/21 日志\n\n\n\n\n# 2023/6/16 日志\n\n优化了数据库查询性能，从原来的全表扫描，到都用上了索引。\n\n单个接口性能 20 qps ---\x3e 400 qps\n\n使用caffeine后缓存后\n\n单个接口性能 400 qps ---\x3e 6000 qps。\n\n\n# 使用本地缓存\n\n接口                                   返回数据\ngetseventimes/2023-06-15             总的运行时间\ngetapprunningtimeoneday/2023-06-15   app的运行时间\ngetrunningtimebyhour/2023-06-15      各个小时的运行时间\n\n这里都有重叠的地方，不需要都建立缓存。保存每个app每个小时的运行时间。\n\napp的个数，我不超过10个，按10个算。按一天休息8小时，最多有16个小时是运行了电脑，要保存每个app每个小时的运行时间即可，一天的数据量是160，每个数据是app名称（假设31字节），时间（1字节），一个数据32字节，一天数据5.12kb，一年的数据不到2mb。\n\n// 8点，app1运行120秒\napphourscache = {\n    "date1": {\n        "hour1": {{"app1": 120}, {"app2", 350}, {"app3", 23}},\n        "hour2": {{"app1": 120}, {"app2", 350}, {"app3", 23}}\n    } \n    "date2": {\n        "hour1": {{"app1": 120}, {"app2", 350}, {"app3", 23}},\n        "hour2": {{"app1": 120}, {"app2", 350}, {"app3", 23}}\n    } \n}\n\n\n接口                                           返回数据\ngetvscoderunningtime/2023-06-08_2023-06-15   返回vscode的各个项目运行时间\ngetidearunningtime/2023-06-08_2023-06-15     返回idea各个项目的运行时间\ngetchrometime/2023-06-08_2023-06-15          返回chrome各个网址的浏览时间\n\n这三个数据都没有重叠的地方，需要分别建立缓存。\n\n分别保存每一天各个项目的运行时间，或者各个网址。\n\n对于当天的缓存数据每十分钟更新一次，凡是过去，皆为序章，对于过往的缓存数据不作处理。\n\nvscodecache = {\n    "date1": {"project1": "time1", "project2": "time2"},\n    "date2": {"project1": "time1", "project2": "time2"},\n    ...\n}\n    \nideacache = {\n    date1: {"project1": "time1", "project2": "time2"},\n    date2: {"project1": "time1", "project2": "time2"},\n    ...\n}\n\n\ntitles = {\n    "date1": ["title1", "title2", "title3",...],\n    "date2": ["title1", "title2", "title3",...],\n    ...\n}\n\nchrometitletourl = {\n    "title1": "url1",\n    "title2": "url1",\n    "title3": "url4",\n    ...\n}\t\t\n\n\n更新当日缓存\n\n每1分钟更新当日数据。线程池，定时任务\n\n更新最新数据（待完成）\n\n使用netty监听python端发送过来的数据，将其汇总，每隔一段时间使用消息队列发布消息，消费者拿到消息后，存到mysql，和添加到缓存。\n\n当缓存中没数据，所有请求都会访问mysql\n\n加锁，只让一个请求去写入缓存\n\n\n# 2023/6/12 更新\n\n使用chrome api来获取网站的图标\n\nhttps://www.google.com/s2/favicons?domain=google.com\n\n读取chrome浏览器的history文件\n\n\n\n\n# 项目架构\n\n\n\npython发送数据格式\n\n * xid x11窗口id\n * title 窗口标题\n * app 激活窗口的软件名称\n * time 激活时间戳\n\n\n# 展示\n\n\n\n\n\n\n# mysql表结构\n\ncreate table statistics_time\n(\n    id           int primary key auto_increment,\n    app          varchar(255) not null,\n    title        varchar(255),\n    start_time   int          not null,\n    end_time     int          not null,\n    running_time int\n);\n\n\n\n# 查询\n\n这种查询方式虽然简单，但是对于数据库而言，查询语句均为all，全表扫描。\n\n查询范围天的运行时间\n\nselect date(date_format(from_unixtime(start_time), \'%y-%m-%d\')) as time_hour,\n       sum(running_time)                                        as total_running_time\nfrom statistics_time\nwhere date(date_format(from_unixtime(start_time), \'%y-%m-%d\')) >= \'2023-04-25\'\n  and date(date_format(from_unixtime(start_time), \'%y-%m-%d\')) <= \'2023-04-27\'\ngroup by time_hour;\n\n\n查询范围天的各app运行时间\n\nselect date(date_format(from_unixtime(start_time), \'%y-%m-%d\')) as time_hour,\n       app,\n       sum(running_time)                                        as total_running_time\nfrom statistics_time\nwhere date(date_format(from_unixtime(start_time), \'%y-%m-%d\')) >= \'2023-04-25\'\n  and date(date_format(from_unixtime(start_time), \'%y-%m-%d\')) <= \'2023-04-27\'\ngroup by time_hour, app;\n\n\n\n# 优化查询\n\n在业务层进行一下数据处理，仅根据时间戳进行查询，不进行日期格式转换，执行的单表查询类型为range。\n\n查询范围时间内总的运行时间\n\nselect running_time as total_running_time\nfrom statistics_time\nwhere start_time >= 1685004118\n  and end_time <= 1685011373;\n\n\n查询范围天的各app运行时间\n\nselect app, sum(running_time) as total_running_time\nfrom statistics_time\nwhere start_time >= 1685000118\n  and end_time <= 1685011373\ngroup by app;\n',charsets:{cjk:!0}},{title:"论坛",frontmatter:{title:"论坛",date:"2023-05-30T21:29:20.000Z",permalink:"/pages/b95b70/"},regularPath:"/01.Java/06.%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/10.nowcode.html",relativePath:"01.Java/06.项目记录/10.nowcode.md",key:"v-265e6c6a",path:"/pages/b95b70/",headers:[{level:2,title:"首页",slug:"首页",normalizedTitle:"首页",charIndex:2},{level:2,title:"帖子详情页",slug:"帖子详情页",normalizedTitle:"帖子详情页",charIndex:290},{level:2,title:"点赞、关注",slug:"点赞、关注",normalizedTitle:"点赞、关注",charIndex:692},{level:2,title:"定时任务",slug:"定时任务",normalizedTitle:"定时任务",charIndex:992},{level:2,title:"拦截器",slug:"拦截器",normalizedTitle:"拦截器",charIndex:1228},{level:3,title:"WebMvcConfigurer",slug:"webmvcconfigurer",normalizedTitle:"webmvcconfigurer",charIndex:1236},{level:3,title:"WebSecurityConfigurerAdapter",slug:"websecurityconfigureradapter",normalizedTitle:"websecurityconfigureradapter",charIndex:1343},{level:2,title:"扩展",slug:"扩展",normalizedTitle:"扩展",charIndex:1799}],headersStr:"首页 帖子详情页 点赞、关注 定时任务 拦截器 WebMvcConfigurer WebSecurityConfigurerAdapter 扩展",content:"# 首页\n\nCaffeine 缓存库来实现帖子列表的缓存。\n\n// 帖子列表缓存\nprivate LoadingCache<String, List<DiscussPost>> postListCache;\n\n// 帖子总数缓存\nprivate LoadingCache<Integer, Integer> postRowsCache;\n\n\n用法，在构造中的build指定加载器来加载缓存项。如果缓存不命中则调用加载器返回值\n\n对比Redis\n\ncaffeine是基于本地应用中的内存的，相比没有网络IO延迟\n\ncaffeine 可以作为一级缓存，Redis作为二级缓存\n\n\n# 帖子详情页\n\n传入帖子id\n\n帖子当前帖子信息，作者信息，点赞数量， 点赞状态，评论列表，评论中的回复列表。\n\n查询一个帖子，查询MySQL。\n\n查询帖子的作者，查询Redis --\x3e MySQL。\n\n查询该帖子的点赞数量，查询Redis。\n\n查询当前用户是否对该帖子点赞，查询Redis。\n\n查询这个帖子的评论，查询MySQL。\n\n查询这个评论的用户，查询Redis --\x3e MySQL。\n\n查询这个评论的点赞，查询Redis。\n\n查询当前用户是否对该评论点赞，查询Redis。\n\n查询这个评论的回复，查询MySQL。\n\n查询这个评论的回复的用户，查询Redis --\x3e MySQL。\n\n查询这个评论的回复的目标用户，查询Redis --\x3e MySQL。\n\n查询这个回复的点赞数量，查询Redis。\n\n查询当前用户是否对该回复点赞，查询Redis。\n\n查询这个帖子的回复数量，查询MySQL。\n\n\n# 点赞、关注\n\n操作Redis，没有将数据持久化存储到MySQL中。\n\n判断是否已经对该实体点赞（1.帖子，2.评论），开启Redis事务\n\n 1. \n\n从该帖子的点赞集合中移除当前用户id；\n\n获赞用户的值减一。\n\n 2. \n\n添加点赞信息；\n\n获赞用户的值加一。\n\n查询某个实体被点赞的数量，Redis\n\n判断当前用户是否对该实体点赞，用于显示（已赞，赞）。\n\n如果刚刚进行了点赞，那么触发点赞事件。\n\n消费点赞事件，对于评论，点赞，关注统一消费\n\n从事件中取出实体，写入message表，发送站内通知。\n\n获取用户关注了谁\n\n查询关注数，Redis；\n\n查询关注人，Redis set。\n\n\n# 定时任务\n\n对于发布帖子，点赞帖子，评论帖子，都将该帖子id存入到Redis post:score集合中。\n\n创建一个简单的quartz定时器，每五分钟执行一次。\n\n每次执行，将Redis post:score集合中取出来，重新计算帖子的分数，同时存入到数据库中，和elasticsearch中。（这里没有事务）\n\n与xxl-job相同，采用竞争数据库锁的方式，来保证一个任务只能有一个节点来执行。性能较差，后续也有改为分布式锁。\n\nxxl-job支持任务分片。\n\n\n# 拦截器\n\n\n# WebMvcConfigurer\n\n从cookie中取出登录凭证，查询凭证对应的用户id，Redis\n\n查询用户，Redis ---\x3e MySQL\n\n将用户存入SecurityContextHolder。\n\n\n# WebSecurityConfigurerAdapter\n\n这里配置哪些路径，需要哪些权限。\n\n如果身份认证失败，则执行commence()方法\n\n如果权限不够，则执行handle()方法。\n\n对于SecurityContextHolder，Spring Security中第二个过滤器会将其存入到HTTPSession中。\n\n第二个过滤器 SecurityContextPersistenceFilter\n\n 1. 当请求到来时，从HttpSession中获取SecurityContext并存入SecurityContextHolder中，这样在同一个请求的后续处理过程中，通过SecurityContextHolder获取数据\n\n 2. 当一个请求处理完毕时，从SecurityContextHolder中获取SecurityContext并存入HttpSession中，方便下一个请求到来时，再从HTTPSession中拿来使用，同时擦除SecurityContextHolder中的登录信息。\n\n\n# 扩展\n\n将点赞，关注行为持久化存储到MySQL。扩展业务，我觉得可以有两种方式，一种可以用AOP，面向切面来扩展，另一种直接写新的业务逻辑，在需要的地方直接调用。考虑到点赞、关注的消息需要存储到Redis，需要保持Redis、MySQL的数据一致性，采用最终一致性的策略，将增删改事件发布RabbitMQ消息，消费者去将数据存储到MySQL。所以客户看到的点赞消息，都是从Redis中存取的。如果异步策略失败，那就是RabbitMQ如何保证消息的可靠了。\n\n要扩展MySQL，新建点赞表（uid, entity_type, entity_id），好友表(uid, friend_id)，同时计算分数的话，也要需要查询帖子的点赞数，同时将帖子，也要存到Redis中，用",normalizedContent:"# 首页\n\ncaffeine 缓存库来实现帖子列表的缓存。\n\n// 帖子列表缓存\nprivate loadingcache<string, list<discusspost>> postlistcache;\n\n// 帖子总数缓存\nprivate loadingcache<integer, integer> postrowscache;\n\n\n用法，在构造中的build指定加载器来加载缓存项。如果缓存不命中则调用加载器返回值\n\n对比redis\n\ncaffeine是基于本地应用中的内存的，相比没有网络io延迟\n\ncaffeine 可以作为一级缓存，redis作为二级缓存\n\n\n# 帖子详情页\n\n传入帖子id\n\n帖子当前帖子信息，作者信息，点赞数量， 点赞状态，评论列表，评论中的回复列表。\n\n查询一个帖子，查询mysql。\n\n查询帖子的作者，查询redis --\x3e mysql。\n\n查询该帖子的点赞数量，查询redis。\n\n查询当前用户是否对该帖子点赞，查询redis。\n\n查询这个帖子的评论，查询mysql。\n\n查询这个评论的用户，查询redis --\x3e mysql。\n\n查询这个评论的点赞，查询redis。\n\n查询当前用户是否对该评论点赞，查询redis。\n\n查询这个评论的回复，查询mysql。\n\n查询这个评论的回复的用户，查询redis --\x3e mysql。\n\n查询这个评论的回复的目标用户，查询redis --\x3e mysql。\n\n查询这个回复的点赞数量，查询redis。\n\n查询当前用户是否对该回复点赞，查询redis。\n\n查询这个帖子的回复数量，查询mysql。\n\n\n# 点赞、关注\n\n操作redis，没有将数据持久化存储到mysql中。\n\n判断是否已经对该实体点赞（1.帖子，2.评论），开启redis事务\n\n 1. \n\n从该帖子的点赞集合中移除当前用户id；\n\n获赞用户的值减一。\n\n 2. \n\n添加点赞信息；\n\n获赞用户的值加一。\n\n查询某个实体被点赞的数量，redis\n\n判断当前用户是否对该实体点赞，用于显示（已赞，赞）。\n\n如果刚刚进行了点赞，那么触发点赞事件。\n\n消费点赞事件，对于评论，点赞，关注统一消费\n\n从事件中取出实体，写入message表，发送站内通知。\n\n获取用户关注了谁\n\n查询关注数，redis；\n\n查询关注人，redis set。\n\n\n# 定时任务\n\n对于发布帖子，点赞帖子，评论帖子，都将该帖子id存入到redis post:score集合中。\n\n创建一个简单的quartz定时器，每五分钟执行一次。\n\n每次执行，将redis post:score集合中取出来，重新计算帖子的分数，同时存入到数据库中，和elasticsearch中。（这里没有事务）\n\n与xxl-job相同，采用竞争数据库锁的方式，来保证一个任务只能有一个节点来执行。性能较差，后续也有改为分布式锁。\n\nxxl-job支持任务分片。\n\n\n# 拦截器\n\n\n# webmvcconfigurer\n\n从cookie中取出登录凭证，查询凭证对应的用户id，redis\n\n查询用户，redis ---\x3e mysql\n\n将用户存入securitycontextholder。\n\n\n# websecurityconfigureradapter\n\n这里配置哪些路径，需要哪些权限。\n\n如果身份认证失败，则执行commence()方法\n\n如果权限不够，则执行handle()方法。\n\n对于securitycontextholder，spring security中第二个过滤器会将其存入到httpsession中。\n\n第二个过滤器 securitycontextpersistencefilter\n\n 1. 当请求到来时，从httpsession中获取securitycontext并存入securitycontextholder中，这样在同一个请求的后续处理过程中，通过securitycontextholder获取数据\n\n 2. 当一个请求处理完毕时，从securitycontextholder中获取securitycontext并存入httpsession中，方便下一个请求到来时，再从httpsession中拿来使用，同时擦除securitycontextholder中的登录信息。\n\n\n# 扩展\n\n将点赞，关注行为持久化存储到mysql。扩展业务，我觉得可以有两种方式，一种可以用aop，面向切面来扩展，另一种直接写新的业务逻辑，在需要的地方直接调用。考虑到点赞、关注的消息需要存储到redis，需要保持redis、mysql的数据一致性，采用最终一致性的策略，将增删改事件发布rabbitmq消息，消费者去将数据存储到mysql。所以客户看到的点赞消息，都是从redis中存取的。如果异步策略失败，那就是rabbitmq如何保证消息的可靠了。\n\n要扩展mysql，新建点赞表（uid, entity_type, entity_id），好友表(uid, friend_id)，同时计算分数的话，也要需要查询帖子的点赞数，同时将帖子，也要存到redis中，用",charsets:{cjk:!0}},{title:"Spring Boot 自动装配",frontmatter:{title:"Spring Boot 自动装配",date:"2023-03-09T15:16:40.000Z",permalink:"/pages/071fc0/"},regularPath:"/01.Java/04.%E6%A1%86%E6%9E%B6/02.springboot.html",relativePath:"01.Java/04.框架/02.springboot.md",key:"v-b225d99c",path:"/pages/071fc0/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"自律社区",frontmatter:{title:"自律社区",date:"2023-07-12T16:29:20.000Z",permalink:"/pages/532cfb/"},regularPath:"/01.Java/06.%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/20.comunity.html",relativePath:"01.Java/06.项目记录/20.comunity.md",key:"v-585a6957",path:"/pages/532cfb/",headers:[{level:2,title:"后端设计",slug:"后端设计",normalizedTitle:"后端设计",charIndex:2},{level:2,title:"用户",slug:"用户",normalizedTitle:"用户",charIndex:13},{level:3,title:"登录",slug:"登录",normalizedTitle:"登录",charIndex:20},{level:3,title:"验证",slug:"验证",normalizedTitle:"验证",charIndex:89},{level:2,title:"自习室",slug:"自习室",normalizedTitle:"自习室",charIndex:684},{level:2,title:"留言版与点赞",slug:"留言版与点赞",normalizedTitle:"留言版与点赞",charIndex:924},{level:4,title:"方案一：",slug:"方案一",normalizedTitle:"方案一：",charIndex:1124},{level:4,title:"方案二",slug:"方案二",normalizedTitle:"方案二",charIndex:1698},{level:2,title:"表设计",slug:"表设计",normalizedTitle:"表设计",charIndex:1766}],headersStr:"后端设计 用户 登录 验证 自习室 留言版与点赞 方案一： 方案二 表设计",content:"# 后端设计\n\n\n\n\n# 用户\n\n\n# 登录\n\n采用Spring Security框架，JWT认证。需要配置令牌存储方式，配置用户名密码认证，标识哪些接口需要访问权限。\n\n\n# 验证\n\n重写UserDetailsService中的loadUserByUsername，该方法表示通过用户名从某个地方取出用户，与框架待验证的用户进行对比。验证成功后，将用户信息AuthenticationHolderContext存储到Session中。之后每次请求到来，可以从Session中取出Authentication用户信息。也可以从Jwt令牌中取出用户信息。\n\nJWT由三部分组成：\n\nHeader : 描述 JWT 的元数据，定义了生成签名的算法以及 Token 的类型。\n\nPayload : 用来存放实际需要传递的数据\n\nSignature（签名）：服务器通过 Payload、Header 和一个密钥(Secret)使用 Header 里面指定的签名算法（默认是 HMAC SHA256）生成。\n\n对于登录成功的用户，将限时JWT令牌发送给客户端，存储到客户端的cookie中，之后每次请求都带上该JWT令牌。服务器验证只需要验证无状态的JWT令牌即可，无需访问数据库。验证方式：\n\n将Header.Payload与服务器的秘钥进行加密，如果密文与令牌第三部分Signature相同，则认为该令牌合法。\n\n续签机制：\n\n登录后返回两个JWT令牌，请求中如果第一个令牌过期，则再次发送第二个令牌，如果没过期，则服务器返回一个新的令牌，否则要求客户端重新登录。\n\n\n# 自习室\n\n1.通过自习室ID，或者自习室名称，在页面进行查询对应的自习室。\n\n2.简单的一个根据索引，查询MySQL。\n\n3.加入自习室：每个用户至多加入一个自习室，只需要在用户与自习室的关系表中插入一条数据。\n\n4.退出自习室：如果是成员，那么只需要在用户与自习室的关系表中删除一条数据。如果是房主，那么就是解散该自习室，简单的一个事务，需要对在自习室表中删除该自习室，以及在用户与自习室的关系表中，移除这些成员。\n\n5.转让房主：只需要更改一下自习室表的创造者ID。\n\n\n# 留言版与点赞\n\n1.加入自习室后，可以进行留言。也可以对留言进行回复，对回复进行回复。\n\n2.对留言点赞，对回复点赞。点赞记录到点赞表中，可以判断某个用户是否点赞，进行对对应的留言或者回复增减赞的数量。个人认为点赞数量的显示不需要做到实时，所以不需要频繁更新数据库中的数据。首先将各个实体点赞的数量存储到Redis中，前端只操作的Redis数据，后端定时更新点赞表，与更新对应数据的点赞数量。\n\n# 方案一：\n\nRedis是单线程的，不会有线程安全问题。存储方案\n\nmessage:\n\tmessageId1: {userId1, userId2, userId3...}\n\tmessageId2: {userId4, userId2, userId6...}\n\t\nreply:\n\treplyId1: {userId1, userId2, userId3...}\n\treplyId2: {userId4, userId2, userId6...}\n\n\n\n后端定期拿到Redis的数据，清空。然后将这些userId去点赞表中查看，如果不存在，则点赞。如果存在，则判断status是点赞状态还是未点赞状态。根据状态，去更新对应的留言表或回复表的点赞数量。\n\n缺点：只维护了点赞的效率，每次请求，都需要从MySQL中查。\n\n将哪些留言放入缓存中？\n\n一些缓存策略\n\n::: Cache Aside 旁路缓存\n\n先更新数据库，再删除缓存\n\n:::\n\n::: Read/Write Through （读穿/写穿）\n\n用户只与缓存打交道，例如本地Caffeine缓存。\n\n:::\n\n::: Write Back (写回)\n\n对于修改的数据只存在缓存中，标记为脏。如果下次读缓存时，如果这个缓存是脏，那么就将它写回数据库，再将数据库的值存入缓存。\n\n:::\n\n# 方案二\n\n使用Hash存储，格式为点赞者::被点赞者 : 1 or 0，被点赞者: 被点赞数。定时任务将两者存储MySQL中。\n\n\n# 表设计\n\n             用户表        \nid                      主键索引\nusername     用户名        二级索引\npassword     密码         \nsalt         盐          \nstatus       用户状态       \nroom_id      加入的自习室id   二级索引\nlast_login   上次登录时间     \ncreat_time   创建时间       \n\n        签到表       \nid                \nuid     用户id      联合索引字段1\nyear    签到年       联合索引字段2\nmonth   签到月       联合索引字段3\nbit     这个月签到情况   \n\n              自习室表    \nid                    主键索引\ncreate_id     创建者     联合索引字段1\nname          自习室名称   联合索引字段2\ncreate_time   创建时间    \n\n              内容表     \nid                    主键索引\nuid           发表人     联合索引字段1\nroom_id       自习室     联合索引字段2\ncontent       发表内容    \nstatus        内容状态    \nlike_count    被点赞数量   \nscore         得分      \ncreate_time   发表时间    \n\n              站内通知表               \nid                                \nfrom_id       发送方                 点赞或关注发送方是系统\nto_id         接收方                 \ntype          通知类型（点赞，关注，评论，私信）   \ncontent       内容                  谁对什么点赞了。谁对什么评论了\nstatus        是否已读                \ncreate_time   发送时间                \n\n              用户点赞表    \nid                     \nuid           点赞人      联合索引字段1\ntarget_type   点赞类型     联合索引字段2\ntarget_id     被点赞的内容   联合索引字段3\ntarget_uid    被点赞人     \nstatus        是否点赞     \n\n              回复表             \nid                            \nuid           回复人             \ntype          对消息回复，对回复进行回复   联合索引字段1\ntarget_id     回复目标的id         联合索引字段2\ntarget_uid    被回复的人           \nlike_count    这条回复被点赞数量       \ncreate_time   回复时间            ",normalizedContent:"# 后端设计\n\n\n\n\n# 用户\n\n\n# 登录\n\n采用spring security框架，jwt认证。需要配置令牌存储方式，配置用户名密码认证，标识哪些接口需要访问权限。\n\n\n# 验证\n\n重写userdetailsservice中的loaduserbyusername，该方法表示通过用户名从某个地方取出用户，与框架待验证的用户进行对比。验证成功后，将用户信息authenticationholdercontext存储到session中。之后每次请求到来，可以从session中取出authentication用户信息。也可以从jwt令牌中取出用户信息。\n\njwt由三部分组成：\n\nheader : 描述 jwt 的元数据，定义了生成签名的算法以及 token 的类型。\n\npayload : 用来存放实际需要传递的数据\n\nsignature（签名）：服务器通过 payload、header 和一个密钥(secret)使用 header 里面指定的签名算法（默认是 hmac sha256）生成。\n\n对于登录成功的用户，将限时jwt令牌发送给客户端，存储到客户端的cookie中，之后每次请求都带上该jwt令牌。服务器验证只需要验证无状态的jwt令牌即可，无需访问数据库。验证方式：\n\n将header.payload与服务器的秘钥进行加密，如果密文与令牌第三部分signature相同，则认为该令牌合法。\n\n续签机制：\n\n登录后返回两个jwt令牌，请求中如果第一个令牌过期，则再次发送第二个令牌，如果没过期，则服务器返回一个新的令牌，否则要求客户端重新登录。\n\n\n# 自习室\n\n1.通过自习室id，或者自习室名称，在页面进行查询对应的自习室。\n\n2.简单的一个根据索引，查询mysql。\n\n3.加入自习室：每个用户至多加入一个自习室，只需要在用户与自习室的关系表中插入一条数据。\n\n4.退出自习室：如果是成员，那么只需要在用户与自习室的关系表中删除一条数据。如果是房主，那么就是解散该自习室，简单的一个事务，需要对在自习室表中删除该自习室，以及在用户与自习室的关系表中，移除这些成员。\n\n5.转让房主：只需要更改一下自习室表的创造者id。\n\n\n# 留言版与点赞\n\n1.加入自习室后，可以进行留言。也可以对留言进行回复，对回复进行回复。\n\n2.对留言点赞，对回复点赞。点赞记录到点赞表中，可以判断某个用户是否点赞，进行对对应的留言或者回复增减赞的数量。个人认为点赞数量的显示不需要做到实时，所以不需要频繁更新数据库中的数据。首先将各个实体点赞的数量存储到redis中，前端只操作的redis数据，后端定时更新点赞表，与更新对应数据的点赞数量。\n\n# 方案一：\n\nredis是单线程的，不会有线程安全问题。存储方案\n\nmessage:\n\tmessageid1: {userid1, userid2, userid3...}\n\tmessageid2: {userid4, userid2, userid6...}\n\t\nreply:\n\treplyid1: {userid1, userid2, userid3...}\n\treplyid2: {userid4, userid2, userid6...}\n\n\n\n后端定期拿到redis的数据，清空。然后将这些userid去点赞表中查看，如果不存在，则点赞。如果存在，则判断status是点赞状态还是未点赞状态。根据状态，去更新对应的留言表或回复表的点赞数量。\n\n缺点：只维护了点赞的效率，每次请求，都需要从mysql中查。\n\n将哪些留言放入缓存中？\n\n一些缓存策略\n\n::: cache aside 旁路缓存\n\n先更新数据库，再删除缓存\n\n:::\n\n::: read/write through （读穿/写穿）\n\n用户只与缓存打交道，例如本地caffeine缓存。\n\n:::\n\n::: write back (写回)\n\n对于修改的数据只存在缓存中，标记为脏。如果下次读缓存时，如果这个缓存是脏，那么就将它写回数据库，再将数据库的值存入缓存。\n\n:::\n\n# 方案二\n\n使用hash存储，格式为点赞者::被点赞者 : 1 or 0，被点赞者: 被点赞数。定时任务将两者存储mysql中。\n\n\n# 表设计\n\n             用户表        \nid                      主键索引\nusername     用户名        二级索引\npassword     密码         \nsalt         盐          \nstatus       用户状态       \nroom_id      加入的自习室id   二级索引\nlast_login   上次登录时间     \ncreat_time   创建时间       \n\n        签到表       \nid                \nuid     用户id      联合索引字段1\nyear    签到年       联合索引字段2\nmonth   签到月       联合索引字段3\nbit     这个月签到情况   \n\n              自习室表    \nid                    主键索引\ncreate_id     创建者     联合索引字段1\nname          自习室名称   联合索引字段2\ncreate_time   创建时间    \n\n              内容表     \nid                    主键索引\nuid           发表人     联合索引字段1\nroom_id       自习室     联合索引字段2\ncontent       发表内容    \nstatus        内容状态    \nlike_count    被点赞数量   \nscore         得分      \ncreate_time   发表时间    \n\n              站内通知表               \nid                                \nfrom_id       发送方                 点赞或关注发送方是系统\nto_id         接收方                 \ntype          通知类型（点赞，关注，评论，私信）   \ncontent       内容                  谁对什么点赞了。谁对什么评论了\nstatus        是否已读                \ncreate_time   发送时间                \n\n              用户点赞表    \nid                     \nuid           点赞人      联合索引字段1\ntarget_type   点赞类型     联合索引字段2\ntarget_id     被点赞的内容   联合索引字段3\ntarget_uid    被点赞人     \nstatus        是否点赞     \n\n              回复表             \nid                            \nuid           回复人             \ntype          对消息回复，对回复进行回复   联合索引字段1\ntarget_id     回复目标的id         联合索引字段2\ntarget_uid    被回复的人           \nlike_count    这条回复被点赞数量       \ncreate_time   回复时间            ",charsets:{cjk:!0}},{title:"分布式共识Raft算法",frontmatter:{title:"分布式共识Raft算法",date:"2023-07-12T16:31:27.000Z",permalink:"/pages/20b125/"},regularPath:"/01.Java/06.%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/30.raft.html",relativePath:"01.Java/06.项目记录/30.raft.md",key:"v-22135ad2",path:"/pages/20b125/",headers:[{level:2,title:"架构设计",slug:"架构设计",normalizedTitle:"架构设计",charIndex:2}],headersStr:"架构设计",content:"# 架构设计\n\n",normalizedContent:"# 架构设计\n\n",charsets:{cjk:!0}},{title:"Spring",frontmatter:{title:"Spring",date:"2023-06-03T11:32:09.000Z",permalink:"/pages/d76f3c/"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/12.framework.html",relativePath:"01.Java/99.秋招/12.framework.md",key:"v-897d32c4",path:"/pages/d76f3c/",headers:[{level:2,title:"单例Bean是线程安全",slug:"单例bean是线程安全",normalizedTitle:"单例bean是线程安全",charIndex:2},{level:2,title:"AOP",slug:"aop",normalizedTitle:"aop",charIndex:210},{level:2,title:"事务失效",slug:"事务失效",normalizedTitle:"事务失效",charIndex:436},{level:2,title:"Spring bean的生命周期",slug:"spring-bean的生命周期",normalizedTitle:"spring bean的生命周期",charIndex:662},{level:2,title:"循环依赖",slug:"循环依赖",normalizedTitle:"循环依赖",charIndex:875},{level:2,title:"构造方法循环依赖",slug:"构造方法循环依赖",normalizedTitle:"构造方法循环依赖",charIndex:1017},{level:2,title:"Spring MVC执行流程",slug:"spring-mvc执行流程",normalizedTitle:"spring mvc执行流程",charIndex:1105},{level:2,title:"Spring Boot自动配置",slug:"spring-boot自动配置",normalizedTitle:"spring boot自动配置",charIndex:1147},{level:2,title:"Spring 常见注解",slug:"spring-常见注解",normalizedTitle:"spring 常见注解",charIndex:1334},{level:2,title:"Spring MVC注解",slug:"spring-mvc注解",normalizedTitle:"spring mvc注解",charIndex:2021},{level:2,title:"Mybatis执行流程",slug:"mybatis执行流程",normalizedTitle:"mybatis执行流程",charIndex:2372},{level:2,title:"延迟加载",slug:"延迟加载",normalizedTitle:"延迟加载",charIndex:2390},{level:2,title:"缓存",slug:"缓存",normalizedTitle:"缓存",charIndex:293}],headersStr:"单例Bean是线程安全 AOP 事务失效 Spring bean的生命周期 循环依赖 构造方法循环依赖 Spring MVC执行流程 Spring Boot自动配置 Spring 常见注解 Spring MVC注解 Mybatis执行流程 延迟加载 缓存",content:'# 单例Bean是线程安全\n\nBean单例还是多例可以通过@Scope指定\n\nsingleton: bean在每个Spring IOC容器中只有一个实例；\n\nprototype：一个bean定义可以有多个实例。\n\nSpring 框架默认使用的单例Bean模式，不是线程安全的。但是一般Spring 中的bean都是无状态的对象，没有线程安全的问题。如果bean中定义了可修改的成员变量，是要考虑线程安全问题的。\n\n\n# AOP\n\n面向切面编程，一般用于将那些与业务无关的代码，公共的，将其抽取出来作为一个模块，这一个模块称为切面，可以将其嵌入到需要的地方。\n\n * 记录操作日志\n * 缓存处理\n * Spring 中内置的事务处理\n\n记录日志，定义切点（监控的范围，方法），对切点定义行为，使用前置通知方式方式，预先拦截一下方法的参数，获取需要记录的部分，然后保存到数据库。\n\n@Transaction 声明式事物，使用AOP将事务处理的功能编织到拦截的方法中\n\n\n# 事务失效\n\n * 异常捕获处理\n   \n   在try中出现异常，并在catch中处理了异常，就事务失效了。需要在catch中throw new RuntimeException(e)。\n\n * 抛出检查异常\n   \n   如果出现异常，只会回滚非检查异常。可以配置rollbackFor = Excetion.class，所有异常都回滚。\n\n * 非public方法\n   \n   spring为该方法创建代理，需要该方法是public的。\n\n\n# Spring bean的生命周期\n\nSpring在容器初始化过程中，会将xml配置的<bean>的信息封装成一个BeanDefinition对象，Spring根据BeanDefinition创建Bean对象，BeanDefinition有很多属性来描述Bean。\n\n * beanClassName\n * initMethodName\n * properryValues\n * scope\n * lazyInit\n\n\n\n\n# 循环依赖\n\n一级缓存，单利池，存放已经初始化完成的bean对象\n\n二级缓存，缓存声明周期还没进行完的bean对象\n\n三级缓存，缓存的是，ObjectFactory对象工厂，用来创建对象。\n\n二级缓存解决循环依赖\n\n\n\n三级缓存解决循环依赖\n\nA依赖B，B依赖A的代理对象\n\n\n\n\n# 构造方法循环依赖\n\npublic A(@Lazy B b){\n\tSystem.out.println("A的构造方法执行了...");\n\tthis.b = b;\n}\n\n\n\n# Spring MVC执行流程\n\n * 视图JSP\n * 前后端分离\n\n\n\n\n\n\n# Spring Boot自动配置\n\n@SpringBootApplication注解中有以下三个注解\n\n * @SpringBootConfiguration\n   \n   配置类，与Configuration相同\n\n * @EnableAutoConfiguration\n   \n   实现自动配置\n\n * @ComponentScan\n   \n   组件扫描\n\n\n\n\n# Spring 常见注解\n\n注解                                            说明\n@Component、@Controller、@Service、@Repository   使用在类上用于实例化Bean\n@Autowired                                    使用在字段上用于根据类型依赖注入\n@Qualifier                                    结合@Autowired一起使用用于根据名称进行依赖注入\n@Scope                                        标注Bean的作用范围\n@Configuration                                指定当前类是一个 Spring 配置类，当创建容器时会从该类上加载注解\n@ComponentScan                                用于指定 Spring 在初始化容器时要扫描的包\n@Bean                                         使用在方法上，标注将该方法的返回值存储到Spring容器中\n@Import                                       使用@Import导入的类会被Spring加载到IOC容器中\n@Aspect、@Before、@After、@Around、@Pointcut      用于切面编程（AOP）\n\n\n# Spring MVC注解\n\n@REQUESTMAPPING   用于映射请求路径，可以定义在类上和方法上。用于类上，则表示类中的所有的方法都是以该地址作为父路径\n@RequestBody      注解实现接收http请求的json数据，将json转换为java对象\n@RequestParam     指定请求参数的名称\n@PathViriable     从请求路径下中获取请求参数(/user/{id})，传递给方法的形式参数\n@ResponseBody     注解实现将controller方法返回对象转化为json对象响应给客户端\n@RequestHeader    获取指定的请求头数据\n@RestController   @Controller + @ResponseBody\n\n\n# Mybatis执行流程\n\n\n\n\n# 延迟加载\n\n\n\n查询用户的时候，把用户中的订单信息也查询出来，这是立即加载。\n\n查询用户时，仅查询用户表信息，当访问orderList时，再查询订单表，这是延迟加载。\n\n\n\n\n# 缓存\n\n * 本地缓存，PerppetualCache，是基于HashMap实现的。\n   * 一级缓存：作用域是session级别\n   * 二级缓存：作用域是namespace和mapper的作用域，不依赖与session\n\n注意事项\n\n * 当缓存的数据更新了，该作用域下所有select中的缓存将被clear\n * 缓存的数据需要实现Serializable接口\n * 只有会话提交后者关闭后，一级缓存中的数据才会转移到二级缓存中。',normalizedContent:'# 单例bean是线程安全\n\nbean单例还是多例可以通过@scope指定\n\nsingleton: bean在每个spring ioc容器中只有一个实例；\n\nprototype：一个bean定义可以有多个实例。\n\nspring 框架默认使用的单例bean模式，不是线程安全的。但是一般spring 中的bean都是无状态的对象，没有线程安全的问题。如果bean中定义了可修改的成员变量，是要考虑线程安全问题的。\n\n\n# aop\n\n面向切面编程，一般用于将那些与业务无关的代码，公共的，将其抽取出来作为一个模块，这一个模块称为切面，可以将其嵌入到需要的地方。\n\n * 记录操作日志\n * 缓存处理\n * spring 中内置的事务处理\n\n记录日志，定义切点（监控的范围，方法），对切点定义行为，使用前置通知方式方式，预先拦截一下方法的参数，获取需要记录的部分，然后保存到数据库。\n\n@transaction 声明式事物，使用aop将事务处理的功能编织到拦截的方法中\n\n\n# 事务失效\n\n * 异常捕获处理\n   \n   在try中出现异常，并在catch中处理了异常，就事务失效了。需要在catch中throw new runtimeexception(e)。\n\n * 抛出检查异常\n   \n   如果出现异常，只会回滚非检查异常。可以配置rollbackfor = excetion.class，所有异常都回滚。\n\n * 非public方法\n   \n   spring为该方法创建代理，需要该方法是public的。\n\n\n# spring bean的生命周期\n\nspring在容器初始化过程中，会将xml配置的<bean>的信息封装成一个beandefinition对象，spring根据beandefinition创建bean对象，beandefinition有很多属性来描述bean。\n\n * beanclassname\n * initmethodname\n * properryvalues\n * scope\n * lazyinit\n\n\n\n\n# 循环依赖\n\n一级缓存，单利池，存放已经初始化完成的bean对象\n\n二级缓存，缓存声明周期还没进行完的bean对象\n\n三级缓存，缓存的是，objectfactory对象工厂，用来创建对象。\n\n二级缓存解决循环依赖\n\n\n\n三级缓存解决循环依赖\n\na依赖b，b依赖a的代理对象\n\n\n\n\n# 构造方法循环依赖\n\npublic a(@lazy b b){\n\tsystem.out.println("a的构造方法执行了...");\n\tthis.b = b;\n}\n\n\n\n# spring mvc执行流程\n\n * 视图jsp\n * 前后端分离\n\n\n\n\n\n\n# spring boot自动配置\n\n@springbootapplication注解中有以下三个注解\n\n * @springbootconfiguration\n   \n   配置类，与configuration相同\n\n * @enableautoconfiguration\n   \n   实现自动配置\n\n * @componentscan\n   \n   组件扫描\n\n\n\n\n# spring 常见注解\n\n注解                                            说明\n@component、@controller、@service、@repository   使用在类上用于实例化bean\n@autowired                                    使用在字段上用于根据类型依赖注入\n@qualifier                                    结合@autowired一起使用用于根据名称进行依赖注入\n@scope                                        标注bean的作用范围\n@configuration                                指定当前类是一个 spring 配置类，当创建容器时会从该类上加载注解\n@componentscan                                用于指定 spring 在初始化容器时要扫描的包\n@bean                                         使用在方法上，标注将该方法的返回值存储到spring容器中\n@import                                       使用@import导入的类会被spring加载到ioc容器中\n@aspect、@before、@after、@around、@pointcut      用于切面编程（aop）\n\n\n# spring mvc注解\n\n@requestmapping   用于映射请求路径，可以定义在类上和方法上。用于类上，则表示类中的所有的方法都是以该地址作为父路径\n@requestbody      注解实现接收http请求的json数据，将json转换为java对象\n@requestparam     指定请求参数的名称\n@pathviriable     从请求路径下中获取请求参数(/user/{id})，传递给方法的形式参数\n@responsebody     注解实现将controller方法返回对象转化为json对象响应给客户端\n@requestheader    获取指定的请求头数据\n@restcontroller   @controller + @responsebody\n\n\n# mybatis执行流程\n\n\n\n\n# 延迟加载\n\n\n\n查询用户的时候，把用户中的订单信息也查询出来，这是立即加载。\n\n查询用户时，仅查询用户表信息，当访问orderlist时，再查询订单表，这是延迟加载。\n\n\n\n\n# 缓存\n\n * 本地缓存，perppetualcache，是基于hashmap实现的。\n   * 一级缓存：作用域是session级别\n   * 二级缓存：作用域是namespace和mapper的作用域，不依赖与session\n\n注意事项\n\n * 当缓存的数据更新了，该作用域下所有select中的缓存将被clear\n * 缓存的数据需要实现serializable接口\n * 只有会话提交后者关闭后，一级缓存中的数据才会转移到二级缓存中。',charsets:{cjk:!0}},{title:"番茄时间社区",frontmatter:{title:"番茄时间社区",date:"2023-03-04T16:41:41.000Z",permalink:"/pages/b3c8f6/"},regularPath:"/01.Java/06.%E9%A1%B9%E7%9B%AE%E8%AE%B0%E5%BD%95/40.doubao.html",relativePath:"01.Java/06.项目记录/40.doubao.md",key:"v-bf2e1f52",path:"/pages/b3c8f6/",headers:[{level:2,title:"展示",slug:"展示",normalizedTitle:"展示",charIndex:2},{level:2,title:"主要实现",slug:"主要实现",normalizedTitle:"主要实现",charIndex:42},{level:3,title:"发帖子",slug:"发帖子",normalizedTitle:"发帖子",charIndex:51},{level:3,title:"查帖子",slug:"查帖子",normalizedTitle:"查帖子",charIndex:1249},{level:3,title:"点赞/关注",slug:"点赞-关注",normalizedTitle:"点赞/关注",charIndex:1412},{level:3,title:"自习室",slug:"自习室",normalizedTitle:"自习室",charIndex:24},{level:3,title:"个人时间统计",slug:"个人时间统计",normalizedTitle:"个人时间统计",charIndex:1805}],headersStr:"展示 主要实现 发帖子 查帖子 点赞/关注 自习室 个人时间统计",content:"# 展示\n\n首页\n\n\n\n关注\n\n\n\n通知\n\n\n\n自习室\n\n\n\n个人主页\n\n\n\n\n# 主要实现\n\n\n# 发帖子\n\n\n\n对于粉丝不多的用户，发布一条帖子，写入帖子表，同时写入MQ。\n\n消费者异步推送到粉丝的收件箱表，后续粉丝查看关注的帖子时，从该收件箱表中取出帖子ID。写放大，后续考虑结合，结合读扩散方式。\n\ncreate table post\n(\n    id          varchar(20)               not null comment '主键',\n    title       varchar(255) default ''   not null comment '标题',\n    content     longtext                  null comment 'markdown内容',\n    user_id     varchar(20)               not null comment '作者ID',\n    comments    int          default 0    not null comment '评论统计',\n    collects    int          default 0    not null comment '收藏统计',\n    view        int          default 0    not null comment '浏览统计',\n    top         bit          default b'0' not null comment '是否置顶，1-是，0-否',\n    essence     bit          default b'0' not null comment '是否加精，1-是，0-否',\n    section_id  int          default 0    null comment '专栏ID',\n    create_time datetime                  not null comment '发布时间',\n    modify_time datetime                  null comment '修改时间',\n    like_number int          default 0    not null comment '被点赞数量',\n)\n    comment '帖子表' charset = utf8mb3\n                     row_format = DYNAMIC;\n\ncreate index create_time\n    on post (create_time);\n\ncreate index user_id\n    on post (user_id);\n\n\n\n\n收件箱表box类似\n\n\n# 查帖子\n\n\n\n采用Redis存储一些额外信息，采用Redis String的方式存储一些热点的帖子，以及点赞关系，帖子-标签为多对多关系，方便查询，使用正向和反向list存储。\n\npost_i: [tag1, tag2, ...]\ntag_i: [post1, post2, ...]\n\n\n标签表，以及帖子话题关系表\n\n\n# 点赞/关注\n\n\n\n采用异步的方式，写入MQ就算操作成功。\n\n对于高并发\n\n前面扩展可以多节点处理请求。\n\n后面扩展可以增加消费者，并且多线程消费。对于计数来说，可以统一更改。\n\n\n# 自习室\n\n\n\n暂时，相当于是一个全站的时长排行榜。\n\n将前端vue项目打包成Electron桌面程序后，可以采用Node.js提供的Python环境来执行Python脚本。当登录后，开始统计桌面窗口信息，与服务器建立Socket连接，将窗口信息发送到服务器。\n\n数据存储，采用InfluxDB，格式如下\n\nstatistic, running_time, app user_id, time\n\n排行榜信息，采用Redis中的Zset存储，set中值为userName，得分该user今天的运行时长\n\n排行榜定时任务每十分钟刷新一次，将InfluxDB中近十分钟数据取出来，更新Zset中的得分\n\n\n# 个人时间统计\n\n对于不同的数据，再代码中分割好不同的查询条件，进行多次查询。",normalizedContent:"# 展示\n\n首页\n\n\n\n关注\n\n\n\n通知\n\n\n\n自习室\n\n\n\n个人主页\n\n\n\n\n# 主要实现\n\n\n# 发帖子\n\n\n\n对于粉丝不多的用户，发布一条帖子，写入帖子表，同时写入mq。\n\n消费者异步推送到粉丝的收件箱表，后续粉丝查看关注的帖子时，从该收件箱表中取出帖子id。写放大，后续考虑结合，结合读扩散方式。\n\ncreate table post\n(\n    id          varchar(20)               not null comment '主键',\n    title       varchar(255) default ''   not null comment '标题',\n    content     longtext                  null comment 'markdown内容',\n    user_id     varchar(20)               not null comment '作者id',\n    comments    int          default 0    not null comment '评论统计',\n    collects    int          default 0    not null comment '收藏统计',\n    view        int          default 0    not null comment '浏览统计',\n    top         bit          default b'0' not null comment '是否置顶，1-是，0-否',\n    essence     bit          default b'0' not null comment '是否加精，1-是，0-否',\n    section_id  int          default 0    null comment '专栏id',\n    create_time datetime                  not null comment '发布时间',\n    modify_time datetime                  null comment '修改时间',\n    like_number int          default 0    not null comment '被点赞数量',\n)\n    comment '帖子表' charset = utf8mb3\n                     row_format = dynamic;\n\ncreate index create_time\n    on post (create_time);\n\ncreate index user_id\n    on post (user_id);\n\n\n\n\n收件箱表box类似\n\n\n# 查帖子\n\n\n\n采用redis存储一些额外信息，采用redis string的方式存储一些热点的帖子，以及点赞关系，帖子-标签为多对多关系，方便查询，使用正向和反向list存储。\n\npost_i: [tag1, tag2, ...]\ntag_i: [post1, post2, ...]\n\n\n标签表，以及帖子话题关系表\n\n\n# 点赞/关注\n\n\n\n采用异步的方式，写入mq就算操作成功。\n\n对于高并发\n\n前面扩展可以多节点处理请求。\n\n后面扩展可以增加消费者，并且多线程消费。对于计数来说，可以统一更改。\n\n\n# 自习室\n\n\n\n暂时，相当于是一个全站的时长排行榜。\n\n将前端vue项目打包成electron桌面程序后，可以采用node.js提供的python环境来执行python脚本。当登录后，开始统计桌面窗口信息，与服务器建立socket连接，将窗口信息发送到服务器。\n\n数据存储，采用influxdb，格式如下\n\nstatistic, running_time, app user_id, time\n\n排行榜信息，采用redis中的zset存储，set中值为username，得分该user今天的运行时长\n\n排行榜定时任务每十分钟刷新一次，将influxdb中近十分钟数据取出来，更新zset中的得分\n\n\n# 个人时间统计\n\n对于不同的数据，再代码中分割好不同的查询条件，进行多次查询。",charsets:{cjk:!0}},{title:"Redis",frontmatter:{title:"Redis",date:"2023-06-01T14:57:29.000Z",permalink:"/pages/729f52/"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/11.Redis.html",relativePath:"01.Java/99.秋招/11.Redis.md",key:"v-18836f34",path:"/pages/729f52/",headers:[{level:2,title:"缓存穿透",slug:"缓存穿透",normalizedTitle:"缓存穿透",charIndex:2},{level:2,title:"缓存击穿",slug:"缓存击穿",normalizedTitle:"缓存击穿",charIndex:283},{level:2,title:"缓存雪崩",slug:"缓存雪崩",normalizedTitle:"缓存雪崩",charIndex:557},{level:2,title:"双写一致",slug:"双写一致",normalizedTitle:"双写一致",charIndex:689},{level:2,title:"持久化",slug:"持久化",normalizedTitle:"持久化",charIndex:924},{level:2,title:"数据过期策略",slug:"数据过期策略",normalizedTitle:"数据过期策略",charIndex:1046},{level:2,title:"数据淘汰策略",slug:"数据淘汰策略",normalizedTitle:"数据淘汰策略",charIndex:1139},{level:2,title:"Redis分布式锁",slug:"redis分布式锁",normalizedTitle:"redis分布式锁",charIndex:1479},{level:2,title:"Redisson",slug:"redisson",normalizedTitle:"redisson",charIndex:1533},{level:2,title:"主从复制",slug:"主从复制",normalizedTitle:"主从复制",charIndex:1874},{level:2,title:"哨兵",slug:"哨兵",normalizedTitle:"哨兵",charIndex:625},{level:2,title:"集群脑裂",slug:"集群脑裂",normalizedTitle:"集群脑裂",charIndex:2195},{level:2,title:"分片集群",slug:"分片集群",normalizedTitle:"分片集群",charIndex:2352},{level:2,title:"Redis为什么快",slug:"redis为什么快",normalizedTitle:"redis为什么快",charIndex:2527},{level:2,title:"I/O多路复用",slug:"i-o多路复用",normalizedTitle:"i/o多路复用",charIndex:2571}],headersStr:"缓存穿透 缓存击穿 缓存雪崩 双写一致 持久化 数据过期策略 数据淘汰策略 Redis分布式锁 Redisson 主从复制 哨兵 集群脑裂 分片集群 Redis为什么快 I/O多路复用",content:"# 缓存穿透\n\n查询一个不存在的数据，MySQL查询不到数据，那也不会写入缓存中，就会导致每次都查询数据库。\n\n方案一： 缓存空数据\n\n把空的数据也存入到缓存中，问题是，当之后数据库有这个数据后，缓存中还是缓存的空，那么就脏读。因为不能一有新数据就往缓存中添加。\n\n方案二： 布隆过滤器\n\n缓存预热过程中，初始化布隆过滤器。对于一个查询，如果查询到布隆过滤器中有数据，那么才进行后面的过程，若布隆过滤器中不存在，则直接返回。布隆过滤器判断数据存在，不代表Redis中数据真的存在。若不存在，那真不存在。对于新添加到Redis中的值，同时添加到布隆过滤器中。\n\n\n# 缓存击穿\n\n给一个key设置了过期时间，当key过期时，有大量请求访问这个key。\n\n每一个请求来访问，都判断缓存中没有这个key，因为这时还没有一个线程请求结束。进而都进行访问数据库。\n\n**方案一：**互斥锁\n\n当某个线程想去访问数据库时，加互斥锁，然后查询数据库，把数据写入缓存。其它线程等待这个线程释放锁，然后去缓存中获取数据。\n\n**方案二：**逻辑过期\n\n把数据设置为不过期，如果查询缓存发现数据逻辑过期，那就获取互斥锁，新开一个线程去数据库把数据写入缓存（写完后新线程释放锁，锁传递？），当前线程就返回过期数据。如果其它线程\n\n\n# 缓存雪崩\n\n同一时间段有大量的key过期，或者Redis服务宕机。\n\n * 给不同的Key的TTL添加随机值\n * 利用Redis集群，哨兵模式，集群模式\n * 加降级和限流策略，Nginx，gateway\n * 加多级缓存，Guava、Caffeine\n\n\n# 双写一致\n\n当修改了数据库的数据，同时更新缓存。\n\n * 延迟双删\n\n删除缓存-》修改数据库-》删除缓存\n\n删除了一次缓存后，在中间过程有请求过来，又会重新写入缓存（脏数据），所以后面再删一次。最后一次删除时间不好把控\n\n * 读写锁\n\n当线程对某个数据获取到写锁，那么其它线程不能读写。\n\n当线程获取了某个数据的读锁，那么其它线程可以进行读。\n\n * 异步通知\n\n保证数据的最终一致性\n\n当有修改数据，写入数据库成功后，发布消息\n\n\n\n * Cannal\n\n\n\n\n# 持久化\n\n * bgsave\n\n开始时，主进程fork子进程，将内存的数据写入RDB文件到本地。\n\n当子进程执行写操作时，会将数据拷贝一份，执行写操作。\n\n * RDB\n\n数据快照文件\n\n * AOF\n\n记录Redis中每一个写命令。\n\n\n# 数据过期策略\n\n**惰性删除：**设置key过期后，不去管它，等查询到这个数据了，发现过期，再删掉。\n\n**定期删除：**每隔一段时间，对key进行检查，删除里面过期的key。\n\n\n# 数据淘汰策略\n\n * noeviction： 不淘汰任何key，但是内存满时不允许写入新数据，默认就是这种策略。\n * volatile-ttl： 对设置了TTL的key，比较key的剩余TTL值，TTL越小越先被淘汰\n * allkeys-random：对全体key ，随机进行淘汰。\n * volatile-random：对设置了TTL的key ，随机进行淘汰。\n * allkeys-lru： 对全体key，基于LRU算法进行淘汰\n * volatile-lru： 对设置了TTL的key，基于LRU算法进行淘汰\n * allkeys-lfu： 对全体key，基于LFU算法进行淘汰\n * volatile-lfu： 对设置了TTL的key，基于LFU算法进行淘汰\n\n\n# Redis分布式锁\n\n获取锁 SETNX key value EX 10\n\n释放锁 DEL key\n\n\n# Redisson\n\n某个业务通过setnx设置变量后，当服务挂了，那么就没有del 该变量，导致其它业务不能setnx，通过设置超时时间，又不够优雅。\n\n获取Redisson锁，其业务内Watch dog机制作为守护线程，定时为key自动续期。如果业务执行完毕，会删除这个key。如果业务中断了，那这个定时任务也不执行了，也就不会自动续期，到期后自动删除。\n\n**可重入：**锁结构上存的字段是获取锁的线程，在一个线程内是共享的，同时存储锁获取次数。\n\n存在主从数据一致性问题，在一个主节点上SETNX，这时主节点挂了，然后有新的主节点，这时其它应用也可以SETNX。\n\nRedLock：在多个实例上创建同一个锁，如果超过半数的实例上SETNX成功，那么客户端获取锁成功。\n\n\n# 主从复制\n\n搭建主从集群，实现读写分离\n\n\n\n全量同步：\n\n先判断主从是否是一个数据集，不是一个数据集，需要进行全量同步，主节点执行bgsave，生成RDB，发送RDB文件给从节点。\n\n增量同步：\n\n记录偏移量，随后的主从是进行增量同步，主节点将repl_baklog大于偏移量的部分的命令，发送给从节点。\n\n\n# 哨兵\n\n实现主从集群的自动故障恢复。\n\nSentinel会心跳检测节点是否活着，如果master故障了，会从slave中选一个作为master，并通知客户端发生集群故障转移。\n\n主观下线：某个Sentinel节点检测不到某个Redis实例。\n\n客观下线：超过指定数量的Sentinel节点检测不到某个Redis实例。\n\n\n# 集群脑裂\n\n主节点、从节点和Sentinel处于不同的网络分区，然后检测不到master，就选举了一个新的master。但实际上就存在了两个master。网络恢复后，老的主节点降为从节点，再从新的master同步数据，导致数据丢失。\n\n解决：减少一下从节点数量，缩短主从同步时间间隔。（没有从根本上解决）\n\n\n# 分片集群\n\n解决海量数据存储问题，高并发写的问题。\n\n * 集群中有多个master，每个master保存不同的数据\n * 每个master又有多个slave节点\n * master ping健康状态。\n\n分片集群有16384个哈希槽，每个key通过CRC16校验后对16384取模，决定存放在哪个槽，集群每个节点负责一部分hash槽。\n\n\n\n\n# Redis为什么快\n\n * 纯内存操作\n * 采用单线程，避免不必要的上下文切换\n * I/O多路复用\n\n\n# I/O多路复用\n\n\n\n对于某个客户端，调用阻塞select，内核监听Socket集合，任一一个socket数据就绪，将会唤起select。随后客户端调用对应的Socket的recvfrom方法获取数据。\n\nselect和poll只会通知用户进程有Socket就绪。\n\nepoll通知用户进程哪些Socket就绪。\n\n",normalizedContent:"# 缓存穿透\n\n查询一个不存在的数据，mysql查询不到数据，那也不会写入缓存中，就会导致每次都查询数据库。\n\n方案一： 缓存空数据\n\n把空的数据也存入到缓存中，问题是，当之后数据库有这个数据后，缓存中还是缓存的空，那么就脏读。因为不能一有新数据就往缓存中添加。\n\n方案二： 布隆过滤器\n\n缓存预热过程中，初始化布隆过滤器。对于一个查询，如果查询到布隆过滤器中有数据，那么才进行后面的过程，若布隆过滤器中不存在，则直接返回。布隆过滤器判断数据存在，不代表redis中数据真的存在。若不存在，那真不存在。对于新添加到redis中的值，同时添加到布隆过滤器中。\n\n\n# 缓存击穿\n\n给一个key设置了过期时间，当key过期时，有大量请求访问这个key。\n\n每一个请求来访问，都判断缓存中没有这个key，因为这时还没有一个线程请求结束。进而都进行访问数据库。\n\n**方案一：**互斥锁\n\n当某个线程想去访问数据库时，加互斥锁，然后查询数据库，把数据写入缓存。其它线程等待这个线程释放锁，然后去缓存中获取数据。\n\n**方案二：**逻辑过期\n\n把数据设置为不过期，如果查询缓存发现数据逻辑过期，那就获取互斥锁，新开一个线程去数据库把数据写入缓存（写完后新线程释放锁，锁传递？），当前线程就返回过期数据。如果其它线程\n\n\n# 缓存雪崩\n\n同一时间段有大量的key过期，或者redis服务宕机。\n\n * 给不同的key的ttl添加随机值\n * 利用redis集群，哨兵模式，集群模式\n * 加降级和限流策略，nginx，gateway\n * 加多级缓存，guava、caffeine\n\n\n# 双写一致\n\n当修改了数据库的数据，同时更新缓存。\n\n * 延迟双删\n\n删除缓存-》修改数据库-》删除缓存\n\n删除了一次缓存后，在中间过程有请求过来，又会重新写入缓存（脏数据），所以后面再删一次。最后一次删除时间不好把控\n\n * 读写锁\n\n当线程对某个数据获取到写锁，那么其它线程不能读写。\n\n当线程获取了某个数据的读锁，那么其它线程可以进行读。\n\n * 异步通知\n\n保证数据的最终一致性\n\n当有修改数据，写入数据库成功后，发布消息\n\n\n\n * cannal\n\n\n\n\n# 持久化\n\n * bgsave\n\n开始时，主进程fork子进程，将内存的数据写入rdb文件到本地。\n\n当子进程执行写操作时，会将数据拷贝一份，执行写操作。\n\n * rdb\n\n数据快照文件\n\n * aof\n\n记录redis中每一个写命令。\n\n\n# 数据过期策略\n\n**惰性删除：**设置key过期后，不去管它，等查询到这个数据了，发现过期，再删掉。\n\n**定期删除：**每隔一段时间，对key进行检查，删除里面过期的key。\n\n\n# 数据淘汰策略\n\n * noeviction： 不淘汰任何key，但是内存满时不允许写入新数据，默认就是这种策略。\n * volatile-ttl： 对设置了ttl的key，比较key的剩余ttl值，ttl越小越先被淘汰\n * allkeys-random：对全体key ，随机进行淘汰。\n * volatile-random：对设置了ttl的key ，随机进行淘汰。\n * allkeys-lru： 对全体key，基于lru算法进行淘汰\n * volatile-lru： 对设置了ttl的key，基于lru算法进行淘汰\n * allkeys-lfu： 对全体key，基于lfu算法进行淘汰\n * volatile-lfu： 对设置了ttl的key，基于lfu算法进行淘汰\n\n\n# redis分布式锁\n\n获取锁 setnx key value ex 10\n\n释放锁 del key\n\n\n# redisson\n\n某个业务通过setnx设置变量后，当服务挂了，那么就没有del 该变量，导致其它业务不能setnx，通过设置超时时间，又不够优雅。\n\n获取redisson锁，其业务内watch dog机制作为守护线程，定时为key自动续期。如果业务执行完毕，会删除这个key。如果业务中断了，那这个定时任务也不执行了，也就不会自动续期，到期后自动删除。\n\n**可重入：**锁结构上存的字段是获取锁的线程，在一个线程内是共享的，同时存储锁获取次数。\n\n存在主从数据一致性问题，在一个主节点上setnx，这时主节点挂了，然后有新的主节点，这时其它应用也可以setnx。\n\nredlock：在多个实例上创建同一个锁，如果超过半数的实例上setnx成功，那么客户端获取锁成功。\n\n\n# 主从复制\n\n搭建主从集群，实现读写分离\n\n\n\n全量同步：\n\n先判断主从是否是一个数据集，不是一个数据集，需要进行全量同步，主节点执行bgsave，生成rdb，发送rdb文件给从节点。\n\n增量同步：\n\n记录偏移量，随后的主从是进行增量同步，主节点将repl_baklog大于偏移量的部分的命令，发送给从节点。\n\n\n# 哨兵\n\n实现主从集群的自动故障恢复。\n\nsentinel会心跳检测节点是否活着，如果master故障了，会从slave中选一个作为master，并通知客户端发生集群故障转移。\n\n主观下线：某个sentinel节点检测不到某个redis实例。\n\n客观下线：超过指定数量的sentinel节点检测不到某个redis实例。\n\n\n# 集群脑裂\n\n主节点、从节点和sentinel处于不同的网络分区，然后检测不到master，就选举了一个新的master。但实际上就存在了两个master。网络恢复后，老的主节点降为从节点，再从新的master同步数据，导致数据丢失。\n\n解决：减少一下从节点数量，缩短主从同步时间间隔。（没有从根本上解决）\n\n\n# 分片集群\n\n解决海量数据存储问题，高并发写的问题。\n\n * 集群中有多个master，每个master保存不同的数据\n * 每个master又有多个slave节点\n * master ping健康状态。\n\n分片集群有16384个哈希槽，每个key通过crc16校验后对16384取模，决定存放在哪个槽，集群每个节点负责一部分hash槽。\n\n\n\n\n# redis为什么快\n\n * 纯内存操作\n * 采用单线程，避免不必要的上下文切换\n * i/o多路复用\n\n\n# i/o多路复用\n\n\n\n对于某个客户端，调用阻塞select，内核监听socket集合，任一一个socket数据就绪，将会唤起select。随后客户端调用对应的socket的recvfrom方法获取数据。\n\nselect和poll只会通知用户进程有socket就绪。\n\nepoll通知用户进程哪些socket就绪。\n\n",charsets:{cjk:!0}},{title:"微服务",frontmatter:{title:"微服务",date:"2023-06-04T14:00:01.000Z",permalink:"/pages/b0a322/"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/13.cloud.html",relativePath:"01.Java/99.秋招/13.cloud.md",key:"v-34050fae",path:"/pages/b0a322/",headers:[{level:2,title:"Spring Cloud组件",slug:"spring-cloud组件",normalizedTitle:"spring cloud组件",charIndex:2},{level:2,title:"Eureka",slug:"eureka",normalizedTitle:"eureka",charIndex:26},{level:2,title:"Ribbon",slug:"ribbon",normalizedTitle:"ribbon",charIndex:47},{level:2,title:"服务雪崩",slug:"服务雪崩",normalizedTitle:"服务雪崩",charIndex:464},{level:2,title:"监控",slug:"监控",normalizedTitle:"监控",charIndex:572},{level:2,title:"限流",slug:"限流",normalizedTitle:"限流",charIndex:484},{level:2,title:"CAP",slug:"cap",normalizedTitle:"cap",charIndex:780},{level:3,title:"seata",slug:"seata",normalizedTitle:"seata",charIndex:930},{level:3,title:"AT模式",slug:"at模式",normalizedTitle:"at模式",charIndex:948},{level:3,title:"TTC模式",slug:"ttc模式",normalizedTitle:"ttc模式",charIndex:959},{level:3,title:"MQ分布式事务",slug:"mq分布式事务",normalizedTitle:"mq分布式事务",charIndex:971},{level:2,title:"幂等",slug:"幂等",normalizedTitle:"幂等",charIndex:985},{level:2,title:"xxl-job",slug:"xxl-job",normalizedTitle:"xxl-job",charIndex:1205}],headersStr:"Spring Cloud组件 Eureka Ribbon 服务雪崩 监控 限流 CAP seata AT模式 TTC模式 MQ分布式事务 幂等 xxl-job",content:"# Spring Cloud组件\n\n * 注册中心：Eureka，Nacos\n * 负载均衡：Ribbon\n * 远程调用：Feign\n * 服务保护：sentinel\n * 网关：Zuul，Gateway\n\n\n# Eureka\n\n注册中心，服务需要去注册中心进行注册，那么注册中心便可以知道当前有什么服务，以及对应的地址是什么，并每30秒服务向注册中心发送消息，表示我还活着。服务消费者可以到注册中心寻找响应的服务提供者来远程调用。\n\n与Nacos区别\n\nNacos对于临时实例，采用心跳模式。对于非临时实例采用主动检测模式。\n\nNacos还支持配置中心。\n\n\n# Ribbon\n\n * RoundRobinRule：轮询服务列表来选择服务器\n * WeightedResponseTime：按照权重来选择服务器，响应时间越长，权重越小\n * RandomRule：随机选择一个可用的服务器\n * ZoneAvoidanceRule：以区域为基础进行服务器选择\n\n如果想自定义实现负载均衡策略，需要实现IRule接口\n\n\n# 服务雪崩\n\n\n\n * 熔断，降级\n * 限流\n\n服务降级，一种自我保护方式，确保服务不会受请求突增影响变得不可用\n\n\n\n服务熔断，如果一定时间内，降级次数过多，则会触发服务熔断，熔断后不再对这个节点进行访问\n\n\n# 监控\n\nskywalking，分布式系统的应用程序性能监控工具，提供完善的链路追踪功能。\n\n * 服务\n * 端点\n * 实例\n\n\n# 限流\n\n第一，并发的流量大，避免将服务器搞垮，影响可用性。第二防止用户恶意刷单刷接口。\n\n * Tomcat：可以设置最大连接数\n   \n   \n\n * Nginx：漏桶算法\n   \n   \n   \n   \n\n * 网关：令牌桶算法\n   \n   \n\n * 自定义拦截器\n\n\n# CAP\n\nCAP，分别是一致性，可用性，分区容错性，分布式系统无法同时满足这三个指标。\n\nBASE\n\n基本可用，有中间状态，但是保证最终一致性。\n\n最终一致性，各个分支事务分别执行提交，如果不一致再想办法恢复数据\n\n强一致性，各个分支事务执行完业务不要提交，等待彼此的结果，统一提交或回滚。\n\n\n# seata\n\nXA模式\n\n\n\n\n# AT模式\n\n\n\n\n# TTC模式\n\n\n\n\n# MQ分布式事务\n\n\n\n\n# 幂等\n\n多次调用同一接口不会改变业务状态，保证结果一致。\n\n * 用户重复点击\n * MQ消息重复\n * 应用使用失败或超时重试机制\n\n通过添加字段，若字段的值已经是目标值，则放弃更改。\n\n使用token+redis，对于新增和修改，在前一个页面，给客户端发放token，服务器将token存到redis中。若当前请求带有token，则是第一次访问，处理完后删除token。若是请求中没有带有token，说明这是重复的请求，忽略。\n\n\n# xxl-job\n\n解决集群中一些需要重复执行的任务，cron表达式定义灵活，并且支持任务分片。\n\n路由策略\n\nROUND，轮询\n\nSHARDING_BROADCAST，分片广播，广播集群中所有机器执行一次任务，同时系统自动传递分片参数，根据分片参数开发分片任务。\n\n任务执行失败\n\n查看日志分析，重试。\n\n大数据量任务\n\n",normalizedContent:"# spring cloud组件\n\n * 注册中心：eureka，nacos\n * 负载均衡：ribbon\n * 远程调用：feign\n * 服务保护：sentinel\n * 网关：zuul，gateway\n\n\n# eureka\n\n注册中心，服务需要去注册中心进行注册，那么注册中心便可以知道当前有什么服务，以及对应的地址是什么，并每30秒服务向注册中心发送消息，表示我还活着。服务消费者可以到注册中心寻找响应的服务提供者来远程调用。\n\n与nacos区别\n\nnacos对于临时实例，采用心跳模式。对于非临时实例采用主动检测模式。\n\nnacos还支持配置中心。\n\n\n# ribbon\n\n * roundrobinrule：轮询服务列表来选择服务器\n * weightedresponsetime：按照权重来选择服务器，响应时间越长，权重越小\n * randomrule：随机选择一个可用的服务器\n * zoneavoidancerule：以区域为基础进行服务器选择\n\n如果想自定义实现负载均衡策略，需要实现irule接口\n\n\n# 服务雪崩\n\n\n\n * 熔断，降级\n * 限流\n\n服务降级，一种自我保护方式，确保服务不会受请求突增影响变得不可用\n\n\n\n服务熔断，如果一定时间内，降级次数过多，则会触发服务熔断，熔断后不再对这个节点进行访问\n\n\n# 监控\n\nskywalking，分布式系统的应用程序性能监控工具，提供完善的链路追踪功能。\n\n * 服务\n * 端点\n * 实例\n\n\n# 限流\n\n第一，并发的流量大，避免将服务器搞垮，影响可用性。第二防止用户恶意刷单刷接口。\n\n * tomcat：可以设置最大连接数\n   \n   \n\n * nginx：漏桶算法\n   \n   \n   \n   \n\n * 网关：令牌桶算法\n   \n   \n\n * 自定义拦截器\n\n\n# cap\n\ncap，分别是一致性，可用性，分区容错性，分布式系统无法同时满足这三个指标。\n\nbase\n\n基本可用，有中间状态，但是保证最终一致性。\n\n最终一致性，各个分支事务分别执行提交，如果不一致再想办法恢复数据\n\n强一致性，各个分支事务执行完业务不要提交，等待彼此的结果，统一提交或回滚。\n\n\n# seata\n\nxa模式\n\n\n\n\n# at模式\n\n\n\n\n# ttc模式\n\n\n\n\n# mq分布式事务\n\n\n\n\n# 幂等\n\n多次调用同一接口不会改变业务状态，保证结果一致。\n\n * 用户重复点击\n * mq消息重复\n * 应用使用失败或超时重试机制\n\n通过添加字段，若字段的值已经是目标值，则放弃更改。\n\n使用token+redis，对于新增和修改，在前一个页面，给客户端发放token，服务器将token存到redis中。若当前请求带有token，则是第一次访问，处理完后删除token。若是请求中没有带有token，说明这是重复的请求，忽略。\n\n\n# xxl-job\n\n解决集群中一些需要重复执行的任务，cron表达式定义灵活，并且支持任务分片。\n\n路由策略\n\nround，轮询\n\nsharding_broadcast，分片广播，广播集群中所有机器执行一次任务，同时系统自动传递分片参数，根据分片参数开发分片任务。\n\n任务执行失败\n\n查看日志分析，重试。\n\n大数据量任务\n\n",charsets:{cjk:!0}},{title:"Java 虚拟机",frontmatter:{title:"Java 虚拟机",date:"2023-06-09T09:07:36.000Z",permalink:"/pages/f1bf72/"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/16.jvm.html",relativePath:"01.Java/99.秋招/16.jvm.md",key:"v-74f9cb10",path:"/pages/f1bf72/",headers:[{level:2,title:"运行流程",slug:"运行流程",normalizedTitle:"运行流程",charIndex:2},{level:2,title:"组件",slug:"组件",normalizedTitle:"组件",charIndex:13},{level:2,title:"类加载器",slug:"类加载器",normalizedTitle:"类加载器",charIndex:217},{level:2,title:"双亲委派",slug:"双亲委派",normalizedTitle:"双亲委派",charIndex:350},{level:2,title:"类装载",slug:"类装载",normalizedTitle:"类装载",charIndex:388},{level:2,title:"垃圾回收",slug:"垃圾回收",normalizedTitle:"垃圾回收",charIndex:398},{level:2,title:"强引用、软引用、弱引用、虚引用",slug:"强引用、软引用、弱引用、虚引用",normalizedTitle:"强引用、软引用、弱引用、虚引用",charIndex:511},{level:2,title:"JVM调优",slug:"jvm调优",normalizedTitle:"jvm调优",charIndex:864}],headersStr:"运行流程 组件 类加载器 双亲委派 类装载 垃圾回收 强引用、软引用、弱引用、虚引用 JVM调优",content:"# 运行流程\n\n\n\n\n# 组件\n\n          \n程序计数器     类似组成原理中pc寄存器，线程私有，记录运行的位置\n堆         线程共享，数组，对象。年轻代+老年代（Eden，幸存区）\n栈         每个线程一个栈，一个栈多个栈帧（方法）。存放方法内的局部变量，栈内存溢出（递归）。\n方法区、元空间   线程共享。Class，ClassLoader，运行时常量池\n直接内存      操作系统的内存\n\n\n# 类加载器\n\n将字节码文件加载到JVM中\n\n * 启动类加载器：加载JAVA_HOME/jre/lib目录下的库\n * 扩展类加载器：加载JAVA_HOME/jre/lib/ext目录中类\n * 应用类加载器：加载classPath下的类\n * 自定义加载器\n\n\n# 双亲委派\n\n踢皮球，避免一个类被重复加载。保证类库API不会被修改\n\n\n# 类装载\n\n\n\n\n# 垃圾回收\n\n * 引用计数法\n * 可达性分析\n * 标记清除法\n * 标记整理算法\n * 复制算法\n * 新生代回收\n * 老年代回收\n * MinorGC\n * Mixed GC\n * Full GC\n * G1\n\n\n# 强引用、软引用、弱引用、虚引用\n\nUser user = new User();\n// 软引用：垃圾回收多次后还是内存不足，就会回收\nSoftReference softReference = new SoftReference(user); \n// 弱引用：只要进行了垃圾回收，就会回收\nWeakReference weakReference = new WeakReference(user); \nReferenceQueue referenceQueue = new ReferenceQueue(); \n// 虚引用，被引用的对象回收时，会回收\nPhantomReference phantomReference = new PhantomReference(user, queue);\n\n\n\n# JVM调优",normalizedContent:"# 运行流程\n\n\n\n\n# 组件\n\n          \n程序计数器     类似组成原理中pc寄存器，线程私有，记录运行的位置\n堆         线程共享，数组，对象。年轻代+老年代（eden，幸存区）\n栈         每个线程一个栈，一个栈多个栈帧（方法）。存放方法内的局部变量，栈内存溢出（递归）。\n方法区、元空间   线程共享。class，classloader，运行时常量池\n直接内存      操作系统的内存\n\n\n# 类加载器\n\n将字节码文件加载到jvm中\n\n * 启动类加载器：加载java_home/jre/lib目录下的库\n * 扩展类加载器：加载java_home/jre/lib/ext目录中类\n * 应用类加载器：加载classpath下的类\n * 自定义加载器\n\n\n# 双亲委派\n\n踢皮球，避免一个类被重复加载。保证类库api不会被修改\n\n\n# 类装载\n\n\n\n\n# 垃圾回收\n\n * 引用计数法\n * 可达性分析\n * 标记清除法\n * 标记整理算法\n * 复制算法\n * 新生代回收\n * 老年代回收\n * minorgc\n * mixed gc\n * full gc\n * g1\n\n\n# 强引用、软引用、弱引用、虚引用\n\nuser user = new user();\n// 软引用：垃圾回收多次后还是内存不足，就会回收\nsoftreference softreference = new softreference(user); \n// 弱引用：只要进行了垃圾回收，就会回收\nweakreference weakreference = new weakreference(user); \nreferencequeue referencequeue = new referencequeue(); \n// 虚引用，被引用的对象回收时，会回收\nphantomreference phantomreference = new phantomreference(user, queue);\n\n\n\n# jvm调优",charsets:{cjk:!0}},{title:"消息队列",frontmatter:{title:"消息队列",date:"2023-06-06T14:52:42.000Z",permalink:"/pages/a20dff/"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/14.message.html",relativePath:"01.Java/99.秋招/14.message.md",key:"v-471876c8",path:"/pages/a20dff/",headers:[{level:2,title:"RabbitMQ-如何保证消息不丢失",slug:"rabbitmq-如何保证消息不丢失",normalizedTitle:"rabbitmq-如何保证消息不丢失",charIndex:2},{level:2,title:"RabbitMQ死信交换机、延迟队列",slug:"rabbitmq死信交换机、延迟队列",normalizedTitle:"rabbitmq死信交换机、延迟队列",charIndex:414},{level:2,title:"RabbitMQ消息堆积",slug:"rabbitmq消息堆积",normalizedTitle:"rabbitmq消息堆积",charIndex:587},{level:2,title:"RabbitMQ集群",slug:"rabbitmq集群",normalizedTitle:"rabbitmq集群",charIndex:672},{level:2,title:"Kafka如何保证消息不丢失",slug:"kafka如何保证消息不丢失",normalizedTitle:"kafka如何保证消息不丢失",charIndex:687},{level:3,title:"Producer",slug:"producer",normalizedTitle:"producer",charIndex:838},{level:3,title:"Broker",slug:"broker",normalizedTitle:"broker",charIndex:957},{level:3,title:"Consumer",slug:"consumer",normalizedTitle:"consumer",charIndex:1059},{level:2,title:"Kafka保证消费顺序",slug:"kafka保证消费顺序",normalizedTitle:"kafka保证消费顺序",charIndex:1201},{level:2,title:"Kafka高可用机制",slug:"kafka高可用机制",normalizedTitle:"kafka高可用机制",charIndex:1242},{level:2,title:"Kafka高性能",slug:"kafka高性能",normalizedTitle:"kafka高性能",charIndex:1257}],headersStr:"RabbitMQ-如何保证消息不丢失 RabbitMQ死信交换机、延迟队列 RabbitMQ消息堆积 RabbitMQ集群 Kafka如何保证消息不丢失 Producer Broker Consumer Kafka保证消费顺序 Kafka高可用机制 Kafka高性能",content:"# RabbitMQ-如何保证消息不丢失\n\n * 消息队列的作用，可以做到异步发送（验证码、短信、邮件）\n\n * MySQL和Redis，ES之间的数据同步\n\n * 分布式事务\n\n * 削峰填谷\n   \n   rabbitMQ工作模式，exchange和Queue进行绑定，根据话题匹配，exchange发送消息到指定的Queue。\n   \n   消息丢失的位置\n\n\n\n框架中实现了发送者发送消息的回调函数，并说明是否发送成功，如果发送失败了，则再回调方法中进行重发。\n\n另外方法可以发送失败时，保存日志，之后定时重发，成功发送后删除日志中的记录。\n\n若消息发送到了Queue中，宕机了，消息丢失。\n\n可以进行消息持久化，交换机持久化，队列持久化。\n\n消费者确认，消费者处理消息后向MQ发送ack回执，收到ack自动删除消息。还有一个，消费者出现异常时，会进行重试，到了一定次数后还是不行，将消息送到异常交换机中记录。\n\n\n# RabbitMQ死信交换机、延迟队列\n\n * 延迟队列：进入队列的消息会被延迟消费\n * 超时订单、限时优惠、定时发布\n\n延迟队列=死信交换机+TTL\n\n死信\n\n * 消息被消费者拒绝了\n * 消息是过期消息\n * 消息队列满了，较早的消息\n\n成为死信的消息，可以转发到死信交换机\n\nTTL\n\n * 消息队列的TTL\n * 消息的TTL\n\n\n# RabbitMQ消息堆积\n\n生产者的生产消息的速度，远超过消费者消费消息的速度。\n\n * 增加消费者\n * 在消费者中开启线程池\n * 惰性队列，把存放在磁盘中\n\n\n# RabbitMQ集群\n\n\n# Kafka如何保证消息不丢失\n\nKafka的工作模式为，生产者向指定的topic发送消息，如果指定了消息的key，则将key hash并取模，存放到指定的分区中，如果没有key，则轮次存放。一个topic有多个分区，每个分区可以放在不同的broker中。一个消费者组中的消费者消费不同的分区。\n\n\n# Producer\n\n生产者发送到主分区后，可以收到broker的ack确认，这个是可以设置的，设置ack=1，或者ack=all。表示主分区收到消息后，和备份分区都收到消息后的回复确认。\n\n如果没有收到确认，生产者尝试进行重发。\n\n\n# Broker\n\nBroker中主分区收到消息后，将数据持久化，操作系统定时将page cache中的数据持久化存盘。如果此时broker宕机，选取了一个落后的备份分区当主分区，那么就会数据丢失。\n\n\n# Consumer\n\n消费者到指定的topic，指定的分区去消费消息。消费完成后会提交offset消费位移进度记录。\n\n * 先提交offset，后处理消息，那么可能会造成消息丢失。\n * 先处理消息，后提交offset，那么可能会造成消息重复消费，这个可以在业务中保证幂等。\n\n\n# Kafka保证消费顺序\n\n对于需要顺序消费的消息，放入到同一个分区即可。\n\n\n# Kafka高可用机制\n\n\n# Kafka高性能\n\n * 消息分区：不同的服务器，并发\n * 顺序读写：\n * 页缓存：\n * 零拷贝：",normalizedContent:"# rabbitmq-如何保证消息不丢失\n\n * 消息队列的作用，可以做到异步发送（验证码、短信、邮件）\n\n * mysql和redis，es之间的数据同步\n\n * 分布式事务\n\n * 削峰填谷\n   \n   rabbitmq工作模式，exchange和queue进行绑定，根据话题匹配，exchange发送消息到指定的queue。\n   \n   消息丢失的位置\n\n\n\n框架中实现了发送者发送消息的回调函数，并说明是否发送成功，如果发送失败了，则再回调方法中进行重发。\n\n另外方法可以发送失败时，保存日志，之后定时重发，成功发送后删除日志中的记录。\n\n若消息发送到了queue中，宕机了，消息丢失。\n\n可以进行消息持久化，交换机持久化，队列持久化。\n\n消费者确认，消费者处理消息后向mq发送ack回执，收到ack自动删除消息。还有一个，消费者出现异常时，会进行重试，到了一定次数后还是不行，将消息送到异常交换机中记录。\n\n\n# rabbitmq死信交换机、延迟队列\n\n * 延迟队列：进入队列的消息会被延迟消费\n * 超时订单、限时优惠、定时发布\n\n延迟队列=死信交换机+ttl\n\n死信\n\n * 消息被消费者拒绝了\n * 消息是过期消息\n * 消息队列满了，较早的消息\n\n成为死信的消息，可以转发到死信交换机\n\nttl\n\n * 消息队列的ttl\n * 消息的ttl\n\n\n# rabbitmq消息堆积\n\n生产者的生产消息的速度，远超过消费者消费消息的速度。\n\n * 增加消费者\n * 在消费者中开启线程池\n * 惰性队列，把存放在磁盘中\n\n\n# rabbitmq集群\n\n\n# kafka如何保证消息不丢失\n\nkafka的工作模式为，生产者向指定的topic发送消息，如果指定了消息的key，则将key hash并取模，存放到指定的分区中，如果没有key，则轮次存放。一个topic有多个分区，每个分区可以放在不同的broker中。一个消费者组中的消费者消费不同的分区。\n\n\n# producer\n\n生产者发送到主分区后，可以收到broker的ack确认，这个是可以设置的，设置ack=1，或者ack=all。表示主分区收到消息后，和备份分区都收到消息后的回复确认。\n\n如果没有收到确认，生产者尝试进行重发。\n\n\n# broker\n\nbroker中主分区收到消息后，将数据持久化，操作系统定时将page cache中的数据持久化存盘。如果此时broker宕机，选取了一个落后的备份分区当主分区，那么就会数据丢失。\n\n\n# consumer\n\n消费者到指定的topic，指定的分区去消费消息。消费完成后会提交offset消费位移进度记录。\n\n * 先提交offset，后处理消息，那么可能会造成消息丢失。\n * 先处理消息，后提交offset，那么可能会造成消息重复消费，这个可以在业务中保证幂等。\n\n\n# kafka保证消费顺序\n\n对于需要顺序消费的消息，放入到同一个分区即可。\n\n\n# kafka高可用机制\n\n\n# kafka高性能\n\n * 消息分区：不同的服务器，并发\n * 顺序读写：\n * 页缓存：\n * 零拷贝：",charsets:{cjk:!0}},{title:"设计模式",frontmatter:{title:"设计模式",date:"2023-06-12T11:34:38.000Z",permalink:"/pages/33bbc8/"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/17.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java/99.秋招/17.设计模式.md",key:"v-1858d133",path:"/pages/33bbc8/",headers:[{level:2,title:"简单工厂",slug:"简单工厂",normalizedTitle:"简单工厂",charIndex:2},{level:2,title:"工厂方法（常用）",slug:"工厂方法-常用",normalizedTitle:"工厂方法（常用）",charIndex:13},{level:2,title:"抽象工厂",slug:"抽象工厂",normalizedTitle:"抽象工厂",charIndex:28},{level:2,title:"策略模式",slug:"策略模式",normalizedTitle:"策略模式",charIndex:39},{level:2,title:"责任链模式",slug:"责任链模式",normalizedTitle:"责任链模式",charIndex:94}],headersStr:"简单工厂 工厂方法（常用） 抽象工厂 策略模式 责任链模式",content:"# 简单工厂\n\n\n\n\n# 工厂方法（常用）\n\n\n\n\n# 抽象工厂\n\n\n\n\n# 策略模式\n\n将算法封装在接口，具体实现类实现具体算法，需要某种具体算法，只需传入具体的实现类即可\n\n\n\n\n# 责任链模式\n\nServlet中的过滤器链，Spring MVC中的拦截器链\n\n",normalizedContent:"# 简单工厂\n\n\n\n\n# 工厂方法（常用）\n\n\n\n\n# 抽象工厂\n\n\n\n\n# 策略模式\n\n将算法封装在接口，具体实现类实现具体算法，需要某种具体算法，只需传入具体的实现类即可\n\n\n\n\n# 责任链模式\n\nservlet中的过滤器链，spring mvc中的拦截器链\n\n",charsets:{cjk:!0}},{title:"场景设计",frontmatter:{title:"场景设计",date:"2023-06-12T11:48:27.000Z",permalink:"/pages/46dd43/"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/18.%E4%B8%80%E4%BA%9B%E5%9C%BA%E6%99%AF.html",relativePath:"01.Java/99.秋招/18.一些场景.md",key:"v-f5bde88e",path:"/pages/46dd43/",headers:[{level:2,title:"JWT解决单点登录",slug:"jwt解决单点登录",normalizedTitle:"jwt解决单点登录",charIndex:2},{level:2,title:"RBAC权限模型",slug:"rbac权限模型",normalizedTitle:"rbac权限模型",charIndex:46},{level:2,title:"项目遇到的问题",slug:"项目遇到的问题",normalizedTitle:"项目遇到的问题",charIndex:61}],headersStr:"JWT解决单点登录 RBAC权限模型 项目遇到的问题",content:"# JWT解决单点登录\n\n网关统一认证token是否有效，并路由到指定的服务。\n\n\n\n\n# RBAC权限模型\n\n\n\n\n# 项目遇到的问题\n\n",normalizedContent:"# jwt解决单点登录\n\n网关统一认证token是否有效，并路由到指定的服务。\n\n\n\n\n# rbac权限模型\n\n\n\n\n# 项目遇到的问题\n\n",charsets:{cjk:!0}},{title:"test",frontmatter:{title:"test",date:"2023-06-22T18:14:21.000Z",permalink:"/pages/545d12/"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/33.test.html",relativePath:"01.Java/99.秋招/33.test.md",key:"v-bbb4debc",path:"/pages/545d12/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"并发编程",frontmatter:{title:"并发编程",date:"2023-06-07T14:30:42.000Z",permalink:"/pages/15ac4e/"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/15.juc.html",relativePath:"01.Java/99.秋招/15.juc.md",key:"v-d62b5838",path:"/pages/15ac4e/",headers:[{level:2,title:"线程和进程的区别",slug:"线程和进程的区别",normalizedTitle:"线程和进程的区别",charIndex:2},{level:2,title:"并行和并发",slug:"并行和并发",normalizedTitle:"并行和并发",charIndex:80},{level:2,title:"创建线程的方式",slug:"创建线程的方式",normalizedTitle:"创建线程的方式",charIndex:133},{level:2,title:"线程状态",slug:"线程状态",normalizedTitle:"线程状态",charIndex:206},{level:2,title:"notify和notifAll",slug:"notify和notifall",normalizedTitle:"notify和notifall",charIndex:217},{level:2,title:"wait和sleep",slug:"wait和sleep",normalizedTitle:"wait和sleep",charIndex:271},{level:2,title:"如何停止线程",slug:"如何停止线程",normalizedTitle:"如何停止线程",charIndex:719},{level:2,title:"synchronized",slug:"synchronized",normalizedTitle:"synchronized",charIndex:670},{level:2,title:"JMM",slug:"jmm",normalizedTitle:"jmm",charIndex:1418},{level:2,title:"CAS",slug:"cas",normalizedTitle:"cas",charIndex:1469},{level:2,title:"volatile",slug:"volatile",normalizedTitle:"volatile",charIndex:1527},{level:2,title:"AQS",slug:"aqs",normalizedTitle:"aqs",charIndex:1563},{level:2,title:"ReentrantLock",slug:"reentrantlock",normalizedTitle:"reentrantlock",charIndex:1640},{level:2,title:"synchronized和lock",slug:"synchronized和lock",normalizedTitle:"synchronized和lock",charIndex:1681},{level:2,title:"ConcurrentHashMap",slug:"concurrenthashmap",normalizedTitle:"concurrenthashmap",charIndex:1772},{level:2,title:"线程池使用场景",slug:"线程池使用场景",normalizedTitle:"线程池使用场景",charIndex:1853},{level:3,title:"分批执行",slug:"分批执行",normalizedTitle:"分批执行",charIndex:1865},{level:3,title:"汇总信息",slug:"汇总信息",normalizedTitle:"汇总信息",charIndex:1876},{level:3,title:"异步调用",slug:"异步调用",normalizedTitle:"异步调用",charIndex:1887},{level:2,title:"控制方法的并发量",slug:"控制方法的并发量",normalizedTitle:"控制方法的并发量",charIndex:1911},{level:2,title:"ThreadLocal",slug:"threadlocal",normalizedTitle:"threadlocal",charIndex:2037},{level:3,title:"底层原理",slug:"底层原理",normalizedTitle:"底层原理",charIndex:2240}],headersStr:"线程和进程的区别 并行和并发 创建线程的方式 线程状态 notify和notifAll wait和sleep 如何停止线程 synchronized JMM CAS volatile AQS ReentrantLock synchronized和lock ConcurrentHashMap 线程池使用场景 分批执行 汇总信息 异步调用 控制方法的并发量 ThreadLocal 底层原理",content:'# 线程和进程的区别\n\n进程是正在运行程序的实例，包含了线程。\n\n不同进程拥有不同的进程空间，一个进程中的线程共用进程内存空间\n\n线程上下文切换成本低\n\n\n# 并行和并发\n\n时间片轮转。\n\n并发，在一段时间内，处理多件事情。\n\n并行，同一时间处理多件事情。\n\n\n# 创建线程的方式\n\n继承Thread类\n\n\n\n实现Runable接口\n\n\n\n实现Callable接口，可以拿到返回值\n\n\n\n使用线程池\n\n\n\n\n# 线程状态\n\n\n\n\n# notify和notifAll\n\n随机唤醒一个线程，和唤醒所有线程。object.notif();\n\n\n# wait和sleep\n\n共同点\n\nwait() ，wait(long) 和 sleep(long) 的效果都是让当前线程暂时放弃 CPU 的使用权，进入阻塞状态\n\n不同点\n\n 1. 方法归属不同\n\nsleep(long) 是 Thread 的静态方法而 wait()，wait(long) 都是 Object 的成员方法，每个对象都有\n\n 2. 醒来时机不同\n\n执行 sleep(long) 和 wait(long) 的线程都会在等待相应毫秒后醒来wait(long) 和 wait() 还以被 notify 唤醒，wait() 如果不唤醒就一直等下去它们都可以被打断唤醒\n\n 3. 锁特性不同（重点）\n\nwait 方法的调用必须先获取 wait 对象的锁，而 sleep 则无此限制wait 方法执行后会释放对象锁，允许其它线程获得该对象锁（我放弃 cpu，但你们还可以用）而 sleep 如果在synchronized 代码块中执行，并不会释放对象锁（我放弃 cpu，你们也用不了）\n\n\n# 如何停止线程\n\n采用退出标记\n\n使用interrupt\n\n打断阻塞的线程（ sleep，wait，join ）的线程，线程会抛出InterruptedException异常 打断正常的线程，可以根据打断状态来标记是否退出线程\n\n\n# synchronized\n\n最多一个线程获得锁，其它线程会阻塞。\n\nJava对象头\n\n|---------------------------------------------------------------|\n|\t\t\t\t\tObject Header (64 bits)\t\t\t\t\t\t|\n|-------------------------------|-------------------------------|\n|\t\tMark Word (32 bits)\t\t|\t\tKlass Word (32bits)\t    |\n|-------------------------------|-------------------------------|\n\n\n创建锁记录对象，每个线程的栈帧都会包含一个所记录，内部存储锁定的对象的Mark Work\n\n\n\n当线程尝试锁定某对象，判断对象头中是否为空闲状态，如果空闲，则将栈帧的锁记录与对象头交换\n\n\n\n如果此时有其它线程想获取该轻量锁，那么会失败，则进行如下步骤\n\n为该对象申请Monitor锁，将对象头指向Monitor锁地址，自己进入EntryList中等待。\n\n锁结构\n\n\n\n等原来获取到轻量级锁的线程，解锁，按照Monitor解锁的流程，情况Owner，唤醒EntryList。\n\n自旋优化\n\n\n# JMM\n\nJava内存模型，划分为工作内存，共享内存。线程之间是相互隔离的，交互需要主内存。\n\n\n# CAS\n\nCompare And Swap\n\n乐观锁，如果旧的值，和原来值不一致，则会自旋（重新进行更新）\n\n\n# volatile\n\n不从缓存，从内存中读取数据。禁止指令重排序\n\n\n# AQS\n\n抽象队列同步器。内部维护一个state变量，如果线程将state成功修改为1，则表示该线程获得锁，否则线程会被标记到AQS中的队列中。\n\n\n# ReentrantLock\n\n可中断，设置超时时间，公平锁，可重入。\n\n\n\n\n# synchronized和lock\n\n前者，C++实现，自动释放锁。后者java实现，需要lock，unlock。\n\n可打断，在获取锁阻塞时，其它线程可以打断他的打断过程。\n\n\n# ConcurrentHashMap\n\n底层数据结构与HashMap一致，数组+链表/红黑二叉树\n\n加锁：采用CAS添加新节点，锁定链表或者红黑树的首节点\n\n\n# 线程池使用场景\n\n\n# 分批执行\n\n\n\n\n# 汇总信息\n\n\n\n\n# 异步调用\n\n@Async("线程池")\n\n\n# 控制方法的并发量\n\n信号量，限流。\n\nSemaphore semaphore = new Semaphore(3);\n\n// 获取信号量\nsemaphore.acquire();\n\n// 释放信号量\nsemaphore.release();\n\n\n\n# ThreadLocal\n\n实现资源对象的线程隔离\n\n每个线程内有一个ThreadLocalMap类型的成员变量，用来存储资源对象。\n\n调用set方法，就是以ThreadLocal作为key，资源对象作为value，放入当前线程的ThreadLocalMap集合中\n\n调用get方法，同理。\n\n调用remove方法，同理。\n\nThreadLocalMap内存泄露，需要手动调用remove释放一下。\n\n\n# 底层原理\n\n每个Thread类都有一个Map，当需要存储一个ThreadLocal<T> tl = new ThreadLocal，值为v时，Thread中的map存储方式为map.set(tl, v)，这样线程取指定ThreadLocal时，只需要在自己线程内map.get(tl)。\n\n使用方式是\n\nThreadLocal<T> tl = new ThreadLocal<>();\ntl.set(val);\ntl.get();\ntl.remove();\n\n\n实际上是，Thread中的ThreadLocalMap存了多个ThreadLocal。',normalizedContent:'# 线程和进程的区别\n\n进程是正在运行程序的实例，包含了线程。\n\n不同进程拥有不同的进程空间，一个进程中的线程共用进程内存空间\n\n线程上下文切换成本低\n\n\n# 并行和并发\n\n时间片轮转。\n\n并发，在一段时间内，处理多件事情。\n\n并行，同一时间处理多件事情。\n\n\n# 创建线程的方式\n\n继承thread类\n\n\n\n实现runable接口\n\n\n\n实现callable接口，可以拿到返回值\n\n\n\n使用线程池\n\n\n\n\n# 线程状态\n\n\n\n\n# notify和notifall\n\n随机唤醒一个线程，和唤醒所有线程。object.notif();\n\n\n# wait和sleep\n\n共同点\n\nwait() ，wait(long) 和 sleep(long) 的效果都是让当前线程暂时放弃 cpu 的使用权，进入阻塞状态\n\n不同点\n\n 1. 方法归属不同\n\nsleep(long) 是 thread 的静态方法而 wait()，wait(long) 都是 object 的成员方法，每个对象都有\n\n 2. 醒来时机不同\n\n执行 sleep(long) 和 wait(long) 的线程都会在等待相应毫秒后醒来wait(long) 和 wait() 还以被 notify 唤醒，wait() 如果不唤醒就一直等下去它们都可以被打断唤醒\n\n 3. 锁特性不同（重点）\n\nwait 方法的调用必须先获取 wait 对象的锁，而 sleep 则无此限制wait 方法执行后会释放对象锁，允许其它线程获得该对象锁（我放弃 cpu，但你们还可以用）而 sleep 如果在synchronized 代码块中执行，并不会释放对象锁（我放弃 cpu，你们也用不了）\n\n\n# 如何停止线程\n\n采用退出标记\n\n使用interrupt\n\n打断阻塞的线程（ sleep，wait，join ）的线程，线程会抛出interruptedexception异常 打断正常的线程，可以根据打断状态来标记是否退出线程\n\n\n# synchronized\n\n最多一个线程获得锁，其它线程会阻塞。\n\njava对象头\n\n|---------------------------------------------------------------|\n|\t\t\t\t\tobject header (64 bits)\t\t\t\t\t\t|\n|-------------------------------|-------------------------------|\n|\t\tmark word (32 bits)\t\t|\t\tklass word (32bits)\t    |\n|-------------------------------|-------------------------------|\n\n\n创建锁记录对象，每个线程的栈帧都会包含一个所记录，内部存储锁定的对象的mark work\n\n\n\n当线程尝试锁定某对象，判断对象头中是否为空闲状态，如果空闲，则将栈帧的锁记录与对象头交换\n\n\n\n如果此时有其它线程想获取该轻量锁，那么会失败，则进行如下步骤\n\n为该对象申请monitor锁，将对象头指向monitor锁地址，自己进入entrylist中等待。\n\n锁结构\n\n\n\n等原来获取到轻量级锁的线程，解锁，按照monitor解锁的流程，情况owner，唤醒entrylist。\n\n自旋优化\n\n\n# jmm\n\njava内存模型，划分为工作内存，共享内存。线程之间是相互隔离的，交互需要主内存。\n\n\n# cas\n\ncompare and swap\n\n乐观锁，如果旧的值，和原来值不一致，则会自旋（重新进行更新）\n\n\n# volatile\n\n不从缓存，从内存中读取数据。禁止指令重排序\n\n\n# aqs\n\n抽象队列同步器。内部维护一个state变量，如果线程将state成功修改为1，则表示该线程获得锁，否则线程会被标记到aqs中的队列中。\n\n\n# reentrantlock\n\n可中断，设置超时时间，公平锁，可重入。\n\n\n\n\n# synchronized和lock\n\n前者，c++实现，自动释放锁。后者java实现，需要lock，unlock。\n\n可打断，在获取锁阻塞时，其它线程可以打断他的打断过程。\n\n\n# concurrenthashmap\n\n底层数据结构与hashmap一致，数组+链表/红黑二叉树\n\n加锁：采用cas添加新节点，锁定链表或者红黑树的首节点\n\n\n# 线程池使用场景\n\n\n# 分批执行\n\n\n\n\n# 汇总信息\n\n\n\n\n# 异步调用\n\n@async("线程池")\n\n\n# 控制方法的并发量\n\n信号量，限流。\n\nsemaphore semaphore = new semaphore(3);\n\n// 获取信号量\nsemaphore.acquire();\n\n// 释放信号量\nsemaphore.release();\n\n\n\n# threadlocal\n\n实现资源对象的线程隔离\n\n每个线程内有一个threadlocalmap类型的成员变量，用来存储资源对象。\n\n调用set方法，就是以threadlocal作为key，资源对象作为value，放入当前线程的threadlocalmap集合中\n\n调用get方法，同理。\n\n调用remove方法，同理。\n\nthreadlocalmap内存泄露，需要手动调用remove释放一下。\n\n\n# 底层原理\n\n每个thread类都有一个map，当需要存储一个threadlocal<t> tl = new threadlocal，值为v时，thread中的map存储方式为map.set(tl, v)，这样线程取指定threadlocal时，只需要在自己线程内map.get(tl)。\n\n使用方式是\n\nthreadlocal<t> tl = new threadlocal<>();\ntl.set(val);\ntl.get();\ntl.remove();\n\n\n实际上是，thread中的threadlocalmap存了多个threadlocal。',charsets:{cjk:!0}},{title:"疑问",frontmatter:{title:"疑问",date:"2023-06-11T14:21:02.000Z",permalink:"/pages/69d257/"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/99.%E4%B8%80%E4%BA%9B%E7%96%91%E9%97%AE.html",relativePath:"01.Java/99.秋招/99.一些疑问.md",key:"v-0a6bb5e5",path:"/pages/69d257/",headers:[{level:2,title:"SpringBoot自启动",slug:"springboot自启动",normalizedTitle:"springboot自启动",charIndex:2},{level:2,title:"SpringSecurity认证",slug:"springsecurity认证",normalizedTitle:"springsecurity认证",charIndex:151},{level:2,title:"Jwt、OAuth2、加密解密",slug:"jwt、oauth2、加密解密",normalizedTitle:"jwt、oauth2、加密解密",charIndex:2247},{level:3,title:"非对称加密",slug:"非对称加密",normalizedTitle:"非对称加密",charIndex:2483},{level:2,title:"MyBatis执行过程",slug:"mybatis执行过程",normalizedTitle:"mybatis执行过程",charIndex:2746},{level:2,title:"MyBatis",slug:"mybatis",normalizedTitle:"mybatis",charIndex:2746},{level:2,title:"HashMap与ConcurrentHashMap",slug:"hashmap与concurrenthashmap",normalizedTitle:"hashmap与concurrenthashmap",charIndex:3823}],headersStr:"SpringBoot自启动 SpringSecurity认证 Jwt、OAuth2、加密解密 非对称加密 MyBatis执行过程 MyBatis HashMap与ConcurrentHashMap",content:'# SpringBoot自启动\n\n实现ApplicationRunner接口，并@Component。\n\n原理，Springboot启动时，先创建context，然后会执行callRunners方法，该方法是找到所有类型为ApplicationRunner的对象，然后执行该对象的run方法。\n\n\n# SpringSecurity认证\n\n疑问，为什么我实现了userDetailsService，框架会自动调用我的loadUserByUsername()方法。\n\nSpring Security框架中有默认的UserDetailsService实现类InMemoryUserDetailsManager，为什么会优先实现我的呢？\n\n发现的自动配置类\n\n@Configuration\n@ConditionalOnClass(AuthenticationManager.class)\n@ConditionalOnBean(ObjectPostProcessor.class)\n@ConditionalOnMissingBean({ \n    AuthenticationManager.class,\n    AuthenticationProvider.class,\n\tUserDetailsService.class })\npublic class UserDetailsServiceAutoConfiguration {\n\n\tprivate static final String NOOP_PASSWORD_PREFIX = "{noop}";\n\n\tprivate static final Pattern PASSWORD_ALGORITHM_PATTERN = Pattern\n\t\t\t.compile("^\\\\{.+}.*$");\n\n\tprivate static final Log logger = LogFactory\n\t\t\t.getLog(UserDetailsServiceAutoConfiguration.class);\n\n\t@Bean\n\t@ConditionalOnMissingBean(type = "org.springframework.security.oauth2.client.registration.ClientRegistrationRepository")\n\t@Lazy\n\tpublic InMemoryUserDetailsManager inMemoryUserDetailsManager(\n\t\t\tSecurityProperties properties,\n\t\t\tObjectProvider<PasswordEncoder> passwordEncoder) {\n\t\tSecurityProperties.User user = properties.getUser();\n\t\tList<String> roles = user.getRoles();\n\t\treturn new InMemoryUserDetailsManager(User.withUsername(user.getName())\n\t\t\t\t.password(getOrDeducePassword(user, passwordEncoder.getIfAvailable()))\n\t\t\t\t.roles(StringUtils.toStringArray(roles)).build());\n\t}\n\n\tprivate String getOrDeducePassword(SecurityProperties.User user,\n\t\t\tPasswordEncoder encoder) {\n\t\tString password = user.getPassword();\n\t\tif (user.isPasswordGenerated()) {\n\t\t\tlogger.info(String.format("%n%nUsing generated security password: %s%n",\n\t\t\t\t\tuser.getPassword()));\n\t\t}\n\t\tif (encoder != null || PASSWORD_ALGORITHM_PATTERN.matcher(password).matches()) {\n\t\t\treturn password;\n\t\t}\n\t\treturn NOOP_PASSWORD_PREFIX + password;\n\t}\n\n}\n\n\n\n阅读源码可以发现，声明InMemoryUserDetailsManager Bean是在UserDetailsServiceAutoConfiguration配置类中，有条件注解\n\n@ConditionalOnMissingBean({ \n    AuthenticationManager.class,\n    AuthenticationProvider.class,\n    UserDetailsService.class })\n\n\n也就是说，若没有类型为UserDetailsService的Bean，则会创建InMemoryUserDetailsManager。\n\n加载顺序\n\n先加载@Component注解的Bean，而后加载@Configuraion中声明的Bean。\n\n\n# Jwt、OAuth2、加密解密\n\nOAuth2是一个认证协议，可以获得授权码，通过授权码可以获得令牌并颁发令牌，这里是指普通的UUID令牌。但是可以选择将令牌转换成Jwt令牌，Jwt令牌由header.payload.sign三部分组成，客户端只能解析前面两部分，header包含加密方式，payload载荷数据。使用Jwt令牌好处就是，资源服务可以通过秘钥自行校验Jwt令牌的合法性，如果校验通过，并任务该请求是合法请求，而无需再进行远程调用认证服务进行认证。\n\n\n# 非对称加密\n\n所有人都拥有自己的一对公钥和私钥，若A想发消息给B，则A的消息通过B的公钥进行加密，这样这条消息只能通过B的私钥进行解密。\n\n验证签名\n\n如果想判断这条消息是否是A发送，A发送消息时将消息的摘要使用私钥进行加密，得到签名，将签名和消息一并发送给B。B得到后，对签名使用A的公钥进行解密，得到摘要D，然后B对消息生成摘要d，对比D和d是否相同，若不相同，则说明消息被篡改，或者这不是A的签名。\n\n发送者：用自己的私钥进行签名，用对方的公钥进行加密；\n\n接受者：用自己的私钥进行解密，用对方的公钥进行验签。\n\n\n# MyBatis执行过程\n\n有一个配置连接的xml，一个写SQL语句的xml，和一个接口。\n\n首先，肯定是要通过配置xml文件，会有一个类来解析xml文件，作为inputstream传递给构建工厂，最终创建SqlSession对象，是MyBatis的顶层API接口，会话访问，执行增删改查。\n\n然后sql，和接口怎么对应起来呢？一个xml文件的id，和接口名相同，这个会绑定起来。然后xml中的有很多标签，那肯定也是有响应的解析类，来解析这些标签。重要的是<select>标签，他会根据namespace和这个标签的id，生成一个MapperStatement对象，放到一个map中，key为namespace和id，value为MapperStatement对象。\n\n对于调用session.selectOne()方法，需要传入的mapper接口的方法的权限名加方法名，以及对应的参数。然后底层会拿到那个MapperStatement对象，交给Executor执行，它会生成SQL语句，进行查询缓存，如何查不到，那就得执行JDBC那一套查询流程，然后过程中肯定也有处理Java类型和jdbc类型转换的操作。\n\n对于整合了Springboot的话，那就不需要写生成SqlSessionFactory的代码了，这些Session交给容器来管理。对于session.selectOne()方法的调用，通过动态代理来调用。\n\n\n# MyBatis\n\n1 总的来说就是解析主配置文件把主配置文件里的所有信息封装到Configuration这个对象中。\n\n2 稍微细一点就是 通过XmlConfigBuilder解析主配置文件，然后通过XmlMapperBuild解析mappers下映射的所有xml文件（循环解析）。把每个xml中的各个sql解析成一个个MapperStatement对象装在Configuration维护的一个Map集合中，key值是id，value是mapperstatement对象-----然后把解析过的xml的名字和名称空间装在set集合中，通过名称空间反射生成的mapper的class对象以及class对象的代理对象装在Configuration对象维护的mapperRegistry中的Map中。\n\n3简化一点：主要就是把每个sql标签解析成mapperstatement对象装进集合，然后把mapper接口的class对象以及代理对象装进集合，方便后来使用。\n\n4一级缓存是sqlsession级别的，二级缓存是全局的。\n\n\n# HashMap与ConcurrentHashMap\n\nHashMap中为什么不线程安全\n\n 1. 当某个桶是空时，在两个线程同时插入元素到这个桶，可能会覆盖元素\n\n 2. 当插入到不同的桶，成员变量的size也会脏读。\n\n 3. JDK1.7中头插法的危害，会造成循环链表，当两个线程同时进行扩容时，一个线程刚开始赋值了e, 和next指针，但另一个线程以及扩容完成，如果e和next指针rehash后仍然在一个桶中，就会导致链表反转，此时当前线程再次进行扩容，就会造成循环链表。\n\n理解上面后，ConcurrentHashMap中保证线程安全的操作就简单了。\n\nJDK1.7中，采用分段锁，插入元素过程中，先从Segments（HashMap）找到具体的Segment，在从Segment中找到具体的Entry，进而进行插入元素。\n\nJDK1.8中，采用CAS + Synchronized，锁粒度更细，实现原理就对应HashMap上面线程不安全。\n\n 1. 当桶是空时，采用CAS判断，真正插入时判断这个桶是不是被占了，是的话就重试。\n 2. 保证不能让多个线程，各自扩容各自的。\n 3. 在正常增加链表元素或者红黑树节点时，使用Synchronized同步。',normalizedContent:'# springboot自启动\n\n实现applicationrunner接口，并@component。\n\n原理，springboot启动时，先创建context，然后会执行callrunners方法，该方法是找到所有类型为applicationrunner的对象，然后执行该对象的run方法。\n\n\n# springsecurity认证\n\n疑问，为什么我实现了userdetailsservice，框架会自动调用我的loaduserbyusername()方法。\n\nspring security框架中有默认的userdetailsservice实现类inmemoryuserdetailsmanager，为什么会优先实现我的呢？\n\n发现的自动配置类\n\n@configuration\n@conditionalonclass(authenticationmanager.class)\n@conditionalonbean(objectpostprocessor.class)\n@conditionalonmissingbean({ \n    authenticationmanager.class,\n    authenticationprovider.class,\n\tuserdetailsservice.class })\npublic class userdetailsserviceautoconfiguration {\n\n\tprivate static final string noop_password_prefix = "{noop}";\n\n\tprivate static final pattern password_algorithm_pattern = pattern\n\t\t\t.compile("^\\\\{.+}.*$");\n\n\tprivate static final log logger = logfactory\n\t\t\t.getlog(userdetailsserviceautoconfiguration.class);\n\n\t@bean\n\t@conditionalonmissingbean(type = "org.springframework.security.oauth2.client.registration.clientregistrationrepository")\n\t@lazy\n\tpublic inmemoryuserdetailsmanager inmemoryuserdetailsmanager(\n\t\t\tsecurityproperties properties,\n\t\t\tobjectprovider<passwordencoder> passwordencoder) {\n\t\tsecurityproperties.user user = properties.getuser();\n\t\tlist<string> roles = user.getroles();\n\t\treturn new inmemoryuserdetailsmanager(user.withusername(user.getname())\n\t\t\t\t.password(getordeducepassword(user, passwordencoder.getifavailable()))\n\t\t\t\t.roles(stringutils.tostringarray(roles)).build());\n\t}\n\n\tprivate string getordeducepassword(securityproperties.user user,\n\t\t\tpasswordencoder encoder) {\n\t\tstring password = user.getpassword();\n\t\tif (user.ispasswordgenerated()) {\n\t\t\tlogger.info(string.format("%n%nusing generated security password: %s%n",\n\t\t\t\t\tuser.getpassword()));\n\t\t}\n\t\tif (encoder != null || password_algorithm_pattern.matcher(password).matches()) {\n\t\t\treturn password;\n\t\t}\n\t\treturn noop_password_prefix + password;\n\t}\n\n}\n\n\n\n阅读源码可以发现，声明inmemoryuserdetailsmanager bean是在userdetailsserviceautoconfiguration配置类中，有条件注解\n\n@conditionalonmissingbean({ \n    authenticationmanager.class,\n    authenticationprovider.class,\n    userdetailsservice.class })\n\n\n也就是说，若没有类型为userdetailsservice的bean，则会创建inmemoryuserdetailsmanager。\n\n加载顺序\n\n先加载@component注解的bean，而后加载@configuraion中声明的bean。\n\n\n# jwt、oauth2、加密解密\n\noauth2是一个认证协议，可以获得授权码，通过授权码可以获得令牌并颁发令牌，这里是指普通的uuid令牌。但是可以选择将令牌转换成jwt令牌，jwt令牌由header.payload.sign三部分组成，客户端只能解析前面两部分，header包含加密方式，payload载荷数据。使用jwt令牌好处就是，资源服务可以通过秘钥自行校验jwt令牌的合法性，如果校验通过，并任务该请求是合法请求，而无需再进行远程调用认证服务进行认证。\n\n\n# 非对称加密\n\n所有人都拥有自己的一对公钥和私钥，若a想发消息给b，则a的消息通过b的公钥进行加密，这样这条消息只能通过b的私钥进行解密。\n\n验证签名\n\n如果想判断这条消息是否是a发送，a发送消息时将消息的摘要使用私钥进行加密，得到签名，将签名和消息一并发送给b。b得到后，对签名使用a的公钥进行解密，得到摘要d，然后b对消息生成摘要d，对比d和d是否相同，若不相同，则说明消息被篡改，或者这不是a的签名。\n\n发送者：用自己的私钥进行签名，用对方的公钥进行加密；\n\n接受者：用自己的私钥进行解密，用对方的公钥进行验签。\n\n\n# mybatis执行过程\n\n有一个配置连接的xml，一个写sql语句的xml，和一个接口。\n\n首先，肯定是要通过配置xml文件，会有一个类来解析xml文件，作为inputstream传递给构建工厂，最终创建sqlsession对象，是mybatis的顶层api接口，会话访问，执行增删改查。\n\n然后sql，和接口怎么对应起来呢？一个xml文件的id，和接口名相同，这个会绑定起来。然后xml中的有很多标签，那肯定也是有响应的解析类，来解析这些标签。重要的是<select>标签，他会根据namespace和这个标签的id，生成一个mapperstatement对象，放到一个map中，key为namespace和id，value为mapperstatement对象。\n\n对于调用session.selectone()方法，需要传入的mapper接口的方法的权限名加方法名，以及对应的参数。然后底层会拿到那个mapperstatement对象，交给executor执行，它会生成sql语句，进行查询缓存，如何查不到，那就得执行jdbc那一套查询流程，然后过程中肯定也有处理java类型和jdbc类型转换的操作。\n\n对于整合了springboot的话，那就不需要写生成sqlsessionfactory的代码了，这些session交给容器来管理。对于session.selectone()方法的调用，通过动态代理来调用。\n\n\n# mybatis\n\n1 总的来说就是解析主配置文件把主配置文件里的所有信息封装到configuration这个对象中。\n\n2 稍微细一点就是 通过xmlconfigbuilder解析主配置文件，然后通过xmlmapperbuild解析mappers下映射的所有xml文件（循环解析）。把每个xml中的各个sql解析成一个个mapperstatement对象装在configuration维护的一个map集合中，key值是id，value是mapperstatement对象-----然后把解析过的xml的名字和名称空间装在set集合中，通过名称空间反射生成的mapper的class对象以及class对象的代理对象装在configuration对象维护的mapperregistry中的map中。\n\n3简化一点：主要就是把每个sql标签解析成mapperstatement对象装进集合，然后把mapper接口的class对象以及代理对象装进集合，方便后来使用。\n\n4一级缓存是sqlsession级别的，二级缓存是全局的。\n\n\n# hashmap与concurrenthashmap\n\nhashmap中为什么不线程安全\n\n 1. 当某个桶是空时，在两个线程同时插入元素到这个桶，可能会覆盖元素\n\n 2. 当插入到不同的桶，成员变量的size也会脏读。\n\n 3. jdk1.7中头插法的危害，会造成循环链表，当两个线程同时进行扩容时，一个线程刚开始赋值了e, 和next指针，但另一个线程以及扩容完成，如果e和next指针rehash后仍然在一个桶中，就会导致链表反转，此时当前线程再次进行扩容，就会造成循环链表。\n\n理解上面后，concurrenthashmap中保证线程安全的操作就简单了。\n\njdk1.7中，采用分段锁，插入元素过程中，先从segments（hashmap）找到具体的segment，在从segment中找到具体的entry，进而进行插入元素。\n\njdk1.8中，采用cas + synchronized，锁粒度更细，实现原理就对应hashmap上面线程不安全。\n\n 1. 当桶是空时，采用cas判断，真正插入时判断这个桶是不是被占了，是的话就重试。\n 2. 保证不能让多个线程，各自扩容各自的。\n 3. 在正常增加链表元素或者红黑树节点时，使用synchronized同步。',charsets:{cjk:!0}},{title:"Untitled",frontmatter:{title:"Untitled",date:"2023-06-05T19:16:47.000Z",permalink:"/pages/851a97/"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/%E4%B8%80%E4%BA%9B%E5%80%99%E9%80%89.html",relativePath:"01.Java/99.秋招/一些候选.md",key:"v-24bec208",path:"/pages/851a97/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"提前批",frontmatter:{mianshititle:"提前批",date:"2023-05-29T14:56:27.000Z",permalink:"/pages/4da935/",title:"提前批"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/%E6%8F%90%E5%89%8D%E6%89%B9.html",relativePath:"01.Java/99.秋招/提前批.md",key:"v-20d4825a",path:"/pages/4da935/",headersStr:null,content:"投递记录\n\n企业               详情                                                                                日期\n中国科学院空天信息创新研究院   https://zhaopin.aircas.ac.cn/system/userInfo/myDelivery                           5.29\n三一重工             http://sanycampus.zhiye.com/Portal/Apply/Index                                    5.29\nTP-LINK          https://hr.tp-link.com.cn/socialDelivery                                          5.30\n华泰证券             https://wecruit.hotjob.cn/SU6013d14e5d83dc11e4a8ae4d/pb/account.html#/myDeliver   5.30\ntp-link联洲        https://career.tplinkglobal.com/personal/deliveryRecord                           6.1\n中新赛克             https://recruit.sinovatio.com/resume/mine                                         6.12\nLazada           https://talent.alibaba.com/personal/social-application?lang=zh                    7.6\n牛客               https://www.nowcoder.com/users/818778787/deliver                                  7.6\n万得               https://www.wind.com.cn/portal/zh/JoinUs/recruit.html?positionType=9002           7.6\n米哈游              https://campus.mihoyo.com/#/campus/applyRecord                                    7.7\n字节跳动提前批          https://jobs.bytedance.com/campus/position/application                            7.23\n科大讯飞             https://campus.iflytek.com/official-pc/delivery                                   7.27\n                                                                                                   ",normalizedContent:"投递记录\n\n企业               详情                                                                                日期\n中国科学院空天信息创新研究院   https://zhaopin.aircas.ac.cn/system/userinfo/mydelivery                           5.29\n三一重工             http://sanycampus.zhiye.com/portal/apply/index                                    5.29\ntp-link          https://hr.tp-link.com.cn/socialdelivery                                          5.30\n华泰证券             https://wecruit.hotjob.cn/su6013d14e5d83dc11e4a8ae4d/pb/account.html#/mydeliver   5.30\ntp-link联洲        https://career.tplinkglobal.com/personal/deliveryrecord                           6.1\n中新赛克             https://recruit.sinovatio.com/resume/mine                                         6.12\nlazada           https://talent.alibaba.com/personal/social-application?lang=zh                    7.6\n牛客               https://www.nowcoder.com/users/818778787/deliver                                  7.6\n万得               https://www.wind.com.cn/portal/zh/joinus/recruit.html?positiontype=9002           7.6\n米哈游              https://campus.mihoyo.com/#/campus/applyrecord                                    7.7\n字节跳动提前批          https://jobs.bytedance.com/campus/position/application                            7.23\n科大讯飞             https://campus.iflytek.com/official-pc/delivery                                   7.27\n                                                                                                   ",charsets:{cjk:!0}},{title:"面试记录",frontmatter:{title:"面试记录",date:"2023-07-27T15:56:41.000Z",permalink:"/pages/7d963b/"},regularPath:"/01.Java/99.%E7%A7%8B%E6%8B%9B/%E9%9D%A2%E8%AF%95%E8%AE%B0%E5%BD%95.html",relativePath:"01.Java/99.秋招/面试记录.md",key:"v-70c2530b",path:"/pages/7d963b/",headers:[{level:3,title:"00. 万得一面（7.10）70分钟（负）",slug:"_00-万得一面-7-10-70分钟-负",normalizedTitle:"00. 万得一面（7.10）70分钟（负）",charIndex:2},{level:3,title:"01. 用友一面（7.27）60分钟（胜）",slug:"_01-用友一面-7-27-60分钟-胜",normalizedTitle:"01. 用友一面（7.27）60分钟（胜）",charIndex:28},{level:3,title:"02. 用友二面（8.02）40分钟（负）",slug:"_02-用友二面-8-02-40分钟-负",normalizedTitle:"02. 用友二面（8.02）40分钟（负）",charIndex:642},{level:3,title:"03. 快手一面（8.08）60分钟（胜）",slug:"_03-快手一面-8-08-60分钟-胜",normalizedTitle:"03. 快手一面（8.08）60分钟（胜）",charIndex:698},{level:3,title:"04. 快手二面（8.15）60分钟（胜）",slug:"_04-快手二面-8-15-60分钟-胜",normalizedTitle:"04. 快手二面（8.15）60分钟（胜）",charIndex:921},{level:3,title:"05. 京东一面（8.16）53分钟（？）",slug:"_05-京东一面-8-16-53分钟",normalizedTitle:"05. 京东一面（8.16）53分钟（？）",charIndex:1479},{level:3,title:"06. 腾讯一面（8.18）70分钟（负）",slug:"_06-腾讯一面-8-18-70分钟-负",normalizedTitle:"06. 腾讯一面（8.18）70分钟（负）",charIndex:1817},{level:3,title:"07. 字节一面（8.21）57分钟（胜）",slug:"_07-字节一面-8-21-57分钟-胜",normalizedTitle:"07. 字节一面（8.21）57分钟（胜）",charIndex:2033},{level:3,title:"08. 京东一面（8.23）35 分钟（胜）",slug:"_08-京东一面-8-23-35-分钟-胜",normalizedTitle:"08. 京东一面（8.23）35 分钟（胜）",charIndex:2496},{level:3,title:"09. 联想一面（8.24）30分钟（负）",slug:"_09-联想一面-8-24-30分钟-负",normalizedTitle:"09. 联想一面（8.24）30分钟（负）",charIndex:2869},{level:3,title:"10. 字节二面（8.24）70分钟（胜）",slug:"_10-字节二面-8-24-70分钟-胜",normalizedTitle:"10. 字节二面（8.24）70分钟（胜）",charIndex:3070},{level:3,title:"11. 美团一面（8.24）70分钟（胜）",slug:"_11-美团一面-8-24-70分钟-胜",normalizedTitle:"11. 美团一面（8.24）70分钟（胜）",charIndex:3376},{level:3,title:"12. 京东二面（8.25）30分钟（负）",slug:"_12-京东二面-8-25-30分钟-负",normalizedTitle:"12. 京东二面（8.25）30分钟（负）",charIndex:3785},{level:3,title:"13. 淘天一面（8.26）50分钟（胜）",slug:"_13-淘天一面-8-26-50分钟-胜",normalizedTitle:"13. 淘天一面（8.26）50分钟（胜）",charIndex:3892},{level:3,title:"14. 得物一面（8.27）30分钟（胜）",slug:"_14-得物一面-8-27-30分钟-胜",normalizedTitle:"14. 得物一面（8.27）30分钟（胜）",charIndex:4336},{level:3,title:"15. 快手三面（8.28）60分钟",slug:"_15-快手三面-8-28-60分钟",normalizedTitle:"15. 快手三面（8.28）60分钟",charIndex:4573},{level:3,title:"16. 美团二面（8.28）60分钟（负）",slug:"_16-美团二面-8-28-60分钟-负",normalizedTitle:"16. 美团二面（8.28）60分钟（负）",charIndex:4803},{level:3,title:"17. 字节三面（8.31）35分钟（恶心）",slug:"_17-字节三面-8-31-35分钟-恶心",normalizedTitle:"17. 字节三面（8.31）35分钟（恶心）",charIndex:5036},{level:3,title:"18. 淘天二面（9.2）40分钟（负）",slug:"_18-淘天二面-9-2-40分钟-负",normalizedTitle:"18. 淘天二面（9.2）40分钟（负）",charIndex:5079},{level:3,title:"19. 得物二面（9.2）20分钟（胜）",slug:"_19-得物二面-9-2-20分钟-胜",normalizedTitle:"19. 得物二面（9.2）20分钟（胜）",charIndex:5104},{level:3,title:"20. 得物三面（9.3）20分钟",slug:"_20-得物三面-9-3-20分钟",normalizedTitle:"20. 得物三面（9.3）20分钟",charIndex:5129},{level:3,title:"21. 讯飞一面（9.5）40分钟",slug:"_21-讯飞一面-9-5-40分钟",normalizedTitle:"21. 讯飞一面（9.5）40分钟",charIndex:5151},{level:3,title:"22. 唯品会一面（9.5）60分钟",slug:"_22-唯品会一面-9-5-60分钟",normalizedTitle:"22. 唯品会一面（9.5）60分钟",charIndex:5173}],headersStr:"00. 万得一面（7.10）70分钟（负） 01. 用友一面（7.27）60分钟（胜） 02. 用友二面（8.02）40分钟（负） 03. 快手一面（8.08）60分钟（胜） 04. 快手二面（8.15）60分钟（胜） 05. 京东一面（8.16）53分钟（？） 06. 腾讯一面（8.18）70分钟（负） 07. 字节一面（8.21）57分钟（胜） 08. 京东一面（8.23）35 分钟（胜） 09. 联想一面（8.24）30分钟（负） 10. 字节二面（8.24）70分钟（胜） 11. 美团一面（8.24）70分钟（胜） 12. 京东二面（8.25）30分钟（负） 13. 淘天一面（8.26）50分钟（胜） 14. 得物一面（8.27）30分钟（胜） 15. 快手三面（8.28）60分钟 16. 美团二面（8.28）60分钟（负） 17. 字节三面（8.31）35分钟（恶心） 18. 淘天二面（9.2）40分钟（负） 19. 得物二面（9.2）20分钟（胜） 20. 得物三面（9.3）20分钟 21. 讯飞一面（9.5）40分钟 22. 唯品会一面（9.5）60分钟",content:'# 00. 万得一面（7.10）70分钟（负）\n\n\n# 01. 用友一面（7.27）60分钟（胜）\n\n 1.  自我介绍\n\n 2.  集合类有哪些\n\n 3.  这些集合是线程安全吗\n\n 4.  HashMap底层原理\n\n 5.  为什么不用头插法\n\n 6.  用了尾插法就线程安全了吗\n\n 7.  保证线程安全几种方式\n\n 8.  Synchronized锁升级过程\n\n 9.  ThreadLocal原理\n\n 10. ThreadLocal需要注意的地方\n\n 11. volatile作用\n\n 12. volatile原理\n\n 13. 缓存和主存在操作系统\\CPU怎么弄的(MESI)\n\n 14. 垃圾回收有哪些回收算法\n\n 15. 从哪些对象开始标记\n\n 16. 三色标记法\n\n 17. CMS和G1收集器收集过程\n\n 18. G1中为什么划分Region\n\n 19. Redis有哪些数据结构\n\n 20. Redis怎么给Hash中单独的key设置过期时间\n\n 21. AOF和RDB\n\n 22. Redis字符串底层和查询过程用的哪些数据结构\n\n 23. RabbitMQ和Kafka原理机制是什么\n\n 24. RabbitMQ和Kafka怎么不丢失数据\n\n 25. MySQL索引一般怎么用\n\n 26. 有哪几种索引\n\n 27. undo log 和 redo log用来干啥的\n\n 28. 说说数据页\n\n 29. 介绍一下项目,以及难点怎么解决\n\n 30. 聊天\n\n\n# 02. 用友二面（8.02）40分钟（负）\n\n两个面试官聊项目，二级缓存，Redis，消息中间件可靠性\n\n\n# 03. 快手一面（8.08）60分钟（胜）\n\n 1. 自我介绍\n 2. 授权怎么实现\n 3. 过滤器和拦截器区别，使用场景\n 4. Redis怎么用，一些底层数据结构\n 5. Kafka原理\n 6. ThreadLocal原理\n 7. volatile作用\n 8. 手撕\n    1. 单例模式\n    2. 两个整数，输出a/b循环小数部分，例如0.1234234234，输出234。（这题写了25分钟）\n 9. 反问\n\n刚好一小时。\n\n\n# 04. 快手二面（8.15）60分钟（胜）\n\n 1.  项目介绍\n\n 2.  表怎么设计的\n\n 3.  ab ac两个联合索引\n     \n     1. select * from t where a = 3;用哪个索引\n     2. select b from t where a = 3;用哪个索引\n\n 4.  主从复制\n\n 5.  在什么系统部署的\n\n 6.  linux常用命令，查看进程命令。查看占用\n\n 7.  部署占用内存设置多少\n\n 8.  指定了哪个垃圾回收器\n\n 9.  G1和CMS区别，mixedGC什么时候触发\n\n 10. 线程池参数，具体表示什么\n\n 11. 关闭线程池怎么关闭\n\n 12. 怎么查看GC情况\n\n 13. zset做排行，key，value怎么设计\n\n 14. 然后挑牛角尖，你项目干啥\n\n 15. zset底层数据结构，介绍一下跳表\n\n 16. 介绍一下Raft，为啥做这个，介绍一下RocksDB\n\n 17. 1万亿个元素，怎么排序\n\n 18. 浏览器输入一个网址过程\n     \n     （45 mins）\n\n 19. 手撕\n     \n     1. 两两交换链表\n     2. 二叉树统计根到叶子节点的所有路径和\n\n 20. 反问\n\n(1 h)\n\n\n# 05. 京东一面（8.16）53分钟（？）\n\n 1.  自我介绍\n 2.  详细介绍其中一个项目\n 3.  收获了什么\n 4.  Zset内部实现\n 5.  B+树用在什么地方\n 6.  介绍Raft算法，为什么实现这个Raft算法\n 7.  手撕\n     1. 字符串数字加法\n     2. 滑动窗口最大值\n 8.  Java里优先队列，List的实现类有哪些，线程安全吗，有线程安全的List的吗\n 9.  LinkedList的一些api的时间复杂度，对于有序的链表，能加快查询吗\n 10. 用户在你的项目站点上发起一个请求之后会发生什么\n 11. 你熟悉这么多种数据库，你总结一下他们的应用场景\n 12. 你哪里人，为什么来北京\n 13. 参加过什么社团\n\n\n# 06. 腾讯一面（8.18）70分钟（负）\n\n 1. 手撕\n    1. 判断单链表是否有环\n    2. LRU缓存\n    3. 有序矩阵中第K小的元素\n 2. 你实现的Raft有应用到实际场景吗，你怎么判断测试\n 3. Raft和Paxos的区别\n 4. 实现Raft有什么棘手的问题\n 5. 分布式事务中，共识算法有什么用处\n 6. MySQL是怎么实现单机的事务\n 7. 介绍一下MySQL索引，B+树有什么好处\n\n\n# 07. 字节一面（8.21）57分钟（胜）\n\n 1.  死扣项目\n 2.  表设计了哪些\n 3.  TCP三次握手\n 4.  HTTP状态码\n 5.  阻塞IO与非阻塞IO\n 6.  IO多路复用\n 7.  Redis使用场景\n 8.  RDB和AOF区别，优缺点\n 9.  MQ作用\n 10. 消费失败怎么处理\n 11. 幂等怎么做\n 12. B+树和B树区别，优缺点\n 13. 回表\n 14. Spring IOC和AOP原理\n 15. 为什么不都用Cglib来做动态代理\n 16. 手撕\n     1. 查询里有如下这些，问怎么创建索引\n        1. where a = xx;\n        2. where b = xx;\n        3. where c = xx;\n        4. where a = xx and b = xx and c = xx;\n     2. 写SQL，学生表，成绩表。查出所有总分低于100的男生\n     3. 判断两个二叉树是否翻转等价。翻转左右孩子\n\n\n# 08. 京东一面（8.23）35 分钟（胜）\n\n 1.  自我介绍\n 2.  详细介绍Raft算法，有哪些开源算法使用这个算法，详细怎么使用的\n 3.  闲聊非技术问题\n     1. 问有没有实习，实验室是否有项目\n     2. 为什么选择后端开发，职业规划偏向工程开发，还是数据方向\n     3. 聊我的研究方向（三维重建），介绍我的研究点\n     4. 做这个遇到了什么困难，怎么解决的\n     5. 对自己的认识，优缺点\n 4.  讲一下面向对象和面向过程，有什么应用场景\n 5.  面向对象的三大特性\n 6.  介绍两种设计模式\n 7.  介绍一下Spring\n 8.  AOP有什么应用场景\n 9.  给你设计一个服务，有用户的信息，需要存到这个服务中，然后也提供查询功能，讲一下你的设计，思考的点。\n 10. 反问\n\n\n# 09. 联想一面（8.24）30分钟（负）\n\n 1. 自我介绍\n 2. 闲聊，有实习吗，又聊三维重建\n 3. 共享屏幕，展示一下你的项目，没有。然后又讲了一下去年的数学建模竞赛，去网上下载了一份题目。介绍了一下分工\n 4. 说GitHub有代码吗，下载了一份打开讲，对着代码讲。挑刺，为什么起这个类名，为什么说MySQL查询慢，说我这个数据量，就算MySQL查也很快，没必要缓存\n 5. 反问\n\n\n# 10. 字节二面（8.24）70分钟（胜）\n\n 1.  自我介绍\n 2.  详细问其中一个项目的实现细节\n 3.  认证授权过程详细介绍一下，jwt组成部分，jwt要注意哪些问题\n 4.  Kafka消息投递有什么特点\n 5.  kafka消息的消费顺序性\n 6.  介绍一下其它类似的MQ，区别\n 7.  手撕，会议室2\n 8.  要访问一个站点，介绍一下访问的过程，常见的负载均衡策略，域名解析过程\n 9.  现在用的IPv4，为什么要推广IPv6\n 10. 给一个场景，假如你是一个视频网站的后台维护人员，发现前一天的播放量骤减。讲一下你的排查思路\n 11. 最近看了什么技术的书，以后的技术方向\n\n\n# 11. 美团一面（8.24）70分钟（胜）\n\n 1.  自我介绍\n 2.  闲聊，研究方向\n 3.  讲一个你项目中的亮点，有什么讲究的点\n 4.  假设你这个QPS不是要提升到4000了，要提升到4w，你有什么优化方法\n 5.  为什么用Jwt，有其它登录凭证保存方式吗\n 6.  Jwt这个冒用，盗号，怎么解决\n 7.  数组和链表优缺点\n 8.  String是不是基本类型，可以被继承吗。用new创建，和""有什么区别\n 9.  保证线程安全有什么方法\n 10. Java里偏向锁，轻量级锁，重量级锁介绍一下\n 11. full GC触发条件\n 12. 动态规划和分治有什么异同，什么情况必须用动态规划\n 13. Redis一致性哈希算法介绍一下\n 14. tcp和udp特点\n 15. cookie和session区别\n 16. 事务的隔离级别，有什么区别\n 17. 手撕，重排链表\n 18. 反问\n\n\n# 12. 京东二面（8.25）30分钟（负）\n\n 1. 自我介绍\n 2. 你的职业规划是什么，怎么做到呢\n 3. 你最想去前三个的公司\n 4. 手撕，给一个数组，用三个线程轮流去读数组中的元素\n 5. 反问\n\n\n# 13. 淘天一面（8.26）50分钟（胜）\n\n 1.  自我介绍\n 2.  介绍项目实现的一个难点亮点\n 3.  介绍kafka架构\n 4.  消息投递有且仅有一次语义是怎么实现的\n 5.  Kafka扩展broker过程\n 6.  负载均衡有哪几种\n 7.  kafka消费消息的实时性怎么样\n 8.  kafka短轮询有哪些优化方法\n 9.  实现长轮询，在五层网络中，是怎么个过程\n 10. jdk8到jdk20的，说一下新特性\n 11. jdk21虚拟线程和线程有什么区别\n 12. 要你实现Java的虚拟线程，你觉得有什么难点\n 13. Java8和Java9的类加载机制有什么区别\n 14. 类加载机制主要在哪些场景，OSGI了解么\n 15. 介绍一下IOC和AOP概念，原理\n 16. Java像Go那样，编译成exe了解么\n 17. 说一个你熟悉的地方吧（数据库），MySQL事务是怎么实现的\n 18. 闲聊，为什么做后端，人工智能热点风口怎么看\n 19. 反问\n\n\n# 14. 得物一面（8.27）30分钟（胜）\n\n 1.  自我介绍\n 2.  介绍一下Tcp/ip协议，各个层\n 3.  加密安全传输怎么做\n 4.  面向对象相比面向过程有什么好处\n 5.  里氏替换原则\n 6.  有哪些树的数据结构，分别什么场景\n 7.  多线程用么，为什么用线程池呢，要注意哪些东西\n 8.  什么是线程安全，怎么保证线程安全\n 9.  Spring IOC和DI有什么区别\n 10. 了解哪些MQ，缓存，数据库，分别什么场景\n 11. 反问\n\n\n# 15. 快手三面（8.28）60分钟\n\n 1. 自我介绍\n 2. 闲聊\n 3. 细问简历中的项目，用了InfluxDB，为什么InfluxDB查询快\n 4. 让你排查QPS的瓶颈，怎么排查\n 5. 点赞系统，点赞怎么做的啊\n 6. 你MySQL用用户ID分库分表，那假如你要一个查一个帖子，被谁点赞了，你怎么做\n 7. 老家是哪的，为什么想来快手，对未来有什么打算\n 8. 手撕，给你一个回文数，返回他下一个回文数。121，下一个131\n 9. 反问\n\n\n# 16. 美团二面（8.28）60分钟（负）\n\n 1.  自我介绍\n 2.  细问项目，为什么用kafka，用kafka遇到什么问题吗\n 3.  主态和客态怎么做\n 4.  为什么用InfluxDB\n 5.  什么是IO多路复用，那三种有什么区别，边缘触发还是水平触发\n 6.  为什么用Caffeine\n 7.  投屏看一下你的成果，打开github看了看截图\n 8.  MySQL索引怎么建的\n 9.  http1.1，2.0，3.0区别\n 10. 闲聊\n\n\n# 17. 字节三面（8.31）35分钟（恶心）\n\n吊儿郎当，叼着牙签，目中无人\n\n\n# 18. 淘天二面（9.2）40分钟（负）\n\n\n# 19. 得物二面（9.2）20分钟（胜）\n\n\n# 20. 得物三面（9.3）20分钟\n\n\n# 21. 讯飞一面（9.5）40分钟\n\n\n# 22. 唯品会一面（9.5）60分钟',normalizedContent:'# 00. 万得一面（7.10）70分钟（负）\n\n\n# 01. 用友一面（7.27）60分钟（胜）\n\n 1.  自我介绍\n\n 2.  集合类有哪些\n\n 3.  这些集合是线程安全吗\n\n 4.  hashmap底层原理\n\n 5.  为什么不用头插法\n\n 6.  用了尾插法就线程安全了吗\n\n 7.  保证线程安全几种方式\n\n 8.  synchronized锁升级过程\n\n 9.  threadlocal原理\n\n 10. threadlocal需要注意的地方\n\n 11. volatile作用\n\n 12. volatile原理\n\n 13. 缓存和主存在操作系统\\cpu怎么弄的(mesi)\n\n 14. 垃圾回收有哪些回收算法\n\n 15. 从哪些对象开始标记\n\n 16. 三色标记法\n\n 17. cms和g1收集器收集过程\n\n 18. g1中为什么划分region\n\n 19. redis有哪些数据结构\n\n 20. redis怎么给hash中单独的key设置过期时间\n\n 21. aof和rdb\n\n 22. redis字符串底层和查询过程用的哪些数据结构\n\n 23. rabbitmq和kafka原理机制是什么\n\n 24. rabbitmq和kafka怎么不丢失数据\n\n 25. mysql索引一般怎么用\n\n 26. 有哪几种索引\n\n 27. undo log 和 redo log用来干啥的\n\n 28. 说说数据页\n\n 29. 介绍一下项目,以及难点怎么解决\n\n 30. 聊天\n\n\n# 02. 用友二面（8.02）40分钟（负）\n\n两个面试官聊项目，二级缓存，redis，消息中间件可靠性\n\n\n# 03. 快手一面（8.08）60分钟（胜）\n\n 1. 自我介绍\n 2. 授权怎么实现\n 3. 过滤器和拦截器区别，使用场景\n 4. redis怎么用，一些底层数据结构\n 5. kafka原理\n 6. threadlocal原理\n 7. volatile作用\n 8. 手撕\n    1. 单例模式\n    2. 两个整数，输出a/b循环小数部分，例如0.1234234234，输出234。（这题写了25分钟）\n 9. 反问\n\n刚好一小时。\n\n\n# 04. 快手二面（8.15）60分钟（胜）\n\n 1.  项目介绍\n\n 2.  表怎么设计的\n\n 3.  ab ac两个联合索引\n     \n     1. select * from t where a = 3;用哪个索引\n     2. select b from t where a = 3;用哪个索引\n\n 4.  主从复制\n\n 5.  在什么系统部署的\n\n 6.  linux常用命令，查看进程命令。查看占用\n\n 7.  部署占用内存设置多少\n\n 8.  指定了哪个垃圾回收器\n\n 9.  g1和cms区别，mixedgc什么时候触发\n\n 10. 线程池参数，具体表示什么\n\n 11. 关闭线程池怎么关闭\n\n 12. 怎么查看gc情况\n\n 13. zset做排行，key，value怎么设计\n\n 14. 然后挑牛角尖，你项目干啥\n\n 15. zset底层数据结构，介绍一下跳表\n\n 16. 介绍一下raft，为啥做这个，介绍一下rocksdb\n\n 17. 1万亿个元素，怎么排序\n\n 18. 浏览器输入一个网址过程\n     \n     （45 mins）\n\n 19. 手撕\n     \n     1. 两两交换链表\n     2. 二叉树统计根到叶子节点的所有路径和\n\n 20. 反问\n\n(1 h)\n\n\n# 05. 京东一面（8.16）53分钟（？）\n\n 1.  自我介绍\n 2.  详细介绍其中一个项目\n 3.  收获了什么\n 4.  zset内部实现\n 5.  b+树用在什么地方\n 6.  介绍raft算法，为什么实现这个raft算法\n 7.  手撕\n     1. 字符串数字加法\n     2. 滑动窗口最大值\n 8.  java里优先队列，list的实现类有哪些，线程安全吗，有线程安全的list的吗\n 9.  linkedlist的一些api的时间复杂度，对于有序的链表，能加快查询吗\n 10. 用户在你的项目站点上发起一个请求之后会发生什么\n 11. 你熟悉这么多种数据库，你总结一下他们的应用场景\n 12. 你哪里人，为什么来北京\n 13. 参加过什么社团\n\n\n# 06. 腾讯一面（8.18）70分钟（负）\n\n 1. 手撕\n    1. 判断单链表是否有环\n    2. lru缓存\n    3. 有序矩阵中第k小的元素\n 2. 你实现的raft有应用到实际场景吗，你怎么判断测试\n 3. raft和paxos的区别\n 4. 实现raft有什么棘手的问题\n 5. 分布式事务中，共识算法有什么用处\n 6. mysql是怎么实现单机的事务\n 7. 介绍一下mysql索引，b+树有什么好处\n\n\n# 07. 字节一面（8.21）57分钟（胜）\n\n 1.  死扣项目\n 2.  表设计了哪些\n 3.  tcp三次握手\n 4.  http状态码\n 5.  阻塞io与非阻塞io\n 6.  io多路复用\n 7.  redis使用场景\n 8.  rdb和aof区别，优缺点\n 9.  mq作用\n 10. 消费失败怎么处理\n 11. 幂等怎么做\n 12. b+树和b树区别，优缺点\n 13. 回表\n 14. spring ioc和aop原理\n 15. 为什么不都用cglib来做动态代理\n 16. 手撕\n     1. 查询里有如下这些，问怎么创建索引\n        1. where a = xx;\n        2. where b = xx;\n        3. where c = xx;\n        4. where a = xx and b = xx and c = xx;\n     2. 写sql，学生表，成绩表。查出所有总分低于100的男生\n     3. 判断两个二叉树是否翻转等价。翻转左右孩子\n\n\n# 08. 京东一面（8.23）35 分钟（胜）\n\n 1.  自我介绍\n 2.  详细介绍raft算法，有哪些开源算法使用这个算法，详细怎么使用的\n 3.  闲聊非技术问题\n     1. 问有没有实习，实验室是否有项目\n     2. 为什么选择后端开发，职业规划偏向工程开发，还是数据方向\n     3. 聊我的研究方向（三维重建），介绍我的研究点\n     4. 做这个遇到了什么困难，怎么解决的\n     5. 对自己的认识，优缺点\n 4.  讲一下面向对象和面向过程，有什么应用场景\n 5.  面向对象的三大特性\n 6.  介绍两种设计模式\n 7.  介绍一下spring\n 8.  aop有什么应用场景\n 9.  给你设计一个服务，有用户的信息，需要存到这个服务中，然后也提供查询功能，讲一下你的设计，思考的点。\n 10. 反问\n\n\n# 09. 联想一面（8.24）30分钟（负）\n\n 1. 自我介绍\n 2. 闲聊，有实习吗，又聊三维重建\n 3. 共享屏幕，展示一下你的项目，没有。然后又讲了一下去年的数学建模竞赛，去网上下载了一份题目。介绍了一下分工\n 4. 说github有代码吗，下载了一份打开讲，对着代码讲。挑刺，为什么起这个类名，为什么说mysql查询慢，说我这个数据量，就算mysql查也很快，没必要缓存\n 5. 反问\n\n\n# 10. 字节二面（8.24）70分钟（胜）\n\n 1.  自我介绍\n 2.  详细问其中一个项目的实现细节\n 3.  认证授权过程详细介绍一下，jwt组成部分，jwt要注意哪些问题\n 4.  kafka消息投递有什么特点\n 5.  kafka消息的消费顺序性\n 6.  介绍一下其它类似的mq，区别\n 7.  手撕，会议室2\n 8.  要访问一个站点，介绍一下访问的过程，常见的负载均衡策略，域名解析过程\n 9.  现在用的ipv4，为什么要推广ipv6\n 10. 给一个场景，假如你是一个视频网站的后台维护人员，发现前一天的播放量骤减。讲一下你的排查思路\n 11. 最近看了什么技术的书，以后的技术方向\n\n\n# 11. 美团一面（8.24）70分钟（胜）\n\n 1.  自我介绍\n 2.  闲聊，研究方向\n 3.  讲一个你项目中的亮点，有什么讲究的点\n 4.  假设你这个qps不是要提升到4000了，要提升到4w，你有什么优化方法\n 5.  为什么用jwt，有其它登录凭证保存方式吗\n 6.  jwt这个冒用，盗号，怎么解决\n 7.  数组和链表优缺点\n 8.  string是不是基本类型，可以被继承吗。用new创建，和""有什么区别\n 9.  保证线程安全有什么方法\n 10. java里偏向锁，轻量级锁，重量级锁介绍一下\n 11. full gc触发条件\n 12. 动态规划和分治有什么异同，什么情况必须用动态规划\n 13. redis一致性哈希算法介绍一下\n 14. tcp和udp特点\n 15. cookie和session区别\n 16. 事务的隔离级别，有什么区别\n 17. 手撕，重排链表\n 18. 反问\n\n\n# 12. 京东二面（8.25）30分钟（负）\n\n 1. 自我介绍\n 2. 你的职业规划是什么，怎么做到呢\n 3. 你最想去前三个的公司\n 4. 手撕，给一个数组，用三个线程轮流去读数组中的元素\n 5. 反问\n\n\n# 13. 淘天一面（8.26）50分钟（胜）\n\n 1.  自我介绍\n 2.  介绍项目实现的一个难点亮点\n 3.  介绍kafka架构\n 4.  消息投递有且仅有一次语义是怎么实现的\n 5.  kafka扩展broker过程\n 6.  负载均衡有哪几种\n 7.  kafka消费消息的实时性怎么样\n 8.  kafka短轮询有哪些优化方法\n 9.  实现长轮询，在五层网络中，是怎么个过程\n 10. jdk8到jdk20的，说一下新特性\n 11. jdk21虚拟线程和线程有什么区别\n 12. 要你实现java的虚拟线程，你觉得有什么难点\n 13. java8和java9的类加载机制有什么区别\n 14. 类加载机制主要在哪些场景，osgi了解么\n 15. 介绍一下ioc和aop概念，原理\n 16. java像go那样，编译成exe了解么\n 17. 说一个你熟悉的地方吧（数据库），mysql事务是怎么实现的\n 18. 闲聊，为什么做后端，人工智能热点风口怎么看\n 19. 反问\n\n\n# 14. 得物一面（8.27）30分钟（胜）\n\n 1.  自我介绍\n 2.  介绍一下tcp/ip协议，各个层\n 3.  加密安全传输怎么做\n 4.  面向对象相比面向过程有什么好处\n 5.  里氏替换原则\n 6.  有哪些树的数据结构，分别什么场景\n 7.  多线程用么，为什么用线程池呢，要注意哪些东西\n 8.  什么是线程安全，怎么保证线程安全\n 9.  spring ioc和di有什么区别\n 10. 了解哪些mq，缓存，数据库，分别什么场景\n 11. 反问\n\n\n# 15. 快手三面（8.28）60分钟\n\n 1. 自我介绍\n 2. 闲聊\n 3. 细问简历中的项目，用了influxdb，为什么influxdb查询快\n 4. 让你排查qps的瓶颈，怎么排查\n 5. 点赞系统，点赞怎么做的啊\n 6. 你mysql用用户id分库分表，那假如你要一个查一个帖子，被谁点赞了，你怎么做\n 7. 老家是哪的，为什么想来快手，对未来有什么打算\n 8. 手撕，给你一个回文数，返回他下一个回文数。121，下一个131\n 9. 反问\n\n\n# 16. 美团二面（8.28）60分钟（负）\n\n 1.  自我介绍\n 2.  细问项目，为什么用kafka，用kafka遇到什么问题吗\n 3.  主态和客态怎么做\n 4.  为什么用influxdb\n 5.  什么是io多路复用，那三种有什么区别，边缘触发还是水平触发\n 6.  为什么用caffeine\n 7.  投屏看一下你的成果，打开github看了看截图\n 8.  mysql索引怎么建的\n 9.  http1.1，2.0，3.0区别\n 10. 闲聊\n\n\n# 17. 字节三面（8.31）35分钟（恶心）\n\n吊儿郎当，叼着牙签，目中无人\n\n\n# 18. 淘天二面（9.2）40分钟（负）\n\n\n# 19. 得物二面（9.2）20分钟（胜）\n\n\n# 20. 得物三面（9.3）20分钟\n\n\n# 21. 讯飞一面（9.5）40分钟\n\n\n# 22. 唯品会一面（9.5）60分钟',charsets:{cjk:!0}},{title:"FlashFusion论文阅读",frontmatter:{title:"FlashFusion论文阅读",date:"2022-04-08T11:01:06.000Z",permalink:"/pages/a2be9b/"},regularPath:"/02.%E7%A7%91%E7%A0%94/01.%E5%AE%A4%E5%86%85%E5%AE%9E%E6%97%B6%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/07.FlashFusion%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB.html",relativePath:"02.科研/01.室内实时三维重建/07.FlashFusion论文阅读.md",key:"v-46223bf5",path:"/pages/a2be9b/",headers:[{level:3,title:"Robust Global Consistent Localization",slug:"robust-global-consistent-localization",normalizedTitle:"robust global consistent localization",charIndex:2},{level:3,title:"Efficient TSDF Fusion",slug:"efficient-tsdf-fusion",normalizedTitle:"efficient tsdf fusion",charIndex:112}],headersStr:"Robust Global Consistent Localization Efficient TSDF Fusion",content:"# Robust Global Consistent Localization\n\n局部对齐 当前帧和上一个关键帧进行ORB特征匹配对齐。\n\n全局对齐 如果当前帧是关键帧，则与历史所有的关键帧进行ORB特征匹配对齐。\n\n\n# Efficient TSDF Fusion\n\n一般的TSDF模型需要融合当前视锥下所有体素。通过分析可知，对表面真正有效的体素只有黄色部分，现在想办法就提取出黄色部分的体素进行融合即可加快时间。\n\n",normalizedContent:"# robust global consistent localization\n\n局部对齐 当前帧和上一个关键帧进行orb特征匹配对齐。\n\n全局对齐 如果当前帧是关键帧，则与历史所有的关键帧进行orb特征匹配对齐。\n\n\n# efficient tsdf fusion\n\n一般的tsdf模型需要融合当前视锥下所有体素。通过分析可知，对表面真正有效的体素只有黄色部分，现在想办法就提取出黄色部分的体素进行融合即可加快时间。\n\n",charsets:{cjk:!0}},{title:"Surfel Meshing",frontmatter:{title:"Surfel Meshing",date:"2022-04-19T11:01:06.000Z",permalink:"/pages/7bbbf3/"},regularPath:"/02.%E7%A7%91%E7%A0%94/01.%E5%AE%A4%E5%86%85%E5%AE%9E%E6%97%B6%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/03.Surfel%20Meshing%20.html",relativePath:"02.科研/01.室内实时三维重建/03.Surfel Meshing .md",key:"v-4ae78607",path:"/pages/7bbbf3/",headers:[{level:3,title:"一、Surfel Reconstruction",slug:"一、surfel-reconstruction",normalizedTitle:"一、surfel reconstruction",charIndex:312},{level:4,title:"Surfel s表示",slug:"surfel-s表示",normalizedTitle:"surfel s表示",charIndex:514},{level:4,title:"数据关联。",slug:"数据关联。",normalizedTitle:"数据关联。",charIndex:591},{level:4,title:"测量融合",slug:"测量融合",normalizedTitle:"测量融合",charIndex:901},{level:4,title:"回环检测",slug:"回环检测",normalizedTitle:"回环检测",charIndex:479},{level:3,title:"二、Surfel Denosing",slug:"二、surfel-denosing",normalizedTitle:"二、surfel denosing",charIndex:1182},{level:4,title:"Regularization",slug:"regularization",normalizedTitle:"regularization",charIndex:1276},{level:4,title:"Observation Boundary Blending",slug:"observation-boundary-blending",normalizedTitle:"observation boundary blending",charIndex:1454},{level:3,title:"Meshing",slug:"meshing",normalizedTitle:"meshing",charIndex:1593},{level:4,title:"Spatial access",slug:"spatial-access",normalizedTitle:"spatial access",charIndex:1676},{level:4,title:"Triangulation",slug:"triangulation",normalizedTitle:"triangulation",charIndex:1756},{level:3,title:"Remeshing",slug:"remeshing",normalizedTitle:"remeshing",charIndex:2249},{level:4,title:"识别步骤",slug:"识别步骤",normalizedTitle:"识别步骤",charIndex:2424}],headersStr:"一、Surfel Reconstruction Surfel s表示 数据关联。 测量融合 回环检测 二、Surfel Denosing Regularization Observation Boundary Blending Meshing Spatial access Triangulation Remeshing 识别步骤",content:"# Surfel-Based Mesh Reconstruction\n\n该算法是输入是RGB-D图像流，和通过SLAM系统求出的相机位姿（ElasticFusion），该算法由四大部分组成\n\nsurfel reconstruction，采用ElasticFusion的方式进行面元重建；\n\nsurfel denoising，创新点；\n\nmeshing，采用A fast and efficient projection-based approach for surface reconstruction类似方法；\n\nremeshing，创新点。\n\n前两部分主要是对点云进行处理，后两部分主要是对点云进行网格三角化。\n\n\n# 一、Surfel Reconstruction\n\n我们的算法是对一个surfel cloud进行三角划分。为重建出这些cloud，我们采用ElasticFusion，以下阐述这种算法以及我们的修改。\n\n从RGB-D图像输入流中，新来一帧图像时，数据关联步骤会决定深度测量值是创建一个新的surfel还是用来修正已有的surfel。对于回环检测部分，surfel cloud会变形对齐到匹配的表面。\n\n# Surfel s表示\n\n坐标颜色法向量置信度半径创建时间最后更新时间{Ps坐标cs颜色ns法向量σs置信度rs半径ts,0创建时间ts最后更新时间\n\n# 数据关联。\n\n~~类似于[24]，我们投影surfels到当前帧图像，决定哪个深度测量值关联已存在的surfels。为了决定哪个surfel投影到哪个pixel，[24]创建了一种super-sampled 索引图来渲染所有surfels， 但仍然受限于分辨率。我们通过始终直接从投影操作的结果中获取面元索引来改进这一点。 对于获取数据关联，~~每个surfel针对投影到像素，以及这个像素相邻像素进行评估，使用一个简单模型，测量深度为z，对于离这个像素距离在[(1−γ)z,(1+γ)z]内的surfel，称为支持sufel，在小于区间的最小值，称为冲突surfel，大于区间的最大值，则称为占用surfel。\n\n# 测量融合\n\n我们为没有关联到冲突surfel或者支持surfel的像素点创建一个新的surfel。初始化surfel的值，半径r由下式计算，p(x,y)是像素点(x,y)对应的3D坐标。\n\n\n\n在图像空间中半径内的像素作为直接邻居，进而推算出3D空间中surfel的邻居以及与邻居的距离。\n\n像[24]那样融合当前surfel，不同的是我们将其融合到支持surfels中，将当前的surfel与每个支持的surfel使用下式进行加权平均。权重ω由所有支持surfels个数的倒数。\n\n# 回环检测\n\n该部分和ElasticFusion中的回环检测相似。\n\n\n# 二、Surfel Denosing\n\n尽管在融合surfel时用的加权平均，但在surfel还是存在很多噪声，在融合深度图的边界可能出现不连续的点，我们使用混合的方式处理这个问题。\n\n# Regularization\n\n正则化的目的是保持一个平滑的surfel，减少与邻近的surfel之间的噪声。对surfel的结构进行扩展，ps,四个邻居surfel的下标索引Ns，用来加速计算梯度临时存储。每个面元的降噪后的位置取决于邻居的降噪后的位置，邻居又取决于邻居的邻居，以此类推。\n\n通过优化两个误差项，来更新surfel的位置和法向量。\n\n# Observation Boundary Blending\n\n使用算法1，来避免，在优化之后，出现观察和没观察的边界之间不连续的情况。\n\n\n\n按照算法1流程，将灰色的点的深度线性靠近到黑色表面。\n\n\n\n最后使用icp将之前重建好的点（黑色）对齐到当前的点（灰色）。\n\n\n\n\n# Meshing\n\n我们需要一个非常快的尺度无关的网格算法，来对数百万surfel进行三角网格化。对于meshing网格化使用[22]、[23]，并作小的修改。\n\n# Spatial access\n\n网格划分算法需要快速准确地找到一个surfel半径内所有其他surfel。因此需要一个空间访问结构。使用八叉树进行存储。\n\n# Triangulation\n\n网格划分算法贪婪地遍历所有surfels，并对每个surfel与它邻近的surfels进行局部三角化，以增加网格。每一个surfel有三种状态，\n\n 1. free 没有附带三角形。\n 2. front 在三角网格的边界上。\n 3. completed 在三角网格里。\n\n所有新的surfel都为free状态。算法遍历所有的新的surfel.......\n\n对于遍历到某surfel，使用surfel的半径来进行搜索srufel，如果当前surfel在网格边界上，且边界邻居在半径外，我们就扩展搜索半径为2倍，以包含这些邻居。将所有的邻居surfel投影到当前surfel的切平面上，对于投影后的surfel不可见，或者法向量相差太多，就丢弃该投影。如下图。\n\n\n\n如果当前surfel是free状态，则首先尝试创建一个初始三角形，如下图。\n\n\n\n将当前surfel的所有邻居按角度进行排序，相邻两个邻居之间成为空隙，如果相邻两个邻居之间的夹角过大，则会形成狭窄的三角形，则会丢弃该三角形。\n\n\n\n最后通过三角形填充完所有相邻邻居之间的空隙。\n\n\n\n\n# Remeshing\n\n当surfels移动或创建新的surfels时，网格的现有部分可能会过时，需要有效地更新。对此，我们提出的方法工作在现有网格算法遍历每个网格之前，首先定义一种网格状态，存在一个洞，上图的e，红色部分的三角形，这里不可能生成一个表面，所以最后的渲染结果会存在一个洞，我们首先要识别所有的洞，然后使用网格算法重建那里的表面。\n\n# 识别步骤\n\n对于一个有效的三角形，它至少有一个顶点s，s是包含了s所有搜索半径内的邻居，且法向量相似。\n\n三角形的法向量必须与这个顶点s的在90度内。\n\n在s的切平面，没有其他邻居再投影到这个三角形中，并且这个三角形不会与另一个三角形相交。\n\n\n\n如上红色部分是一个洞，导致周围几个三角形都不是有效的三角形。接下来将这些三角形，以及对应的顶点的三角形都删除，最后再进行上一节中的meshing，就可以重建出有效的比较好的表面。\n\n",normalizedContent:"# surfel-based mesh reconstruction\n\n该算法是输入是rgb-d图像流，和通过slam系统求出的相机位姿（elasticfusion），该算法由四大部分组成\n\nsurfel reconstruction，采用elasticfusion的方式进行面元重建；\n\nsurfel denoising，创新点；\n\nmeshing，采用a fast and efficient projection-based approach for surface reconstruction类似方法；\n\nremeshing，创新点。\n\n前两部分主要是对点云进行处理，后两部分主要是对点云进行网格三角化。\n\n\n# 一、surfel reconstruction\n\n我们的算法是对一个surfel cloud进行三角划分。为重建出这些cloud，我们采用elasticfusion，以下阐述这种算法以及我们的修改。\n\n从rgb-d图像输入流中，新来一帧图像时，数据关联步骤会决定深度测量值是创建一个新的surfel还是用来修正已有的surfel。对于回环检测部分，surfel cloud会变形对齐到匹配的表面。\n\n# surfel s表示\n\n坐标颜色法向量置信度半径创建时间最后更新时间{ps坐标cs颜色ns法向量σs置信度rs半径ts,0创建时间ts最后更新时间\n\n# 数据关联。\n\n~~类似于[24]，我们投影surfels到当前帧图像，决定哪个深度测量值关联已存在的surfels。为了决定哪个surfel投影到哪个pixel，[24]创建了一种super-sampled 索引图来渲染所有surfels， 但仍然受限于分辨率。我们通过始终直接从投影操作的结果中获取面元索引来改进这一点。 对于获取数据关联，~~每个surfel针对投影到像素，以及这个像素相邻像素进行评估，使用一个简单模型，测量深度为z，对于离这个像素距离在[(1−γ)z,(1+γ)z]内的surfel，称为支持sufel，在小于区间的最小值，称为冲突surfel，大于区间的最大值，则称为占用surfel。\n\n# 测量融合\n\n我们为没有关联到冲突surfel或者支持surfel的像素点创建一个新的surfel。初始化surfel的值，半径r由下式计算，p(x,y)是像素点(x,y)对应的3d坐标。\n\n\n\n在图像空间中半径内的像素作为直接邻居，进而推算出3d空间中surfel的邻居以及与邻居的距离。\n\n像[24]那样融合当前surfel，不同的是我们将其融合到支持surfels中，将当前的surfel与每个支持的surfel使用下式进行加权平均。权重ω由所有支持surfels个数的倒数。\n\n# 回环检测\n\n该部分和elasticfusion中的回环检测相似。\n\n\n# 二、surfel denosing\n\n尽管在融合surfel时用的加权平均，但在surfel还是存在很多噪声，在融合深度图的边界可能出现不连续的点，我们使用混合的方式处理这个问题。\n\n# regularization\n\n正则化的目的是保持一个平滑的surfel，减少与邻近的surfel之间的噪声。对surfel的结构进行扩展，ps,四个邻居surfel的下标索引ns，用来加速计算梯度临时存储。每个面元的降噪后的位置取决于邻居的降噪后的位置，邻居又取决于邻居的邻居，以此类推。\n\n通过优化两个误差项，来更新surfel的位置和法向量。\n\n# observation boundary blending\n\n使用算法1，来避免，在优化之后，出现观察和没观察的边界之间不连续的情况。\n\n\n\n按照算法1流程，将灰色的点的深度线性靠近到黑色表面。\n\n\n\n最后使用icp将之前重建好的点（黑色）对齐到当前的点（灰色）。\n\n\n\n\n# meshing\n\n我们需要一个非常快的尺度无关的网格算法，来对数百万surfel进行三角网格化。对于meshing网格化使用[22]、[23]，并作小的修改。\n\n# spatial access\n\n网格划分算法需要快速准确地找到一个surfel半径内所有其他surfel。因此需要一个空间访问结构。使用八叉树进行存储。\n\n# triangulation\n\n网格划分算法贪婪地遍历所有surfels，并对每个surfel与它邻近的surfels进行局部三角化，以增加网格。每一个surfel有三种状态，\n\n 1. free 没有附带三角形。\n 2. front 在三角网格的边界上。\n 3. completed 在三角网格里。\n\n所有新的surfel都为free状态。算法遍历所有的新的surfel.......\n\n对于遍历到某surfel，使用surfel的半径来进行搜索srufel，如果当前surfel在网格边界上，且边界邻居在半径外，我们就扩展搜索半径为2倍，以包含这些邻居。将所有的邻居surfel投影到当前surfel的切平面上，对于投影后的surfel不可见，或者法向量相差太多，就丢弃该投影。如下图。\n\n\n\n如果当前surfel是free状态，则首先尝试创建一个初始三角形，如下图。\n\n\n\n将当前surfel的所有邻居按角度进行排序，相邻两个邻居之间成为空隙，如果相邻两个邻居之间的夹角过大，则会形成狭窄的三角形，则会丢弃该三角形。\n\n\n\n最后通过三角形填充完所有相邻邻居之间的空隙。\n\n\n\n\n# remeshing\n\n当surfels移动或创建新的surfels时，网格的现有部分可能会过时，需要有效地更新。对此，我们提出的方法工作在现有网格算法遍历每个网格之前，首先定义一种网格状态，存在一个洞，上图的e，红色部分的三角形，这里不可能生成一个表面，所以最后的渲染结果会存在一个洞，我们首先要识别所有的洞，然后使用网格算法重建那里的表面。\n\n# 识别步骤\n\n对于一个有效的三角形，它至少有一个顶点s，s是包含了s所有搜索半径内的邻居，且法向量相似。\n\n三角形的法向量必须与这个顶点s的在90度内。\n\n在s的切平面，没有其他邻居再投影到这个三角形中，并且这个三角形不会与另一个三角形相交。\n\n\n\n如上红色部分是一个洞，导致周围几个三角形都不是有效的三角形。接下来将这些三角形，以及对应的顶点的三角形都删除，最后再进行上一节中的meshing，就可以重建出有效的比较好的表面。\n\n",charsets:{cjk:!0}},{title:"kinectFusion",frontmatter:{title:"kinectFusion",date:"2022-03-26T11:01:06.000Z",permalink:"/pages/aa9650/"},regularPath:"/02.%E7%A7%91%E7%A0%94/01.%E5%AE%A4%E5%86%85%E5%AE%9E%E6%97%B6%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/01.kinectFusion.html",relativePath:"02.科研/01.室内实时三维重建/01.kinectFusion.md",key:"v-4b9be2e2",path:"/pages/aa9650/",headers:[{level:3,title:"表面测量",slug:"表面测量",normalizedTitle:"表面测量",charIndex:171},{level:3,title:"表面更新",slug:"表面更新",normalizedTitle:"表面更新",charIndex:394},{level:3,title:"表面预测",slug:"表面预测",normalizedTitle:"表面预测",charIndex:963},{level:3,title:"位姿估计",slug:"位姿估计",normalizedTitle:"位姿估计",charIndex:1190},{level:3,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:1346}],headersStr:"表面测量 表面更新 表面预测 位姿估计 参考",content:"第一篇基于RGB-D相机实时稠密三维重建的论文。\n\n\n\n过程梳理：对于上一帧的最后，生成一个Surface Prediction，当前帧深度图输入，由深度图生成Surface Measurement，通过Surface Prediction和Surface Measurement使用icp进行配准估计位姿，更新和融合全局TSDF。\n\n\n# 表面测量\n\n通过当前原始的深度图生成分层稠密的顶点图和法向量图。\n\n 1. 首先对当前帧的深度图进行双边滤波；\n\n 2. 利用深度图信息生成当前帧的点云图；\n    \n    \n\n 3. 点云图中三个点确定一个平面，利用叉乘算出这个平面的法向量，并归一化。\n    \n    \n\n 4. 对深度图进行分层，最底层是原始的双边滤波深度图，每高一层，用块平均把分辨率降低一半，这里平均的深度是距离中心坐标不超过3σ。然后计算相应的法向量图。\n\n\n# 表面更新\n\n将当前帧生成的表面融合到全局模型中。\n\n对于当前帧深度图，和当前位姿，建图就是通过TSDF融合增量的过程。TSDF模型如下简单介绍，\n\n将要重建的场景放到这个大长方体中，每一个小正方体代表一个体素，每一个体素都有一个TSDF值，和一个权重w。\n\n\n\n现在要做的就是，对计算每一个体素的TSDF值和权重，首先计算SDF等于相机到实际表面的距离减去相机到体素的距离，即体素到表面的距离。如果值为零或者接近零，则这个体素代表实际表面上的点。\n\n\n\nT为截断的意思，SDF值超出一定范围，就将其置正负1。\n\n\n\n论文中每个体素p用距离F和权重W来表示。\n\n深度传感器测量的深度假设有误差正负u，经过光心的射线viewing ray，离相机光心的距离r，当前测量的深度R(u)，如果，r<(λRk(u)−μ)，λ=‖K−1u‖2 ，这个范围里都是空闲空间，这个范围的体素SDF值被截断，反之，则是不可观测到的空间，这个范围的体素不参与融合。\n\n论文中计算距离公式\n\n\n\n解释如下\n\n\n\n体素的权值为cos⁡(θ)/Rk(x)，这里的θ是viewing ray 与 实际表面的夹角。实际发现，将所有权值置为1，也可以有很好的重建结果。\n\n融合公式\n\n\n\n上面计算SDF值时用的深度值是原始深度图的值，而不是使用经过双边滤波后的。\n\n\n# 表面预测\n\n对当前帧生成一个表面。当前时刻的预测图是通过上一时刻构建完成的TSDF模型获得，对于知道当前时刻的位置，通过光线透射方法获得当前时刻相机能够观测的场景，（对当前时刻每个像素发出一条光线，方向是Tg,kK−1u ），遍历这条路径上的体素，存储体素为零的点，或者当体素值从负到正，也停止搜索，对于搜索出来的点，通过下式计算法向量。（曲面该点的法向量由三个方向的偏导数表示）\n\n\n\n预测表面这一步完成一个顶点图（点云图），和对应的法向量。\n\n\n# 位姿估计\n\n对当前帧生成的测量表面与预测表面进行icp配准，估计当前帧的位姿。假设两帧之间的相对运动很小，利用上一帧的位姿作为当前帧的初始值，然后通过初始位姿进行投影，找到测量表面和预测表面之间的数据关联（有深度测量，坐标相近，法向量相近），然后进行点到面的icp。\n\n习以为常的点到面icp误差项\n\n\n\n\n# 参考\n\nhttps://ieeexplore.ieee.org/document/6162880\n\nhttps://blog.csdn.net/fuxingyin/article/details/51417822\n\nhttps://blog.csdn.net/qq_40213457/article/details/82383621?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164566967616780271931390%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=164566967616780271931390&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-4-82383621.pc_search_result_cache&utm_term=tsdf&spm=1018.2226.3001.4187\n\nhttps://zhuanlan.zhihu.com/p/35894630",normalizedContent:"第一篇基于rgb-d相机实时稠密三维重建的论文。\n\n\n\n过程梳理：对于上一帧的最后，生成一个surface prediction，当前帧深度图输入，由深度图生成surface measurement，通过surface prediction和surface measurement使用icp进行配准估计位姿，更新和融合全局tsdf。\n\n\n# 表面测量\n\n通过当前原始的深度图生成分层稠密的顶点图和法向量图。\n\n 1. 首先对当前帧的深度图进行双边滤波；\n\n 2. 利用深度图信息生成当前帧的点云图；\n    \n    \n\n 3. 点云图中三个点确定一个平面，利用叉乘算出这个平面的法向量，并归一化。\n    \n    \n\n 4. 对深度图进行分层，最底层是原始的双边滤波深度图，每高一层，用块平均把分辨率降低一半，这里平均的深度是距离中心坐标不超过3σ。然后计算相应的法向量图。\n\n\n# 表面更新\n\n将当前帧生成的表面融合到全局模型中。\n\n对于当前帧深度图，和当前位姿，建图就是通过tsdf融合增量的过程。tsdf模型如下简单介绍，\n\n将要重建的场景放到这个大长方体中，每一个小正方体代表一个体素，每一个体素都有一个tsdf值，和一个权重w。\n\n\n\n现在要做的就是，对计算每一个体素的tsdf值和权重，首先计算sdf等于相机到实际表面的距离减去相机到体素的距离，即体素到表面的距离。如果值为零或者接近零，则这个体素代表实际表面上的点。\n\n\n\nt为截断的意思，sdf值超出一定范围，就将其置正负1。\n\n\n\n论文中每个体素p用距离f和权重w来表示。\n\n深度传感器测量的深度假设有误差正负u，经过光心的射线viewing ray，离相机光心的距离r，当前测量的深度r(u)，如果，r<(λrk(u)−μ)，λ=‖k−1u‖2 ，这个范围里都是空闲空间，这个范围的体素sdf值被截断，反之，则是不可观测到的空间，这个范围的体素不参与融合。\n\n论文中计算距离公式\n\n\n\n解释如下\n\n\n\n体素的权值为cos⁡(θ)/rk(x)，这里的θ是viewing ray 与 实际表面的夹角。实际发现，将所有权值置为1，也可以有很好的重建结果。\n\n融合公式\n\n\n\n上面计算sdf值时用的深度值是原始深度图的值，而不是使用经过双边滤波后的。\n\n\n# 表面预测\n\n对当前帧生成一个表面。当前时刻的预测图是通过上一时刻构建完成的tsdf模型获得，对于知道当前时刻的位置，通过光线透射方法获得当前时刻相机能够观测的场景，（对当前时刻每个像素发出一条光线，方向是tg,kk−1u ），遍历这条路径上的体素，存储体素为零的点，或者当体素值从负到正，也停止搜索，对于搜索出来的点，通过下式计算法向量。（曲面该点的法向量由三个方向的偏导数表示）\n\n\n\n预测表面这一步完成一个顶点图（点云图），和对应的法向量。\n\n\n# 位姿估计\n\n对当前帧生成的测量表面与预测表面进行icp配准，估计当前帧的位姿。假设两帧之间的相对运动很小，利用上一帧的位姿作为当前帧的初始值，然后通过初始位姿进行投影，找到测量表面和预测表面之间的数据关联（有深度测量，坐标相近，法向量相近），然后进行点到面的icp。\n\n习以为常的点到面icp误差项\n\n\n\n\n# 参考\n\nhttps://ieeexplore.ieee.org/document/6162880\n\nhttps://blog.csdn.net/fuxingyin/article/details/51417822\n\nhttps://blog.csdn.net/qq_40213457/article/details/82383621?ops_request_misc=%257b%2522request%255fid%2522%253a%2522164566967616780271931390%2522%252c%2522scm%2522%253a%252220140713.130102334.pc%255fall.%2522%257d&request_id=164566967616780271931390&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-4-82383621.pc_search_result_cache&utm_term=tsdf&spm=1018.2226.3001.4187\n\nhttps://zhuanlan.zhihu.com/p/35894630",charsets:{cjk:!0}},{title:"BAD_SLAM",frontmatter:{title:"BAD_SLAM",date:"2022-03-28T11:01:06.000Z",permalink:"/pages/24a5f4/"},regularPath:"/02.%E7%A7%91%E7%A0%94/01.%E5%AE%A4%E5%86%85%E5%AE%9E%E6%97%B6%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/06.BAD_SLAM.html",relativePath:"02.科研/01.室内实时三维重建/06.BAD_SLAM.md",key:"v-cb83c1e2",path:"/pages/24a5f4/",headers:[{level:3,title:"介绍",slug:"介绍",normalizedTitle:"介绍",charIndex:2},{level:3,title:"相关工作",slug:"相关工作",normalizedTitle:"相关工作",charIndex:176},{level:4,title:"Frame-to-model tracking",slug:"frame-to-model-tracking",normalizedTitle:"frame-to-model tracking",charIndex:198},{level:4,title:"Map deformation",slug:"map-deformation",normalizedTitle:"map deformation",charIndex:253},{level:4,title:"Pose graph optimization",slug:"pose-graph-optimization",normalizedTitle:"pose graph optimization",charIndex:285},{level:4,title:"Fragment-based optimization",slug:"fragment-based-optimization",normalizedTitle:"fragment-based optimization",charIndex:334},{level:4,title:"Indirect (feature-based) BA",slug:"indirect-feature-based-ba",normalizedTitle:"indirect (feature-based) ba",charIndex:393},{level:4,title:"Direct BA",slug:"direct-ba",normalizedTitle:"direct ba",charIndex:457},{level:4,title:"Benchmarking RGB-D SLAM",slug:"benchmarking-rgb-d-slam",normalizedTitle:"benchmarking rgb-d slam",charIndex:504},{level:3,title:"数据表示",slug:"数据表示",normalizedTitle:"数据表示",charIndex:575},{level:3,title:"损失函数",slug:"损失函数",normalizedTitle:"损失函数",charIndex:730},{level:4,title:"几何误差",slug:"几何误差",normalizedTitle:"几何误差",charIndex:760},{level:4,title:"光度误差",slug:"光度误差",normalizedTitle:"光度误差",charIndex:765},{level:3,title:"算法流程",slug:"算法流程",normalizedTitle:"算法流程",charIndex:1089},{level:4,title:"创建面元",slug:"创建面元",normalizedTitle:"创建面元",charIndex:1097},{level:4,title:"面元与像素点进行关联",slug:"面元与像素点进行关联",normalizedTitle:"面元与像素点进行关联",charIndex:1202},{level:4,title:"外点过滤",slug:"外点过滤",normalizedTitle:"外点过滤",charIndex:1391},{level:4,title:"面元的法向量更新",slug:"面元的法向量更新",normalizedTitle:"面元的法向量更新",charIndex:1534},{level:4,title:"面元的中心位置和描述子优化",slug:"面元的中心位置和描述子优化",normalizedTitle:"面元的中心位置和描述子优化",charIndex:1575},{level:4,title:"面元融合",slug:"面元融合",normalizedTitle:"面元融合",charIndex:1701},{level:4,title:"关键帧的位姿优化",slug:"关键帧的位姿优化",normalizedTitle:"关键帧的位姿优化",charIndex:1798},{level:4,title:"相机内参优化",slug:"相机内参优化",normalizedTitle:"相机内参优化",charIndex:1829},{level:4,title:"面元清理和更新半径",slug:"面元清理和更新半径",normalizedTitle:"面元清理和更新半径",charIndex:1901},{level:3,title:"前端",slug:"前端",normalizedTitle:"前端",charIndex:2009},{level:4,title:"预处理",slug:"预处理",normalizedTitle:"预处理",charIndex:2040},{level:4,title:"里程计",slug:"里程计",normalizedTitle:"里程计",charIndex:2063},{level:4,title:"回环检测",slug:"回环检测",normalizedTitle:"回环检测",charIndex:2120},{level:3,title:"基准数据集",slug:"基准数据集",normalizedTitle:"基准数据集",charIndex:138},{level:4,title:"动因",slug:"动因",normalizedTitle:"动因",charIndex:2321},{level:4,title:"创建基准数据集",slug:"创建基准数据集",normalizedTitle:"创建基准数据集",charIndex:2445}],headersStr:"介绍 相关工作 Frame-to-model tracking Map deformation Pose graph optimization Fragment-based optimization Indirect (feature-based) BA Direct BA Benchmarking RGB-D SLAM 数据表示 损失函数 几何误差 光度误差 算法流程 创建面元 面元与像素点进行关联 外点过滤 面元的法向量更新 面元的中心位置和描述子优化 面元融合 关键帧的位姿优化 相机内参优化 面元清理和更新半径 前端 预处理 里程计 回环检测 基准数据集 动因 创建基准数据集",content:"# 介绍\n\n当时BA算法被广泛的使用在特征点法的系统中，作者认为这些方法丢弃了图像的大部分信息。并且在稠密重建中，使用完整的BA是做不到实时的。在这篇文章中，作者提出了一种改进BA算法（基于Surfels模型），可以用单个GPU就可以实现实时稠密重建。还有一个贡献就是提出一种基准数据集，在这种数据集下测试，SLAM系统都能z`有更好的结果。\n\n\n# 相关工作\n\n与本文的提出的系统的差异\n\n# Frame-to-model tracking\n\n这种方法的相机位姿不再进行后续优化，会导致累积误差。\n\n# Map deformation\n\n没有使用所有可用信息。\n\n# Pose graph optimization\n\n虽然可以简化优化问题，但也只是近似BA。\n\n# Fragment-based optimization\n\n分层优化，虽然可以减少优化的变量，但也只是近似BA。\n\n# Indirect (feature-based) BA\n\n这里的ORB-SLAM2和Bundlefusion效果都很好。\n\n# Direct BA\n\n同时优化相机位姿和场景参数，但需要大量的计算时间，举了离线系统。\n\n# Benchmarking RGB-D SLAM\n\n作者提供了基准数据集，这种数据集是同步全局快门，对比现有的数据集，重建的结果更好。\n\n\n# 数据表示\n\n作者使用场景表示是surfels，且只对关键帧进行BA。\n\n关键帧作者没有作严格的筛选，每10帧，选一帧作为关键帧。\n\n作者的surfels是一个圆盘，其包含3D圆心坐标（全局坐标系），表面的法向量，圆盘半径，描述子。\n\n作者选择surfels是因为他们能够通过BA有效的进行融合和更新。\n\n\n# 损失函数\n\n\n\n遍历所有的关键帧，所有建立好关联的面元，进行几何误差，光度误差优化。\n\n这两个误差项前面都有一个偏置σD−1和σp−1 ，对于第一个偏置，作者认为对于一个标定好的相机，不确定性只会出现在深度方向上，所以建立一个模型消除深度上的不确定性。第二个的不确定性在于反射，光照变化。\n\n# 几何误差\n\n\n\n将面元中心3D坐标投影到第K帧关键帧的坐标系，进而投影到第K帧关键帧像素平面，在通过深度图的深度转换到K相机坐标系。点到面的icp。\n\n# 光度误差\n\n\n\n~~这里I（）不是直接用亮度值，而是用的亮度的梯度图的信息（对亮度变换更加鲁棒）。~~这里用两个点来做，这两个点是在以面元中心ps为圆心的圆上，而且s1−ps和s2−ps正交。这里亮度值相减，本质上是梯度值，与以往的不同，这里的跨度是半径。\n\n\n# 算法流程\n\n# 创建面元\n\n首先遍历所有关键帧，为每个关键帧创建surfels，将关键帧分为若干个4*4大小的网格，每个网格中至少有一个像素与一个面元关联，如果没有，则从深度图中随机选取一个深度创建一个面元s与之关联。\n\n# 面元与像素点进行关联\n\n把面元的中心坐标投影到关键帧上，首先投影点要在这个关键帧中，\n\n 1. 投影点具有深度测量；\n\n 2. 深度测量值和面元的深度足够近似；\n\n 3. 深度图的方向和面元的法向量足够近似；\n    \n    符合上述条件，那么就建立像素到面元的关联。\n\n面元的属性都是由创建它的那个像素计算而成。计算面元的中心ps，法向量ns，半径rs，描述子ds。\n\n# 外点过滤\n\n像素与面元关联，那么这个像素需要符合一定条件：将这个像素点的3D坐标投影到其它关键帧，记录有多少关键帧可以观测到这个像素点，和没有观测到的次数。如果没观测到的次数比观测到次数多，或者观测到的次数小于一定阈值，则认为这个像素点是外点，则不对这个像素点进行关联一个面元。\n\n# 面元的法向量更新\n\n平均所有与该面元关联的像素点的法向量，随后进行归一化。\n\n# 面元的中心位置和描述子优化\n\n在更新完面元的法向量后，对面元的中心位置，描述子通过（1）式进行优化。这里还限制面元的中心的优化方向，只允许沿着面元的法向量方向进行优化，所以优化式子为ps+t⋅ns，只有一个优化量t。\n\n描述子更新方法呢？？？？\n\n# 面元融合\n\n在BA的第一次迭代后，开始融合具有相似属性的面元，比如法向量接近，位置接近。为了更快的找到需要融合的面元，将面元投影到所有的关键帧中，位于同一个4*4的网格中的面元进行融合。\n\n# 关键帧的位姿优化\n\n对（1）式进行高斯牛顿法进行优化。\n\n# 相机内参优化\n\n同样对（1）式进行高斯牛顿法进行优化，不过这次优化的是相机内参，同时，使用深度偏移模型，建立真实深度与偏移的深度联系\n\n\n\n# 面元清理和更新半径\n\n与上面的外点过滤方法类似，将面元投影到每个关键帧，计算这个面元在关键帧集出现的次数。\n\n与法向量更新方法类似，与面元关联的所有像素点，都计算出一个半径，该面元半径更新为最小的半径。\n\n\n\n\n# 前端\n\n本文的主要贡献是提供了一个后端稠密的BA方法。\n\n# 预处理\n\n使用双边滤波，对深度图过滤。\n\n# 里程计\n\n通过上一关键帧，估计当前帧的位姿，使用标准的直接法，其中包括几何误差，光度梯度误差。【参考文献】\n\n# 回环检测\n\n当创建一个关键帧时（每10帧），执行回环检测。使用基于二进制特征，的词袋模型，找到当前关键帧k与历史哪个关键帧m最相似。首先通过特征匹配估计关键帧的初始相对位姿，然后通过直接法对齐。同时也对齐m-1，m+1帧，如果这些对齐，都满足一定条件（变换和角度的差异），则接受这次回环。使用刚刚算出的三个相对位姿的平均相对位姿，使用位姿图优化，随后使用作者提出的BA优化。\n\n\n# 基准数据集\n\n# 动因\n\n作者认为，在流行的TUM RGB-D 数据集中，与真实世界都多多少少有偏差，因为采集数据时，RGB图和depth图的时间不同步，深度图畸变，不能准确获得对应像素点的深度，这会导致各种RGB-D SLAM系统的运行结果也会更加不准确。\n\n# 创建基准数据集\n\n作者创建基准数据集使用两种方法，一种是作者采用同步装置、全局快门相机记录数据集；另一种是在原有数据集重建出3D模型后，通过数据集原始轨迹，重新渲染数据集。作者渲染出四种数据集，卷帘快门和异步的排列组合。基于全局快门同步数据集，卷帘快门数据集是通过估计卷帘快门的时间（第一行和最后一行的时间差）来模拟卷帘快门的效果，对于异步快门数据集，RGB图像的深度对应两张时间连续的深度图像之间深度图像。",normalizedContent:"# 介绍\n\n当时ba算法被广泛的使用在特征点法的系统中，作者认为这些方法丢弃了图像的大部分信息。并且在稠密重建中，使用完整的ba是做不到实时的。在这篇文章中，作者提出了一种改进ba算法（基于surfels模型），可以用单个gpu就可以实现实时稠密重建。还有一个贡献就是提出一种基准数据集，在这种数据集下测试，slam系统都能z`有更好的结果。\n\n\n# 相关工作\n\n与本文的提出的系统的差异\n\n# frame-to-model tracking\n\n这种方法的相机位姿不再进行后续优化，会导致累积误差。\n\n# map deformation\n\n没有使用所有可用信息。\n\n# pose graph optimization\n\n虽然可以简化优化问题，但也只是近似ba。\n\n# fragment-based optimization\n\n分层优化，虽然可以减少优化的变量，但也只是近似ba。\n\n# indirect (feature-based) ba\n\n这里的orb-slam2和bundlefusion效果都很好。\n\n# direct ba\n\n同时优化相机位姿和场景参数，但需要大量的计算时间，举了离线系统。\n\n# benchmarking rgb-d slam\n\n作者提供了基准数据集，这种数据集是同步全局快门，对比现有的数据集，重建的结果更好。\n\n\n# 数据表示\n\n作者使用场景表示是surfels，且只对关键帧进行ba。\n\n关键帧作者没有作严格的筛选，每10帧，选一帧作为关键帧。\n\n作者的surfels是一个圆盘，其包含3d圆心坐标（全局坐标系），表面的法向量，圆盘半径，描述子。\n\n作者选择surfels是因为他们能够通过ba有效的进行融合和更新。\n\n\n# 损失函数\n\n\n\n遍历所有的关键帧，所有建立好关联的面元，进行几何误差，光度误差优化。\n\n这两个误差项前面都有一个偏置σd−1和σp−1 ，对于第一个偏置，作者认为对于一个标定好的相机，不确定性只会出现在深度方向上，所以建立一个模型消除深度上的不确定性。第二个的不确定性在于反射，光照变化。\n\n# 几何误差\n\n\n\n将面元中心3d坐标投影到第k帧关键帧的坐标系，进而投影到第k帧关键帧像素平面，在通过深度图的深度转换到k相机坐标系。点到面的icp。\n\n# 光度误差\n\n\n\n~~这里i（）不是直接用亮度值，而是用的亮度的梯度图的信息（对亮度变换更加鲁棒）。~~这里用两个点来做，这两个点是在以面元中心ps为圆心的圆上，而且s1−ps和s2−ps正交。这里亮度值相减，本质上是梯度值，与以往的不同，这里的跨度是半径。\n\n\n# 算法流程\n\n# 创建面元\n\n首先遍历所有关键帧，为每个关键帧创建surfels，将关键帧分为若干个4*4大小的网格，每个网格中至少有一个像素与一个面元关联，如果没有，则从深度图中随机选取一个深度创建一个面元s与之关联。\n\n# 面元与像素点进行关联\n\n把面元的中心坐标投影到关键帧上，首先投影点要在这个关键帧中，\n\n 1. 投影点具有深度测量；\n\n 2. 深度测量值和面元的深度足够近似；\n\n 3. 深度图的方向和面元的法向量足够近似；\n    \n    符合上述条件，那么就建立像素到面元的关联。\n\n面元的属性都是由创建它的那个像素计算而成。计算面元的中心ps，法向量ns，半径rs，描述子ds。\n\n# 外点过滤\n\n像素与面元关联，那么这个像素需要符合一定条件：将这个像素点的3d坐标投影到其它关键帧，记录有多少关键帧可以观测到这个像素点，和没有观测到的次数。如果没观测到的次数比观测到次数多，或者观测到的次数小于一定阈值，则认为这个像素点是外点，则不对这个像素点进行关联一个面元。\n\n# 面元的法向量更新\n\n平均所有与该面元关联的像素点的法向量，随后进行归一化。\n\n# 面元的中心位置和描述子优化\n\n在更新完面元的法向量后，对面元的中心位置，描述子通过（1）式进行优化。这里还限制面元的中心的优化方向，只允许沿着面元的法向量方向进行优化，所以优化式子为ps+t⋅ns，只有一个优化量t。\n\n描述子更新方法呢？？？？\n\n# 面元融合\n\n在ba的第一次迭代后，开始融合具有相似属性的面元，比如法向量接近，位置接近。为了更快的找到需要融合的面元，将面元投影到所有的关键帧中，位于同一个4*4的网格中的面元进行融合。\n\n# 关键帧的位姿优化\n\n对（1）式进行高斯牛顿法进行优化。\n\n# 相机内参优化\n\n同样对（1）式进行高斯牛顿法进行优化，不过这次优化的是相机内参，同时，使用深度偏移模型，建立真实深度与偏移的深度联系\n\n\n\n# 面元清理和更新半径\n\n与上面的外点过滤方法类似，将面元投影到每个关键帧，计算这个面元在关键帧集出现的次数。\n\n与法向量更新方法类似，与面元关联的所有像素点，都计算出一个半径，该面元半径更新为最小的半径。\n\n\n\n\n# 前端\n\n本文的主要贡献是提供了一个后端稠密的ba方法。\n\n# 预处理\n\n使用双边滤波，对深度图过滤。\n\n# 里程计\n\n通过上一关键帧，估计当前帧的位姿，使用标准的直接法，其中包括几何误差，光度梯度误差。【参考文献】\n\n# 回环检测\n\n当创建一个关键帧时（每10帧），执行回环检测。使用基于二进制特征，的词袋模型，找到当前关键帧k与历史哪个关键帧m最相似。首先通过特征匹配估计关键帧的初始相对位姿，然后通过直接法对齐。同时也对齐m-1，m+1帧，如果这些对齐，都满足一定条件（变换和角度的差异），则接受这次回环。使用刚刚算出的三个相对位姿的平均相对位姿，使用位姿图优化，随后使用作者提出的ba优化。\n\n\n# 基准数据集\n\n# 动因\n\n作者认为，在流行的tum rgb-d 数据集中，与真实世界都多多少少有偏差，因为采集数据时，rgb图和depth图的时间不同步，深度图畸变，不能准确获得对应像素点的深度，这会导致各种rgb-d slam系统的运行结果也会更加不准确。\n\n# 创建基准数据集\n\n作者创建基准数据集使用两种方法，一种是作者采用同步装置、全局快门相机记录数据集；另一种是在原有数据集重建出3d模型后，通过数据集原始轨迹，重新渲染数据集。作者渲染出四种数据集，卷帘快门和异步的排列组合。基于全局快门同步数据集，卷帘快门数据集是通过估计卷帘快门的时间（第一行和最后一行的时间差）来模拟卷帘快门的效果，对于异步快门数据集，rgb图像的深度对应两张时间连续的深度图像之间深度图像。",charsets:{cjk:!0}},{title:"intrinsic3d论文阅读",frontmatter:{title:"intrinsic3d论文阅读",date:"2022-05-18T11:01:06.000Z",permalink:"/pages/c06e38/"},regularPath:"/02.%E7%A7%91%E7%A0%94/01.%E5%AE%A4%E5%86%85%E5%AE%9E%E6%97%B6%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/08.intrinsic3d%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB.html",relativePath:"02.科研/01.室内实时三维重建/08.intrinsic3d论文阅读.md",key:"v-66cbb422",path:"/pages/c06e38/",headers:[{level:3,title:"Introducting",slug:"introducting",normalizedTitle:"introducting",charIndex:72},{level:3,title:"Overview",slug:"overview",normalizedTitle:"overview",charIndex:944},{level:4,title:"Signed Distance Field",slug:"signed-distance-field",normalizedTitle:"signed distance field",charIndex:1213},{level:4,title:"Image Formation Model and Sampling",slug:"image-formation-model-and-sampling",normalizedTitle:"image formation model and sampling",charIndex:1428},{level:3,title:"Lighting Estimation using Spatially-varying Spherical Harmonics",slug:"lighting-estimation-using-spatially-varying-spherical-harmonics",normalizedTitle:"lighting estimation using spatially-varying spherical harmonics",charIndex:1794},{level:3,title:"Joint Optimization of Geometry, Albedo, and Image Formation Model",slug:"joint-optimization-of-geometry-albedo-and-image-formation-model",normalizedTitle:"joint optimization of geometry, albedo, and image formation model",charIndex:2370}],headersStr:"Introducting Overview Signed Distance Field Image Formation Model and Sampling Lighting Estimation using Spatially-varying Spherical Harmonics Joint Optimization of Geometry, Albedo, and Image Formation Model",content:"这篇文章的核心idea主要是纹理细化，同时优化geometry,texures,camera pose，这方法是基于SfS和SVSH。\n\n\n# Introducting\n\n1.体积融合方法能够有效的减少传感器噪声的影响，但因此重建的表面更偏向平滑，缺少细节。\n\n2.很多RGB-D重建框架只是简单地将深度像素的RGB值映射到几何图形上，在对应体素上加权平均，这也会导致表面模糊。\n\n为了解决上述两个问题，于是有了两种独立的解决方法：\n\n 1. 首先通过迭代求解位姿对齐，然后颜色平均，对于错误的几何对齐，通过非刚性变化来优化，最后也可以得到高质量的表面纹理。\n 2. 基于阴影的细化技术，通过阴影约束来增强深度帧。这种技术一般是一个顺序管道，首先对齐RGB-D帧，然后融合RGB和depth到体积网格中，最后细化重建。但是这管道下，如果先前有错误，那么后面的纹理细化也会跟着出错。\n\n在作者的工作中，结合这两种方向去解决上述两个问题，计算精确的表面几何，再重构纹理。作者的思路如下：\n\n 1. 表面几何由SDF来表示，通过输入的深度信息，阴影，RGB来约束。\n 2. 通过全局光度和几何一致性，矫正相机位姿和内参。\n 3. 细化表面纹理。\n 4. 空间变化的照明和表面反照率值受到RGB测量和表面几何的限制。\n\n主要是为了参数化3D模型。\n\n 1. 我们通过联合优化三维几何、表面材料(反照率)、摄像机姿态、摄像机内部(包括镜头畸变)以及使用球谐基函数精确的场景照明，重构了一个体符号距离函数。\n\n 2. 不只是估计一个单一的全局场景照明，我们估计空间变化的球形谐波来检索准确的场景照明。\n\n 3. 我们利用时间视图采样和过滤技术来减轻运动模糊的影响，从而有效地处理来自低成本消费级的数据RGB-D传感器设备\n\nSfS旨在从单张RGB图像中提取3D结构，当光源和相机位置都是已知时，理论已经是很成熟了。因此阴影和反射估计已经成为细化几何的重要上下文的线索。参考文献[20]使用SDF重建方法有两个缺点，第一，假设了一个单一的全局照明设置；第二优化是一个顺序管道，意味着位姿和表面颜色只进行一次优化。\n\n在我们的方法中，系统的解决这些缺点通过联合优化策略，以及空间变化照明参数化。\n\n\n# Overview\n\n 1. 通过输入带有初始位姿的RGB-D图像序列，首先估计一个SDF模型。为了减少运动模糊的试图的影响，根据模糊度量自动选择视图来建立颜色约束。\n 2. 分层的SDF模型，RGB帧，使用金字塔分层优化。\n 3. 在每次迭代的内部，通过将SDF体积分割成具有独立球形谐波（SH）参数的固定大小的子体积。在估计过程中联合求解所有SH参数，通过在给定体积中三线性插值获得子体积。\n 4. 在框架的主阶段中，利用估计的光照来联合细化SDF的表面和反射率，图像位姿，内参。最后通过Marching Cubes来提取模型。\n\n# Signed Distance Field\n\n每个体素包含SDF值D(v)，颜色C(v)，权重W(v)，反射率a(v)，优化后的SDF值$\\widetilde{D}(v) 。使用加权平均融合。使用加权平均融合D(v),W(v)在融合完所有的图像，用融合好的模型,在融合完所有的RGB−D图像，用融合好的SDF模型D，初始化一个优化的，初始化一个优化的\\widetilde{D} $，通过向前差分，直接计算每个体素的法向量。\n\n# Image Formation Model and Sampling\n\nRGB-D Data && Camera Model 说明图像数据的一些符号定义，旋转平移的位姿参数,内参，投影模型。\n\nKeyframe Selection 为了减少运动模糊的影响，使用参考文献[6]的模糊度测量来选择视图，具体的说，在连续tKF帧中选择最不模糊的帧进行处理，但这里，他又选择所有的帧。\n\nObservations Sampling and Colorization 通过关键帧，重新计算等值面的体素的颜色值，首先判断体素是否在某个相机视野，最后这个体素的所有颜色和权重观测存放在$\\mathcal{O}_v 中。然后通过权重对中。然后通过权重对\\mathcal{O} _v$排序，只保留最好的观测，体素的颜色是这些观测的加权平均。\n\n\n# Lighting Estimation using Spatially-varying Spherical Harmonics\n\nLighting Model 为了表示场景的照明，对每个表面点的阴影参数化表示。通过体素的法向量，反照率，照明参数计算体素的阴影B。\n\nB(v)=a(v)∑m=1b2lmHm(n(v))\n\nSpherical Harmonics 为了估计体素的阴影B，使用b=3的SH基函数Hm来参数化表示光照。然而一个单一的SH基不能如实地同时表示所有表面点的照明。\n\nSubbolume Partitioning 为了解决一个单一SH基的缺点，我们扩展了传统的公式。将重建好的体积转换到一个固定大小的K个子体积中，每个子体积都分配一个SH基。\n\nSpatially-varying Spherical Harmonics 我们现在有K×b2个未知参数，这在场景照明模型中提供了更多的可表达性，直觉上，我们试图用不同的局部光照模型来近似复杂的全局光照。通过最小化以下目标函数来估计子体积的照明\n\nElighting (ℓ1,…,ℓK)=Eappearance +λdiffuse Ediffuse \n\n其中，\n\nEappearance =∑v∈D~0(B(v)−I(v))2Ediffuse=∑s∈S∑r∈Ns(ℓs−ℓr)2\n\n\n# Joint Optimization of Geometry, Albedo, and Image Formation Model\n\n同时优化相机位姿，体素sdf值，反照率，相机内参。\n\nEscene (X)=∑v∈D~0λgEg+λvEv+λsEs+λaEa\n\n其中，Eg为体素v的当前亮度 与 体素v在各个观测中的亮度 的梯度差。\n\nEg(v)=∑Ii∈Vbest wiv‖∇B(v)−∇Ii(π(vi))‖22\n\nEv(v)是拉普拉斯平滑项，正则化我们的符号距离域，增强了相邻体素之间的距离值的平滑性。\n\nEv(v)=(△D~(v))2\n\nEs(v)是用来约束表面优化范围。\n\nEs(v)=(D~(v)−D(v))2\n\nEa(v)是用来约束当前体素v与邻居体素v的颜色，反照率的平滑度。\n\nEa(v)=∑u∈Nvϕ(Γ(v)−Γ(u))⋅(a(v)−a(u))2",normalizedContent:"这篇文章的核心idea主要是纹理细化，同时优化geometry,texures,camera pose，这方法是基于sfs和svsh。\n\n\n# introducting\n\n1.体积融合方法能够有效的减少传感器噪声的影响，但因此重建的表面更偏向平滑，缺少细节。\n\n2.很多rgb-d重建框架只是简单地将深度像素的rgb值映射到几何图形上，在对应体素上加权平均，这也会导致表面模糊。\n\n为了解决上述两个问题，于是有了两种独立的解决方法：\n\n 1. 首先通过迭代求解位姿对齐，然后颜色平均，对于错误的几何对齐，通过非刚性变化来优化，最后也可以得到高质量的表面纹理。\n 2. 基于阴影的细化技术，通过阴影约束来增强深度帧。这种技术一般是一个顺序管道，首先对齐rgb-d帧，然后融合rgb和depth到体积网格中，最后细化重建。但是这管道下，如果先前有错误，那么后面的纹理细化也会跟着出错。\n\n在作者的工作中，结合这两种方向去解决上述两个问题，计算精确的表面几何，再重构纹理。作者的思路如下：\n\n 1. 表面几何由sdf来表示，通过输入的深度信息，阴影，rgb来约束。\n 2. 通过全局光度和几何一致性，矫正相机位姿和内参。\n 3. 细化表面纹理。\n 4. 空间变化的照明和表面反照率值受到rgb测量和表面几何的限制。\n\n主要是为了参数化3d模型。\n\n 1. 我们通过联合优化三维几何、表面材料(反照率)、摄像机姿态、摄像机内部(包括镜头畸变)以及使用球谐基函数精确的场景照明，重构了一个体符号距离函数。\n\n 2. 不只是估计一个单一的全局场景照明，我们估计空间变化的球形谐波来检索准确的场景照明。\n\n 3. 我们利用时间视图采样和过滤技术来减轻运动模糊的影响，从而有效地处理来自低成本消费级的数据rgb-d传感器设备\n\nsfs旨在从单张rgb图像中提取3d结构，当光源和相机位置都是已知时，理论已经是很成熟了。因此阴影和反射估计已经成为细化几何的重要上下文的线索。参考文献[20]使用sdf重建方法有两个缺点，第一，假设了一个单一的全局照明设置；第二优化是一个顺序管道，意味着位姿和表面颜色只进行一次优化。\n\n在我们的方法中，系统的解决这些缺点通过联合优化策略，以及空间变化照明参数化。\n\n\n# overview\n\n 1. 通过输入带有初始位姿的rgb-d图像序列，首先估计一个sdf模型。为了减少运动模糊的试图的影响，根据模糊度量自动选择视图来建立颜色约束。\n 2. 分层的sdf模型，rgb帧，使用金字塔分层优化。\n 3. 在每次迭代的内部，通过将sdf体积分割成具有独立球形谐波（sh）参数的固定大小的子体积。在估计过程中联合求解所有sh参数，通过在给定体积中三线性插值获得子体积。\n 4. 在框架的主阶段中，利用估计的光照来联合细化sdf的表面和反射率，图像位姿，内参。最后通过marching cubes来提取模型。\n\n# signed distance field\n\n每个体素包含sdf值d(v)，颜色c(v)，权重w(v)，反射率a(v)，优化后的sdf值$\\widetilde{d}(v) 。使用加权平均融合。使用加权平均融合d(v),w(v)在融合完所有的图像，用融合好的模型,在融合完所有的rgb−d图像，用融合好的sdf模型d，初始化一个优化的，初始化一个优化的\\widetilde{d} $，通过向前差分，直接计算每个体素的法向量。\n\n# image formation model and sampling\n\nrgb-d data && camera model 说明图像数据的一些符号定义，旋转平移的位姿参数,内参，投影模型。\n\nkeyframe selection 为了减少运动模糊的影响，使用参考文献[6]的模糊度测量来选择视图，具体的说，在连续tkf帧中选择最不模糊的帧进行处理，但这里，他又选择所有的帧。\n\nobservations sampling and colorization 通过关键帧，重新计算等值面的体素的颜色值，首先判断体素是否在某个相机视野，最后这个体素的所有颜色和权重观测存放在$\\mathcal{o}_v 中。然后通过权重对中。然后通过权重对\\mathcal{o} _v$排序，只保留最好的观测，体素的颜色是这些观测的加权平均。\n\n\n# lighting estimation using spatially-varying spherical harmonics\n\nlighting model 为了表示场景的照明，对每个表面点的阴影参数化表示。通过体素的法向量，反照率，照明参数计算体素的阴影b。\n\nb(v)=a(v)∑m=1b2lmhm(n(v))\n\nspherical harmonics 为了估计体素的阴影b，使用b=3的sh基函数hm来参数化表示光照。然而一个单一的sh基不能如实地同时表示所有表面点的照明。\n\nsubbolume partitioning 为了解决一个单一sh基的缺点，我们扩展了传统的公式。将重建好的体积转换到一个固定大小的k个子体积中，每个子体积都分配一个sh基。\n\nspatially-varying spherical harmonics 我们现在有k×b2个未知参数，这在场景照明模型中提供了更多的可表达性，直觉上，我们试图用不同的局部光照模型来近似复杂的全局光照。通过最小化以下目标函数来估计子体积的照明\n\nelighting (ℓ1,…,ℓk)=eappearance +λdiffuse ediffuse \n\n其中，\n\neappearance =∑v∈d~0(b(v)−i(v))2ediffuse=∑s∈s∑r∈ns(ℓs−ℓr)2\n\n\n# joint optimization of geometry, albedo, and image formation model\n\n同时优化相机位姿，体素sdf值，反照率，相机内参。\n\nescene (x)=∑v∈d~0λgeg+λvev+λses+λaea\n\n其中，eg为体素v的当前亮度 与 体素v在各个观测中的亮度 的梯度差。\n\neg(v)=∑ii∈vbest wiv‖∇b(v)−∇ii(π(vi))‖22\n\nev(v)是拉普拉斯平滑项，正则化我们的符号距离域，增强了相邻体素之间的距离值的平滑性。\n\nev(v)=(△d~(v))2\n\nes(v)是用来约束表面优化范围。\n\nes(v)=(d~(v)−d(v))2\n\nea(v)是用来约束当前体素v与邻居体素v的颜色，反照率的平滑度。\n\nea(v)=∑u∈nvϕ(γ(v)−γ(u))⋅(a(v)−a(u))2",charsets:{cjk:!0}},{title:"factor",frontmatter:{title:"factor",date:"2022-05-26T11:01:06.000Z",permalink:"/pages/0af3d9/"},regularPath:"/02.%E7%A7%91%E7%A0%94/01.%E5%AE%A4%E5%86%85%E5%AE%9E%E6%97%B6%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/09.factor.html",relativePath:"02.科研/01.室内实时三维重建/09.factor.md",key:"v-37a31fef",path:"/pages/0af3d9/",headers:[{level:3,title:"Prior and Odometry Estimation",slug:"prior-and-odometry-estimation",normalizedTitle:"prior and odometry estimation",charIndex:134},{level:3,title:"Factor Graph Representation",slug:"factor-graph-representation",normalizedTitle:"factor graph representation",charIndex:290},{level:3,title:"Pose Initialization: Interpolation on SE(3) Manifold",slug:"pose-initialization-interpolation-on-se-3-manifold",normalizedTitle:"pose initialization: interpolation on se(3) manifold",charIndex:365},{level:3,title:"Scale Initialization",slug:"scale-initialization",normalizedTitle:"scale initialization",charIndex:526},{level:3,title:"Optimization and Surfel-based Model Reconstruction",slug:"optimization-and-surfel-based-model-reconstruction",normalizedTitle:"optimization and surfel-based model reconstruction",charIndex:685}],headersStr:"Prior and Odometry Estimation Factor Graph Representation Pose Initialization: Interpolation on SE(3) Manifold Scale Initialization Optimization and Surfel-based Model Reconstruction",content:"概述：该系统的输入是，一系列RGB-D图像，关键帧的初始位姿（通过SFM系统获得），通过插值关键帧，得到所有关键帧的初始位姿，然后相机位姿通过联合优化初始位姿和里程计位姿（ElasticFusion稠密跟踪获得），优化后的位姿用来最后的surfel重建。\n\n\n\n\n# Prior and Odometry Estimation\n\n估计关键帧位姿：对输入的RGB图，每隔λ 帧选取一帧作为关键帧，然后通过目前最先进的算法COLMAP来估计它的初始位姿以及对应的协方差矩阵。参考[1],[2]。\n\n估计里程计位姿：使用ElasticFusion来估计帧i,j之间的相对位姿。\n\n\n# Factor Graph Representation\n\n这里是系统的核心，采用作者提出的因子图公式，联合优化关键帧的初始位姿和里程计位姿。\n\n\n# Pose Initialization: Interpolation on SE(3) Manifold\n\n使用[25]来初始化两个关键帧之间的位姿。首先计算两个关键帧位姿的差值，然后映射到se(3)上δξ，以满足线性操作。最后估计第k帧的位姿Pk，Pi是上一个关键帧的位姿。\n\nPk=Piexp(k−iλδξ)\n\n\n# Scale Initialization\n\n由于SFM估计的位姿有尺度不确定性，所以需要找到一个尺度因子去对齐这两组位姿。对于一组已知的全局坐标的3D路标点Xsfm以及这些路标在第一帧里的像素坐标，然后通过深度信息，计算出路标像素点对应的3D坐标Xslam，通过icp使用SVD分解估计两组3D点的变换矩阵。\n\n\n# Optimization and Surfel-based Model Reconstruction\n\n当获得新的里程计位姿，将其插入到因子图中，使用iSAM2进行增量优化[27]。通过全局一致的先验位姿约束里程计位姿。",normalizedContent:"概述：该系统的输入是，一系列rgb-d图像，关键帧的初始位姿（通过sfm系统获得），通过插值关键帧，得到所有关键帧的初始位姿，然后相机位姿通过联合优化初始位姿和里程计位姿（elasticfusion稠密跟踪获得），优化后的位姿用来最后的surfel重建。\n\n\n\n\n# prior and odometry estimation\n\n估计关键帧位姿：对输入的rgb图，每隔λ 帧选取一帧作为关键帧，然后通过目前最先进的算法colmap来估计它的初始位姿以及对应的协方差矩阵。参考[1],[2]。\n\n估计里程计位姿：使用elasticfusion来估计帧i,j之间的相对位姿。\n\n\n# factor graph representation\n\n这里是系统的核心，采用作者提出的因子图公式，联合优化关键帧的初始位姿和里程计位姿。\n\n\n# pose initialization: interpolation on se(3) manifold\n\n使用[25]来初始化两个关键帧之间的位姿。首先计算两个关键帧位姿的差值，然后映射到se(3)上δξ，以满足线性操作。最后估计第k帧的位姿pk，pi是上一个关键帧的位姿。\n\npk=piexp(k−iλδξ)\n\n\n# scale initialization\n\n由于sfm估计的位姿有尺度不确定性，所以需要找到一个尺度因子去对齐这两组位姿。对于一组已知的全局坐标的3d路标点xsfm以及这些路标在第一帧里的像素坐标，然后通过深度信息，计算出路标像素点对应的3d坐标xslam，通过icp使用svd分解估计两组3d点的变换矩阵。\n\n\n# optimization and surfel-based model reconstruction\n\n当获得新的里程计位姿，将其插入到因子图中，使用isam2进行增量优化[27]。通过全局一致的先验位姿约束里程计位姿。",charsets:{cjk:!0}},{title:"CLD_MVS",frontmatter:{title:"CLD_MVS",date:"2022-05-31T11:01:06.000Z",permalink:"/pages/3a8868/"},regularPath:"/02.%E7%A7%91%E7%A0%94/01.%E5%AE%A4%E5%86%85%E5%AE%9E%E6%97%B6%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/10.CLD_MVS.html",relativePath:"02.科研/01.室内实时三维重建/10.CLD_MVS.md",key:"v-4633e0e5",path:"/pages/3a8868/",headers:[{level:3,title:"summarized",slug:"summarized",normalizedTitle:"summarized",charIndex:2},{level:3,title:"Related Work",slug:"related-work",normalizedTitle:"related work",charIndex:194},{level:4,title:"volumetric-based",slug:"volumetric-based",normalizedTitle:"volumetric-based",charIndex:225},{level:4,title:"mesh-based",slug:"mesh-based",normalizedTitle:"mesh-based",charIndex:269},{level:4,title:"feature-based",slug:"feature-based",normalizedTitle:"feature-based",charIndex:311},{level:4,title:"depth map-based",slug:"depth-map-based",normalizedTitle:"depth map-based",charIndex:340},{level:4,title:"Confidence Prediction",slug:"confidence-prediction",normalizedTitle:"confidence prediction",charIndex:409},{level:3,title:"Approach",slug:"approach",normalizedTitle:"approach",charIndex:458}],headersStr:"summarized Related Work volumetric-based mesh-based feature-based depth map-based Confidence Prediction Approach",content:"# summarized\n\n 1. CLD_MVS管道由 初始重建，自信度预测，自信度驱动，边界插值，像素级优化。\n 2. 提出了一种normal-aware PatchMatch来提高法线贴图的精度。\n 3. 提出了一种基于置信度驱动和边界感知的插值方式，获得可靠的先验深度图。将空间置信度和视差图置信度结合来检测可靠的地面控制点。\n 4. 通过高度匹配误差提高视差图的精度。\n\n\n# Related Work\n\nMVS方法可以分为四个类别\n\n# volumetric-based\n\n假设3D场景嵌入在一个预先定义的3D体块中。\n\n# mesh-based\n\n对三角mesh进行最小化能量函数变形对齐到真是表面。\n\n# feature-based\n\n重建有特征点的区域。\n\n# depth map-based\n\n一般分为两个阶段深度估计和深度融合。每一张图项选择视图然后建立局部关联，提出外点，然后点云融合。\n\n# Confidence Prediction\n\n置信度度量方法可以改善立体匹配中的视差图。\n\n\n# Approach\n\n该方法的主要思想是基于真实场景中存在许多底纹理表面，且难以通过多视图匹配进行可靠重构的假设，我们提出了充分利用可靠重构部分来帮助不可靠重构部分的方法。我们首先需要一个初始的稠密重建和一个检测重建好部分的置信度的方法。然后使用一个可靠的插值方法来填充缺失的表面来改善视差图的一致性和几何细节。在给定一个参考视图，采用一下四个步骤来估计深度图和法线贴图。\n\n 1. 使用PatchMatch算法来初步估计深度和法线贴图。\n 2. 将视差图一致性和空间一致性的置信度相结合，可靠的预测每个深度的正确性。用DCNNs来算空间一致性的置信度。\n 3. 通过动态和静态指导的置信度驱动和边界感知插值来获得可靠的深度和法线估计。\n 4. 进一步优化深度和法线误差。\n\n",normalizedContent:"# summarized\n\n 1. cld_mvs管道由 初始重建，自信度预测，自信度驱动，边界插值，像素级优化。\n 2. 提出了一种normal-aware patchmatch来提高法线贴图的精度。\n 3. 提出了一种基于置信度驱动和边界感知的插值方式，获得可靠的先验深度图。将空间置信度和视差图置信度结合来检测可靠的地面控制点。\n 4. 通过高度匹配误差提高视差图的精度。\n\n\n# related work\n\nmvs方法可以分为四个类别\n\n# volumetric-based\n\n假设3d场景嵌入在一个预先定义的3d体块中。\n\n# mesh-based\n\n对三角mesh进行最小化能量函数变形对齐到真是表面。\n\n# feature-based\n\n重建有特征点的区域。\n\n# depth map-based\n\n一般分为两个阶段深度估计和深度融合。每一张图项选择视图然后建立局部关联，提出外点，然后点云融合。\n\n# confidence prediction\n\n置信度度量方法可以改善立体匹配中的视差图。\n\n\n# approach\n\n该方法的主要思想是基于真实场景中存在许多底纹理表面，且难以通过多视图匹配进行可靠重构的假设，我们提出了充分利用可靠重构部分来帮助不可靠重构部分的方法。我们首先需要一个初始的稠密重建和一个检测重建好部分的置信度的方法。然后使用一个可靠的插值方法来填充缺失的表面来改善视差图的一致性和几何细节。在给定一个参考视图，采用一下四个步骤来估计深度图和法线贴图。\n\n 1. 使用patchmatch算法来初步估计深度和法线贴图。\n 2. 将视差图一致性和空间一致性的置信度相结合，可靠的预测每个深度的正确性。用dcnns来算空间一致性的置信度。\n 3. 通过动态和静态指导的置信度驱动和边界感知插值来获得可靠的深度和法线估计。\n 4. 进一步优化深度和法线误差。\n\n",charsets:{cjk:!0}},{title:"TextureMe",frontmatter:{title:"TextureMe",date:"2022-04-06T11:01:06.000Z",permalink:"/pages/49bbb9/"},regularPath:"/02.%E7%A7%91%E7%A0%94/01.%E5%AE%A4%E5%86%85%E5%AE%9E%E6%97%B6%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/11.TextureMe.html",relativePath:"02.科研/01.室内实时三维重建/11.TextureMe.md",key:"v-629fc96e",path:"/pages/49bbb9/",headers:[{level:3,title:"介绍",slug:"介绍",normalizedTitle:"介绍",charIndex:20},{level:3,title:"相关工作",slug:"相关工作",normalizedTitle:"相关工作",charIndex:645},{level:3,title:"系统概述",slug:"系统概述",normalizedTitle:"系统概述",charIndex:654},{level:3,title:"纹理图集表示",slug:"纹理图集表示",normalizedTitle:"纹理图集表示",charIndex:996},{level:3,title:"纹理块融合",slug:"纹理块融合",normalizedTitle:"纹理块融合",charIndex:1656},{level:3,title:"纹理块优化",slug:"纹理块优化",normalizedTitle:"纹理块优化",charIndex:2248}],headersStr:"介绍 相关工作 系统概述 纹理图集表示 纹理块融合 纹理块优化",content:"# TextureMe论文阅读\n\n\n# 介绍\n\n高质量的纹理建图一般都是离线的后处理步骤，在这篇文章中，提出一种实时的联合恢复3D几何表面和高质量纹理。核心方法是创建与TSDF零交点相关联的三角形。\n\n虽然基于TSDF重建，使用有噪声的深度图融合，也能得到干净的表明，但传统的TSDF一个体素只能存储一个颜色值，要表示精细的表面颜色，那么就需要微小的体素，并需要大量的内存。通过Marching Cubes 可以从一个体素获得多个三角形，一般传统的方法通过对相邻体素插值来获得详细的三角形的颜色，因此受限于体素的分辨率。为了解决这个问题，提出了离线的纹理贴图方法，因为通过融合颜色图的方法来获得纹理图一般会受颜色图的位姿漂移影响，所以先前方法尝试取优化相机位姿和纹理图位置来获得高质量的纹理贴图。\n\n我们提出一个框架TextureMe，从RGB-D图像序列联合创建一个高质量的纹理地图和表面几何。其核心idea是 维护一个全局的纹理地图集 ** 其由直角三角形组成，我们称纹理patch，存储重建表面的三角形的颜色细节**。对Marching Cubes获得的三角形映射到当前帧得到纹理patch，然后整理纹理patch到全局纹理地图集中。\n\n本文贡献点概述：\n\n * 提出一个实时的同时重建几何和纹理的3D重建框架，没有采用任何后处理步骤；\n * 我们的方法值利用了颜色图，构建和更新一个全局纹理地图集；\n * 处理纹理patch不对齐，网格连接更新，纹理patch更新等问题；\n\n\n# 相关工作\n\n\n# 系统概述\n\nTextureMe的几何重建模块是基于KinectFusion的，并且融合RGB信息，使用光度误差和几何误差来估计当前帧的位姿，虽然使用当前帧的位姿和深度图来更新TSDF模型。\n\n为了重建纹理块，网格模型是必要的。TSDF是暗含表面的表示方法，因此我们使用Marching Cubes去获得包含零点的三角形，然后使用位姿映射这些三角形到当前帧，来获得关联的详细颜色，然后在当前帧构建纹理块，使用纹理块去更新全局纹理地图集，当前帧的纹理块与全局纹理地图集中对应的纹理块进行平均更新。\n\nTextureMe的核心是在全局纹理地图集中有效地表示，存储，构建，更新纹理块。接下来就第4节介绍纹理块的表示和存储，第5节介绍纹理快的构建和更新，第6节介绍优化误对齐的纹理块。\n\n\n# 纹理图集表示\n\n纹理块 是一个带有详细颜色信息的直角三角形，存储在纹理地图集中。\n\n纹理地图集 纹理图集是存储了一组直角三角形纹理块的大型图像，在重建开始之前，预先为纹理地图集分配显存，同时，通过将纹理图集均匀划分为直角三角形，预先计算纹理图集中每个纹理块的顶点的UV坐标，预先定义一个最小纹理块的大小，它可以存储从输入的彩色图像中可能的最大纹理细节。具体来说，将体素投影到当前的彩色图中，来计算纹理块的直角三角形大小。\n\n存储 我们从零交叉体素中生成三角形并分配一个唯一的纹理块索引，当一个体素第一次表示一个表面时，给他创建一个纹理块，然后存储在纹理图集中。设定每个体素最多能提取出ntri个三角网格，假设当前整个体积有nv，那么就要给纹理图集分配ntri×nv个纹理块的大小，这显然会浪费巨大的显存空间。作者使用一个空闲栈取管理纹理块，用来存储在纹理图集中暂无对应的纹理块的索引。一开始空闲栈填充纹理块数量的最大值个索引，每当创建一个纹理块，就从空闲栈中pop出一个索引分配给这个纹理块，当清除一个纹理块时，就push对应的索引到空闲栈中。\n\n如图，体素A有3个纹理块，当释放体素A的纹理块时，free list push进去纹理块的索引，当体素B需要创建一个纹理块时，从free list 中pop一个索引出来。\n\n\n\n某一帧使用Marching Cubes在体素A创建了某种类型的纹理块，但随后某帧在体素A创建了与之前不同数量或不同类型的纹理块，这时候就需要删除之前的纹理块，重新创建纹理块。（重采样）\n\n\n# 纹理块融合\n\n我们首先通过更新后的TSDF体积中提取三角形，将其投影到当前彩色图像上来构造新的纹理块，然后自适应地将来自当前帧的新纹理块与现有纹理图集中的纹理块进行融合，采用图像模糊度的加权融合，纹理块融合后还要解决网格连接问题。\n\n构建 Mk表示第k帧从TSDF模型中提取的三角网格，为每一个网格构建一个纹理块Tk′，将这个网格投影到当前的颜色图Ck中，可以在颜色图Ck中找到对应的三角形。\n\n\n\n更新 对纹理块的颜色进行加权平均，类似与TSDF的更新方式。如果当前体素中的纹理块类型数量都没变，那么在全局纹理图集中有一个当前体素中的纹理块对应，然后采用如下的更新方式：\n\nTk=Wk−1⊙Tk−1+Wk′⊙Tk′Wk−1+Wk′Wk′(p)=wn⋅wd⋅wb\n\n过滤 避免体素的顶点在零点附近反复横跳，从而避免提取的三角形会经常改变。\n\ntk′={tk if |tk|≥δ+δ if |tk|<δ and tk−1≥+δ−δ if |tk|<δ and tk−1≤−δtk−1′ otherwise (|tk|<δ and |tk−1|<δ)\n\n重采样 前n帧在体素A创建了某种类型的纹理块，但随后帧在体素A创建了与之前不同数量或不同类型的纹理块，这时候就需要删除之前的纹理块，重新创建纹理块。将新创建的纹理块投影到预测表面（KinectFusion）进行采样颜色信息。\n\n\n# 纹理块优化\n\n实际中，相机位姿不可能完美准确，输入的彩色图像本身也经常收到镜头变形、快门失真以及不完美的颜色和深度图像同步的影响。在这一节中介绍一种优化方法使得对这些情况更加鲁棒。（对不对齐不是跟踪的事情吗，这里还优化啥呢，李在赣什魔）\n\n图像变形场 理想情况下，输入图像和当前模型渲染出来的图像（预测图）应该是完美对齐上的，但实际上会存在误对齐。在输入的图像和预测图都建立规则的网格变形场。\n\n目标 最小化当前颜色图和预测图在位置s的光度误差，这里s是2D三角网格的重心坐标。用网格的边长作为惩罚项。\n\n多尺度优化 金字塔。\n\n优化纹理块采样流程 当前帧从模型中提取出纹理块，当前帧颜色图和预测图都规则的分成网格，",normalizedContent:"# textureme论文阅读\n\n\n# 介绍\n\n高质量的纹理建图一般都是离线的后处理步骤，在这篇文章中，提出一种实时的联合恢复3d几何表面和高质量纹理。核心方法是创建与tsdf零交点相关联的三角形。\n\n虽然基于tsdf重建，使用有噪声的深度图融合，也能得到干净的表明，但传统的tsdf一个体素只能存储一个颜色值，要表示精细的表面颜色，那么就需要微小的体素，并需要大量的内存。通过marching cubes 可以从一个体素获得多个三角形，一般传统的方法通过对相邻体素插值来获得详细的三角形的颜色，因此受限于体素的分辨率。为了解决这个问题，提出了离线的纹理贴图方法，因为通过融合颜色图的方法来获得纹理图一般会受颜色图的位姿漂移影响，所以先前方法尝试取优化相机位姿和纹理图位置来获得高质量的纹理贴图。\n\n我们提出一个框架textureme，从rgb-d图像序列联合创建一个高质量的纹理地图和表面几何。其核心idea是 维护一个全局的纹理地图集 ** 其由直角三角形组成，我们称纹理patch，存储重建表面的三角形的颜色细节**。对marching cubes获得的三角形映射到当前帧得到纹理patch，然后整理纹理patch到全局纹理地图集中。\n\n本文贡献点概述：\n\n * 提出一个实时的同时重建几何和纹理的3d重建框架，没有采用任何后处理步骤；\n * 我们的方法值利用了颜色图，构建和更新一个全局纹理地图集；\n * 处理纹理patch不对齐，网格连接更新，纹理patch更新等问题；\n\n\n# 相关工作\n\n\n# 系统概述\n\ntextureme的几何重建模块是基于kinectfusion的，并且融合rgb信息，使用光度误差和几何误差来估计当前帧的位姿，虽然使用当前帧的位姿和深度图来更新tsdf模型。\n\n为了重建纹理块，网格模型是必要的。tsdf是暗含表面的表示方法，因此我们使用marching cubes去获得包含零点的三角形，然后使用位姿映射这些三角形到当前帧，来获得关联的详细颜色，然后在当前帧构建纹理块，使用纹理块去更新全局纹理地图集，当前帧的纹理块与全局纹理地图集中对应的纹理块进行平均更新。\n\ntextureme的核心是在全局纹理地图集中有效地表示，存储，构建，更新纹理块。接下来就第4节介绍纹理块的表示和存储，第5节介绍纹理快的构建和更新，第6节介绍优化误对齐的纹理块。\n\n\n# 纹理图集表示\n\n纹理块 是一个带有详细颜色信息的直角三角形，存储在纹理地图集中。\n\n纹理地图集 纹理图集是存储了一组直角三角形纹理块的大型图像，在重建开始之前，预先为纹理地图集分配显存，同时，通过将纹理图集均匀划分为直角三角形，预先计算纹理图集中每个纹理块的顶点的uv坐标，预先定义一个最小纹理块的大小，它可以存储从输入的彩色图像中可能的最大纹理细节。具体来说，将体素投影到当前的彩色图中，来计算纹理块的直角三角形大小。\n\n存储 我们从零交叉体素中生成三角形并分配一个唯一的纹理块索引，当一个体素第一次表示一个表面时，给他创建一个纹理块，然后存储在纹理图集中。设定每个体素最多能提取出ntri个三角网格，假设当前整个体积有nv，那么就要给纹理图集分配ntri×nv个纹理块的大小，这显然会浪费巨大的显存空间。作者使用一个空闲栈取管理纹理块，用来存储在纹理图集中暂无对应的纹理块的索引。一开始空闲栈填充纹理块数量的最大值个索引，每当创建一个纹理块，就从空闲栈中pop出一个索引分配给这个纹理块，当清除一个纹理块时，就push对应的索引到空闲栈中。\n\n如图，体素a有3个纹理块，当释放体素a的纹理块时，free list push进去纹理块的索引，当体素b需要创建一个纹理块时，从free list 中pop一个索引出来。\n\n\n\n某一帧使用marching cubes在体素a创建了某种类型的纹理块，但随后某帧在体素a创建了与之前不同数量或不同类型的纹理块，这时候就需要删除之前的纹理块，重新创建纹理块。（重采样）\n\n\n# 纹理块融合\n\n我们首先通过更新后的tsdf体积中提取三角形，将其投影到当前彩色图像上来构造新的纹理块，然后自适应地将来自当前帧的新纹理块与现有纹理图集中的纹理块进行融合，采用图像模糊度的加权融合，纹理块融合后还要解决网格连接问题。\n\n构建 mk表示第k帧从tsdf模型中提取的三角网格，为每一个网格构建一个纹理块tk′，将这个网格投影到当前的颜色图ck中，可以在颜色图ck中找到对应的三角形。\n\n\n\n更新 对纹理块的颜色进行加权平均，类似与tsdf的更新方式。如果当前体素中的纹理块类型数量都没变，那么在全局纹理图集中有一个当前体素中的纹理块对应，然后采用如下的更新方式：\n\ntk=wk−1⊙tk−1+wk′⊙tk′wk−1+wk′wk′(p)=wn⋅wd⋅wb\n\n过滤 避免体素的顶点在零点附近反复横跳，从而避免提取的三角形会经常改变。\n\ntk′={tk if |tk|≥δ+δ if |tk|<δ and tk−1≥+δ−δ if |tk|<δ and tk−1≤−δtk−1′ otherwise (|tk|<δ and |tk−1|<δ)\n\n重采样 前n帧在体素a创建了某种类型的纹理块，但随后帧在体素a创建了与之前不同数量或不同类型的纹理块，这时候就需要删除之前的纹理块，重新创建纹理块。将新创建的纹理块投影到预测表面（kinectfusion）进行采样颜色信息。\n\n\n# 纹理块优化\n\n实际中，相机位姿不可能完美准确，输入的彩色图像本身也经常收到镜头变形、快门失真以及不完美的颜色和深度图像同步的影响。在这一节中介绍一种优化方法使得对这些情况更加鲁棒。（对不对齐不是跟踪的事情吗，这里还优化啥呢，李在赣什魔）\n\n图像变形场 理想情况下，输入图像和当前模型渲染出来的图像（预测图）应该是完美对齐上的，但实际上会存在误对齐。在输入的图像和预测图都建立规则的网格变形场。\n\n目标 最小化当前颜色图和预测图在位置s的光度误差，这里s是2d三角网格的重心坐标。用网格的边长作为惩罚项。\n\n多尺度优化 金字塔。\n\n优化纹理块采样流程 当前帧从模型中提取出纹理块，当前帧颜色图和预测图都规则的分成网格，",charsets:{cjk:!0}},{title:"bundlefusion",frontmatter:{title:"bundlefusion",date:"2023-02-26T11:01:06.000Z",permalink:"/pages/cdb05f/"},regularPath:"/02.%E7%A7%91%E7%A0%94/01.%E5%AE%A4%E5%86%85%E5%AE%9E%E6%97%B6%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/bundlefusion.html",relativePath:"02.科研/01.室内实时三维重建/bundlefusion.md",key:"v-ca2c37f2",path:"/pages/cdb05f/",headers:[{level:2,title:"论文",slug:"论文",normalizedTitle:"论文",charIndex:2},{level:3,title:"摘要",slug:"摘要",normalizedTitle:"摘要",charIndex:9},{level:3,title:"介绍",slug:"介绍",normalizedTitle:"介绍",charIndex:165},{level:3,title:"方法概述",slug:"方法概述",normalizedTitle:"方法概述",charIndex:476},{level:3,title:"寻找特征关联",slug:"寻找特征关联",normalizedTitle:"寻找特征关联",charIndex:753},{level:4,title:"去除两帧之间的关联",slug:"去除两帧之间的关联",normalizedTitle:"去除两帧之间的关联",charIndex:838},{level:4,title:"去除关键点误匹配",slug:"去除关键点误匹配",normalizedTitle:"去除关键点误匹配",charIndex:944},{level:4,title:"通过表面过滤",slug:"通过表面过滤",normalizedTitle:"通过表面过滤",charIndex:1107},{level:4,title:"密集验证",slug:"密集验证",normalizedTitle:"密集验证",charIndex:1242},{level:3,title:"分层优化",slug:"分层优化",normalizedTitle:"分层优化",charIndex:1319},{level:4,title:"块内局部对齐",slug:"块内局部对齐",normalizedTitle:"块内局部对齐",charIndex:1410},{level:4,title:"关键帧优化",slug:"关键帧优化",normalizedTitle:"关键帧优化",charIndex:1654},{level:4,title:"全局块间优化",slug:"全局块间优化",normalizedTitle:"全局块间优化",charIndex:1720},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:1798},{level:4,title:"基于非结构化点的表示",slug:"基于非结构化点的表示",normalizedTitle:"基于非结构化点的表示",charIndex:1806},{level:4,title:"基于2.5D深度图",slug:"基于2-5d深度图",normalizedTitle:"基于2.5d深度图",charIndex:2508},{level:4,title:"基于高度场",slug:"基于高度场",normalizedTitle:"基于高度场",charIndex:2855},{level:4,title:"基于占用网格的体积",slug:"基于占用网格的体积",normalizedTitle:"基于占用网格的体积",charIndex:3009},{level:4,title:"基于隐式曲面",slug:"基于隐式曲面",normalizedTitle:"基于隐式曲面",charIndex:3459},{level:4,title:"基于TSDF（隐式截断符号距离）",slug:"基于tsdf-隐式截断符号距离",normalizedTitle:"基于tsdf（隐式截断符号距离）",charIndex:3761},{level:4,title:"最近最突出的例子是 KinectFusion [20, 34]，其中展示了较小场景的实时体积融合。",slug:"最近最突出的例子是-kinectfusion-20-34-其中展示了较小场景的实时体积融合。",normalizedTitle:"最近最突出的例子是 kinectfusion [20, 34]，其中展示了较小场景的实时体积融合。",charIndex:4389},{level:4,title:"用于体积融合的实时高效数据结构。",slug:"用于体积融合的实时高效数据结构。",normalizedTitle:"用于体积融合的实时高效数据结构。",charIndex:4948},{level:4,title:"通过优化整个位姿轨迹来得到全局一致的模型",slug:"通过优化整个位姿轨迹来得到全局一致的模型",normalizedTitle:"通过优化整个位姿轨迹来得到全局一致的模型",charIndex:6344},{level:4,title:"实时单目RGB方法",slug:"实时单目rgb方法",normalizedTitle:"实时单目rgb方法",charIndex:7124},{level:4,title:"稀疏",slug:"稀疏",normalizedTitle:"稀疏",charIndex:488},{level:4,title:"半稠密",slug:"半稠密",normalizedTitle:"半稠密",charIndex:7263},{level:4,title:"直接法",slug:"直接法",normalizedTitle:"直接法",charIndex:7547},{level:4,title:"位姿图优化",slug:"位姿图优化",normalizedTitle:"位姿图优化",charIndex:7877},{level:4,title:"捆绑调整",slug:"捆绑调整",normalizedTitle:"捆绑调整",charIndex:8064},{level:4,title:"ICP",slug:"icp",normalizedTitle:"icp",charIndex:8832}],headersStr:"论文 摘要 介绍 方法概述 寻找特征关联 去除两帧之间的关联 去除关键点误匹配 通过表面过滤 密集验证 分层优化 块内局部对齐 关键帧优化 全局块间优化 参考文献 基于非结构化点的表示 基于2.5D深度图 基于高度场 基于占用网格的体积 基于隐式曲面 基于TSDF（隐式截断符号距离） 最近最突出的例子是 KinectFusion [20, 34]，其中展示了较小场景的实时体积融合。 用于体积融合的实时高效数据结构。 通过优化整个位姿轨迹来得到全局一致的模型 实时单目RGB方法 稀疏 半稠密 直接法 位姿图优化 捆绑调整 ICP",content:"# 论文\n\n\n# 摘要\n\n一般重建结果比较好的方法都需要几个小时的离线处理。最近在线重建的效果还没那么好，有以下问题\n\n * 需要几分钟的处理，不能达到实时；\n * 脆弱的跟踪模型，导致跟踪失败；\n * 仅支持基于点的非结构化表示，这限制了扫描质量和适用性。\n\n我们消除了对时间跟踪的严重依赖，而是不断定位到全局优化的帧\n\n\n# 介绍\n\n大规模实时3D重建问题需要满足以下条件\n\n高质量的表面模型\n\n我们需要一个单一的纹理和无噪点 3D 场景模型，可由标准图形应用程序使用。 这需要一个可以模拟连续表面而不是离散点的高质量表示。\n\n可扩展性\n\n全局模型一致性\n\n随着规模的发函，需要纠正姿态漂移和估计误差。\n\n鲁棒的相机跟踪\n\n在特征不明显的区域可能跟踪失败，需要有重定位能力。许多先有的方法是基于与前一阵的接近度，从而限制了相机快速运动。我们就需要在不依赖时间连贯性的情况下的稳健的方法重定位。\n\n即时模型更新\n\n根据最新的姿态估计更新模型。\n\n由于我们全局关联每个 RGB-D 帧，因此可以隐式且连续地处理回环，从而无需任何显式回环检测。\n\n\n# 方法概述\n\n我们使用一组稀疏特征对应来获得粗略的全局对齐，因为稀疏特征固有地提供了回环检测和重新定位。然后通过优化密集的光度和几何一致性来细化这种对齐方式。\n\n提取SIFT关键点，和以前所有帧进行匹配，并且严格的取出无匹配。\n\n使用过滤后的关联，分层地局部到全局的位姿优化方法，在第一层，连续n帧（时间）组成一个chunk，在块内进行局部位姿优化。在第二层，所有的chunk相互关联进行全局优化。这种优化策略减少了未知量保证大范围重建。\n\n为了使用改进的估计来跟新帧的位姿，使用新的实时分离步骤移除旧位姿的RGB-D图像，并在新位姿处重新整合。\n\n\n# 寻找特征关联\n\n对于新来的每一帧，提取SIFT特征，和以前所有帧进行匹配。之后筛选没两帧之间的匹配，取出匹配，并生成有效的成对关联的列表，作为全局位姿优化的输入。\n\n# 去除两帧之间的关联\n\n为了最小化外点，根据几何和光度一致性过滤检测到的成对对应集。在进行优化后算出一个残差，如果大于某个值，就移除这两帧之间所有的匹配，另外，如果某一帧与任何一帧都没有关联，则称为无效帧。\n\n# 去除关键点误匹配\n\n当前关联Pcur，Qcur，对于新添加的关联，p,q，计算出一个变换，使得Pcur, Qcur的RMSD最小。之后计算Pcur，Qcur的一些有关误差的数，如果大于一个阈值，贼认为系统是不稳定的，那么就移除这些关联，直到这不够计算出一个变换。如果计算不出一个变换，那么就把这两帧之间的所有关联移除。\n\n# 通过表面过滤\n\n检查特征跨越的表面是否足够大，因为跨越太小的尺寸的关联会引起歧义。对于每组3D点，我们将它们投影到由它们的两个主轴方向（可以用中心距和重心求出）给定的平面中，表面积由生成的投影点的2D定向边界框给定。如果跨越的区域不足多少平米，则该组匹配被丢弃。\n\n# 密集验证\n\n\n\n以上式子都通过，就添加这关联到有效的关联集中，这之后用来做位姿优化。如果两帧之间关联数量大于一定值，则只使用帧间匹配来估计位姿。\n\n\n# 分层优化\n\n在输入的图像序列中，连续n帧组成一个chunk。在底层优化中，在一个块内进行局部对齐。在第二层，每一块的第一帧，作为这个块的关键帧，全局优化就是，对齐这些关键帧。\n\n# 块内局部对齐\n\n基于输入RGB-D流中连续11个帧，组成一个块，相邻的块重叠1帧。局部位姿优化是，计算与参考帧（块的第一帧）最优的相对位姿。优化的方法是，首先是上面的寻找特征关联，并且使用能量函数\n\n\n\nwdense是线性增加的，这让离散项找到一个比较好的全局结构，然后使用稠密项优化。\n\n在离散的匹配项，最小化S中所有帧对，所有关联的特征，投影到世界坐标系，的差。\n\n\n\nC(i, j)是第i帧和第j帧关联的特征。\n\n之后对块进行密集验证，如果重投影误差大于阈值，则丢弃这个块。\n\n# 关键帧优化\n\n一旦一个块完成优化，那么就定义块内第一帧作为关键帧。获得一个关键帧特征集，一旦获得关键帧特征集，就丢弃块数据。\n\n# 全局块间优化\n\n一旦一个关键帧没有找到一个以前的帧作为匹配，那么就视为无效帧，之后可以恢复。和局部块内优化一样，使用离散项和密集项来优化全局位姿。\n\n\n# 参考文献\n\n# 基于非结构化点的表示\n\nP. Henry, M. Krainin, E. Herbst, X. Ren, and D. Fox. 2010. RGB-D mapping: Using depth cameras for dense 3D modeling of indoor environments. In Proc. Int. Symp. Experimental Robotics, Vol. 20. 22–25.\n\nMaik Keller, Damien Leoch, Martin Lambers, Shahram Izadi, Tim Weyrich, and Andreas Kolb. 2013. Real-time 3D Reconstruction in Dynamic Scenes using Point-based Fusion. In Proc. 3DV. IEEE, 1–8.\n\nT. Weise, T. Wismer, B. Leibe, and L. Van Gool. 2009. In-hand scanning with online loop closure. In Proc. ICCV Workshops. 1630–1637.\n\nT. Whelan, S. Leutenegger, R. F. Salas-Moreno, B. Glocker, and A. J. Davison. 2015. ElasticFusion: Dense SLAM Without A Pose Graph. In Proc. RSS. Rome, Italy.\n\n# 基于2.5D深度图\n\nMaxime Meilland, Andrew Comport, and others. 2013. On unifying key-frame and voxel-based dense visual SLAM at large scales. In Proc. IROS. IEEE, 3677–3683.\n\nP. Merrell, A. Akbarzadeh, L. Wang, P. Mordohai, J.M. Frahm, R. Yang, D. Nister, ´ and M. Pollefeys. 2007. Real-time visibility-based fusion of depth maps. In Proc. ICCV. 1–8.\n\n# 基于高度场\n\nDavid Gallup, Marc Pollefeys, and Jan-Michael Frahm. 2010. 3D reconstruction using an n-layer heightmap. In Paern Recognition. Springer, 1–10.\n\n# 基于占用网格的体积\n\nAlberto Elfes and Larry Mahies. 1987. Sensor integration for robot navigation: combining sonar and stereo range data in a grid-based representataion. In Decision and Control, 1987. 26th IEEE Conference on, Vol. 26. IEEE, 1802–1807.\n\nKai M Wurm, Armin Hornung, Maren Bennewitz, Cyrill Stachniss, and Wolfram Burgard. 2010. OctoMap: A probabilistic, exible, and compact 3D map representation for robotic systems. In Proc. ICRA, Vol. 2.\n\n# 基于隐式曲面\n\nBrian Curless and Marc Levoy. 1996. A volumetric method for building complex models from range images. In In Proc. SIGGRAPH. ACM, 303–312.\n\nA. Hilton, A. Stoddart, J. Illingworth, and T. Windea. 1996. Reliable surface reconstruction from multiple range images. JProc. ECCV (1996), 117–126.\n\n# 基于TSDF（隐式截断符号距离）\n\nNicola Fioraio, Jonathan Taylor, Andrew Fitzgibbon, Luigi Di Stefano, and Shahram Izadi. 2015. Large-Scale and Dri-Free Surface Reconstruction Using Online Subvolume Registration. Proc. CVPR (June 2015).\n\nSimon Fuhrmann and Michael Goesele. 2014. Floating Scale Surface Reconstruction. In Proc. SIGGRAPH.\n\nMarc Levoy, Kari Pulli, Brian Curless, Szymon Rusinkiewicz, David Koller, Lucas Pereira, Ma Ginzton, Sean Anderson, James Davis, Jeremy Ginsberg, and others. 2000. e digital Michelangelo project: 3D scanning of large statues. In In Proc. SIGGRAPH. ACM Press/Addison-Wesley Publishing Co., 131–144.\n\n# 最近最突出的例子是 KinectFusion [20, 34]，其中展示了较小场景的实时体积融合。\n\nS. Izadi, D. Kim, O. Hilliges, D. Molyneaux, R. Newcombe, P. Kohli, J. Shoon, S. Hodges, D. Freeman, A. Davison, and A. Fitzgibbon. 2011. KinectFusion: Realtime 3D reconstruction and interaction using a moving depth camera. In Proc. UIST. 559–568.\n\nRichard A Newcombe, Shahram Izadi, Otmar Hilliges, David Molyneaux, David Kim, Andrew J Davison, Pushmeet Kohli, Jamie Shoon, Steve Hodges, and Andrew Fitzgibbon. 2011. KinectFusion: Real-time dense surface mapping and tracking. In Proc. ISMAR. 127–136.\n\n# 用于体积融合的实时高效数据结构。\n\nJiawen Chen, Dennis Bautembach, and Shahram Izadi. 2013. Scalable real-time volumetric surface reconstruction. ACM TOG 32, 4 (2013), 113.\n\nMaik Keller, Damien Leoch, Martin Lambers, Shahram Izadi, Tim Weyrich, and Andreas Kolb. 2013. Real-time 3D Reconstruction in Dynamic Scenes using Point-based Fusion. In Proc. 3DV. IEEE, 1–8.\n\nM. Nießner, M. Zollhofer, S. Izadi, and M. Stamminger. 2013. Real-time 3D ¨ Reconstruction at Scale using Voxel Hashing. ACM TOG (2013).\n\nF Reichl, J Weiss, and R Westermann. 2015. Memory-Ecient Interactive Online Reconstruction From Depth Image Streams. In Computer Graphics Forum. Wiley Online Library\n\nH. Roth and M. Vona. 2012. Moving Volume KinectFusion. In Proc. BMVC\n\nF. Steinbruecker, J. Sturm, and D. Cremers. 2014. Volumetric 3D Mapping in RealTime on a CPU. In 2014 IEEE International Conference on Robotics and Automation (ICRA). Hongkong, China.\n\nT Whelan, H Johannsson, M Kaess, J Leonard, and J McDonald. 2012. Robust Tracking for Real-Time Dense RGB-D Mapping with Kintinuous. Technical Report. ery date: 2012-10-25.\n\nM. Zeng, F. Zhao, J. Zheng, and X. Liu. 2012. Octree-based Fusion for Realtime 3D Reconstruction. Graphical Models (2012).\n\nYizhong Zhang, Weiwei Xu, Yiying Tong, and Kun Zhou. 2015. Online structure analysis for real-time indoor scene reconstruction. ACM Transactions on Graphics (TOG) 34, 5 (2015), 159.\n\n# 通过优化整个位姿轨迹来得到全局一致的模型\n\nSungjoon Choi, Qian-Yi Zhou, and Vladlen Koltun. 2015. Robust Reconstruction of Indoor Scenes. Proc. CVPR (June 2015).\n\nHao Li, Etienne Vouga, Anton Gudym, Linjie Luo, Jonathan T Barron, and Gleb Gusev. 2013. 3D self-portraits. ACM TOG 32, 6 (2013), 187.\n\nQian-Yi Zhou and Vladlen Koltun. 2013. Dense scene reconstruction with points of interest. ACM Transactions on Graphics (TOG) 32, 4 (2013), 112.\n\nQian-Yi Zhou and Vladlen Koltun. 2014. Color map optimization for 3D reconstruction with consumer depth cameras. ACM Transactions on Graphics (TOG) 33, 4 (2014), 155.\n\nQian-Yi Zhou, Steven Miller, and Vladlen Koltun. 2013. Elastic fragments for dense scene reconstruction. In Computer Vision (ICCV), 2013 IEEE International Conference on. IEEE, 473–480\n\n# 实时单目RGB方法\n\n# 稀疏\n\nGeorg Klein and David Murray. 2007. Parallel Tracking and Mapping for Small AR Workspaces. In Proc. ISMAR. Nara, Japan\n\n# 半稠密\n\nJakob Engel, Jurgen Sturm, and Daniel Cremers. 2013. Semi-dense visual odometry for a monocular camera. In Proc. ICCV. IEEE, 1449–1456.\n\nChristian Forster, Matia Pizzoli, and Davide Scaramuzza. 2014. SVO: Fast semidirect monocular visual odometry. In Proc. ICRA. IEEE, 15–22.\n\n# 直接法\n\nJ. Engel, T. Schops, and D. Cremers. 2014. LSD-SLAM: Large-Scale Direct Monoc- ¨ ular SLAM. In European Conference on Computer Vision.\n\nMaxime Meilland, A Comport, Patrick Rives, and INRIA Sophia Antipolis Mediterran ´ ee. 2011. Real-time dense visual tracking under large lighting varia- ´ tions. In Proc. BMVC, Vol. 29.\n\n# 位姿图优化\n\nRainer Kummerle, Giorgio Grisei, Hauke Strasdat, Kurt Konolige, and Wolfram ¨ Burgard. 2011. g 2 o: A general framework for graph optimization. In Proc. ICRA. IEEE, 3607–3613.\n\n# 捆绑调整\n\nBill Triggs, Philip F McLauchlan, Richard I Hartley, and Andrew W Fitzgibbon. 2000. Bundle adjustmen, a modern synthesis. In Vision algorithms: theory and practice. Springer, 298–372\n\nMonoFusion [38] 通过密集体积融合增强了稀疏 SLAM 束调整，在小规模场景中显示出令人信服的单目结果。 实时 SLAM 方法通常首先逐帧估计位姿，然后在后台线程中执行校正（运行速度低于实时速率；例如，1Hz）。\n\nVivek Pradeep, Christoph Rhemann, Shahram Izadi, Christopher Zach, Michael Bleyer, and Steven Bathiche. 2013. MonoFusion: Real-time 3D reconstruction of small scenes with a single web camera. In Proc. ISMAR. 83–88.\n\n相比之下，DTAM [35] 使用帧到模型跟踪的概念（来自 KinectFusion [20, 34]）直接从重建的密集 3D 模型估计姿势。 这省略了校正步骤的需要，但显然不能扩展到更大的场景。\n\nRichard A. Newcombe, Steven J. Lovegrove, and Andrew J. Davison. 2011. DTAM: Dense Tracking and Mapping in Real-time. In Proc. ICCV. 2320–2327.\n\n# ICP\n\nP.J. Besl and N.D. McKay. 1992. A method for registration of 3-D shapes. IEEE Trans. PAMI 14, 2 (1992), 239–256.\n\nS. Rusinkiewicz and M. Levoy. 2001. Ecient variants of the ICP algorithm. In Proc. 3DIM. 145–152.",normalizedContent:"# 论文\n\n\n# 摘要\n\n一般重建结果比较好的方法都需要几个小时的离线处理。最近在线重建的效果还没那么好，有以下问题\n\n * 需要几分钟的处理，不能达到实时；\n * 脆弱的跟踪模型，导致跟踪失败；\n * 仅支持基于点的非结构化表示，这限制了扫描质量和适用性。\n\n我们消除了对时间跟踪的严重依赖，而是不断定位到全局优化的帧\n\n\n# 介绍\n\n大规模实时3d重建问题需要满足以下条件\n\n高质量的表面模型\n\n我们需要一个单一的纹理和无噪点 3d 场景模型，可由标准图形应用程序使用。 这需要一个可以模拟连续表面而不是离散点的高质量表示。\n\n可扩展性\n\n全局模型一致性\n\n随着规模的发函，需要纠正姿态漂移和估计误差。\n\n鲁棒的相机跟踪\n\n在特征不明显的区域可能跟踪失败，需要有重定位能力。许多先有的方法是基于与前一阵的接近度，从而限制了相机快速运动。我们就需要在不依赖时间连贯性的情况下的稳健的方法重定位。\n\n即时模型更新\n\n根据最新的姿态估计更新模型。\n\n由于我们全局关联每个 rgb-d 帧，因此可以隐式且连续地处理回环，从而无需任何显式回环检测。\n\n\n# 方法概述\n\n我们使用一组稀疏特征对应来获得粗略的全局对齐，因为稀疏特征固有地提供了回环检测和重新定位。然后通过优化密集的光度和几何一致性来细化这种对齐方式。\n\n提取sift关键点，和以前所有帧进行匹配，并且严格的取出无匹配。\n\n使用过滤后的关联，分层地局部到全局的位姿优化方法，在第一层，连续n帧（时间）组成一个chunk，在块内进行局部位姿优化。在第二层，所有的chunk相互关联进行全局优化。这种优化策略减少了未知量保证大范围重建。\n\n为了使用改进的估计来跟新帧的位姿，使用新的实时分离步骤移除旧位姿的rgb-d图像，并在新位姿处重新整合。\n\n\n# 寻找特征关联\n\n对于新来的每一帧，提取sift特征，和以前所有帧进行匹配。之后筛选没两帧之间的匹配，取出匹配，并生成有效的成对关联的列表，作为全局位姿优化的输入。\n\n# 去除两帧之间的关联\n\n为了最小化外点，根据几何和光度一致性过滤检测到的成对对应集。在进行优化后算出一个残差，如果大于某个值，就移除这两帧之间所有的匹配，另外，如果某一帧与任何一帧都没有关联，则称为无效帧。\n\n# 去除关键点误匹配\n\n当前关联pcur，qcur，对于新添加的关联，p,q，计算出一个变换，使得pcur, qcur的rmsd最小。之后计算pcur，qcur的一些有关误差的数，如果大于一个阈值，贼认为系统是不稳定的，那么就移除这些关联，直到这不够计算出一个变换。如果计算不出一个变换，那么就把这两帧之间的所有关联移除。\n\n# 通过表面过滤\n\n检查特征跨越的表面是否足够大，因为跨越太小的尺寸的关联会引起歧义。对于每组3d点，我们将它们投影到由它们的两个主轴方向（可以用中心距和重心求出）给定的平面中，表面积由生成的投影点的2d定向边界框给定。如果跨越的区域不足多少平米，则该组匹配被丢弃。\n\n# 密集验证\n\n\n\n以上式子都通过，就添加这关联到有效的关联集中，这之后用来做位姿优化。如果两帧之间关联数量大于一定值，则只使用帧间匹配来估计位姿。\n\n\n# 分层优化\n\n在输入的图像序列中，连续n帧组成一个chunk。在底层优化中，在一个块内进行局部对齐。在第二层，每一块的第一帧，作为这个块的关键帧，全局优化就是，对齐这些关键帧。\n\n# 块内局部对齐\n\n基于输入rgb-d流中连续11个帧，组成一个块，相邻的块重叠1帧。局部位姿优化是，计算与参考帧（块的第一帧）最优的相对位姿。优化的方法是，首先是上面的寻找特征关联，并且使用能量函数\n\n\n\nwdense是线性增加的，这让离散项找到一个比较好的全局结构，然后使用稠密项优化。\n\n在离散的匹配项，最小化s中所有帧对，所有关联的特征，投影到世界坐标系，的差。\n\n\n\nc(i, j)是第i帧和第j帧关联的特征。\n\n之后对块进行密集验证，如果重投影误差大于阈值，则丢弃这个块。\n\n# 关键帧优化\n\n一旦一个块完成优化，那么就定义块内第一帧作为关键帧。获得一个关键帧特征集，一旦获得关键帧特征集，就丢弃块数据。\n\n# 全局块间优化\n\n一旦一个关键帧没有找到一个以前的帧作为匹配，那么就视为无效帧，之后可以恢复。和局部块内优化一样，使用离散项和密集项来优化全局位姿。\n\n\n# 参考文献\n\n# 基于非结构化点的表示\n\np. henry, m. krainin, e. herbst, x. ren, and d. fox. 2010. rgb-d mapping: using depth cameras for dense 3d modeling of indoor environments. in proc. int. symp. experimental robotics, vol. 20. 22–25.\n\nmaik keller, damien leoch, martin lambers, shahram izadi, tim weyrich, and andreas kolb. 2013. real-time 3d reconstruction in dynamic scenes using point-based fusion. in proc. 3dv. ieee, 1–8.\n\nt. weise, t. wismer, b. leibe, and l. van gool. 2009. in-hand scanning with online loop closure. in proc. iccv workshops. 1630–1637.\n\nt. whelan, s. leutenegger, r. f. salas-moreno, b. glocker, and a. j. davison. 2015. elasticfusion: dense slam without a pose graph. in proc. rss. rome, italy.\n\n# 基于2.5d深度图\n\nmaxime meilland, andrew comport, and others. 2013. on unifying key-frame and voxel-based dense visual slam at large scales. in proc. iros. ieee, 3677–3683.\n\np. merrell, a. akbarzadeh, l. wang, p. mordohai, j.m. frahm, r. yang, d. nister, ´ and m. pollefeys. 2007. real-time visibility-based fusion of depth maps. in proc. iccv. 1–8.\n\n# 基于高度场\n\ndavid gallup, marc pollefeys, and jan-michael frahm. 2010. 3d reconstruction using an n-layer heightmap. in paern recognition. springer, 1–10.\n\n# 基于占用网格的体积\n\nalberto elfes and larry mahies. 1987. sensor integration for robot navigation: combining sonar and stereo range data in a grid-based representataion. in decision and control, 1987. 26th ieee conference on, vol. 26. ieee, 1802–1807.\n\nkai m wurm, armin hornung, maren bennewitz, cyrill stachniss, and wolfram burgard. 2010. octomap: a probabilistic, exible, and compact 3d map representation for robotic systems. in proc. icra, vol. 2.\n\n# 基于隐式曲面\n\nbrian curless and marc levoy. 1996. a volumetric method for building complex models from range images. in in proc. siggraph. acm, 303–312.\n\na. hilton, a. stoddart, j. illingworth, and t. windea. 1996. reliable surface reconstruction from multiple range images. jproc. eccv (1996), 117–126.\n\n# 基于tsdf（隐式截断符号距离）\n\nnicola fioraio, jonathan taylor, andrew fitzgibbon, luigi di stefano, and shahram izadi. 2015. large-scale and dri-free surface reconstruction using online subvolume registration. proc. cvpr (june 2015).\n\nsimon fuhrmann and michael goesele. 2014. floating scale surface reconstruction. in proc. siggraph.\n\nmarc levoy, kari pulli, brian curless, szymon rusinkiewicz, david koller, lucas pereira, ma ginzton, sean anderson, james davis, jeremy ginsberg, and others. 2000. e digital michelangelo project: 3d scanning of large statues. in in proc. siggraph. acm press/addison-wesley publishing co., 131–144.\n\n# 最近最突出的例子是 kinectfusion [20, 34]，其中展示了较小场景的实时体积融合。\n\ns. izadi, d. kim, o. hilliges, d. molyneaux, r. newcombe, p. kohli, j. shoon, s. hodges, d. freeman, a. davison, and a. fitzgibbon. 2011. kinectfusion: realtime 3d reconstruction and interaction using a moving depth camera. in proc. uist. 559–568.\n\nrichard a newcombe, shahram izadi, otmar hilliges, david molyneaux, david kim, andrew j davison, pushmeet kohli, jamie shoon, steve hodges, and andrew fitzgibbon. 2011. kinectfusion: real-time dense surface mapping and tracking. in proc. ismar. 127–136.\n\n# 用于体积融合的实时高效数据结构。\n\njiawen chen, dennis bautembach, and shahram izadi. 2013. scalable real-time volumetric surface reconstruction. acm tog 32, 4 (2013), 113.\n\nmaik keller, damien leoch, martin lambers, shahram izadi, tim weyrich, and andreas kolb. 2013. real-time 3d reconstruction in dynamic scenes using point-based fusion. in proc. 3dv. ieee, 1–8.\n\nm. nießner, m. zollhofer, s. izadi, and m. stamminger. 2013. real-time 3d ¨ reconstruction at scale using voxel hashing. acm tog (2013).\n\nf reichl, j weiss, and r westermann. 2015. memory-ecient interactive online reconstruction from depth image streams. in computer graphics forum. wiley online library\n\nh. roth and m. vona. 2012. moving volume kinectfusion. in proc. bmvc\n\nf. steinbruecker, j. sturm, and d. cremers. 2014. volumetric 3d mapping in realtime on a cpu. in 2014 ieee international conference on robotics and automation (icra). hongkong, china.\n\nt whelan, h johannsson, m kaess, j leonard, and j mcdonald. 2012. robust tracking for real-time dense rgb-d mapping with kintinuous. technical report. ery date: 2012-10-25.\n\nm. zeng, f. zhao, j. zheng, and x. liu. 2012. octree-based fusion for realtime 3d reconstruction. graphical models (2012).\n\nyizhong zhang, weiwei xu, yiying tong, and kun zhou. 2015. online structure analysis for real-time indoor scene reconstruction. acm transactions on graphics (tog) 34, 5 (2015), 159.\n\n# 通过优化整个位姿轨迹来得到全局一致的模型\n\nsungjoon choi, qian-yi zhou, and vladlen koltun. 2015. robust reconstruction of indoor scenes. proc. cvpr (june 2015).\n\nhao li, etienne vouga, anton gudym, linjie luo, jonathan t barron, and gleb gusev. 2013. 3d self-portraits. acm tog 32, 6 (2013), 187.\n\nqian-yi zhou and vladlen koltun. 2013. dense scene reconstruction with points of interest. acm transactions on graphics (tog) 32, 4 (2013), 112.\n\nqian-yi zhou and vladlen koltun. 2014. color map optimization for 3d reconstruction with consumer depth cameras. acm transactions on graphics (tog) 33, 4 (2014), 155.\n\nqian-yi zhou, steven miller, and vladlen koltun. 2013. elastic fragments for dense scene reconstruction. in computer vision (iccv), 2013 ieee international conference on. ieee, 473–480\n\n# 实时单目rgb方法\n\n# 稀疏\n\ngeorg klein and david murray. 2007. parallel tracking and mapping for small ar workspaces. in proc. ismar. nara, japan\n\n# 半稠密\n\njakob engel, jurgen sturm, and daniel cremers. 2013. semi-dense visual odometry for a monocular camera. in proc. iccv. ieee, 1449–1456.\n\nchristian forster, matia pizzoli, and davide scaramuzza. 2014. svo: fast semidirect monocular visual odometry. in proc. icra. ieee, 15–22.\n\n# 直接法\n\nj. engel, t. schops, and d. cremers. 2014. lsd-slam: large-scale direct monoc- ¨ ular slam. in european conference on computer vision.\n\nmaxime meilland, a comport, patrick rives, and inria sophia antipolis mediterran ´ ee. 2011. real-time dense visual tracking under large lighting varia- ´ tions. in proc. bmvc, vol. 29.\n\n# 位姿图优化\n\nrainer kummerle, giorgio grisei, hauke strasdat, kurt konolige, and wolfram ¨ burgard. 2011. g 2 o: a general framework for graph optimization. in proc. icra. ieee, 3607–3613.\n\n# 捆绑调整\n\nbill triggs, philip f mclauchlan, richard i hartley, and andrew w fitzgibbon. 2000. bundle adjustmen, a modern synthesis. in vision algorithms: theory and practice. springer, 298–372\n\nmonofusion [38] 通过密集体积融合增强了稀疏 slam 束调整，在小规模场景中显示出令人信服的单目结果。 实时 slam 方法通常首先逐帧估计位姿，然后在后台线程中执行校正（运行速度低于实时速率；例如，1hz）。\n\nvivek pradeep, christoph rhemann, shahram izadi, christopher zach, michael bleyer, and steven bathiche. 2013. monofusion: real-time 3d reconstruction of small scenes with a single web camera. in proc. ismar. 83–88.\n\n相比之下，dtam [35] 使用帧到模型跟踪的概念（来自 kinectfusion [20, 34]）直接从重建的密集 3d 模型估计姿势。 这省略了校正步骤的需要，但显然不能扩展到更大的场景。\n\nrichard a. newcombe, steven j. lovegrove, and andrew j. davison. 2011. dtam: dense tracking and mapping in real-time. in proc. iccv. 2320–2327.\n\n# icp\n\np.j. besl and n.d. mckay. 1992. a method for registration of 3-d shapes. ieee trans. pami 14, 2 (1992), 239–256.\n\ns. rusinkiewicz and m. levoy. 2001. ecient variants of the icp algorithm. in proc. 3dim. 145–152.",charsets:{cjk:!0}},{title:"基于信息论自主探索",frontmatter:{title:"基于信息论自主探索",date:"2022-06-15T12:47:36.000Z",permalink:"/pages/8487b5/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/02.%E5%9F%BA%E4%BA%8E%E4%BF%A1%E6%81%AF%E8%AE%BA%E8%87%AA%E4%B8%BB%E6%8E%A2%E7%B4%A2.html",relativePath:"02.科研/02.大规模三维重建/02.基于信息论自主探索.md",key:"v-13e764ec",path:"/pages/8487b5/",headersStr:null,content:"通过信息论的方法来解决机器人自主探索问题，在机器人视野内，选择一个包含信息量最大的位置。该论文提出，使用贝叶斯优化预测互信息(MI)，机器人感知候选动作由贝叶斯优化给出，然后添加到高斯过程中训练？高斯过程估计机器人整个动作空间的MI，然后通过acquisition function选择下一个候选动作？\n\n自主探索问题：在一个没有先验的环境中，依次决定下一个动作。最终目标让整个栅格地图熵变小，往近了看就是每次找MI最大的动作。\n\n本文工作中，显示地计算MI。使用高斯过程的后验mean function估计MI。在每次贝叶斯优化迭代中，计算出一个候选动作，然后添加到一个用于近似MI的动作池中？？高斯过程可以估计MI，也形成acquisition function用于选择下一个候选动作？？云里雾里。",normalizedContent:"通过信息论的方法来解决机器人自主探索问题，在机器人视野内，选择一个包含信息量最大的位置。该论文提出，使用贝叶斯优化预测互信息(mi)，机器人感知候选动作由贝叶斯优化给出，然后添加到高斯过程中训练？高斯过程估计机器人整个动作空间的mi，然后通过acquisition function选择下一个候选动作？\n\n自主探索问题：在一个没有先验的环境中，依次决定下一个动作。最终目标让整个栅格地图熵变小，往近了看就是每次找mi最大的动作。\n\n本文工作中，显示地计算mi。使用高斯过程的后验mean function估计mi。在每次贝叶斯优化迭代中，计算出一个候选动作，然后添加到一个用于近似mi的动作池中？？高斯过程可以估计mi，也形成acquisition function用于选择下一个候选动作？？云里雾里。",charsets:{cjk:!0}},{title:"ORB_SLAM2原理、代码流程文档",frontmatter:{title:"ORB_SLAM2原理、代码流程文档",date:"2021-11-21T11:08:31.000Z",permalink:"/pages/cc3afe/"},regularPath:"/02.%E7%A7%91%E7%A0%94/01.%E5%AE%A4%E5%86%85%E5%AE%9E%E6%97%B6%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/14.ORB_SLAM2%E5%8E%9F%E7%90%86%E3%80%81%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E6%96%87%E6%A1%A3.html",relativePath:"02.科研/01.室内实时三维重建/14.ORB_SLAM2原理、代码流程文档.md",key:"v-4f35af8e",path:"/pages/cc3afe/",headers:[{level:2,title:"算法原理",slug:"算法原理",normalizedTitle:"算法原理",charIndex:2},{level:3,title:"Tracking",slug:"tracking",normalizedTitle:"tracking",charIndex:22},{level:3,title:"LocalMapping",slug:"localmapping",normalizedTitle:"localmapping",charIndex:31},{level:3,title:"LoopClosing",slug:"loopclosing",normalizedTitle:"loopclosing",charIndex:44},{level:3,title:"① 检测闭环",slug:"_1-检测闭环",normalizedTitle:"① 检测闭环",charIndex:6922},{level:3,title:"② 计算sim3 相似变换",slug:"_2-计算sim3-相似变换",normalizedTitle:"② 计算sim3 相似变换",charIndex:7272},{level:3,title:"③ 回环矫正",slug:"_3-回环矫正",normalizedTitle:"③ 回环矫正",charIndex:7777},{level:2,title:"代码流程",slug:"代码流程",normalizedTitle:"代码流程",charIndex:8440},{level:3,title:"文件的调用关系",slug:"文件的调用关系",normalizedTitle:"文件的调用关系",charIndex:8449},{level:3,title:"重要变量的意义",slug:"重要变量的意义",normalizedTitle:"重要变量的意义",charIndex:8595},{level:3,title:"Tracking流程",slug:"tracking流程",normalizedTitle:"tracking流程",charIndex:17329},{level:3,title:"LocalMapping流程",slug:"localmapping流程",normalizedTitle:"localmapping流程",charIndex:20004},{level:3,title:"LoopClosing流程",slug:"loopclosing流程",normalizedTitle:"loopclosing流程",charIndex:22450}],headersStr:"算法原理 Tracking LocalMapping LoopClosing ① 检测闭环 ② 计算sim3 相似变换 ③ 回环矫正 代码流程 文件的调用关系 重要变量的意义 Tracking流程 LocalMapping流程 LoopClosing流程",content:'# 算法原理\n\n算法由三大部分组成，分别是 Tracking、LocalMapping、LoopClosing 三个线程\n\n\n# Tracking\n\n 1. 特征点的提取（ORB Extraction） 在此之前，特征点的提取方法有sift，surf等，但相比ORB都比较耗时。ORB算法先提取FAST角点，再计算BRIEF描述子，最终利用Bow词袋模型来匹配特征点。\n    \n    * 建立图像金字塔：将原图像按不同比例缩小，得到多张图片，分别对每张图片进行下述操作。\n    \n    * FAST角点提取（对所有像素点进行提取）\n      \n      * 将图像转为灰度图，选取像素 p， 假设他的亮度为 Ip\n      * 设定一个阈值 T，其大小与 Ip 成正比\n      * 以 p 为中心，半径为3的圆上选16个像素点\n      * 如果有连续N个点亮度大于 Ip+T 或小于Ip−T，则 p 被认为是一个FAST角点 ![在这里插入图片描述](https://img-blog.csdnimg.cn/c20d47d96bd34496b6479aa829565f2b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQUTni5fkuJw=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center =400x200)\n    \n    ----------------------------------------\n    \n    * BRIEF描述子（对所有的FAST角点计算描述子）\n      \n      * 计算每个FAST角点圆心到质心点的方向\n      \n      * 将每个角点对应的圆域进行旋转，旋转至所有角点对应的方向相同。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/bed388824aab4c818d38ead3a1c21f5a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQUTni5fkuJw=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center =300x135)\n      \n      * 圆域内选取N个点对（默认指定了128对点），通过将亮度的比较结果，将角点映射为：只由0、1组成的128维向量，将此向量作为BRIEF描述子\n      \n      * 最后，对每个FAST角点，都生成了128维描述子。\n      \n      * 当被拍摄物体放大或者缩小时，FAST角点会产生不同的提取结果（比如缩小会引起角点消失），但在图像金字塔的其他层中依然可以提取到缩放前对应的FAST角点，从而具有良好的尺度不变性。当被拍摄物体发生旋转时，其FAST角点的方向也会随之旋转，计算BRIEF描述子前，将所有FAST角点旋转至同一方向，相当于将所有拍摄对象都旋转到同一方向，从而具有良好的旋转不变性\n    \n    * BoW 词袋模型（对图片、特征进行查找和索引）\n      * 词袋模型作为所有描述子的字典， 用于量化两张图或两个特征点的相似性\n      * 字典的数据结构为 k叉树，上层是下层的聚类，最底层的每个叶子节点对应的是最小特征单元：BRIEF描述子\n      * 获得描述子后，通过次查找k叉树，来得到此描述子的匹配点，降低了查找匹配的复杂度\n\n 2. 旋转不变性来自：提取FAST特征时，计算了每个角点的中心点到质心点的方向向量，即使物体发生了旋转，也可利用方向向量来识别。\n\n 3. 尺度不变性来自：对每一帧，建立4层的高斯金字塔，分别在每层金字塔上做特征提取，即使A图中的特征在B图中变小，也可以在A图金字塔高层提取到B图中同尺度的特征\n    \n    ----------------------------------------\n\n 4. 点云初始化 这部分在论文中没有提及。发生在整个算法刚开始运行时，点云的初始化是此后每一帧能成功定位的前提\n    \n    * 作用：特征匹配、三角化，得到初始点云图，对于单目来说，就是将P2P问题转为PnP问题\n    * 步骤(以单目为例）：\n      * 初始选取2个特征点较多的帧（ 特征点数特征点数>100 )，并在词袋中进行特征匹配\n      * 并行计算单应性矩阵 H 和基础矩阵 F 。 当对极约束不成立的时候（相机只有旋转没有平移），或场景都在同一平面时，用单应性矩阵来计算两帧之间的变换矩阵。否则用基础矩阵计算变换矩阵\n      * 将第一帧的位姿设置为基准位姿，第二帧的位姿为上一步所求出的变换矩阵\n      * 创建地图点对象MapPoint，恢复出所有匹配点对应的世界坐标\n    \n    ----------------------------------------\n\n 5. 位姿初始化（Initial Pose Estimation） 对 CurrFrame (此刻的帧)位姿优化之前，先要有一个大概的估计，作为之后优化位姿的初值。根据当前跟踪状态的不同，一共有三种初始化方法：根据参考关键帧估计，根据匀速运动模型估计，重定位。除此之外，还要对此帧观测到的特征点进行估计\n    \n    * 作用：估计帧的位置，以及观测到的局部地图点\n    * 步骤：\n      \n      * 跟踪状态为LOST时：\n        \n        * 用重定位估计位姿（Relocation），用词袋模型寻找与 CurrFrame 最相似的帧 RelocFrame，进行特征匹配\n        * 统计 CurrFrame 上匹配点数量，数量太少则认为匹配效果差，保持状态为LOST，结束对此帧的处理，等待下一帧；数量足够的话，进行一次仅优化位姿的BA（motion-only BA），数量不够则舍弃此帧\n      \n      * 跟踪状态NORMAL时：\n        \n        * 根据匀速运动模型估计位姿，默认上一帧到 CurrFrame 的变换矩阵等于上上帧到上一帧的变换矩阵。（track with Motion model）\n        * 将上一帧（LastFrame）观测到的MapPoint 投影到估计的位姿上，观测有多少投影点与特征点位置重合，重合则认为是一对匹配点，如果重合的足够多，则进行一次仅优化位姿的BA，如果重合的个数太少，表明匹配失败改用参考关键帧估计；\n      \n      * 根据参考关键帧估计位姿：（Track with RefFrame）\n        \n        * 用词袋模型，将 CurrFrame 与参考关键帧（最新的关键帧）进行特征匹配\n        * 匹配后执行一次仅优化位姿的BA（motion-only BA）\n        * 统计匹配特征点数，数量少则认为匹配失败，将状态改为LOST，结束对此帧的处理，等待下一帧；\n    * 需要注意：初始化后的Frame 中仍会有大量特征点没建立匹配 ，这也体现了tracking线程的重要思想：在尽可能少的建立匹配的情况下，初始化出相机的位姿。\n    \n    ----------------------------------------\n\n 6. 局部位姿优化（Track Local Map） 经过上面的初始化，失败的 Frame ，说明其与地图联系不够紧密，无法建立稳健的约束和估计；而与地图联系紧密的Frame 则初始化成功。 但刚刚初始化所得位姿仅依赖于与某一帧（前一帧或参考关键帧）中的匹配关系，置信度较低。 接下来，我们在局部图中寻找更多的匹配关系，利用这些匹配关系进一步优化CurrFrame的位姿。\n    \n    * covisibility graph定义：covisibility graph，是无向加权图，如果两个关键帧之间有共视关系（共同观测到>15个地图点）就连成一条有权边，这些边和所有关键帧节点组成共视图。\n    * 在共视图中，针对CurrFrame定义一组关键帧为局部关键帧，局部关键帧由四种邻居组成。这四种邻居为：\n      * 与 CurrFrame 有共视点的帧（一级共视帧）\n      * 与 一级共视帧 有共视点的前十个帧（二级共视帧）（按共视点个数排序）\n      * 一级共视帧的子关键帧\n      * 一级共视帧的父关键帧（与一级共视帧共视程度最高的帧）\n    * 将 CurrFrame、局部关键帧 、以及这些帧观测到的 MapPoint作为：局部图 （localmap）\n    * 将localmap 中的MapPoint向 CurrFrame 投影![请添加图片描述](https://img-blog.csdnimg.cn/38d7c6d141d34d95837c80abd9b6a72b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQUTni5fkuJw=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center =420x350)\n    * 对 CurrFrame再进行一次仅位姿BA（motion-only BA）优化，估计出各个局部关键帧的位姿\n    \n    ----------------------------------------\n\n 7. 关键帧的审核与生成 (New Keyframe Decision)\n    \n    * 检测系统是否允许关键帧的插入\n      * only_Tracking 模式下，不需要关键帧\n      * localmap 被 loopclosing线程占用，不能插入关键帧\n      * 关键帧总数较多，且距离上一个关键帧距离很近，不需要插入关键帧\n    * 审核CurrFrame是否有资格做关键帧\n      * 记录CurrFrame 观察到的MapPoint总数，numcurr\n      * 记录RefFrame 观察到的MapPoint总数，numref![请添加图片描述](https://img-blog.csdnimg.cn/3789e59c73034275a21d8a682ed6d9d4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQUTni5fkuJw=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center =420x350)\n      * 如果numcurrnumref小于一定阈值，则允许 CurrFrame作为一个关键帧\n    * 将 CurrFrame 设置为关键帧\n      * 将自己生成的关键帧PkF 作为CurrFrame 的参考关键帧\n      * 在地图中新建地图点 ![请添加图片描述](https://img-blog.csdnimg.cn/e33fd597a7484bbc9529fe590caa24be.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAQUTni5fkuJw=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center =420x350)\n    \n    ----------------------------------------\n\n * 总结\n * Tracking线程根据状态的不同，以三种方式来初始化每一帧的位置和姿态，这三种方式速度由慢到快为：\n * 回顾Tracking过程\n   * 整个过程可以看做三步：获取位置、优化位置、关键帧审核\n   * 在尽可能少建立匹配或者不建立匹配的情况下，进行位姿初始化（获取位置）\n   * 尽可能建立一个：体量尽量小、但与CurrFrame关系足够多（四种邻居）的局部图，在此局部图的基础上进行图优化BA （优化位置）\n   * 在跟踪到的点足够多的情况下（>50个），尽可能多地生成关键帧，因为后面的关键帧删除策略很严格，这里关键帧的生成比较宽松（关键帧审核）\n * 可以看出，Tracking的一个重要特点是提速（不到万不得已，不进行耗时的匹配操作）\n\n\n# LocalMapping\n\n 1. 当待处理KeyFrame队列非空， localMapping线程就开始工作、\n\n 2. 将此KeyFrame插入共视图中（KeyFrame Insertion）\n    \n    * 计算此KeyFrame对应的词袋向量（应该是在回环检测会用到）\n    * 获取localMap中，被此KeyFrame观测到的点（在Tracking线程中的位姿初始化步骤已经被初始化），更新此KeyFrame的平均观测方向，以及各个MapPoint的最佳描述子\n    * 根据共视程度创建有权边，将KeyFrame插入共视图中\n\n----------------------------------------\n\n 4. 删除多余的MapPoint 此前LocalMapping线程可能删除了一些冗余关键帧，导致对应的地图点接近于“无帧观测”的状态，不满足以下2条件中任意一条的MapPoint会被移除\n    * 对于localmap中的任意地图点P，如果 实际观测到的帧数量预测会观测到的帧数量实际观测到P的帧数量预测会观测到P的帧数量>25%\n    * 如果观测到P的是一个关键帧，则至少三个连续关键帧都观测到P\n\n----------------------------------------\n\n 5. 创建新的MapPoint\n    * 创建MapPoint点：对当前关键帧（Kc）的未匹配特征点，在所有其他关键帧中寻找特征匹配（利用词袋模型），得一定数量的最佳共视关键帧（Ki），相互匹配后进行三角化，计算出新MapPoint P 的位置\n    * 构建MapPoint、Kc与全局map的联系：得出MapPoint的位置后，还需要将P与全局map融合，也就是建立P与其他关键帧的联系\n      * 定义一级二级关键帧：\n        * 一级关键帧：在共视图中挑选10个共视程度最佳的邻居\n        * 二级关键帧：对每个一级关键帧，分别挑选5个共视程度最高的邻居\n      * 正向投影融合：此时P点只被Kc和Ki两个帧所观测到，还需将P分别投影到一、二级关键帧，观察是否与其他关键帧中的特征点匹配 投影至一、二级关键帧上后，如果投影点恰好与某个特征点重合，会有两种情况\n        * 特征点没有对应的MapPoint： 设置P为此特征点对应的MapPoint\n        * 特征点有对应的MapPoint P′：删除、P、P′其中之一，即被观测帧数最少的\n        * 此时当前帧Kc的所有地图点已与localmap融合、建立联系；\n      * 反向投影融合：将一、二级关键帧观测的特征点投影到Kc，投影后同样会有两种情况，处理方式同上\n      * 至此，当前帧Kc的所有地图点已与全局map融合；一、二级关键帧观测的特征点也与Kc建立匹配关系\n\n----------------------------------------\n\n 6. 进行全局BA优化，优化所有的MapPoint、所有的KeyPoint\n\n----------------------------------------\n\n 7. 删除冗余的关键帧 为了防止关键帧数量无上限增长，需要不停检测冗余的关键帧，如果Kc中 90%的点已经在其他帧中被观测到，就将冗余关键帧Kc删除，方法如下：\n    * 首先遍历共视图中的邻居Kci，再遍历Kc的每个MapPoint Pi ( i=0,1,...n)\n    * 记录被观测数大于3的Pi，如果此类Pi占所有Pi超过90% ，就将Kc删除。\n\n\n# LoopClosing\n\n\n# ① 检测闭环\n\n\n\n关键帧 与 其 共视帧 组成一个候选关键帧组 ， 不同候选关键帧组中有相同的关键帧，则称这两个组是连续的。\n\n 1. 从队列头中取出一个关键帧, 作为当前检测闭环的关键帧；\n 2. 如果距离上次闭环没过多久, 或者map中关键帧总共还没有10帧, 则不进行闭环检测；\n 3. 计算这个关键帧与它所有的共视帧的Bow相似度得分, 得到最低得分minScore；\n 4. 计算这个关键帧与关键帧数据库中所有帧的相似度得分, 将得分大于minScore的作为候选关键帧，放入候选关键帧组 列表中；\n 5. 在候选关键帧中检测具有连续性 > 3 的候选帧；\n 6. 将满足要求的关键帧存放在列表 mvpEnoughConsistentCandidates 中(最优质关键帧组)。\n\n\n# ② 计算sim3 相似变换\n\n 1.  遍历上一步得到的每一个闭环候选关键帧；\n 2.  通过Bow加速得到 闭环候选关键帧 与 当前关键帧 之间的匹配点；\n 3.  如果匹配点个数 小于 20， 则剔除该 闭环候选关键帧；\n 4.  计算闭环候选关键帧 与 当前关键帧 之间的 Sim3 变换；\n 5.  通过RANSAC 算法迭代五次，求出候选帧到当前关键帧的Sim3变换Scm；\n 6.  通过Sim3变换把候选帧的特征点变换到当前关键帧中，反之同理，求出相互匹配的特征点；\n 7.  再通过上一步 求出的特征点，通过g2o来优化刚刚的Scm，得到mg2oScw；算出一个好的，为mpMatchedKF，就退出循环；\n 8.  将上面能算的好的mpMatchedKF，将其与其共视关键帧都放入列表vpLoopConnectedKFs中，它们对应的地图点放入列表mvpLoopMapPoints中；\n 9.  再将mvpLoopMapPoints中的地图点，通过Sim3变换投影到当前关键帧，搜索更多的匹配对；\n 10. 如果匹配对超过40，回环成功。最终的形成回环的帧是mpMatchedKF。\n\n\n# ③ 回环矫正\n\n 1. 需要请求局部地图停止，防止它向缓冲区插入新的关键帧。\n 2. 因为，步骤四中的6，将当前关键帧通过一次Sim3变换一次，所以需要对当前关键帧通过共视关系更新它的连接关系；\n 3. 遍历当前关键帧组，通过关键帧和共视帧的对应关系，很容易求出共视帧的Sim3变换，当前关键帧到其共视帧的Sim3变换g2oSic * mg2oScw，将这个通过g2o优化好的Sim3变换存入到列表CorrectedSim3中。与直接求出这一帧的相机坐标系位姿GetPose()变换，转换成Sim变换，存入到列表NonCorrectedSim3中；\n 4. 遍历当前关键帧的共视关键帧，修正这些共视关键帧的地图点。变换关系：这个点的世界坐标系 --(NonCorrectedSim3中的变换)--\x3e 未矫正的相机坐标系 --(CorrectedSim3中的逆变换)--\x3e 矫正后的世界坐标系。将这个共视关键帧的位姿设置为CorrectedSim3中的变换；\n 5. 检查当前帧地图点与经过闭环匹配后该帧的地图点是否存在冲突，对冲突进行替换或者填补。同时遍历匹配点和当前关键帧的地图点，如果当前关键帧地图点存在，那么就用匹配点代替，否则就把匹配点添加到当前关键帧地图点；\n 6. 同理，将闭环关键帧组的地图点，投影到当前关键帧组地图点进行匹配，融合，新增或者替换；\n 7. 更新当前关键帧组之间的两级共视相连关系；\n 8. 进行本质图优化，优化本质图中所有关键帧的位姿和地图点；\n 9. 新建一个线程用于全局BA优化。\n\n\n# 代码流程\n\n\n# 文件的调用关系\n\n主函数只调用了Tracking线程 LocalMapping、LoopClosing线程不断查找关键帧队列，如果队列非空，LocalMapping线程开始工作，LoopClosing线程继续检查是否构成回环，如果队列非空且构成回环则LoopClosing开始工作。\n\n\n# 重要变量的意义\n\n线程            函数名                          变量名                             变量类型                             意义\nTracking      track()                      mState                          bool                             标志系统状态：未初始化、正常或丢失\n                                           bOK                             bool                             衡量track()中每一步跟踪的质量\n                                           mbOnlyTracking                  bool                             标志系统是否处于只跟踪不建图模式\n              CheckReplacedInLastFrame()   mLastFrame                      Frame                            当前帧的上一帧\n              TrackWithMotionModel()       vpMapPointMatches               vector<MapPoint*>                上一帧与当前帧的匹配关系\n                                           nmatchesMap                     int                              记录特征匹配的内点数目\n              TrackReferenceKeyFrame()     vpMapPointMatches               vector<MapPoint*>                上一帧与当前帧的匹配关系\n                                           nmatchesMap                     int                              记录特征匹配的内点数目\n              Relocalization()             vpCandidateKFs                  vector<KeyFrame*>                与当前帧最相似的关键帧队列\n                                           vvpMapPointMatches              vector<vector<MapPoint*> >       帧队列中所有帧与当前帧的匹配关系\n                                           nCandidates                     int                              质量好的候选帧数量\n                                           bNoMore                         bool                             为true表示RANSAC已达到最大迭代次数\n                                           sFound                          set<MapPoint*>                   投影到当前帧为内点的MapPoint集合\n              NeedNewKeyFrame()            mpLocalMapper                   LocalMapping*                    局部建图线程对象\n                                           mpMap                           Map*                             全局地图对象\n                                           nKFs                            int                              全局地图中的关键帧数\n                                           nMinObs                         int                              规定的最小观测次数\n                                           mpReferenceKF                   KeyFrame*                        最新的关键帧作为参考关键帧\n                                           nRefMatches                     int                              参考关键帧中,被观测次数>nMinObs的地图点数量\n                                           thRefRatio                      int                              值越大，越倾向于接受关键帧\n              CreateNewKeyFrame()          pKF                             KeyFrame*                        新建的关键帧对象\n                                           mpLastKeyFrame                  KeyFrame*                        最新的关键帧\n                                           mlNewKeyFrames                  list<KeyFrame*>                  存放Tracking产生的关键帧\n                                                                                                            \nLoopMapping   ProcessNewKeyFrame()         vpMapPointMatches               vector<MapPoint*>                当前帧对应的所有地图点\n                                           mlpRecentAddedMapPoints         list<MapPoint*>                  还需被MapCulling检验的地图点列表\n                                           mspKeyFrames                    set<KeyFrame*>                   存储全局map中所有的关键帧\n              MapPointCulling()            nThObs                          int                              根据相机类型设置不同的观测阈值\n                                           mlpRecentAddedMapPoints         list<MapPoint*>                  还需被MapCulling检验的地图点列表\n                                           nCurrentKFid                    unsigned long                    当前帧的id\n                                           mnFirstKFid                     int                              地图点对象的属性，记录创建此地图点的关键帧id\n              CreateNewMapPoints()         nn                              int                              选取一级共视关键帧的个数\n                                           vpNeighKFs                      vector<KeyFrame*>                存放nn个一级共视关键帧\n                                           .......待更新                                                       \n              SearchInNeighbors()          nn                              int                              选取一级共视关键帧的个数\n                                           vpNeighKFs                      vector<KeyFrame*>                存放nn个一级共视关键帧\n                                           pKFi                            KeyFrame*                        一级共视关键帧\n                                           vpSecondNeighKFs                vector<KeyFrame*>                存放5个二级关键帧\n                                           vpFuseCandidates                vector<MapPoint*>                一、二级关键帧中，需要与当前帧融合的地图点\n              KeyFrameCulling()            vpLocalKeyFrames                vector<KeyFrame*>                当前帧的所有一级共视关键帧\n                                           vpMapPoints                     vector<MapPoint*>                每个共视关键帧对应的地图点\n                                           nRedundantObservations          int                              记录冗余点的数量\n                                           thObs                           int                              规定的最小观测次数\n                                           scaleLevel                      int                              关键帧的金字塔尺度，值越大越靠近顶端\n                                           nObs                            int                              记录有多少个关键帧高质量地观测到同一个地图点\n                                           nMPs                            int                              记录当前帧中非坏点的个数\n              InsertKeyFrame()             mlpLoopKeyFrameQueue            list<KeyFrame*>                  存放LoopClosing产生的关键帧\n                                                                                                            \nLoopClosing   DetectLoop()                 mlpLoopKeyFrameQueue            list<KeyFrame*>                  关键帧缓冲队列\n                                           vpConnectedKeyFrames            vector<KeyFrame *>               与当前帧相连的共视关键帧\n                                           mpORBVocabulary                 ORBVocabulary* mpORBVocabulary   词袋模型中的大词典\n                                           vpCandidateKFs                  vector<KeyFrame *>               当前帧的候选回环关键帧\n                                           mvConsistentGroups              vector                           上一次产生的连续组\n                                           vCurrentConsistentGroups        vector                           筛选出来的连续组\n                                           ConsistentGroup                 pair<set<KeyFrame*>,int>         连续组结构\n                                           mvpEnoughConsistentCandidates   std::vector<KeyFrame*>           最优质的闭环候选帧\n              DetectLoopCandidates()       spConnectedKeyFrames            set<KeyFrame*>                   与当前帧相连的关键帧\n                                           lKFsSharingWords                list<KeyFrame*>                  可能与当前关键帧形成闭环的候选帧\n                                           mBowVec                         map<WordId, WordValue>           WordId 和 WordValue 表示Word在叶子中的id和权重\n                                           mvInvertedFile                  vector<list<KeyFrame*> >         vector的下标是WordId，list是包含这个Word的所有关键帧\n                                           lKFsSharingWords                list<KeyFrame *>                 初步候选关键帧列表\n                                           lScoreAndMatch                  list<pair<float, KeyFrame *>>    筛选单词数后的候选关键帧列表\n                                           vpLoopCandidates                vector<KeyFrame *>               最后返回的关键帧列表\n              UpdateConnections()          KFcounter                       map<KeyFrame*,int>               关键帧 -- 共视程度(地图点个数)\n                                           vpMP                            vector<MapPoint*>                关键帧的地图点\n                                           observations                    map<KeyFrame*,size_t>            观察到这个地图点的关键帧，size_t表示这个地图点对应在该关键帧的特征点id\n              ComputeSim3()                vvpMapPointMatches              vector<vector<MapPoint *>>       存储每个候选帧的匹配地图点信息\n                                           mvpCurrentMatchedPoints         vector<MapPoint*>                存储的地图点在"当前关键帧"中成功地找到了匹配点的地图点的集合\n              CorrectLoop()                CorrectedSim3                   map<KeyFrame *, Sim3>            存储的地图点在"当前关键帧"中成功地找到了匹配点的地图点的集合\n                                           NonCorrectedSim3                map<KeyFrame *, Sim3>            存放没有矫正的当前关键帧的共视关键帧的世界坐标系下Sim变换\n\n\n# Tracking流程\n\n 1. 位姿初始化（截取部分）：根据系统状况、跟踪效果选择不同的位姿初始化方法\n    \n    if(mState==OK){\n        CheckReplacedInLastFrame();\n        \n        if(mVelocity.empty() || mCurrentFrame.mnId<mnLastRelocFrameId+2)\n            bOK = TrackReferenceKeyFrame();\n        else{\n            bOK = TrackWithMotionModel();\n            if(!bOK)\n                //根据恒速模型失败，根据参考关键帧来跟踪\n                bOK = TrackReferenceKeyFrame();\n        }\n    }\n    else\n        bOK = Relocalization();\n    \n    \n    CheckReplacedInLastFrame() ==更新上一帧中的地图点==\n    \n    >   - 检查$CurrFrame$中是否有地图点被LocalMapping线程替换或者删除\n    >   \t\t\t\t\t\n    >   \t- 被替换则更新，被删除则将地图点赋值为NULL\n    \n    ----------------------------------------\n    \n    TrackWithMotionModel() ==用匀速运动模型，对CurrFrame进行位姿初始化==\n    \n    >   - 默认上一帧到 $CurrFrame$ 的变换矩阵等于上上帧到上一帧的变换矩阵。\n    >   \t\t\t\t\t\n    >   - 将上一帧观测到的地图点，投影到$CurrFrame$ ，投影点与特征点的间距作为error，如果匹配点不够，则进行`TrackReferenceKeyFrame()`\n    >   - 如果匹配点足够，进行一次仅位姿的BA优化，优化$CurrFrame$的pose，使error最小\n    \n    ----------------------------------------\n    \n    TrackReferenceKeyFrame() ==用上一帧，对CurrFrame进行位姿初始化==\n    \n    >   - 用**词袋模型**，将 $CurrFrame$ 与**参考关键帧**（最新的关键帧）进行特征匹配\n    >   \t\t\t\t\t\n    >   - 将 **参考关键帧**的地图点投影到$CurrFrame$ ，投影点与特征点的间距作为error\n    >   - 如果匹配点足够，进行仅位姿的BA优化，优化$CurrFrame$的pose，使error最小\n    \n    ----------------------------------------\n    \n    Relocalization() ==用词袋模型寻找RelocFrame，对CurrFrame进行位姿初始化==\n    \n    >   - 在所有关键帧中，先用词袋模型找出一批，与$CurrFrame$共同单词最多的关键帧，作为候选关键帧`vpCandidateKFs`\n    >   \t\t\t\t\t\n    >   - 遍历`vpCandidateKFs`，用词袋模型，找出与$CurrFrame$相似度最高的帧作为$RelocFrame$\n    >   -  用**词袋模型**，将 $CurrFrame$ 与 **$RelocFrame$** 进行特征匹配\n    >   - 将 **$RelocFrame$**的对应地图点投影到$CurrFrame$ 上，投影点与特征点的间距作为error\n    >   - 如果匹配点足够，进行仅位姿的BA优化，优化$CurrFrame$的pose，使error最小\n    \n    ----------------------------------------\n\n 2. 局部位姿优化 、关键帧审核（截取部分）\n\n//更新参考关键帧\nmCurrentFrame.mpReferenceKF = mpReferenceKF;\nif(!mbOnlyTracking){\nif(bOK)\n    bOK = TrackLocalMap();\n}\nelse\n{\nif(bOK && !mbVO)\n    bOK = TrackLocalMap();\n}\n\n//更新系统状态、更新显示、 等等\n.....\n\n\nif(NeedNewKeyFrame())\n    CreateNewKeyFrame();\n\n\nTrackLocalMap() ==局部地图中，用BA优化 CurrFrame 的位姿==\n\n>  * 更新局部关键帧、局部地图点，构建局部地图\n> \n>  * 将局部地图中的MapPoint投影到CurrFrame，建立新的匹配关系\n> \n>  * 仅位姿的BA优化\n> \n>  * 更新CurrFrame对应的每个MapPoint的被观测信息、删除外点\n\n * 根据匹配点数目判断局部位姿优化的好坏，好的话(成功匹配50个点)返回true，否则flase\n\n----------------------------------------\n\nNeedNewKeyFrame() ==检测系统是否需要插入关键帧==\n\n>  * 纯Tracking模式，不生产关键帧\n> \n>  * LoopCLosing线程正在使用局部地图时，不生产关键帧\n> \n>  * 关键帧数目较多、且位置离上一个关键帧较近，不生产关键帧\n\n * 当LocalMapping线程不忙，且numcurrnumref小于一定阈值，则需要生产关键帧，返回true\n\n----------------------------------------\n\nCreateNewKeyFrame() 将设置为一个关键帧对象，并插入CurrFrame设置为一个关键帧对象，并插入mlNewKeyFrames\n\n----------------------------------------\n\n\n# LocalMapping流程\n\n函数主体（截取部分）\n\nif(CheckNewKeyFrames())\n{\n    ProcessNewKeyFrame();\n    \n    MapPointCulling();\n    \n    CreateNewMapPoints();\n    \n    if(!CheckNewKeyFrames())\n        SearchInNeighbors();\n                \n    mbAbortBA = false;\n    \n    if(!CheckNewKeyFrames() && !stopRequested())\n    {\n        if(mpMap->KeyFramesInMap()>2)\n            Optimizer::LocalBundleAdjustment(mpCurrentKeyFrame,&mbAbortBA, mpMap);\n        KeyFrameCulling();\n    }\n    mpLoopCloser->InsertKeyFrame(mpCurrentKeyFrame);\n}\n\n\nCheckNewKeyFrames() ==检查关键帧队列mlNewKeyFrames是否非空==\n\n----------------------------------------\n\nProcessNewKeyFrame()\n==将此帧对地图点的观测信息补充进（融入）全局图，再将此帧作为节点插入共视图和全局地图==\n\n>  * 计算此关键帧帧的BOW词袋向量\n>  * 获取全局图中被此关键帧观测到的地图点 vpMapPointMatches\n>  * 对vpMapPointMatches中每一个地图点，更新：地图点的被观测数（+1），平均观测方向、最佳描述子等；不够确定的地图点，记录在 mlpLoopKeyFrameQueue，需进一步检查\n>  * 把帧插入共视图：寻找共视关系，更新共视图链接关系\n>  * 把帧插入全局地图\n\n----------------------------------------\n\nMapPointCulling() ==遍历mlpLoopKeyFrameQueue 中地图点P，删除其中质量不好的点==\n\n>  * P为坏点，直接删除\n>  * 实际上观测到的帧数理论上应该观测到的帧数实际上观测到P的帧数理论上应该观测到P的帧数<25% ，删除P\n>  * 当前关键帧ID - 创建P的帧ID>2（相当于在时间空间上已经进行了一段时间）但实际观测数仍小于一个阈值cnTHObs，删除P\n\n----------------------------------------\n\nCreateNewMapPoints() ==将关键帧中的特征点三角化，创建新MapPoint==\n\n>  * 拿到Tracking审核得到的关键帧CurrFrame后，获取共视程度最高的帧作为相邻关键帧\n>  * 遍历相邻共视关键帧，分别与CurrFrame进行特征匹配和三角化，生成地图点\n>  * 生成的地图点记录在mlpLoopKeyFrameQueue，还需进一步检查\n\n----------------------------------------\n\nSearchInNeighbors() ==将所有新的MapPoint融入全局map中，并建立与其他帧的联系== ==将当前关键帧融入全局map中，建立与其他地图点的联系==\n\n>  * 获取此关键帧在共视图中的一级、二级相邻关键帧，并存放在队列vpTargetKFs中\n>  * 正向投影融合，将Kc观测到的MapPoint投影至vpTargetKFs中的关键帧，与其中的特征点建立匹配关系\n>  * 获取一、二级相邻关键帧观测到的MapPoint集合，并存放在vpFuseCandidates中\n>  * 反向投影融合，将vpFuseCandidates中的MapPoint投影到Kc，与Kc中的特征点建立匹配关系\n>  * 经过以上步骤，新建了许多共视关系，所以还需更新共视图中Kc的邻居\n\n----------------------------------------\n\nKeyFrameCulling() ==删除冗余关键帧==\n\n>  * 获取此关键帧在共视图中的一级相邻关键帧，并存放在队列vpLocalKeyFrames中\n>  * 遍历vpLocalKeyFrames，获取每一共视关键帧vit所观测到的地图点pMP，存放在队列vpMapPoints中\n>  * 遍历vpMapPoints中每一个地图点pMP，根据pMP->GetObservations()遍历所有能观测到pMP的关键帧mit\n>  * 此时， mit、vit都观测到pMP，如果mit对应的关键帧尺度比较小，说明mit对应的关键帧要比vit对应的关键帧更靠近金字塔底部，则mit对pMP观测的效果更好\n>  * 如果pMP被超过3个mit更好地观测，则将冗余点数目nRedundantObservations+1\n>  * 遍历完每个vit和其对应的每个mit后，统计nRedundantObservationn，如果nRedundantObservationn>90% ，删除关键帧Kc\n\n----------------------------------------\n\nMapPoint::GetObservations() ==获得所有能观测到MapPoint 的关键帧集合==\n\n----------------------------------------\n\nInsertKeyFrame(mpCurrentKeyFrame) ==将某一帧放入回环检测处理队列==\n\n\n# LoopClosing流程\n\n函数主题\n\nwhile (1)\n\t{\n    // 检查缓冲队列中是否有关键帧\n    if (CheckNewKeyFrames())\n    {\n\t\t// 检测闭环\n        if (DetectLoop())\n        {\n            // 计算sim3 相似变换\n            if (ComputeSim3())\n            {\n                // 闭环矫正\n                CorrectLoop();\n            }\n        }\n    }\n\n\nGetVectorCovisibleKeyFrames()\n\n==获得该帧的共视帧(已按权值排序)==\n\nDetectLoopCandidates()\n\n==找出初步闭环候选关键帧==\n\n>  * 遍历当前关键帧的所有单词，找到这些单词的所有关键帧（不包含与当前帧相连的关键帧），作为候选关键帧，放入集合lKFsSharingWords中，并记录候选关键帧与当前帧的共同单词数mnLoopWords；\n>  * 从lKFsSharingWords取出关键帧，确定最小公共单词数为最大公共单词数目的0.8倍，并且与当前帧的相似度得分要大于阈值minScore，符合要求的候选关键帧放入集合lScoreAndMatch；\n>  * 从lScoreAndMatch中取出关键帧pKFi，pKFi与其前10的共视帧组成一个组，计算这个组的最高得分和累计得分，只留下最高累计得分的0.75倍的组，将留下的组里最高得分的关键帧放入到vpLoopCandidates返回。\n\nSearchByBoW()\n\n==通过词袋向量进行特征匹配==\n\n>  * 遍历两个关键帧Bow的所有相同node的特征点，通过描述子距离进行匹配；\n>  * 通过距离、比例阈值和角度直方图投票剔除错误匹配。\n> \n> 这里之后可能会算出一个Sim3变换，地图点发生了变化。\n\nSearchBySim3()\n\n==通过Sim3变换相互投影特征匹配==\n\n>  * 首先计算一些必要的矩阵，进行位姿变换，投影；\n>  * 将关键帧KF1的特征点投影到KF2，在一个半径范围内就算特征匹配成功；\n>  * 同理，将关键帧KF2的特征点投影到KF1；\n>  * 保留两次匹配都出现的匹配。\n> \n> 这里之后会对Sim3变换进行优化。\n\nSearchByProjection()\n\n==投影一次，查找特征匹配，范围比较大==\n\n>  * 跳过**SearchBySim3()**的匹配，遍历闭环KF及其共视KF的所有地图点，投影到当前KF；\n>  * 搜索半径10，搜索新的匹配点。\n\nUpdateConnections()\n\n==更新关键帧之间的共视关系==\n\n>  * 获取该关键帧的地图点vpMP，遍历地图点，得到所有观测到该地图点的关键帧observations，并记录关键帧共视的地图点个数，关键帧和共视点个数组成一个pair\n>  * 对pair排序，将共视点个数大于阈值th=15的关键帧，建立与当前帧的共视关系。\n\nSearchAndFuse()\n\n==融合和替换地图点==\n\n>  * 遍历待矫正的当前关键帧的相连关键帧；\n>  * 将闭环帧组所有地图点mvpLoopMapPoints，投影到当前关键帧；\n>  * 替换或融合闭环帧组中的地图点mvpLoopMapPoints。',normalizedContent:'# 算法原理\n\n算法由三大部分组成，分别是 tracking、localmapping、loopclosing 三个线程\n\n\n# tracking\n\n 1. 特征点的提取（orb extraction） 在此之前，特征点的提取方法有sift，surf等，但相比orb都比较耗时。orb算法先提取fast角点，再计算brief描述子，最终利用bow词袋模型来匹配特征点。\n    \n    * 建立图像金字塔：将原图像按不同比例缩小，得到多张图片，分别对每张图片进行下述操作。\n    \n    * fast角点提取（对所有像素点进行提取）\n      \n      * 将图像转为灰度图，选取像素 p， 假设他的亮度为 ip\n      * 设定一个阈值 t，其大小与 ip 成正比\n      * 以 p 为中心，半径为3的圆上选16个像素点\n      * 如果有连续n个点亮度大于 ip+t 或小于ip−t，则 p 被认为是一个fast角点 ![在这里插入图片描述](https://img-blog.csdnimg.cn/c20d47d96bd34496b6479aa829565f2b.png?x-oss-process=image/watermark,type_zhjvawrzyw5zzmfsbgjhy2s,shadow_50,text_q1netibaqutni5fkujw=,size_20,color_ffffff,t_70,g_se,x_16#pic_center =400x200)\n    \n    ----------------------------------------\n    \n    * brief描述子（对所有的fast角点计算描述子）\n      \n      * 计算每个fast角点圆心到质心点的方向\n      \n      * 将每个角点对应的圆域进行旋转，旋转至所有角点对应的方向相同。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/bed388824aab4c818d38ead3a1c21f5a.png?x-oss-process=image/watermark,type_zhjvawrzyw5zzmfsbgjhy2s,shadow_50,text_q1netibaqutni5fkujw=,size_20,color_ffffff,t_70,g_se,x_16#pic_center =300x135)\n      \n      * 圆域内选取n个点对（默认指定了128对点），通过将亮度的比较结果，将角点映射为：只由0、1组成的128维向量，将此向量作为brief描述子\n      \n      * 最后，对每个fast角点，都生成了128维描述子。\n      \n      * 当被拍摄物体放大或者缩小时，fast角点会产生不同的提取结果（比如缩小会引起角点消失），但在图像金字塔的其他层中依然可以提取到缩放前对应的fast角点，从而具有良好的尺度不变性。当被拍摄物体发生旋转时，其fast角点的方向也会随之旋转，计算brief描述子前，将所有fast角点旋转至同一方向，相当于将所有拍摄对象都旋转到同一方向，从而具有良好的旋转不变性\n    \n    * bow 词袋模型（对图片、特征进行查找和索引）\n      * 词袋模型作为所有描述子的字典， 用于量化两张图或两个特征点的相似性\n      * 字典的数据结构为 k叉树，上层是下层的聚类，最底层的每个叶子节点对应的是最小特征单元：brief描述子\n      * 获得描述子后，通过次查找k叉树，来得到此描述子的匹配点，降低了查找匹配的复杂度\n\n 2. 旋转不变性来自：提取fast特征时，计算了每个角点的中心点到质心点的方向向量，即使物体发生了旋转，也可利用方向向量来识别。\n\n 3. 尺度不变性来自：对每一帧，建立4层的高斯金字塔，分别在每层金字塔上做特征提取，即使a图中的特征在b图中变小，也可以在a图金字塔高层提取到b图中同尺度的特征\n    \n    ----------------------------------------\n\n 4. 点云初始化 这部分在论文中没有提及。发生在整个算法刚开始运行时，点云的初始化是此后每一帧能成功定位的前提\n    \n    * 作用：特征匹配、三角化，得到初始点云图，对于单目来说，就是将p2p问题转为pnp问题\n    * 步骤(以单目为例）：\n      * 初始选取2个特征点较多的帧（ 特征点数特征点数>100 )，并在词袋中进行特征匹配\n      * 并行计算单应性矩阵 h 和基础矩阵 f 。 当对极约束不成立的时候（相机只有旋转没有平移），或场景都在同一平面时，用单应性矩阵来计算两帧之间的变换矩阵。否则用基础矩阵计算变换矩阵\n      * 将第一帧的位姿设置为基准位姿，第二帧的位姿为上一步所求出的变换矩阵\n      * 创建地图点对象mappoint，恢复出所有匹配点对应的世界坐标\n    \n    ----------------------------------------\n\n 5. 位姿初始化（initial pose estimation） 对 currframe (此刻的帧)位姿优化之前，先要有一个大概的估计，作为之后优化位姿的初值。根据当前跟踪状态的不同，一共有三种初始化方法：根据参考关键帧估计，根据匀速运动模型估计，重定位。除此之外，还要对此帧观测到的特征点进行估计\n    \n    * 作用：估计帧的位置，以及观测到的局部地图点\n    * 步骤：\n      \n      * 跟踪状态为lost时：\n        \n        * 用重定位估计位姿（relocation），用词袋模型寻找与 currframe 最相似的帧 relocframe，进行特征匹配\n        * 统计 currframe 上匹配点数量，数量太少则认为匹配效果差，保持状态为lost，结束对此帧的处理，等待下一帧；数量足够的话，进行一次仅优化位姿的ba（motion-only ba），数量不够则舍弃此帧\n      \n      * 跟踪状态normal时：\n        \n        * 根据匀速运动模型估计位姿，默认上一帧到 currframe 的变换矩阵等于上上帧到上一帧的变换矩阵。（track with motion model）\n        * 将上一帧（lastframe）观测到的mappoint 投影到估计的位姿上，观测有多少投影点与特征点位置重合，重合则认为是一对匹配点，如果重合的足够多，则进行一次仅优化位姿的ba，如果重合的个数太少，表明匹配失败改用参考关键帧估计；\n      \n      * 根据参考关键帧估计位姿：（track with refframe）\n        \n        * 用词袋模型，将 currframe 与参考关键帧（最新的关键帧）进行特征匹配\n        * 匹配后执行一次仅优化位姿的ba（motion-only ba）\n        * 统计匹配特征点数，数量少则认为匹配失败，将状态改为lost，结束对此帧的处理，等待下一帧；\n    * 需要注意：初始化后的frame 中仍会有大量特征点没建立匹配 ，这也体现了tracking线程的重要思想：在尽可能少的建立匹配的情况下，初始化出相机的位姿。\n    \n    ----------------------------------------\n\n 6. 局部位姿优化（track local map） 经过上面的初始化，失败的 frame ，说明其与地图联系不够紧密，无法建立稳健的约束和估计；而与地图联系紧密的frame 则初始化成功。 但刚刚初始化所得位姿仅依赖于与某一帧（前一帧或参考关键帧）中的匹配关系，置信度较低。 接下来，我们在局部图中寻找更多的匹配关系，利用这些匹配关系进一步优化currframe的位姿。\n    \n    * covisibility graph定义：covisibility graph，是无向加权图，如果两个关键帧之间有共视关系（共同观测到>15个地图点）就连成一条有权边，这些边和所有关键帧节点组成共视图。\n    * 在共视图中，针对currframe定义一组关键帧为局部关键帧，局部关键帧由四种邻居组成。这四种邻居为：\n      * 与 currframe 有共视点的帧（一级共视帧）\n      * 与 一级共视帧 有共视点的前十个帧（二级共视帧）（按共视点个数排序）\n      * 一级共视帧的子关键帧\n      * 一级共视帧的父关键帧（与一级共视帧共视程度最高的帧）\n    * 将 currframe、局部关键帧 、以及这些帧观测到的 mappoint作为：局部图 （localmap）\n    * 将localmap 中的mappoint向 currframe 投影![请添加图片描述](https://img-blog.csdnimg.cn/38d7c6d141d34d95837c80abd9b6a72b.png?x-oss-process=image/watermark,type_zhjvawrzyw5zzmfsbgjhy2s,shadow_50,text_q1netibaqutni5fkujw=,size_20,color_ffffff,t_70,g_se,x_16#pic_center =420x350)\n    * 对 currframe再进行一次仅位姿ba（motion-only ba）优化，估计出各个局部关键帧的位姿\n    \n    ----------------------------------------\n\n 7. 关键帧的审核与生成 (new keyframe decision)\n    \n    * 检测系统是否允许关键帧的插入\n      * only_tracking 模式下，不需要关键帧\n      * localmap 被 loopclosing线程占用，不能插入关键帧\n      * 关键帧总数较多，且距离上一个关键帧距离很近，不需要插入关键帧\n    * 审核currframe是否有资格做关键帧\n      * 记录currframe 观察到的mappoint总数，numcurr\n      * 记录refframe 观察到的mappoint总数，numref![请添加图片描述](https://img-blog.csdnimg.cn/3789e59c73034275a21d8a682ed6d9d4.png?x-oss-process=image/watermark,type_zhjvawrzyw5zzmfsbgjhy2s,shadow_50,text_q1netibaqutni5fkujw=,size_20,color_ffffff,t_70,g_se,x_16#pic_center =420x350)\n      * 如果numcurrnumref小于一定阈值，则允许 currframe作为一个关键帧\n    * 将 currframe 设置为关键帧\n      * 将自己生成的关键帧pkf 作为currframe 的参考关键帧\n      * 在地图中新建地图点 ![请添加图片描述](https://img-blog.csdnimg.cn/e33fd597a7484bbc9529fe590caa24be.png?x-oss-process=image/watermark,type_zhjvawrzyw5zzmfsbgjhy2s,shadow_50,text_q1netibaqutni5fkujw=,size_20,color_ffffff,t_70,g_se,x_16#pic_center =420x350)\n    \n    ----------------------------------------\n\n * 总结\n * tracking线程根据状态的不同，以三种方式来初始化每一帧的位置和姿态，这三种方式速度由慢到快为：\n * 回顾tracking过程\n   * 整个过程可以看做三步：获取位置、优化位置、关键帧审核\n   * 在尽可能少建立匹配或者不建立匹配的情况下，进行位姿初始化（获取位置）\n   * 尽可能建立一个：体量尽量小、但与currframe关系足够多（四种邻居）的局部图，在此局部图的基础上进行图优化ba （优化位置）\n   * 在跟踪到的点足够多的情况下（>50个），尽可能多地生成关键帧，因为后面的关键帧删除策略很严格，这里关键帧的生成比较宽松（关键帧审核）\n * 可以看出，tracking的一个重要特点是提速（不到万不得已，不进行耗时的匹配操作）\n\n\n# localmapping\n\n 1. 当待处理keyframe队列非空， localmapping线程就开始工作、\n\n 2. 将此keyframe插入共视图中（keyframe insertion）\n    \n    * 计算此keyframe对应的词袋向量（应该是在回环检测会用到）\n    * 获取localmap中，被此keyframe观测到的点（在tracking线程中的位姿初始化步骤已经被初始化），更新此keyframe的平均观测方向，以及各个mappoint的最佳描述子\n    * 根据共视程度创建有权边，将keyframe插入共视图中\n\n----------------------------------------\n\n 4. 删除多余的mappoint 此前localmapping线程可能删除了一些冗余关键帧，导致对应的地图点接近于“无帧观测”的状态，不满足以下2条件中任意一条的mappoint会被移除\n    * 对于localmap中的任意地图点p，如果 实际观测到的帧数量预测会观测到的帧数量实际观测到p的帧数量预测会观测到p的帧数量>25%\n    * 如果观测到p的是一个关键帧，则至少三个连续关键帧都观测到p\n\n----------------------------------------\n\n 5. 创建新的mappoint\n    * 创建mappoint点：对当前关键帧（kc）的未匹配特征点，在所有其他关键帧中寻找特征匹配（利用词袋模型），得一定数量的最佳共视关键帧（ki），相互匹配后进行三角化，计算出新mappoint p 的位置\n    * 构建mappoint、kc与全局map的联系：得出mappoint的位置后，还需要将p与全局map融合，也就是建立p与其他关键帧的联系\n      * 定义一级二级关键帧：\n        * 一级关键帧：在共视图中挑选10个共视程度最佳的邻居\n        * 二级关键帧：对每个一级关键帧，分别挑选5个共视程度最高的邻居\n      * 正向投影融合：此时p点只被kc和ki两个帧所观测到，还需将p分别投影到一、二级关键帧，观察是否与其他关键帧中的特征点匹配 投影至一、二级关键帧上后，如果投影点恰好与某个特征点重合，会有两种情况\n        * 特征点没有对应的mappoint： 设置p为此特征点对应的mappoint\n        * 特征点有对应的mappoint p′：删除、p、p′其中之一，即被观测帧数最少的\n        * 此时当前帧kc的所有地图点已与localmap融合、建立联系；\n      * 反向投影融合：将一、二级关键帧观测的特征点投影到kc，投影后同样会有两种情况，处理方式同上\n      * 至此，当前帧kc的所有地图点已与全局map融合；一、二级关键帧观测的特征点也与kc建立匹配关系\n\n----------------------------------------\n\n 6. 进行全局ba优化，优化所有的mappoint、所有的keypoint\n\n----------------------------------------\n\n 7. 删除冗余的关键帧 为了防止关键帧数量无上限增长，需要不停检测冗余的关键帧，如果kc中 90%的点已经在其他帧中被观测到，就将冗余关键帧kc删除，方法如下：\n    * 首先遍历共视图中的邻居kci，再遍历kc的每个mappoint pi ( i=0,1,...n)\n    * 记录被观测数大于3的pi，如果此类pi占所有pi超过90% ，就将kc删除。\n\n\n# loopclosing\n\n\n# ① 检测闭环\n\n\n\n关键帧 与 其 共视帧 组成一个候选关键帧组 ， 不同候选关键帧组中有相同的关键帧，则称这两个组是连续的。\n\n 1. 从队列头中取出一个关键帧, 作为当前检测闭环的关键帧；\n 2. 如果距离上次闭环没过多久, 或者map中关键帧总共还没有10帧, 则不进行闭环检测；\n 3. 计算这个关键帧与它所有的共视帧的bow相似度得分, 得到最低得分minscore；\n 4. 计算这个关键帧与关键帧数据库中所有帧的相似度得分, 将得分大于minscore的作为候选关键帧，放入候选关键帧组 列表中；\n 5. 在候选关键帧中检测具有连续性 > 3 的候选帧；\n 6. 将满足要求的关键帧存放在列表 mvpenoughconsistentcandidates 中(最优质关键帧组)。\n\n\n# ② 计算sim3 相似变换\n\n 1.  遍历上一步得到的每一个闭环候选关键帧；\n 2.  通过bow加速得到 闭环候选关键帧 与 当前关键帧 之间的匹配点；\n 3.  如果匹配点个数 小于 20， 则剔除该 闭环候选关键帧；\n 4.  计算闭环候选关键帧 与 当前关键帧 之间的 sim3 变换；\n 5.  通过ransac 算法迭代五次，求出候选帧到当前关键帧的sim3变换scm；\n 6.  通过sim3变换把候选帧的特征点变换到当前关键帧中，反之同理，求出相互匹配的特征点；\n 7.  再通过上一步 求出的特征点，通过g2o来优化刚刚的scm，得到mg2oscw；算出一个好的，为mpmatchedkf，就退出循环；\n 8.  将上面能算的好的mpmatchedkf，将其与其共视关键帧都放入列表vploopconnectedkfs中，它们对应的地图点放入列表mvploopmappoints中；\n 9.  再将mvploopmappoints中的地图点，通过sim3变换投影到当前关键帧，搜索更多的匹配对；\n 10. 如果匹配对超过40，回环成功。最终的形成回环的帧是mpmatchedkf。\n\n\n# ③ 回环矫正\n\n 1. 需要请求局部地图停止，防止它向缓冲区插入新的关键帧。\n 2. 因为，步骤四中的6，将当前关键帧通过一次sim3变换一次，所以需要对当前关键帧通过共视关系更新它的连接关系；\n 3. 遍历当前关键帧组，通过关键帧和共视帧的对应关系，很容易求出共视帧的sim3变换，当前关键帧到其共视帧的sim3变换g2osic * mg2oscw，将这个通过g2o优化好的sim3变换存入到列表correctedsim3中。与直接求出这一帧的相机坐标系位姿getpose()变换，转换成sim变换，存入到列表noncorrectedsim3中；\n 4. 遍历当前关键帧的共视关键帧，修正这些共视关键帧的地图点。变换关系：这个点的世界坐标系 --(noncorrectedsim3中的变换)--\x3e 未矫正的相机坐标系 --(correctedsim3中的逆变换)--\x3e 矫正后的世界坐标系。将这个共视关键帧的位姿设置为correctedsim3中的变换；\n 5. 检查当前帧地图点与经过闭环匹配后该帧的地图点是否存在冲突，对冲突进行替换或者填补。同时遍历匹配点和当前关键帧的地图点，如果当前关键帧地图点存在，那么就用匹配点代替，否则就把匹配点添加到当前关键帧地图点；\n 6. 同理，将闭环关键帧组的地图点，投影到当前关键帧组地图点进行匹配，融合，新增或者替换；\n 7. 更新当前关键帧组之间的两级共视相连关系；\n 8. 进行本质图优化，优化本质图中所有关键帧的位姿和地图点；\n 9. 新建一个线程用于全局ba优化。\n\n\n# 代码流程\n\n\n# 文件的调用关系\n\n主函数只调用了tracking线程 localmapping、loopclosing线程不断查找关键帧队列，如果队列非空，localmapping线程开始工作，loopclosing线程继续检查是否构成回环，如果队列非空且构成回环则loopclosing开始工作。\n\n\n# 重要变量的意义\n\n线程            函数名                          变量名                             变量类型                             意义\ntracking      track()                      mstate                          bool                             标志系统状态：未初始化、正常或丢失\n                                           bok                             bool                             衡量track()中每一步跟踪的质量\n                                           mbonlytracking                  bool                             标志系统是否处于只跟踪不建图模式\n              checkreplacedinlastframe()   mlastframe                      frame                            当前帧的上一帧\n              trackwithmotionmodel()       vpmappointmatches               vector<mappoint*>                上一帧与当前帧的匹配关系\n                                           nmatchesmap                     int                              记录特征匹配的内点数目\n              trackreferencekeyframe()     vpmappointmatches               vector<mappoint*>                上一帧与当前帧的匹配关系\n                                           nmatchesmap                     int                              记录特征匹配的内点数目\n              relocalization()             vpcandidatekfs                  vector<keyframe*>                与当前帧最相似的关键帧队列\n                                           vvpmappointmatches              vector<vector<mappoint*> >       帧队列中所有帧与当前帧的匹配关系\n                                           ncandidates                     int                              质量好的候选帧数量\n                                           bnomore                         bool                             为true表示ransac已达到最大迭代次数\n                                           sfound                          set<mappoint*>                   投影到当前帧为内点的mappoint集合\n              neednewkeyframe()            mplocalmapper                   localmapping*                    局部建图线程对象\n                                           mpmap                           map*                             全局地图对象\n                                           nkfs                            int                              全局地图中的关键帧数\n                                           nminobs                         int                              规定的最小观测次数\n                                           mpreferencekf                   keyframe*                        最新的关键帧作为参考关键帧\n                                           nrefmatches                     int                              参考关键帧中,被观测次数>nminobs的地图点数量\n                                           threfratio                      int                              值越大，越倾向于接受关键帧\n              createnewkeyframe()          pkf                             keyframe*                        新建的关键帧对象\n                                           mplastkeyframe                  keyframe*                        最新的关键帧\n                                           mlnewkeyframes                  list<keyframe*>                  存放tracking产生的关键帧\n                                                                                                            \nloopmapping   processnewkeyframe()         vpmappointmatches               vector<mappoint*>                当前帧对应的所有地图点\n                                           mlprecentaddedmappoints         list<mappoint*>                  还需被mapculling检验的地图点列表\n                                           mspkeyframes                    set<keyframe*>                   存储全局map中所有的关键帧\n              mappointculling()            nthobs                          int                              根据相机类型设置不同的观测阈值\n                                           mlprecentaddedmappoints         list<mappoint*>                  还需被mapculling检验的地图点列表\n                                           ncurrentkfid                    unsigned long                    当前帧的id\n                                           mnfirstkfid                     int                              地图点对象的属性，记录创建此地图点的关键帧id\n              createnewmappoints()         nn                              int                              选取一级共视关键帧的个数\n                                           vpneighkfs                      vector<keyframe*>                存放nn个一级共视关键帧\n                                           .......待更新                                                       \n              searchinneighbors()          nn                              int                              选取一级共视关键帧的个数\n                                           vpneighkfs                      vector<keyframe*>                存放nn个一级共视关键帧\n                                           pkfi                            keyframe*                        一级共视关键帧\n                                           vpsecondneighkfs                vector<keyframe*>                存放5个二级关键帧\n                                           vpfusecandidates                vector<mappoint*>                一、二级关键帧中，需要与当前帧融合的地图点\n              keyframeculling()            vplocalkeyframes                vector<keyframe*>                当前帧的所有一级共视关键帧\n                                           vpmappoints                     vector<mappoint*>                每个共视关键帧对应的地图点\n                                           nredundantobservations          int                              记录冗余点的数量\n                                           thobs                           int                              规定的最小观测次数\n                                           scalelevel                      int                              关键帧的金字塔尺度，值越大越靠近顶端\n                                           nobs                            int                              记录有多少个关键帧高质量地观测到同一个地图点\n                                           nmps                            int                              记录当前帧中非坏点的个数\n              insertkeyframe()             mlploopkeyframequeue            list<keyframe*>                  存放loopclosing产生的关键帧\n                                                                                                            \nloopclosing   detectloop()                 mlploopkeyframequeue            list<keyframe*>                  关键帧缓冲队列\n                                           vpconnectedkeyframes            vector<keyframe *>               与当前帧相连的共视关键帧\n                                           mporbvocabulary                 orbvocabulary* mporbvocabulary   词袋模型中的大词典\n                                           vpcandidatekfs                  vector<keyframe *>               当前帧的候选回环关键帧\n                                           mvconsistentgroups              vector                           上一次产生的连续组\n                                           vcurrentconsistentgroups        vector                           筛选出来的连续组\n                                           consistentgroup                 pair<set<keyframe*>,int>         连续组结构\n                                           mvpenoughconsistentcandidates   std::vector<keyframe*>           最优质的闭环候选帧\n              detectloopcandidates()       spconnectedkeyframes            set<keyframe*>                   与当前帧相连的关键帧\n                                           lkfssharingwords                list<keyframe*>                  可能与当前关键帧形成闭环的候选帧\n                                           mbowvec                         map<wordid, wordvalue>           wordid 和 wordvalue 表示word在叶子中的id和权重\n                                           mvinvertedfile                  vector<list<keyframe*> >         vector的下标是wordid，list是包含这个word的所有关键帧\n                                           lkfssharingwords                list<keyframe *>                 初步候选关键帧列表\n                                           lscoreandmatch                  list<pair<float, keyframe *>>    筛选单词数后的候选关键帧列表\n                                           vploopcandidates                vector<keyframe *>               最后返回的关键帧列表\n              updateconnections()          kfcounter                       map<keyframe*,int>               关键帧 -- 共视程度(地图点个数)\n                                           vpmp                            vector<mappoint*>                关键帧的地图点\n                                           observations                    map<keyframe*,size_t>            观察到这个地图点的关键帧，size_t表示这个地图点对应在该关键帧的特征点id\n              computesim3()                vvpmappointmatches              vector<vector<mappoint *>>       存储每个候选帧的匹配地图点信息\n                                           mvpcurrentmatchedpoints         vector<mappoint*>                存储的地图点在"当前关键帧"中成功地找到了匹配点的地图点的集合\n              correctloop()                correctedsim3                   map<keyframe *, sim3>            存储的地图点在"当前关键帧"中成功地找到了匹配点的地图点的集合\n                                           noncorrectedsim3                map<keyframe *, sim3>            存放没有矫正的当前关键帧的共视关键帧的世界坐标系下sim变换\n\n\n# tracking流程\n\n 1. 位姿初始化（截取部分）：根据系统状况、跟踪效果选择不同的位姿初始化方法\n    \n    if(mstate==ok){\n        checkreplacedinlastframe();\n        \n        if(mvelocity.empty() || mcurrentframe.mnid<mnlastrelocframeid+2)\n            bok = trackreferencekeyframe();\n        else{\n            bok = trackwithmotionmodel();\n            if(!bok)\n                //根据恒速模型失败，根据参考关键帧来跟踪\n                bok = trackreferencekeyframe();\n        }\n    }\n    else\n        bok = relocalization();\n    \n    \n    checkreplacedinlastframe() ==更新上一帧中的地图点==\n    \n    >   - 检查$currframe$中是否有地图点被localmapping线程替换或者删除\n    >   \t\t\t\t\t\n    >   \t- 被替换则更新，被删除则将地图点赋值为null\n    \n    ----------------------------------------\n    \n    trackwithmotionmodel() ==用匀速运动模型，对currframe进行位姿初始化==\n    \n    >   - 默认上一帧到 $currframe$ 的变换矩阵等于上上帧到上一帧的变换矩阵。\n    >   \t\t\t\t\t\n    >   - 将上一帧观测到的地图点，投影到$currframe$ ，投影点与特征点的间距作为error，如果匹配点不够，则进行`trackreferencekeyframe()`\n    >   - 如果匹配点足够，进行一次仅位姿的ba优化，优化$currframe$的pose，使error最小\n    \n    ----------------------------------------\n    \n    trackreferencekeyframe() ==用上一帧，对currframe进行位姿初始化==\n    \n    >   - 用**词袋模型**，将 $currframe$ 与**参考关键帧**（最新的关键帧）进行特征匹配\n    >   \t\t\t\t\t\n    >   - 将 **参考关键帧**的地图点投影到$currframe$ ，投影点与特征点的间距作为error\n    >   - 如果匹配点足够，进行仅位姿的ba优化，优化$currframe$的pose，使error最小\n    \n    ----------------------------------------\n    \n    relocalization() ==用词袋模型寻找relocframe，对currframe进行位姿初始化==\n    \n    >   - 在所有关键帧中，先用词袋模型找出一批，与$currframe$共同单词最多的关键帧，作为候选关键帧`vpcandidatekfs`\n    >   \t\t\t\t\t\n    >   - 遍历`vpcandidatekfs`，用词袋模型，找出与$currframe$相似度最高的帧作为$relocframe$\n    >   -  用**词袋模型**，将 $currframe$ 与 **$relocframe$** 进行特征匹配\n    >   - 将 **$relocframe$**的对应地图点投影到$currframe$ 上，投影点与特征点的间距作为error\n    >   - 如果匹配点足够，进行仅位姿的ba优化，优化$currframe$的pose，使error最小\n    \n    ----------------------------------------\n\n 2. 局部位姿优化 、关键帧审核（截取部分）\n\n//更新参考关键帧\nmcurrentframe.mpreferencekf = mpreferencekf;\nif(!mbonlytracking){\nif(bok)\n    bok = tracklocalmap();\n}\nelse\n{\nif(bok && !mbvo)\n    bok = tracklocalmap();\n}\n\n//更新系统状态、更新显示、 等等\n.....\n\n\nif(neednewkeyframe())\n    createnewkeyframe();\n\n\ntracklocalmap() ==局部地图中，用ba优化 currframe 的位姿==\n\n>  * 更新局部关键帧、局部地图点，构建局部地图\n> \n>  * 将局部地图中的mappoint投影到currframe，建立新的匹配关系\n> \n>  * 仅位姿的ba优化\n> \n>  * 更新currframe对应的每个mappoint的被观测信息、删除外点\n\n * 根据匹配点数目判断局部位姿优化的好坏，好的话(成功匹配50个点)返回true，否则flase\n\n----------------------------------------\n\nneednewkeyframe() ==检测系统是否需要插入关键帧==\n\n>  * 纯tracking模式，不生产关键帧\n> \n>  * loopclosing线程正在使用局部地图时，不生产关键帧\n> \n>  * 关键帧数目较多、且位置离上一个关键帧较近，不生产关键帧\n\n * 当localmapping线程不忙，且numcurrnumref小于一定阈值，则需要生产关键帧，返回true\n\n----------------------------------------\n\ncreatenewkeyframe() 将设置为一个关键帧对象，并插入currframe设置为一个关键帧对象，并插入mlnewkeyframes\n\n----------------------------------------\n\n\n# localmapping流程\n\n函数主体（截取部分）\n\nif(checknewkeyframes())\n{\n    processnewkeyframe();\n    \n    mappointculling();\n    \n    createnewmappoints();\n    \n    if(!checknewkeyframes())\n        searchinneighbors();\n                \n    mbabortba = false;\n    \n    if(!checknewkeyframes() && !stoprequested())\n    {\n        if(mpmap->keyframesinmap()>2)\n            optimizer::localbundleadjustment(mpcurrentkeyframe,&mbabortba, mpmap);\n        keyframeculling();\n    }\n    mploopcloser->insertkeyframe(mpcurrentkeyframe);\n}\n\n\nchecknewkeyframes() ==检查关键帧队列mlnewkeyframes是否非空==\n\n----------------------------------------\n\nprocessnewkeyframe()\n==将此帧对地图点的观测信息补充进（融入）全局图，再将此帧作为节点插入共视图和全局地图==\n\n>  * 计算此关键帧帧的bow词袋向量\n>  * 获取全局图中被此关键帧观测到的地图点 vpmappointmatches\n>  * 对vpmappointmatches中每一个地图点，更新：地图点的被观测数（+1），平均观测方向、最佳描述子等；不够确定的地图点，记录在 mlploopkeyframequeue，需进一步检查\n>  * 把帧插入共视图：寻找共视关系，更新共视图链接关系\n>  * 把帧插入全局地图\n\n----------------------------------------\n\nmappointculling() ==遍历mlploopkeyframequeue 中地图点p，删除其中质量不好的点==\n\n>  * p为坏点，直接删除\n>  * 实际上观测到的帧数理论上应该观测到的帧数实际上观测到p的帧数理论上应该观测到p的帧数<25% ，删除p\n>  * 当前关键帧id - 创建p的帧id>2（相当于在时间空间上已经进行了一段时间）但实际观测数仍小于一个阈值cnthobs，删除p\n\n----------------------------------------\n\ncreatenewmappoints() ==将关键帧中的特征点三角化，创建新mappoint==\n\n>  * 拿到tracking审核得到的关键帧currframe后，获取共视程度最高的帧作为相邻关键帧\n>  * 遍历相邻共视关键帧，分别与currframe进行特征匹配和三角化，生成地图点\n>  * 生成的地图点记录在mlploopkeyframequeue，还需进一步检查\n\n----------------------------------------\n\nsearchinneighbors() ==将所有新的mappoint融入全局map中，并建立与其他帧的联系== ==将当前关键帧融入全局map中，建立与其他地图点的联系==\n\n>  * 获取此关键帧在共视图中的一级、二级相邻关键帧，并存放在队列vptargetkfs中\n>  * 正向投影融合，将kc观测到的mappoint投影至vptargetkfs中的关键帧，与其中的特征点建立匹配关系\n>  * 获取一、二级相邻关键帧观测到的mappoint集合，并存放在vpfusecandidates中\n>  * 反向投影融合，将vpfusecandidates中的mappoint投影到kc，与kc中的特征点建立匹配关系\n>  * 经过以上步骤，新建了许多共视关系，所以还需更新共视图中kc的邻居\n\n----------------------------------------\n\nkeyframeculling() ==删除冗余关键帧==\n\n>  * 获取此关键帧在共视图中的一级相邻关键帧，并存放在队列vplocalkeyframes中\n>  * 遍历vplocalkeyframes，获取每一共视关键帧vit所观测到的地图点pmp，存放在队列vpmappoints中\n>  * 遍历vpmappoints中每一个地图点pmp，根据pmp->getobservations()遍历所有能观测到pmp的关键帧mit\n>  * 此时， mit、vit都观测到pmp，如果mit对应的关键帧尺度比较小，说明mit对应的关键帧要比vit对应的关键帧更靠近金字塔底部，则mit对pmp观测的效果更好\n>  * 如果pmp被超过3个mit更好地观测，则将冗余点数目nredundantobservations+1\n>  * 遍历完每个vit和其对应的每个mit后，统计nredundantobservationn，如果nredundantobservationn>90% ，删除关键帧kc\n\n----------------------------------------\n\nmappoint::getobservations() ==获得所有能观测到mappoint 的关键帧集合==\n\n----------------------------------------\n\ninsertkeyframe(mpcurrentkeyframe) ==将某一帧放入回环检测处理队列==\n\n\n# loopclosing流程\n\n函数主题\n\nwhile (1)\n\t{\n    // 检查缓冲队列中是否有关键帧\n    if (checknewkeyframes())\n    {\n\t\t// 检测闭环\n        if (detectloop())\n        {\n            // 计算sim3 相似变换\n            if (computesim3())\n            {\n                // 闭环矫正\n                correctloop();\n            }\n        }\n    }\n\n\ngetvectorcovisiblekeyframes()\n\n==获得该帧的共视帧(已按权值排序)==\n\ndetectloopcandidates()\n\n==找出初步闭环候选关键帧==\n\n>  * 遍历当前关键帧的所有单词，找到这些单词的所有关键帧（不包含与当前帧相连的关键帧），作为候选关键帧，放入集合lkfssharingwords中，并记录候选关键帧与当前帧的共同单词数mnloopwords；\n>  * 从lkfssharingwords取出关键帧，确定最小公共单词数为最大公共单词数目的0.8倍，并且与当前帧的相似度得分要大于阈值minscore，符合要求的候选关键帧放入集合lscoreandmatch；\n>  * 从lscoreandmatch中取出关键帧pkfi，pkfi与其前10的共视帧组成一个组，计算这个组的最高得分和累计得分，只留下最高累计得分的0.75倍的组，将留下的组里最高得分的关键帧放入到vploopcandidates返回。\n\nsearchbybow()\n\n==通过词袋向量进行特征匹配==\n\n>  * 遍历两个关键帧bow的所有相同node的特征点，通过描述子距离进行匹配；\n>  * 通过距离、比例阈值和角度直方图投票剔除错误匹配。\n> \n> 这里之后可能会算出一个sim3变换，地图点发生了变化。\n\nsearchbysim3()\n\n==通过sim3变换相互投影特征匹配==\n\n>  * 首先计算一些必要的矩阵，进行位姿变换，投影；\n>  * 将关键帧kf1的特征点投影到kf2，在一个半径范围内就算特征匹配成功；\n>  * 同理，将关键帧kf2的特征点投影到kf1；\n>  * 保留两次匹配都出现的匹配。\n> \n> 这里之后会对sim3变换进行优化。\n\nsearchbyprojection()\n\n==投影一次，查找特征匹配，范围比较大==\n\n>  * 跳过**searchbysim3()**的匹配，遍历闭环kf及其共视kf的所有地图点，投影到当前kf；\n>  * 搜索半径10，搜索新的匹配点。\n\nupdateconnections()\n\n==更新关键帧之间的共视关系==\n\n>  * 获取该关键帧的地图点vpmp，遍历地图点，得到所有观测到该地图点的关键帧observations，并记录关键帧共视的地图点个数，关键帧和共视点个数组成一个pair\n>  * 对pair排序，将共视点个数大于阈值th=15的关键帧，建立与当前帧的共视关系。\n\nsearchandfuse()\n\n==融合和替换地图点==\n\n>  * 遍历待矫正的当前关键帧的相连关键帧；\n>  * 将闭环帧组所有地图点mvploopmappoints，投影到当前关键帧；\n>  * 替换或融合闭环帧组中的地图点mvploopmappoints。',charsets:{cjk:!0}},{title:"基于投票的增量重建",frontmatter:{title:"基于投票的增量重建",date:"2022-07-29T12:47:36.000Z",permalink:"/pages/9af622/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/04.%E5%9F%BA%E4%BA%8E%E6%8A%95%E7%A5%A8%E7%9A%84%E5%A2%9E%E9%87%8F%E9%87%8D%E5%BB%BA.html",relativePath:"02.科研/02.大规模三维重建/04.基于投票的增量重建.md",key:"v-4735ad30",path:"/pages/9af622/",headers:[{level:3,title:"Priori Camera Rotations Estimation",slug:"priori-camera-rotations-estimation",normalizedTitle:"priori camera rotations estimation",charIndex:30},{level:3,title:"Camera Seeds Reconstruction",slug:"camera-seeds-reconstruction",normalizedTitle:"camera seeds reconstruction",charIndex:69},{level:3,title:"Camera Registration",slug:"camera-registration",normalizedTitle:"camera registration",charIndex:103},{level:4,title:"Camera Selection",slug:"camera-selection",normalizedTitle:"camera selection",charIndex:126},{level:4,title:"Camera Calibration",slug:"camera-calibration",normalizedTitle:"camera calibration",charIndex:148},{level:4,title:"Camera Verification",slug:"camera-verification",normalizedTitle:"camera verification",charIndex:172},{level:4,title:"Bundle Adjustment",slug:"bundle-adjustment",normalizedTitle:"bundle adjustment",charIndex:197}],headersStr:"Priori Camera Rotations Estimation Camera Seeds Reconstruction Camera Registration Camera Selection Camera Calibration Camera Verification Bundle Adjustment",content:"输入是所有图像的连接图，输出是相机位姿和稀疏模型。\n\n\n# Priori Camera Rotations Estimation\n\n\n# Camera Seeds Reconstruction\n\n\n\n\n# Camera Registration\n\n# Camera Selection\n\n\n\n# Camera Calibration\n\n\n\n# Camera Verification\n\n\n\n# Bundle Adjustment\n\n",normalizedContent:"输入是所有图像的连接图，输出是相机位姿和稀疏模型。\n\n\n# priori camera rotations estimation\n\n\n# camera seeds reconstruction\n\n\n\n\n# camera registration\n\n# camera selection\n\n\n\n# camera calibration\n\n\n\n# camera verification\n\n\n\n# bundle adjustment\n\n",charsets:{cjk:!0}},{title:"TheiaSfM代码阅读",frontmatter:{title:"TheiaSfM代码阅读",date:"2022-07-29T12:47:36.000Z",permalink:"/pages/299ec4/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/03.TheiaSfM%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB.html",relativePath:"02.科研/02.大规模三维重建/03.TheiaSfM代码阅读.md",key:"v-03535536",path:"/pages/299ec4/",headers:[{level:3,title:"0. The pipeline for estimating camera poses and structure is as follows:",slug:"_0-the-pipeline-for-estimating-camera-poses-and-structure-is-as-follows",normalizedTitle:"0. the pipeline for estimating camera poses and structure is as follows:",charIndex:2},{level:3,title:"1. View Graph",slug:"_1-view-graph",normalizedTitle:"1. view graph",charIndex:632},{level:3,title:"2. Calibrate",slug:"_2-calibrate",normalizedTitle:"2. calibrate",charIndex:720},{level:3,title:"3. Estimate Global Rotation",slug:"_3-estimate-global-rotation",normalizedTitle:"3. estimate global rotation",charIndex:783},{level:4,title:"L1L2",slug:"l1l2",normalizedTitle:"l1l2",charIndex:847},{level:4,title:"Linear",slug:"linear",normalizedTitle:"linear",charIndex:1011},{level:4,title:"nonLinear",slug:"nonlinear",normalizedTitle:"nonlinear",charIndex:1021},{level:3,title:"4. Filter Rotation",slug:"_4-filter-rotation",normalizedTitle:"4. filter rotation",charIndex:1035},{level:3,title:"5. Optimize relative translations",slug:"_5-optimize-relative-translations",normalizedTitle:"5. optimize relative translations",charIndex:1144},{level:3,title:"6. Filter relative translations",slug:"_6-filter-relative-translations",normalizedTitle:"6. filter relative translations",charIndex:1182},{level:3,title:"7. Estimate Global Positions",slug:"_7-estimate-global-positions",normalizedTitle:"7. estimate global positions",charIndex:1218},{level:3,title:"8. Triangulate features",slug:"_8-triangulate-features",normalizedTitle:"8. triangulate features",charIndex:1251},{level:3,title:"9. Bundle Adjustment",slug:"_9-bundle-adjustment",normalizedTitle:"9. bundle adjustment",charIndex:1279},{level:3,title:"10. Output",slug:"_10-output",normalizedTitle:"10. output",charIndex:1304}],headersStr:"0. The pipeline for estimating camera poses and structure is as follows: 1. View Graph 2. Calibrate 3. Estimate Global Rotation L1L2 Linear nonLinear 4. Filter Rotation 5. Optimize relative translations 6. Filter relative translations 7. Estimate Global Positions 8. Triangulate features 9. Bundle Adjustment 10. Output",content:"# 0. The pipeline for estimating camera poses and structure is as follows:\n\n>  1.  Filter potentially bad pairwise geometries by enforcing a loop constaint on rotations that form a triplet.\n>  2.  Initialize focal lengths.\n>  3.  Estimate the global rotation for each camera.\n>  4.  Remove any pairwise geometries where the relative rotation is not consistent with the global rotation.\n>  5.  Optimize the relative translation given the known rotations.\n>  6.  Filter potentially bad relative translations.\n>  7.  Estimate positions.\n>  8.  Estimate structure.\n>  9.  Bundle adjustment.\n>  10. Retriangulate, and bundle adjust.\n\n\n# 1. View Graph\n\n遍历View Graph中所有的边，如果边的两视图内点小于阈值，则删除该条边。\n\n遍历所有的边，计算每条边的连接数，保留连接数最大的边。\n\n\n# 2. Calibrate\n\n加入视图时设立分组的结构，每一组设立一个代表性的视图，同一组中的视图共享代表视图的内参。\n\n\n# 3. Estimate Global Rotation\n\n生成最大生成树，与最小生成树方法类似，只需要把权值设置为负值。\n\n选择L1L2、nonlinear、linear求解。\n\n# L1L2\n\n构建线性系统，Aωglobal−ωrel中的 A。\n\n计算误差项 Rerr=R2T∗R12∗R1。\n\n构建方程组，执行L1_solver，求解出增量，更新GlobalRotations。\n\n计算当前的误差项，迭代。\n\nSolveIRLS()，看不懂了。\n\n# Linear\n\n# nonLinear\n\n\n# 4. Filter Rotation\n\n通过Rotations过滤边，如果一条边的两个视图有任意一个视图没有估计出rotation，或者，如果两视图间的旋转过大，则删除这条边。\n\n移除没有连接到最大子图的边。\n\n\n# 5. Optimize relative translations\n\n\n# 6. Filter relative translations\n\n\n# 7. Estimate Global Positions\n\n\n# 8. Triangulate features\n\n\n# 9. Bundle Adjustment\n\n\n# 10. Output",normalizedContent:"# 0. the pipeline for estimating camera poses and structure is as follows:\n\n>  1.  filter potentially bad pairwise geometries by enforcing a loop constaint on rotations that form a triplet.\n>  2.  initialize focal lengths.\n>  3.  estimate the global rotation for each camera.\n>  4.  remove any pairwise geometries where the relative rotation is not consistent with the global rotation.\n>  5.  optimize the relative translation given the known rotations.\n>  6.  filter potentially bad relative translations.\n>  7.  estimate positions.\n>  8.  estimate structure.\n>  9.  bundle adjustment.\n>  10. retriangulate, and bundle adjust.\n\n\n# 1. view graph\n\n遍历view graph中所有的边，如果边的两视图内点小于阈值，则删除该条边。\n\n遍历所有的边，计算每条边的连接数，保留连接数最大的边。\n\n\n# 2. calibrate\n\n加入视图时设立分组的结构，每一组设立一个代表性的视图，同一组中的视图共享代表视图的内参。\n\n\n# 3. estimate global rotation\n\n生成最大生成树，与最小生成树方法类似，只需要把权值设置为负值。\n\n选择l1l2、nonlinear、linear求解。\n\n# l1l2\n\n构建线性系统，aωglobal−ωrel中的 a。\n\n计算误差项 rerr=r2t∗r12∗r1。\n\n构建方程组，执行l1_solver，求解出增量，更新globalrotations。\n\n计算当前的误差项，迭代。\n\nsolveirls()，看不懂了。\n\n# linear\n\n# nonlinear\n\n\n# 4. filter rotation\n\n通过rotations过滤边，如果一条边的两个视图有任意一个视图没有估计出rotation，或者，如果两视图间的旋转过大，则删除这条边。\n\n移除没有连接到最大子图的边。\n\n\n# 5. optimize relative translations\n\n\n# 6. filter relative translations\n\n\n# 7. estimate global positions\n\n\n# 8. triangulate features\n\n\n# 9. bundle adjustment\n\n\n# 10. output",charsets:{cjk:!0}},{title:"外点去除",frontmatter:{title:"外点去除",date:"2022-07-31T12:47:36.000Z",permalink:"/pages/7453b3/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/05.%E5%A4%96%E7%82%B9%E5%8E%BB%E9%99%A4.html",relativePath:"02.科研/02.大规模三维重建/05.外点去除.md",key:"v-44e6151e",path:"/pages/7453b3/",headers:[{level:3,title:"基于可见性的外点去除",slug:"基于可见性的外点去除",normalizedTitle:"基于可见性的外点去除",charIndex:2},{level:4,title:"Initialization",slug:"initialization",normalizedTitle:"initialization",charIndex:16},{level:4,title:"Database Image Voting",slug:"database-image-voting",normalizedTitle:"database image voting",charIndex:94},{level:4,title:"Database Image Re-Ranking",slug:"database-image-re-ranking",normalizedTitle:"database image re-ranking",charIndex:121},{level:4,title:"Outlier Filter and Match Augmentation",slug:"outlier-filter-and-match-augmentation",normalizedTitle:"outlier filter and match augmentation",charIndex:152},{level:3,title:"基于几何的外点去除",slug:"基于几何的外点去除",normalizedTitle:"基于几何的外点去除",charIndex:196},{level:4,title:"A Data-Driven Geometrical Constraint",slug:"a-data-driven-geometrical-constraint",normalizedTitle:"a data-driven geometrical constraint",charIndex:209},{level:4,title:"The Outlier Filter",slug:"the-outlier-filter",normalizedTitle:"the outlier filter",charIndex:251}],headersStr:"基于可见性的外点去除 Initialization Database Image Voting Database Image Re-Ranking Outlier Filter and Match Augmentation 基于几何的外点去除 A Data-Driven Geometrical Constraint The Outlier Filter",content:"# 基于可见性的外点去除\n\n# Initialization\n\n对于新加入的一幅图像中的某特征点q，找到的3D关联 p1st，p2nd， 如果两个匹配关系相差较多，则保留下来。\n\n\n\n# Database Image Voting\n\n\n\n# Database Image Re-Ranking\n\n\n\n# Outlier Filter and Match Augmentation\n\n\n\n\n# 基于几何的外点去除\n\n# A Data-Driven Geometrical Constraint\n\n\n\n# The Outlier Filter\n\n",normalizedContent:"# 基于可见性的外点去除\n\n# initialization\n\n对于新加入的一幅图像中的某特征点q，找到的3d关联 p1st，p2nd， 如果两个匹配关系相差较多，则保留下来。\n\n\n\n# database image voting\n\n\n\n# database image re-ranking\n\n\n\n# outlier filter and match augmentation\n\n\n\n\n# 基于几何的外点去除\n\n# a data-driven geometrical constraint\n\n\n\n# the outlier filter\n\n",charsets:{cjk:!0}},{title:"orbslam论文阅读笔记",frontmatter:{title:"orbslam论文阅读笔记",date:"2022-05-16T11:01:06.000Z",permalink:"/pages/ed705b/"},regularPath:"/02.%E7%A7%91%E7%A0%94/01.%E5%AE%A4%E5%86%85%E5%AE%9E%E6%97%B6%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/13.orbslam%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.html",relativePath:"02.科研/01.室内实时三维重建/13.orbslam论文阅读笔记.md",key:"v-35d02571",path:"/pages/ed705b/",headersStr:null,content:"使用ORB特征\n\n三大主线程，Tracking、Local Mapping、Loop Closing。\n\nTracking 首先对当前帧，和上一帧进行特征匹配计算位姿，然后使用motion-only BA进行优化。如果跟踪失败，则执行全局重定位（词袋模型）。一旦初始化成功，则通过共视图来优化当前局部地图。通过重投影在局部地图中搜索匹配点，进一步优化相机的位姿。最后决定当前帧是否是关键帧。\n\nLocal Mapping 处理处理一个新的关键帧，并进行局部BA来优化当前场景下附近的帧的位姿。在共视图中与相连的关键帧进行三角化，创建地图点。剔除地图点。\n\nLoop Closing 检测每一个关键帧。匹配回环后进行位姿图优化。\n\n一些数据表示：\n\n地图点 世界坐标系下的3D坐标；观测方向（与关键帧光心相连，所有关键帧的平均值）；ORB描述符；观测到该点的最大深度和最小深度；\n\n关键帧 相机位姿；相机内参；ORB特征点；\n\n共视图 如果两个关键帧之间有15个共同观测的地图点，则他们之间存在一条边，边的权值为共同观测的点数。\n\n本质图 包含所有关键帧的最小生成树、共视图中权值大于100的边以及回环边。\n\n地图初始化 自动选择一个模型进行地图初始化，首先通过两帧并行计算H矩阵和F矩阵，并且计算他们的得分，根据得分来选择使用H矩阵，还是F矩阵来进行初始化。一般来说，场景是平面或低视差就用H矩阵，非平面足够视差就用F矩阵。",normalizedContent:"使用orb特征\n\n三大主线程，tracking、local mapping、loop closing。\n\ntracking 首先对当前帧，和上一帧进行特征匹配计算位姿，然后使用motion-only ba进行优化。如果跟踪失败，则执行全局重定位（词袋模型）。一旦初始化成功，则通过共视图来优化当前局部地图。通过重投影在局部地图中搜索匹配点，进一步优化相机的位姿。最后决定当前帧是否是关键帧。\n\nlocal mapping 处理处理一个新的关键帧，并进行局部ba来优化当前场景下附近的帧的位姿。在共视图中与相连的关键帧进行三角化，创建地图点。剔除地图点。\n\nloop closing 检测每一个关键帧。匹配回环后进行位姿图优化。\n\n一些数据表示：\n\n地图点 世界坐标系下的3d坐标；观测方向（与关键帧光心相连，所有关键帧的平均值）；orb描述符；观测到该点的最大深度和最小深度；\n\n关键帧 相机位姿；相机内参；orb特征点；\n\n共视图 如果两个关键帧之间有15个共同观测的地图点，则他们之间存在一条边，边的权值为共同观测的点数。\n\n本质图 包含所有关键帧的最小生成树、共视图中权值大于100的边以及回环边。\n\n地图初始化 自动选择一个模型进行地图初始化，首先通过两帧并行计算h矩阵和f矩阵，并且计算他们的得分，根据得分来选择使用h矩阵，还是f矩阵来进行初始化。一般来说，场景是平面或低视差就用h矩阵，非平面足够视差就用f矩阵。",charsets:{cjk:!0}},{title:"MVS",frontmatter:{title:"MVS",date:"2022-04-13T12:47:36.000Z",permalink:"/pages/98600a/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/01.MVS.html",relativePath:"02.科研/02.大规模三维重建/01.MVS.md",key:"v-e08ea78c",path:"/pages/98600a/",headers:[{level:3,title:"Global View Selection",slug:"global-view-selection",normalizedTitle:"global view selection",charIndex:115},{level:3,title:"Local View Selection",slug:"local-view-selection",normalizedTitle:"local view selection",charIndex:335},{level:3,title:"Multi-View Stereo Reconstruction",slug:"multi-view-stereo-reconstruction",normalizedTitle:"multi-view stereo reconstruction",charIndex:414}],headersStr:"Global View Selection Local View Selection Multi-View Stereo Reconstruction",content:"我们从互联网收集的图片重建几何图形的方法包括几个阶段\n\n * 相机标定\n * 为每一张图像估计一张深度图\n * 两级视图选择算法\n   * 全局视图选择：找到一组邻域图像。\n   * 局部视图选择：再找到最好的匹配图像。\n\n\n# Global View Selection\n\n对于每一参考视图R，全局视图选择旨在寻找一组邻域图像N，这些图像在场景内容、外观和尺度方面是立体匹配的良好候选图像。候选图像应与参考图像R有足够的视差。设计一个评分函数来衡量候选图像的质量。\n\n共享特征加权和\n\ngR(V)=∑FV∩FRwN(f)⋅ws(f)\n\nFX是视图X的观测到的特征点，wN是计算两视图之间，共视的角度权重。ws是计算两视图之间在共视特征区域的3D分辨率的差异。\n\n\n# Local View Selection\n\n从全局视图中选取一个子集。首先计算local得分，然后计算NCC得分，如果大于阈值，则加入到局部视图中。\n\n\n# Multi-View Stereo Reconstruction\n\n...",normalizedContent:"我们从互联网收集的图片重建几何图形的方法包括几个阶段\n\n * 相机标定\n * 为每一张图像估计一张深度图\n * 两级视图选择算法\n   * 全局视图选择：找到一组邻域图像。\n   * 局部视图选择：再找到最好的匹配图像。\n\n\n# global view selection\n\n对于每一参考视图r，全局视图选择旨在寻找一组邻域图像n，这些图像在场景内容、外观和尺度方面是立体匹配的良好候选图像。候选图像应与参考图像r有足够的视差。设计一个评分函数来衡量候选图像的质量。\n\n共享特征加权和\n\ngr(v)=∑fv∩frwn(f)⋅ws(f)\n\nfx是视图x的观测到的特征点，wn是计算两视图之间，共视的角度权重。ws是计算两视图之间在共视特征区域的3d分辨率的差异。\n\n\n# local view selection\n\n从全局视图中选取一个子集。首先计算local得分，然后计算ncc得分，如果大于阈值，则加入到局部视图中。\n\n\n# multi-view stereo reconstruction\n\n...",charsets:{cjk:!0}},{title:"学习opengl",frontmatter:{title:"学习opengl",date:"2022-03-17T12:47:36.000Z",permalink:"/pages/cc38e6/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/06.%E5%AD%A6%E4%B9%A0opengl.html",relativePath:"02.科研/02.大规模三维重建/06.学习opengl.md",key:"v-56cefa9b",path:"/pages/cc38e6/",headersStr:null,content:"首先初始化。\n\n创建一个窗口对象，名称，大小。\n\n循环渲染。\n\n图像渲染管线接受一组3D坐标，然后把他们转变为屏幕上的有色的2D像素输出。图形渲染管线可以被划分为几个阶段，每个阶段将会把前一个的输出作为输入。每一个阶段运行各自的小程序（着色器Shader）。\n\n一般只需要配置顶点着色器和片段着色器。\n\n顶点着色器：把一个3D坐标转到另一种3D坐标。\n\n片段着色器：计算像素最后的颜色输出。\n\n首先定义一组顶点数据，float数组。\n\n通过VBO一次性把大批数据发送到GPU中。\n\n定义顶点着色器，使用着色器语言GLSL。\n\n将着色器源码附加到着色器对象上，然后编译它。\n\n片段着色器同理。\n\n链接顶点着色器和片段着色器。\n\n给顶点着色器输入数据。",normalizedContent:"首先初始化。\n\n创建一个窗口对象，名称，大小。\n\n循环渲染。\n\n图像渲染管线接受一组3d坐标，然后把他们转变为屏幕上的有色的2d像素输出。图形渲染管线可以被划分为几个阶段，每个阶段将会把前一个的输出作为输入。每一个阶段运行各自的小程序（着色器shader）。\n\n一般只需要配置顶点着色器和片段着色器。\n\n顶点着色器：把一个3d坐标转到另一种3d坐标。\n\n片段着色器：计算像素最后的颜色输出。\n\n首先定义一组顶点数据，float数组。\n\n通过vbo一次性把大批数据发送到gpu中。\n\n定义顶点着色器，使用着色器语言glsl。\n\n将着色器源码附加到着色器对象上，然后编译它。\n\n片段着色器同理。\n\n链接顶点着色器和片段着色器。\n\n给顶点着色器输入数据。",charsets:{cjk:!0}},{title:"密集匹配",frontmatter:{title:"密集匹配",date:"2022-04-13T12:47:36.000Z",permalink:"/pages/8a4bae/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/07.%E5%AF%86%E9%9B%86%E5%8C%B9%E9%85%8D.html",relativePath:"02.科研/02.大规模三维重建/07.密集匹配.md",key:"v-db9fa682",path:"/pages/8a4bae/",headers:[{level:3,title:"双目平面几何模型",slug:"双目平面几何模型",normalizedTitle:"双目平面几何模型",charIndex:371},{level:3,title:"多视平面几何模型",slug:"多视平面几何模型",normalizedTitle:"多视平面几何模型",charIndex:409},{level:3,title:"密集匹配",slug:"密集匹配-2",normalizedTitle:"密集匹配",charIndex:2},{level:3,title:"PatchMatch",slug:"patchmatch",normalizedTitle:"patchmatch",charIndex:1485}],headersStr:"双目平面几何模型 多视平面几何模型 密集匹配 PatchMatch",content:"# 密集匹配\n\n基于图像的密集匹配方法包括双目立体匹配和多视图立体匹配两大类方法。\n\n双目立体匹配 以两张矫正后的极线立体图像作为输入，选取其中一张影响作为参考图像，另一张图像作为匹配图像，通过密集匹配手段获得参考图像对应的视差图。\n\n多视图立体匹配 通过多张重叠图像同时进行密集匹配，相比于双目立体匹配，利用多视冗余数据，能够明显提高底弱纹理及遮挡区域的匹配准确率，同时通过多视深度图一致性检验也能够有效的提出误匹配结果。\n\n传统的密集匹配方法假设局部支撑窗口内的像素具有相同的深度值，即场景几何机构满足平行平面条件假设。对于真实场景中任意点A，只有其深度在整像素位置且局部窗口像素深度相同时，平行平面模型才能刻画真实的物体表面。红色短线为局部窗口，紫色点为待匹配像元，真实点B在局部窗口中找不到匹配点，从而出现“阶梯”现象。\n\n\n\n\n# 双目平面几何模型\n\n\n\n极线矫正后只需与同一行的元素进行匹配即可。\n\n\n# 多视平面几何模型\n\n用多视立体匹配倾斜平面几何模型来表示欧几里得空间中多视图片同名像素与对应的物方空间三维坐标及其所在局部倾斜平面之间的联系。通过倾斜平面几何模型的引入， 可以将深度重建问题转换为求解各参考影像中每个像素对应物方空间局部倾斜平面，从而直接获得子像素深度及法向量。通过Cr,C1,C2,C3相机的位姿，就可以推导出Cr到Ci的单应矩阵，从而可以知道x′的对应点x′,x″,x‴。\n\n\n\n\n# 密集匹配\n\n通常密集匹配都可以转换为马尔科夫随机场（MRF）能量函数最优化问题，即通过小化能量方程来得到全局最优的深度图\n\n（）E(D)=Edata(D)+Esmooth(D)（1）\n\n其中，Edata来度量同名像素的图像一致性，Esmooth度量相邻像素的视差不一致性。\n\n如果能量函数只包含Edata则仅通过图像一致性来度量各像素的深度值,这类方法成为局部法.\n\n如果能量函数只包含Esmooth，则称全局法。\n\n无论全局法还是局部法，密集匹配都可以归纳为以下四个步骤：\n\n匹配代价计算 在给定视差搜索空间范围[dmin,dmax]，通过选择相应的代价函数（AD,HMI,ZNCC等）来确定参考图像中各像素在不同像素下的匹配代价，从而生成对应的三维视差空间体积。使用赢者通吃（Winner-takes-all, WTA）策略来选择代价最小的匹配像素点，因为受光照等噪声影响，这样的匹配效果并不好。\n\n\n\n代价聚合 为了过滤代价体积中噪声,必须进行代价聚合,即借助相邻像素提供的有效信息进一步提高匹配代价体积的鲁棒性。常用的代价聚合有自适应支撑权滤波、指导图滤波、非局部代价聚合以及自适应支撑窗口滤波等。代价聚合的本质是对匹配代价进行平滑滤波处理\n\n视差计算或优化 通过代价聚合对代价体积降噪后,局部立体匹配方法采用 WTA 策略得到参考影像对应的视差图D。但是对于弱纹理、重复纹理以及包含大量图像噪声等具有挑战的区域,仍然会出现大量的误匹配结果。对于真实的环境,由于相邻像元间深度在全局空间具有一致性,通过增加这一先验条件,从而求解式(1)中的能量方程可以有效的改善挑战图像区域的匹配模糊,并获得全局空间近似最优深度图。常用的求解器有置信度传播(BP)，图割(GC)，半全局匹配(SGM)等。\n\n视差精化 由于光照变化、遮挡及弱纹理区域的存在,全局能量函数最优化得到的视深度图中仍然存在大量的误匹配像元,同时传统的全局方法只能得到视差图的整像素精度。视差精化处理过程主要包括:视差图过滤及插值、子像素增强、中值滤波及双边滤波等过程。\n\n\n# PatchMatch\n\nPatchMatch最开始被提出来的目的是用来快速匹配给定影响中图像块在对应目标图像集中最相似的图像块。对于图像A中的图像块，在目标图像B中随机分配一个初始的对应位置，一般使用金字塔技术，底分辨率的迭代后的位置给高分辨率提供初始位置。通过选择最优匹配的相邻像素传播，直到接近真实图像块，进行随机扰动避免陷入局部最优。\n\n基于PatchMatch的视差估计法：\n\n 1. 随机初始化\n 2. 迭代传播\n    * 空间传播\n    * 视图传播\n    * 时序传播\n    * 平面优化\n 3. 后处理\n\n参考博士论文\n\n参考博客",normalizedContent:"# 密集匹配\n\n基于图像的密集匹配方法包括双目立体匹配和多视图立体匹配两大类方法。\n\n双目立体匹配 以两张矫正后的极线立体图像作为输入，选取其中一张影响作为参考图像，另一张图像作为匹配图像，通过密集匹配手段获得参考图像对应的视差图。\n\n多视图立体匹配 通过多张重叠图像同时进行密集匹配，相比于双目立体匹配，利用多视冗余数据，能够明显提高底弱纹理及遮挡区域的匹配准确率，同时通过多视深度图一致性检验也能够有效的提出误匹配结果。\n\n传统的密集匹配方法假设局部支撑窗口内的像素具有相同的深度值，即场景几何机构满足平行平面条件假设。对于真实场景中任意点a，只有其深度在整像素位置且局部窗口像素深度相同时，平行平面模型才能刻画真实的物体表面。红色短线为局部窗口，紫色点为待匹配像元，真实点b在局部窗口中找不到匹配点，从而出现“阶梯”现象。\n\n\n\n\n# 双目平面几何模型\n\n\n\n极线矫正后只需与同一行的元素进行匹配即可。\n\n\n# 多视平面几何模型\n\n用多视立体匹配倾斜平面几何模型来表示欧几里得空间中多视图片同名像素与对应的物方空间三维坐标及其所在局部倾斜平面之间的联系。通过倾斜平面几何模型的引入， 可以将深度重建问题转换为求解各参考影像中每个像素对应物方空间局部倾斜平面，从而直接获得子像素深度及法向量。通过cr,c1,c2,c3相机的位姿，就可以推导出cr到ci的单应矩阵，从而可以知道x′的对应点x′,x″,x‴。\n\n\n\n\n# 密集匹配\n\n通常密集匹配都可以转换为马尔科夫随机场（mrf）能量函数最优化问题，即通过小化能量方程来得到全局最优的深度图\n\n（）e(d)=edata(d)+esmooth(d)（1）\n\n其中，edata来度量同名像素的图像一致性，esmooth度量相邻像素的视差不一致性。\n\n如果能量函数只包含edata则仅通过图像一致性来度量各像素的深度值,这类方法成为局部法.\n\n如果能量函数只包含esmooth，则称全局法。\n\n无论全局法还是局部法，密集匹配都可以归纳为以下四个步骤：\n\n匹配代价计算 在给定视差搜索空间范围[dmin,dmax]，通过选择相应的代价函数（ad,hmi,zncc等）来确定参考图像中各像素在不同像素下的匹配代价，从而生成对应的三维视差空间体积。使用赢者通吃（winner-takes-all, wta）策略来选择代价最小的匹配像素点，因为受光照等噪声影响，这样的匹配效果并不好。\n\n\n\n代价聚合 为了过滤代价体积中噪声,必须进行代价聚合,即借助相邻像素提供的有效信息进一步提高匹配代价体积的鲁棒性。常用的代价聚合有自适应支撑权滤波、指导图滤波、非局部代价聚合以及自适应支撑窗口滤波等。代价聚合的本质是对匹配代价进行平滑滤波处理\n\n视差计算或优化 通过代价聚合对代价体积降噪后,局部立体匹配方法采用 wta 策略得到参考影像对应的视差图d。但是对于弱纹理、重复纹理以及包含大量图像噪声等具有挑战的区域,仍然会出现大量的误匹配结果。对于真实的环境,由于相邻像元间深度在全局空间具有一致性,通过增加这一先验条件,从而求解式(1)中的能量方程可以有效的改善挑战图像区域的匹配模糊,并获得全局空间近似最优深度图。常用的求解器有置信度传播(bp)，图割(gc)，半全局匹配(sgm)等。\n\n视差精化 由于光照变化、遮挡及弱纹理区域的存在,全局能量函数最优化得到的视深度图中仍然存在大量的误匹配像元,同时传统的全局方法只能得到视差图的整像素精度。视差精化处理过程主要包括:视差图过滤及插值、子像素增强、中值滤波及双边滤波等过程。\n\n\n# patchmatch\n\npatchmatch最开始被提出来的目的是用来快速匹配给定影响中图像块在对应目标图像集中最相似的图像块。对于图像a中的图像块，在目标图像b中随机分配一个初始的对应位置，一般使用金字塔技术，底分辨率的迭代后的位置给高分辨率提供初始位置。通过选择最优匹配的相邻像素传播，直到接近真实图像块，进行随机扰动避免陷入局部最优。\n\n基于patchmatch的视差估计法：\n\n 1. 随机初始化\n 2. 迭代传播\n    * 空间传播\n    * 视图传播\n    * 时序传播\n    * 平面优化\n 3. 后处理\n\n参考博士论文\n\n参考博客",charsets:{cjk:!0}},{title:"自我描述",frontmatter:{title:"自我描述",date:"2022-09-16T12:50:47.000Z",permalink:"/pages/fc7936/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/10.%E8%87%AA%E6%88%91%E6%8F%8F%E8%BF%B0.html",relativePath:"02.科研/02.大规模三维重建/10.自我描述.md",key:"v-384a84e1",path:"/pages/fc7936/",headers:[{level:3,title:"增量SfM",slug:"增量sfm",normalizedTitle:"增量sfm",charIndex:28},{level:4,title:"一",slug:"一",normalizedTitle:"一",charIndex:37},{level:4,title:"二",slug:"二",normalizedTitle:"二",charIndex:298},{level:3,title:"全局SfM",slug:"全局sfm",normalizedTitle:"全局sfm",charIndex:347},{level:4,title:"Rotation Averaging",slug:"rotation-averaging",normalizedTitle:"rotation averaging",charIndex:388},{level:4,title:"Translation Averaging",slug:"translation-averaging",normalizedTitle:"translation averaging",charIndex:613},{level:2,title:"track selection and camera prioritization",slug:"track-selection-and-camera-prioritization",normalizedTitle:"track selection and camera prioritization",charIndex:811},{level:6,title:"问题",slug:"问题",normalizedTitle:"问题",charIndex:858},{level:6,title:"解决",slug:"解决",normalizedTitle:"解决",charIndex:935},{level:6,title:"问题： 初始种子选择",slug:"问题-初始种子选择",normalizedTitle:"问题： 初始种子选择",charIndex:1032},{level:6,title:"解决",slug:"解决-2",normalizedTitle:"解决",charIndex:935},{level:6,title:"问题：Track Triangulation & Selection",slug:"问题-track-triangulation-selection",normalizedTitle:"问题：track triangulation &amp; selection",charIndex:null},{level:6,title:"解决",slug:"解决-3",normalizedTitle:"解决",charIndex:935},{level:6,title:"RA",slug:"ra",normalizedTitle:"ra",charIndex:883},{level:2,title:"CSFM",slug:"csfm",normalizedTitle:"csfm",charIndex:1542},{level:2,title:"Rotation-Only BA",slug:"rotation-only-ba",normalizedTitle:"rotation-only ba",charIndex:1611},{level:2,title:"ROBUST AND ACCURATE HYBRID STRUCTURE-FROM-MOTION",slug:"robust-and-accurate-hybrid-structure-from-motion",normalizedTitle:"robust and accurate hybrid structure-from-motion",charIndex:1872},{level:6,title:"方法：",slug:"方法",normalizedTitle:"方法：",charIndex:1796},{level:6,title:"场景图优化",slug:"场景图优化",normalizedTitle:"场景图优化",charIndex:1978},{level:6,title:"Hybrid",slug:"hybrid",normalizedTitle:"hybrid",charIndex:2063},{level:2,title:"Hybrid Rotation Averaging: A Fast and Robust Rotation Averaging Approach",slug:"hybrid-rotation-averaging-a-fast-and-robust-rotation-averaging-approach",normalizedTitle:"hybrid rotation averaging: a fast and robust rotation averaging approach",charIndex:2125},{level:6,title:"RA",slug:"ra-2",normalizedTitle:"ra",charIndex:883},{level:2,title:"Incremental Rotation Averaging",slug:"incremental-rotation-averaging",normalizedTitle:"incremental rotation averaging",charIndex:2367},{level:6,title:"创新点",slug:"创新点",normalizedTitle:"创新点",charIndex:2688},{level:6,title:"后续",slug:"后续",normalizedTitle:"后续",charIndex:1111},{level:2,title:"Image-Matching From Paper to Practice",slug:"image-matching-from-paper-to-practice",normalizedTitle:"image-matching from paper to practice",charIndex:2869},{level:2,title:"A hybrid global structure from motion method for synchronously estimating global rotations and global translations",slug:"a-hybrid-global-structure-from-motion-method-for-synchronously-estimating-global-rotations-and-global-translations",normalizedTitle:"a hybrid global structure from motion method for synchronously estimating global rotations and global translations",charIndex:3043},{level:6,title:"贡献",slug:"贡献",normalizedTitle:"贡献",charIndex:3161},{level:2,title:"To Learn or Not to Learn: Visual Localization from Essential Matrices",slug:"to-learn-or-not-to-learn-visual-localization-from-essential-matrices",normalizedTitle:"to learn or not to learn: visual localization from essential matrices",charIndex:3186},{level:3,title:"Essential Matrix Based Location",slug:"essential-matrix-based-location",normalizedTitle:"essential matrix based location",charIndex:3634},{level:6,title:"Retrieving",slug:"retrieving",normalizedTitle:"retrieving",charIndex:3761},{level:6,title:"Pair Selection",slug:"pair-selection",normalizedTitle:"pair selection",charIndex:3834},{level:6,title:"Pairwise Relative Pose Estimation",slug:"pairwise-relative-pose-estimation",normalizedTitle:"pairwise relative pose estimation",charIndex:3945},{level:6,title:"Absolute Pose Estimation via RANSAC",slug:"absolute-pose-estimation-via-ransac",normalizedTitle:"absolute pose estimation via ransac",charIndex:4019},{level:3,title:"Essential Matrix Estimation",slug:"essential-matrix-estimation",normalizedTitle:"essential matrix estimation",charIndex:4237},{level:6,title:"Feature-based",slug:"feature-based",normalizedTitle:"feature-based",charIndex:4268},{level:6,title:"Learning-based",slug:"learning-based",normalizedTitle:"learning-based",charIndex:4332},{level:6,title:"Hybrid: Learning Matching + five-Point Solver",slug:"hybrid-learning-matching-five-point-solver",normalizedTitle:"hybrid: learning matching + five-point solver",charIndex:4747},{level:6,title:"结论",slug:"结论",normalizedTitle:"结论",charIndex:4865},{level:2,title:"View-graph construction framework for robust and eﬃcient structure-from-motion",slug:"view-graph-construction-framework-for-robust-and-efficient-structure-from-motion",normalizedTitle:"view-graph construction framework for robust and eﬃcient structure-from-motion",charIndex:4923},{level:4,title:"方法",slug:"方法-2",normalizedTitle:"方法",charIndex:151},{level:2,title:"Robust Motion Averaging for Multi-view Registration of Point Sets Based Maximum Correntropy Criterion",slug:"robust-motion-averaging-for-multi-view-registration-of-point-sets-based-maximum-correntropy-criterion",normalizedTitle:"robust motion averaging for multi-view registration of point sets based maximum correntropy criterion",charIndex:5665},{level:2,title:"Progressive Large-Scale Structure-from-Motion with Orthogonal MSTs",slug:"progressive-large-scale-structure-from-motion-with-orthogonal-msts",normalizedTitle:"progressive large-scale structure-from-motion with orthogonal msts",charIndex:6074},{level:2,title:"TC-SfM: Robust Track-Community-Based Structure-from-Motion",slug:"tc-sfm-robust-track-community-based-structure-from-motion",normalizedTitle:"tc-sfm: robust track-community-based structure-from-motion",charIndex:6504},{level:2,title:"Accurate and eﬃcient ground-to-aerial model alignment",slug:"accurate-and-efficient-ground-to-aerial-model-alignment",normalizedTitle:"accurate and eﬃcient ground-to-aerial model alignment",charIndex:6823},{level:2,title:"Progressive Structure from Motion",slug:"progressive-structure-from-motion",normalizedTitle:"progressive structure from motion",charIndex:7097},{level:4,title:"方法：",slug:"方法-3",normalizedTitle:"方法：",charIndex:1796},{level:6,title:"view graph",slug:"view-graph",normalizedTitle:"view graph",charIndex:7350},{level:2,title:"Hybrid Camera Pose Estimation With Online Partitioning for SLAM",slug:"hybrid-camera-pose-estimation-with-online-partitioning-for-slam",normalizedTitle:"hybrid camera pose estimation with online partitioning for slam",charIndex:7552},{level:6,title:"局部共视",slug:"局部共视",normalizedTitle:"局部共视",charIndex:7796},{level:6,title:"全局共视",slug:"全局共视",normalizedTitle:"全局共视",charIndex:7824},{level:2,title:"Revisiting Viewing Graph Solvability: an Effective Approach Based on Cycle Consistency",slug:"revisiting-viewing-graph-solvability-an-effective-approach-based-on-cycle-consistency",normalizedTitle:"revisiting viewing graph solvability: an effective approach based on cycle consistency",charIndex:7845},{level:2,title:"Progressive Structure from Motion by Iteratively Prioritizing and Refining Match Pairs",slug:"progressive-structure-from-motion-by-iteratively-prioritizing-and-refining-match-pairs",normalizedTitle:"progressive structure from motion by iteratively prioritizing and refining match pairs",charIndex:8060},{level:6,title:"初始化",slug:"初始化",normalizedTitle:"初始化",charIndex:2589},{level:6,title:"扩展",slug:"扩展",normalizedTitle:"扩展",charIndex:1859},{level:6,title:"colmap",slug:"colmap",normalizedTitle:"colmap",charIndex:8372},{level:6,title:"算法流程",slug:"算法流程",normalizedTitle:"算法流程",charIndex:8403},{level:2,title:"IRAv3: Hierarchical Incremental Rotation Averaging on the Fly",slug:"irav3-hierarchical-incremental-rotation-averaging-on-the-fly",normalizedTitle:"irav3: hierarchical incremental rotation averaging on the fly",charIndex:8549},{level:4,title:"IRA",slug:"ira",normalizedTitle:"ira",charIndex:8549},{level:4,title:"IRA++",slug:"ira-2",normalizedTitle:"ira++",charIndex:8737},{level:4,title:"IRAv3",slug:"irav3",normalizedTitle:"irav3",charIndex:8549}],headersStr:"增量SfM 一 二 全局SfM Rotation Averaging Translation Averaging track selection and camera prioritization 问题 解决 问题： 初始种子选择 解决 问题：Track Triangulation & Selection 解决 RA CSFM Rotation-Only BA ROBUST AND ACCURATE HYBRID STRUCTURE-FROM-MOTION 方法： 场景图优化 Hybrid Hybrid Rotation Averaging: A Fast and Robust Rotation Averaging Approach RA Incremental Rotation Averaging 创新点 后续 Image-Matching From Paper to Practice A hybrid global structure from motion method for synchronously estimating global rotations and global translations 贡献 To Learn or Not to Learn: Visual Localization from Essential Matrices Essential Matrix Based Location Retrieving Pair Selection Pairwise Relative Pose Estimation Absolute Pose Estimation via RANSAC Essential Matrix Estimation Feature-based Learning-based Hybrid: Learning Matching + five-Point Solver 结论 View-graph construction framework for robust and eﬃcient structure-from-motion 方法 Robust Motion Averaging for Multi-view Registration of Point Sets Based Maximum Correntropy Criterion Progressive Large-Scale Structure-from-Motion with Orthogonal MSTs TC-SfM: Robust Track-Community-Based Structure-from-Motion Accurate and eﬃcient ground-to-aerial model alignment Progressive Structure from Motion 方法： view graph Hybrid Camera Pose Estimation With Online Partitioning for SLAM 局部共视 全局共视 Revisiting Viewing Graph Solvability: an Effective Approach Based on Cycle Consistency Progressive Structure from Motion by Iteratively Prioritizing and Refining Match Pairs 初始化 扩展 colmap 算法流程 IRAv3: Hierarchical Incremental Rotation Averaging on the Fly IRA IRA++ IRAv3",content:"# Structure from Motion\n\n\n# 增量SfM\n\n# 一\n\n从两视图或三视图作为种子开始进行重建，然后添加新的视图到系统中，最后进行BA。这种方式通常敏感于初始种子选择，和遭受累计误差。像VSFM、COLMAP提出re-triangulate tracks来消除结构误差。\n\n传统的方法过度关注下一个视图选择，并且每次迭代时只注册一个或多个相机，导致BA执行很多次，花费很多计算时间。\n\n在每一次迭代中，所有可见的tracks都三角化和优化，在计算相机位姿时显得冗余。\n\n在摄像机配准过程中，通常忽略极几何测量。\n\n在增量配准期间，错误边缘可能会将低SfM系统的性能。\n\n# 二\n\n首先创建小的3D模型，然后合并不同的模型。\n\n增量SfM都存在累计误差和大计算量。\n\n\n# 全局SfM\n\n同时估计所有的相机位姿然后BA一次，包含旋转平均和平移平均。\n\n# Rotation Averaging\n\nd(Rij−RjRiT)=0\n\n最开始构建求解该方法的误差函数使用四元数的F-范数。\n\n提出李代数的旋转平均。\n\n使用L1优化方法来求解。\n\nWilson et al. [43]发现有两个因素影响旋转平均的精度，一个是Edge Graph（EG）结构，另一个是极几何的精度，然后推荐当摄像机分布均匀时，建议先将其群集。\n\nHSfM基于这个理论，提出一个基于社区的旋转平均方法群集，然后贪婪的的合并EG。\n\n# Translation Averaging\n\nλijtij=Rj(Ci−Cj)\n\n很多线性方法通过矩阵分解的方式来求解该方程，但这些方法敏感于极几何的外点。\n\n也有很多方法先剔除极几何的外点，通过回环等，但这些方法需要冗余的图像对。\n\n一些方法局部BA或者多视图tracks的一致性来优化极几何。\n\n也有方法同时求解相机的平移和三维点。\n\n还有方法通过融合辅助的成像信息来获得相机平移。\n\n\n# track selection and camera prioritization\n\n\n\n# 问题\n\n 1. 在完整的view-graph中执行RA仅仅考虑最大连接的紧密型，而忽视精确度。\n 2. 加速摄像机配准的过程，减少BA的内存占用。\n\n# 解决\n\n 1. 在view-graph的多个正交最大生成树中执行RA。该精度取决于view-graph的连接紧密性，以及极几何的精度。\n 2. 选择一个子集轨迹来优化注册好的摄像机位姿。\n\n# 问题： 初始种子选择\n\n 1. 选择特征匹配数量多的图像对\n 2. 通过基础矩阵过滤匹配点\n 3. 要求种子具有底重投影误差和小协方差\n\n# 解决\n\n没有考虑后续摄像机匹配。良好的种子应与视图中其它节点紧密连接。\n\n# 问题：Track Triangulation & Selection\n\n 1. 在相机注册完，对所有的tracks进行三角化，这样花费大量时间和内存，降低系统的性能。\n\n# 解决\n\n 1. 在一些global SfM中，采用track selection 来加速三角化，知道所有相机位姿。\n 2. 在增量SfM中，相机位姿是逐步知道的\n 3. 所以考虑，在当前次迭代和下一次迭代中选择tracks给BA。\n\n# RA\n\n 1. F-范数，李代数，使用IRLS，2016视图结构也会影响RA的精度。然而大多数工作都没有考虑。\n 2. 对于精度，通过局部BA来优化极几何相对位姿，通过三焦量一致性来验证相对位姿，通过longer tracks来一致性来提升相对位姿的精度。\n 3. 将视图选择作为最小成本网络流问题。\n 4. 忽略了结构的约束。\n 5. 对一般和模糊的数据集使用不同的先验因子。\n\n\n# CSFM\n\n\n\n首先，对极几何图划分为单独的社区，然后并行解决每个社区的重建问题，最后通过全局相似度平均方法对重建结果进行合并。\n\n\n# Rotation-Only BA\n\nBA旨在获得一个优化的结构点和相机位姿通过最小化图像的重投影误差。\n\n在Global SfM框架下，对旋转进行准确的初始猜测很重要。所以一般有改进旋转平均方法 或 相对位姿输入。\n\n然而相对位姿估计仅仅限制于两张图像之间，而旋转平均不直接利用图像测量，即使它们是从具体有不同噪声统计和分布的不同点数估计，它也会平等对待所有相对旋转\n\n方法： 给定旋转的初始估计，使用图像测量作为直接输入执行仅旋转优化。\n\n基于先前一篇的独立于平移的仅优化两图像之间的旋转。\n\n扩展到多个视图。\n\n\n# ROBUST AND ACCURATE HYBRID STRUCTURE-FROM-MOTION\n\n# 方法：\n\n * 构建一个最大生成树，使用Global SfM重建\n * 剩下图片使用增量方式进行重建\n\n# 场景图优化\n\n增量全局方法的输入都是场景图\n\ngraph\nA[提取一个骨干图] \n--\x3e \nB[通过回环一致性提出边之间的误差]\n--\x3e\nC[从最大生成树开始]\n\n\n# Hybrid\n\ngraph\n\nA[HSfM]\n--\x3e\nB[增量估计平移]\n--\x3e\nC[子图像全局 剩余图像增量]\n\n\n\n# Hybrid Rotation Averaging: A Fast and Robust Rotation Averaging Approach\n\n局部优化方法尽管只是保证局部最优，但是最好的选择\n\n全局优化可以在低噪点的情况下保证全局最优，但通常都不满足该条件\n\n# RA\n\n * 局部求解器，陷入局部最小值\n * 全局求解器，敏感于噪点\n\nHSFM，通过global 方法求解旋转，然后相机中心通过P2P方式增量估计，但一些估计的绝对旋转不正确，因此影响后续的重建过程。\n\n\n# Incremental Rotation Averaging\n\n相比于全局SfM，即时增量SfM效率比较底，但其可以保证精度通过频繁的RANSAC和BA。\n\n大多数全局SfM执行旋转平均和平移平均是一个向后顺序，在执行平移平均时候，旋转是固定的。\n\n又因为旋转平均取决于极几何，其中又受无匹配影响，尤其对一些互联网图片。\n\n为了解决这个问题，\n\n 1. 去寻找更加鲁棒的损失函数，让优化的过程更加鲁棒。\n\n这些方法中的优化过程在很大程度上取决于初始化，并且由于问题公式复杂而通常效率低下。\n\n 2. 尝试去剔除EG图的外点。\n\n然而，相对旋转外点过滤和绝对旋转估计是一个鸡与蛋的问题，只有准确估计绝对旋转，才能有效过滤相对旋转异常值。\n\n# 创新点\n\n以增量的方式估计绝对旋转。\n\n使用一些关键点，初始三元组，下一个最佳视图选择策略，迭代参与的加权局部/全局优化，重新旋转平均。\n\n迭代执行外点检测和鲁棒优化，利用部分估计的绝对旋转来有效地检测相对旋转外点，然后使用L2范数来估计绝对旋转。\n\n# 后续\n\n采取分而治之的策略来进行大规模的旋转平均，划分为多个场景图，分别进行旋转平均，最后合并。\n\n\n# Image-Matching From Paper to Practice\n\n最近的努力已经转向整体的端到端的解决方案。尽管他们有希望但他们尚未超越基于分布解决方案的经典范式的分离主义者\n\ngraph\n\nA[提取局部特征 SIFT]\n--\x3e\nB[描述符]\n--\x3e\nC[最近邻搜索]\n--\x3e\nD[RANSAC循环]\n--\x3e\nE[BA管道]\n\n\n\n# A hybrid global structure from motion method for synchronously estimating global rotations and global translations\n\n# 贡献\n\n分层同步解决全局旋转和平移问题，\n\n\n# To Learn or Not to Learn: Visual Localization from Essential Matrices\n\n最近，已经提出了基于相对姿态估计的学习方法，有望轻松适应新场景。然而，他们目前的准确度明显低于最先进的方法。这里有兴趣分析这种行为。\n\n给定一张查询图像，视觉定位算法的目标是估计其相机姿态。\n\n当前实现最先进的姿态估计方法，基于3D信息，他们首先在查询图像中的2D像素位置和场景中的3D点之间建立2D-3D匹配，然后使用得到的对应关系来估计相机姿态。3D场景几何既可以通过3D点云显示表示，也可以通过卷积神经网络的权重隐式表示。\n\n与基于3D的方法相比，基于相对位姿的视觉定位方法具有理想的特性，即场景表示的简单性和灵活性以及易于适应新场景。此外，利用现代机器学习技术进行相对姿态估计似乎很自然，但为什么基于学习的方法在这中情况下表现不佳呢？\n\n本文提出一种新颖且通用的视觉定位框架，该框架使用新颖的RANSAC方案中的基本矩阵来恢复绝对位姿。\n\n\n# Essential Matrix Based Location\n\n 1. 使用图像检索来识别一组图像；\n 2. 对每个检索到的图像计算其与查询图像的本质矩阵；\n 3. 使用检索到的图像的本质矩阵，和已知绝对位姿的查询图像，估计检索图像的绝对位姿。\n\n# Retrieving\n\n通过用3096维DenseVLAD描述符表示每个数据库图像来执行图像检索，这已被证明可以咋具有挑战性的条件下工作。\n\n# Pair Selection\n\n简单地为每个查询图像挑选top-k不足以获得良好的性能。希望确保更大的三角测量角度，同时扔保持足够的视觉重叠以成功进行相对姿态估计。\n\n迭代选择与先前检索图像有一定的最小/最大距离。\n\n# Pairwise Relative Pose Estimation\n\n对于每个图像对，我们计算查询图像和数据库图像之间的相对位姿的本质矩阵。\n\n# Absolute Pose Estimation via RANSAC\n\n使用RANSAC，在每次迭代中，我们对图像对进行采样，并使用他们来估计查询图像的绝对位姿。接下来确定哪些图像对是该绝对位姿假设的内点。\n\n我们首先最小化绝对旋转和相对旋转之间的误差，得到一个绝对旋转，然后用来衡量上面的绝对位姿。\n\n有了旋转后计算平移，测量的平移和预测的绝对位姿中的平移计算余弦相似度，小于一定阈值则视为内点。最后返回最大内点数的位姿。\n\n\n# Essential Matrix Estimation\n\n# Feature-based\n\n在查询和数据库图像之间建立2D2D匹配，然后通过RANSAC循环内应用5点法图集本质矩阵。\n\n# Learning-based\n\nRelative pose parametrizaiton\n\n是相对位姿标签Lw(y∗−y)=||t−t∗||2+β||q−q∗||y∗=(q∗,t∗)是相对位姿标签\n\nNetwork architecture\n\n 1. 一个简单的固定匹配层（EssNet），本质上是来自两个图像的特征图之间的矩阵点积。\n\n 2. 可学习的领域共视匹配层，它强制匹配的局部几何一致性。\n\n两个匹配层豆浆ResNet生成的两个特征图组合成一个单一的特征向量，可以看做是一个匹配分数图。\n\n将分数图输入到回归层来预测本质矩阵，回归层由两个卷积层块组成，然后用ReLU进行批量归一化，最后是一个全连接层回归一个近似于本质矩阵的9D向量。然后将近似的前两个奇异值替换为其均值，将其近似投影到一个有效的本质矩阵上。\n\nLoss function\n\n最小化预测的E 和真实E\n\nLess(E∗−E)=||e−e∗||2\n\n# Hybrid: Learning Matching + five-Point Solver\n\n作为经典方法和回归方法的结合。通过神经网络学习特征提取和匹配，从而产生一组2D-2D匹配。然后使用RANSAC循环5点法估计本质矩阵。\n\n# 结论\n\n在数据驱动的视觉定位方法能够准确并轻松地推广到新场景之前，还需要进行更多的研究。\n\n\n# 0919\n\n\n# View-graph construction framework for robust and eﬃcient structure-from-motion\n\n传统的矩阵分解方式平等对待所有的边，这样在较少特征匹配对会产生外点，而且也会影响其它的边。\n\n为了解决这个问题，我们提出了一个用于视图图构建的增量骨架，具有大量特征匹配的匹配对的鲁棒性被传播到它们的连接图像。\n\n# 方法\n\n首先构建一个经过验证的最大生成树。\n\n对于最大生成树中的每条边，我们执行局部中间并配准其可见相机。\n\n基于局部配准，计算成对的相对几何位姿。\n\n一方面，由于使用了所有特征匹配，因此冗余边缘可能会引入许多错误的边。尽管SfM系统通过几何验证过滤特征匹配异常值，但存在于重复纹理区域中的错误异常值不仅在视觉上相似，而且还可能通过两视图几何验证并形成错误的相对几何。\n\n为了解决歧义问题，方法{20，21}通过一些量身定制的策略顾虑不一致的边缘。\n\n另一方面，两视图极几何通常是通过分解基本矩阵来产生的。对匹配异常值敏感。尽管几何验证利用点对线约束来过滤原理极线的异常值，但无法识别位于极线附近的异常值。虽然BA可以解决该问题，但仍可能还会失败。\n\n为视图图构造提出了一个增量框架，其中自动选择边并通过三视图计算相对几何。为了保证场景的完整性，我们首先从匹配图中构建一个验证的最大生成树，其中边缘由匹配特征的数量加权，并执行验证。对于最大生成树中的每条边，我们通过投票验证相对位姿，并执行局部重建配准可见的相机。根据局部重建中的位姿计算相对位姿。然后将这些计算出的相对位姿插入最大生成树中。迭代执行完局部重建，最后将最大生成树扩展到视图图中。\n\n没有分解基本矩阵，而是利用局部重建来获得相对几何。\n\n\n# Robust Motion Averaging for Multi-view Registration of Point Sets Based Maximum Correntropy Criterion\n\n运动平均，从相对运动中恢复全局运动，并利用信息冗余来平均累计误差。我们提出了一种新颖的运动平均框架，用于使用基于拉普拉斯核的最大相关熵准则（LMCC）进行多视图配准。利用李代数运动框架和相关熵度量，我们提出了一种新的成本函数，该函数将相对运动提供的所有约束都考虑在内。\n\n获得用于校正全局运动的增量可以进一步表述为在最大化成本函数的优化问题。将优化问题分解为两个子问题，根据当前残差计算每个相对运动的权重，并在下一次迭代中求解增量的二阶锥规划问题。\n\n由于场景或物体的遮挡以及扫描视野有限，大多数扫描设备只能捕获部分点云。为了从不同视点捕获的一系列扫描中准确地恢复整个模型或场景，就会出现点集配准问题。\n\n\n# Progressive Large-Scale Structure-from-Motion with Orthogonal MSTs\n\n特征匹配不足可能会破坏重建场景的完整性，而冗余对可能会带来许多错误的匹配。外层循环迭代选择图像相似度的最大生成树来执行图像匹配。内层循环配准相机。\n\n首先，基于从词汇树计算的图像描述符，构建图像相似度图，其中节点表示图像，边表示连接图像之间的相似度得分。\n\n然后，选择图相似度的MST进行图像匹配。给定匹配的特征匹配，相机以增量方式校准。不能保证所有相机都可以通过MST校准。\n\n因此，我们迭代地选择正交MST进行相机校准，前一次迭代产生的特征匹配与新选择的MST产生的特征匹配相结合，并且在前一次迭代中校准的相机位姿被继承到当前迭代中。\n\n根据相机标定的反馈，逐步选择图像相似度的多个正交MST进行图像匹配。此前，大多数SfM方法中，所有匹配对都被视为同等重要，并在相机校准中同时考虑。生成的特征轨迹容易被污染。\n\n\n# TC-SfM: Robust Track-Community-Based Structure-from-Motion\n\n由重复结构引起的模糊性总会导致错误的相机位姿和3D结构。\n\n在本文中，我们建议利用场景中高级信息，即局部区域的空间上下文信息来指导重建。\n\ntrack-community\n\n每个community由一组track组成，并代表场景中的一个局部片段。\n\ncommunity检测算法用于将场景划分为几个部分。\n\n通过分析track的邻域来检测潜在的模糊片段，并通过检查位姿一致性来进行校正。\n\n对每一个片段进行部分重建，并将它们与一个新颖的双向一致性成本函数对齐，该函数同时考虑3D-3D对应关系和成对的相机位姿。\n\n\n# Accurate and eﬃcient ground-to-aerial model alignment\n\n为了生成大规模建筑场景的完整3D重建，通常会同时捕获地面和航拍图像。一种常见的方法是首先分别从不同的图像源重建模型，然后将它们对齐。\n\n使用GPS元信息将地面模型和航拍模型转换为地理参考坐标系进行粗略对齐。\n\n通过基于它们之间的3D点对应关系估计的相似性变换来细化粗对齐模型。\n\na)选择合适的航拍图像子集以正确覆盖地面模型\n\nb)在所选航拍图像的视点下合成来自地面模型的图像\n\nc)获得合成图像与所选航拍图像之间的二维点匹配。\n\n\n# Progressive Structure from Motion\n\n现有的重建框架都没有完全解决一个渐进的场景，提供一个中间结果。增量方式由于错误的信息陷入局部最小值，全局方式，需要访问完整的视图，也无法提供一个中间结果。\n\n本文提出一种渐进式框架，而不是批处理。\n\n传统方式通常设计为批处理算法，其中图像采集和图像处理分为两个独立的步骤。在以用户为中心的场景中，图像是现场拍摄的，并且由3D建模管道即时处理。\n\n将动态全局视图图与基于连通性得分的局部聚类相结合。\n\n# 方法：\n\n 1. 逐步建立场景图view graph，并在整个重建过程中作为全局知识。\n 2. 在算法每次迭代中，view graph都会根据本地连通性进行聚类，并在本地处理单个聚类。\n 3. 在每个聚类中旋转平均，并使用增量或全局估算3D结构。\n 4. 通过使用集群间约束来稳健地估计它们之间的相似变换，来估计单个集群的全局变换。\n\n# view graph\n\n通过单链接聚类分层生长，直到两个聚类之间不存在dij<η的边。\n\n\n# Hybrid Camera Pose Estimation With Online Partitioning for SLAM\n\n通过将空间强连接的摄像机聚集到每个块中，显著提高了局部BA的准确性，并即时更新相机运动估计。基于时间和空间共视将摄像机分块。\n\n块之间中间计算值的传播--\x3e1)动态提供良好的初始化；2)有效地避免了重复计算。\n\n 1. 根据时间和空间特征的对应关系开发了基于协同可见性的分区方案；\n 2. 引入运动平均；\n 3. 动态块间传播和中间计算值的块内广播。\n\n# 局部共视\n\n通过平均在一个3D点集上的相机数量，\n\n# 全局共视\n\n某一块和某一帧的共视\n\n\n# Revisiting Viewing Graph Solvability: an Effective Approach Based on Cycle Consistency\n\n提供了一种新的共视和一种算法，用于确定view graph是否可解，即唯一地确定一组投影相机。\n\n两幅图像之间存在基本矩阵时，存在一条边。\n\n可解性的定义，当且仅当可用的基本矩阵唯一地确定其余基本矩阵时，图才是可解的，即输入图可以转换为完整图。\n\n\n# Progressive Structure from Motion by Iteratively Prioritizing and Refining Match Pairs\n\n从有问题的匹配对去恢复正确的重建结果。我们基于所有潜在匹配对构建了一个加权视图图，并提出一种渐进式SfM方法，该方法迭代地优先考虑和细化其匹配对。初始化和扩展。\n\n# 初始化\n\n从多个独立的最小生成树的联合对匹配对进行排序，并通过循环一致性推断的思想进行优化，其旨在通过分析其几何一致性来推断不正确的边。\n\n# 扩展\n\nseed reconstruction 迭代添加新的最小生成树和细化相应的匹配对来逐步扩展，当扩展到一定的完整性时终止。\n\n# colmap\n\n在重复结构或者短基线的情况匹配错误较多\n\n# 算法流程\n\n 1. 按照colmap的程序获得所有潜在的匹配对，构建加权视图图，边的权值越小，匹配的正确的可能性越大。\n\n 2. 初始化中，生成一个包含多个独立最小生成树的种子视图，并使用CCI过滤种子视图中的异常值。\n\n 3. 扩展，迭代将其它最小生成树扩展进来，实现更密集的图。\n\n\n# IRAv3: Hierarchical Incremental Rotation Averaging on the Fly\n\n# IRA\n\n 1. Initial Triplet Selection， 从场景图中选出最初的三个顶点；\n 2. NBV Selection, 选择边多的下一个结点；\n 3. 局部优化当前新添加结点的旋转；\n 4. 全局优化所有结点的旋转。\n\n# IRA++\n\n 1. 在输入的EG上进行社区检测聚类；\n 2. 对每个社区进行基于IRA的旋转平均，获得在局部坐标系中的旋转；\n 3. 基于VSRA的旋转估计，获得每个社区之间的相对旋转；\n 4. 再次执行基于IRA的旋转平均，估计每个社区的绝对旋转；\n 5. 进行旋转对齐和优化。\n\n# IRAv3\n\n 1. 基于社区检测的种子重建；\n 2. 潜在聚类和顶点预选，下一最佳视图选择和聚类隶属关系，增量绝对旋转计算；\n 3. 3~5 同上",normalizedContent:"# structure from motion\n\n\n# 增量sfm\n\n# 一\n\n从两视图或三视图作为种子开始进行重建，然后添加新的视图到系统中，最后进行ba。这种方式通常敏感于初始种子选择，和遭受累计误差。像vsfm、colmap提出re-triangulate tracks来消除结构误差。\n\n传统的方法过度关注下一个视图选择，并且每次迭代时只注册一个或多个相机，导致ba执行很多次，花费很多计算时间。\n\n在每一次迭代中，所有可见的tracks都三角化和优化，在计算相机位姿时显得冗余。\n\n在摄像机配准过程中，通常忽略极几何测量。\n\n在增量配准期间，错误边缘可能会将低sfm系统的性能。\n\n# 二\n\n首先创建小的3d模型，然后合并不同的模型。\n\n增量sfm都存在累计误差和大计算量。\n\n\n# 全局sfm\n\n同时估计所有的相机位姿然后ba一次，包含旋转平均和平移平均。\n\n# rotation averaging\n\nd(rij−rjrit)=0\n\n最开始构建求解该方法的误差函数使用四元数的f-范数。\n\n提出李代数的旋转平均。\n\n使用l1优化方法来求解。\n\nwilson et al. [43]发现有两个因素影响旋转平均的精度，一个是edge graph（eg）结构，另一个是极几何的精度，然后推荐当摄像机分布均匀时，建议先将其群集。\n\nhsfm基于这个理论，提出一个基于社区的旋转平均方法群集，然后贪婪的的合并eg。\n\n# translation averaging\n\nλijtij=rj(ci−cj)\n\n很多线性方法通过矩阵分解的方式来求解该方程，但这些方法敏感于极几何的外点。\n\n也有很多方法先剔除极几何的外点，通过回环等，但这些方法需要冗余的图像对。\n\n一些方法局部ba或者多视图tracks的一致性来优化极几何。\n\n也有方法同时求解相机的平移和三维点。\n\n还有方法通过融合辅助的成像信息来获得相机平移。\n\n\n# track selection and camera prioritization\n\n\n\n# 问题\n\n 1. 在完整的view-graph中执行ra仅仅考虑最大连接的紧密型，而忽视精确度。\n 2. 加速摄像机配准的过程，减少ba的内存占用。\n\n# 解决\n\n 1. 在view-graph的多个正交最大生成树中执行ra。该精度取决于view-graph的连接紧密性，以及极几何的精度。\n 2. 选择一个子集轨迹来优化注册好的摄像机位姿。\n\n# 问题： 初始种子选择\n\n 1. 选择特征匹配数量多的图像对\n 2. 通过基础矩阵过滤匹配点\n 3. 要求种子具有底重投影误差和小协方差\n\n# 解决\n\n没有考虑后续摄像机匹配。良好的种子应与视图中其它节点紧密连接。\n\n# 问题：track triangulation & selection\n\n 1. 在相机注册完，对所有的tracks进行三角化，这样花费大量时间和内存，降低系统的性能。\n\n# 解决\n\n 1. 在一些global sfm中，采用track selection 来加速三角化，知道所有相机位姿。\n 2. 在增量sfm中，相机位姿是逐步知道的\n 3. 所以考虑，在当前次迭代和下一次迭代中选择tracks给ba。\n\n# ra\n\n 1. f-范数，李代数，使用irls，2016视图结构也会影响ra的精度。然而大多数工作都没有考虑。\n 2. 对于精度，通过局部ba来优化极几何相对位姿，通过三焦量一致性来验证相对位姿，通过longer tracks来一致性来提升相对位姿的精度。\n 3. 将视图选择作为最小成本网络流问题。\n 4. 忽略了结构的约束。\n 5. 对一般和模糊的数据集使用不同的先验因子。\n\n\n# csfm\n\n\n\n首先，对极几何图划分为单独的社区，然后并行解决每个社区的重建问题，最后通过全局相似度平均方法对重建结果进行合并。\n\n\n# rotation-only ba\n\nba旨在获得一个优化的结构点和相机位姿通过最小化图像的重投影误差。\n\n在global sfm框架下，对旋转进行准确的初始猜测很重要。所以一般有改进旋转平均方法 或 相对位姿输入。\n\n然而相对位姿估计仅仅限制于两张图像之间，而旋转平均不直接利用图像测量，即使它们是从具体有不同噪声统计和分布的不同点数估计，它也会平等对待所有相对旋转\n\n方法： 给定旋转的初始估计，使用图像测量作为直接输入执行仅旋转优化。\n\n基于先前一篇的独立于平移的仅优化两图像之间的旋转。\n\n扩展到多个视图。\n\n\n# robust and accurate hybrid structure-from-motion\n\n# 方法：\n\n * 构建一个最大生成树，使用global sfm重建\n * 剩下图片使用增量方式进行重建\n\n# 场景图优化\n\n增量全局方法的输入都是场景图\n\ngraph\na[提取一个骨干图] \n--\x3e \nb[通过回环一致性提出边之间的误差]\n--\x3e\nc[从最大生成树开始]\n\n\n# hybrid\n\ngraph\n\na[hsfm]\n--\x3e\nb[增量估计平移]\n--\x3e\nc[子图像全局 剩余图像增量]\n\n\n\n# hybrid rotation averaging: a fast and robust rotation averaging approach\n\n局部优化方法尽管只是保证局部最优，但是最好的选择\n\n全局优化可以在低噪点的情况下保证全局最优，但通常都不满足该条件\n\n# ra\n\n * 局部求解器，陷入局部最小值\n * 全局求解器，敏感于噪点\n\nhsfm，通过global 方法求解旋转，然后相机中心通过p2p方式增量估计，但一些估计的绝对旋转不正确，因此影响后续的重建过程。\n\n\n# incremental rotation averaging\n\n相比于全局sfm，即时增量sfm效率比较底，但其可以保证精度通过频繁的ransac和ba。\n\n大多数全局sfm执行旋转平均和平移平均是一个向后顺序，在执行平移平均时候，旋转是固定的。\n\n又因为旋转平均取决于极几何，其中又受无匹配影响，尤其对一些互联网图片。\n\n为了解决这个问题，\n\n 1. 去寻找更加鲁棒的损失函数，让优化的过程更加鲁棒。\n\n这些方法中的优化过程在很大程度上取决于初始化，并且由于问题公式复杂而通常效率低下。\n\n 2. 尝试去剔除eg图的外点。\n\n然而，相对旋转外点过滤和绝对旋转估计是一个鸡与蛋的问题，只有准确估计绝对旋转，才能有效过滤相对旋转异常值。\n\n# 创新点\n\n以增量的方式估计绝对旋转。\n\n使用一些关键点，初始三元组，下一个最佳视图选择策略，迭代参与的加权局部/全局优化，重新旋转平均。\n\n迭代执行外点检测和鲁棒优化，利用部分估计的绝对旋转来有效地检测相对旋转外点，然后使用l2范数来估计绝对旋转。\n\n# 后续\n\n采取分而治之的策略来进行大规模的旋转平均，划分为多个场景图，分别进行旋转平均，最后合并。\n\n\n# image-matching from paper to practice\n\n最近的努力已经转向整体的端到端的解决方案。尽管他们有希望但他们尚未超越基于分布解决方案的经典范式的分离主义者\n\ngraph\n\na[提取局部特征 sift]\n--\x3e\nb[描述符]\n--\x3e\nc[最近邻搜索]\n--\x3e\nd[ransac循环]\n--\x3e\ne[ba管道]\n\n\n\n# a hybrid global structure from motion method for synchronously estimating global rotations and global translations\n\n# 贡献\n\n分层同步解决全局旋转和平移问题，\n\n\n# to learn or not to learn: visual localization from essential matrices\n\n最近，已经提出了基于相对姿态估计的学习方法，有望轻松适应新场景。然而，他们目前的准确度明显低于最先进的方法。这里有兴趣分析这种行为。\n\n给定一张查询图像，视觉定位算法的目标是估计其相机姿态。\n\n当前实现最先进的姿态估计方法，基于3d信息，他们首先在查询图像中的2d像素位置和场景中的3d点之间建立2d-3d匹配，然后使用得到的对应关系来估计相机姿态。3d场景几何既可以通过3d点云显示表示，也可以通过卷积神经网络的权重隐式表示。\n\n与基于3d的方法相比，基于相对位姿的视觉定位方法具有理想的特性，即场景表示的简单性和灵活性以及易于适应新场景。此外，利用现代机器学习技术进行相对姿态估计似乎很自然，但为什么基于学习的方法在这中情况下表现不佳呢？\n\n本文提出一种新颖且通用的视觉定位框架，该框架使用新颖的ransac方案中的基本矩阵来恢复绝对位姿。\n\n\n# essential matrix based location\n\n 1. 使用图像检索来识别一组图像；\n 2. 对每个检索到的图像计算其与查询图像的本质矩阵；\n 3. 使用检索到的图像的本质矩阵，和已知绝对位姿的查询图像，估计检索图像的绝对位姿。\n\n# retrieving\n\n通过用3096维densevlad描述符表示每个数据库图像来执行图像检索，这已被证明可以咋具有挑战性的条件下工作。\n\n# pair selection\n\n简单地为每个查询图像挑选top-k不足以获得良好的性能。希望确保更大的三角测量角度，同时扔保持足够的视觉重叠以成功进行相对姿态估计。\n\n迭代选择与先前检索图像有一定的最小/最大距离。\n\n# pairwise relative pose estimation\n\n对于每个图像对，我们计算查询图像和数据库图像之间的相对位姿的本质矩阵。\n\n# absolute pose estimation via ransac\n\n使用ransac，在每次迭代中，我们对图像对进行采样，并使用他们来估计查询图像的绝对位姿。接下来确定哪些图像对是该绝对位姿假设的内点。\n\n我们首先最小化绝对旋转和相对旋转之间的误差，得到一个绝对旋转，然后用来衡量上面的绝对位姿。\n\n有了旋转后计算平移，测量的平移和预测的绝对位姿中的平移计算余弦相似度，小于一定阈值则视为内点。最后返回最大内点数的位姿。\n\n\n# essential matrix estimation\n\n# feature-based\n\n在查询和数据库图像之间建立2d2d匹配，然后通过ransac循环内应用5点法图集本质矩阵。\n\n# learning-based\n\nrelative pose parametrizaiton\n\n是相对位姿标签lw(y∗−y)=||t−t∗||2+β||q−q∗||y∗=(q∗,t∗)是相对位姿标签\n\nnetwork architecture\n\n 1. 一个简单的固定匹配层（essnet），本质上是来自两个图像的特征图之间的矩阵点积。\n\n 2. 可学习的领域共视匹配层，它强制匹配的局部几何一致性。\n\n两个匹配层豆浆resnet生成的两个特征图组合成一个单一的特征向量，可以看做是一个匹配分数图。\n\n将分数图输入到回归层来预测本质矩阵，回归层由两个卷积层块组成，然后用relu进行批量归一化，最后是一个全连接层回归一个近似于本质矩阵的9d向量。然后将近似的前两个奇异值替换为其均值，将其近似投影到一个有效的本质矩阵上。\n\nloss function\n\n最小化预测的e 和真实e\n\nless(e∗−e)=||e−e∗||2\n\n# hybrid: learning matching + five-point solver\n\n作为经典方法和回归方法的结合。通过神经网络学习特征提取和匹配，从而产生一组2d-2d匹配。然后使用ransac循环5点法估计本质矩阵。\n\n# 结论\n\n在数据驱动的视觉定位方法能够准确并轻松地推广到新场景之前，还需要进行更多的研究。\n\n\n# 0919\n\n\n# view-graph construction framework for robust and eﬃcient structure-from-motion\n\n传统的矩阵分解方式平等对待所有的边，这样在较少特征匹配对会产生外点，而且也会影响其它的边。\n\n为了解决这个问题，我们提出了一个用于视图图构建的增量骨架，具有大量特征匹配的匹配对的鲁棒性被传播到它们的连接图像。\n\n# 方法\n\n首先构建一个经过验证的最大生成树。\n\n对于最大生成树中的每条边，我们执行局部中间并配准其可见相机。\n\n基于局部配准，计算成对的相对几何位姿。\n\n一方面，由于使用了所有特征匹配，因此冗余边缘可能会引入许多错误的边。尽管sfm系统通过几何验证过滤特征匹配异常值，但存在于重复纹理区域中的错误异常值不仅在视觉上相似，而且还可能通过两视图几何验证并形成错误的相对几何。\n\n为了解决歧义问题，方法{20，21}通过一些量身定制的策略顾虑不一致的边缘。\n\n另一方面，两视图极几何通常是通过分解基本矩阵来产生的。对匹配异常值敏感。尽管几何验证利用点对线约束来过滤原理极线的异常值，但无法识别位于极线附近的异常值。虽然ba可以解决该问题，但仍可能还会失败。\n\n为视图图构造提出了一个增量框架，其中自动选择边并通过三视图计算相对几何。为了保证场景的完整性，我们首先从匹配图中构建一个验证的最大生成树，其中边缘由匹配特征的数量加权，并执行验证。对于最大生成树中的每条边，我们通过投票验证相对位姿，并执行局部重建配准可见的相机。根据局部重建中的位姿计算相对位姿。然后将这些计算出的相对位姿插入最大生成树中。迭代执行完局部重建，最后将最大生成树扩展到视图图中。\n\n没有分解基本矩阵，而是利用局部重建来获得相对几何。\n\n\n# robust motion averaging for multi-view registration of point sets based maximum correntropy criterion\n\n运动平均，从相对运动中恢复全局运动，并利用信息冗余来平均累计误差。我们提出了一种新颖的运动平均框架，用于使用基于拉普拉斯核的最大相关熵准则（lmcc）进行多视图配准。利用李代数运动框架和相关熵度量，我们提出了一种新的成本函数，该函数将相对运动提供的所有约束都考虑在内。\n\n获得用于校正全局运动的增量可以进一步表述为在最大化成本函数的优化问题。将优化问题分解为两个子问题，根据当前残差计算每个相对运动的权重，并在下一次迭代中求解增量的二阶锥规划问题。\n\n由于场景或物体的遮挡以及扫描视野有限，大多数扫描设备只能捕获部分点云。为了从不同视点捕获的一系列扫描中准确地恢复整个模型或场景，就会出现点集配准问题。\n\n\n# progressive large-scale structure-from-motion with orthogonal msts\n\n特征匹配不足可能会破坏重建场景的完整性，而冗余对可能会带来许多错误的匹配。外层循环迭代选择图像相似度的最大生成树来执行图像匹配。内层循环配准相机。\n\n首先，基于从词汇树计算的图像描述符，构建图像相似度图，其中节点表示图像，边表示连接图像之间的相似度得分。\n\n然后，选择图相似度的mst进行图像匹配。给定匹配的特征匹配，相机以增量方式校准。不能保证所有相机都可以通过mst校准。\n\n因此，我们迭代地选择正交mst进行相机校准，前一次迭代产生的特征匹配与新选择的mst产生的特征匹配相结合，并且在前一次迭代中校准的相机位姿被继承到当前迭代中。\n\n根据相机标定的反馈，逐步选择图像相似度的多个正交mst进行图像匹配。此前，大多数sfm方法中，所有匹配对都被视为同等重要，并在相机校准中同时考虑。生成的特征轨迹容易被污染。\n\n\n# tc-sfm: robust track-community-based structure-from-motion\n\n由重复结构引起的模糊性总会导致错误的相机位姿和3d结构。\n\n在本文中，我们建议利用场景中高级信息，即局部区域的空间上下文信息来指导重建。\n\ntrack-community\n\n每个community由一组track组成，并代表场景中的一个局部片段。\n\ncommunity检测算法用于将场景划分为几个部分。\n\n通过分析track的邻域来检测潜在的模糊片段，并通过检查位姿一致性来进行校正。\n\n对每一个片段进行部分重建，并将它们与一个新颖的双向一致性成本函数对齐，该函数同时考虑3d-3d对应关系和成对的相机位姿。\n\n\n# accurate and eﬃcient ground-to-aerial model alignment\n\n为了生成大规模建筑场景的完整3d重建，通常会同时捕获地面和航拍图像。一种常见的方法是首先分别从不同的图像源重建模型，然后将它们对齐。\n\n使用gps元信息将地面模型和航拍模型转换为地理参考坐标系进行粗略对齐。\n\n通过基于它们之间的3d点对应关系估计的相似性变换来细化粗对齐模型。\n\na)选择合适的航拍图像子集以正确覆盖地面模型\n\nb)在所选航拍图像的视点下合成来自地面模型的图像\n\nc)获得合成图像与所选航拍图像之间的二维点匹配。\n\n\n# progressive structure from motion\n\n现有的重建框架都没有完全解决一个渐进的场景，提供一个中间结果。增量方式由于错误的信息陷入局部最小值，全局方式，需要访问完整的视图，也无法提供一个中间结果。\n\n本文提出一种渐进式框架，而不是批处理。\n\n传统方式通常设计为批处理算法，其中图像采集和图像处理分为两个独立的步骤。在以用户为中心的场景中，图像是现场拍摄的，并且由3d建模管道即时处理。\n\n将动态全局视图图与基于连通性得分的局部聚类相结合。\n\n# 方法：\n\n 1. 逐步建立场景图view graph，并在整个重建过程中作为全局知识。\n 2. 在算法每次迭代中，view graph都会根据本地连通性进行聚类，并在本地处理单个聚类。\n 3. 在每个聚类中旋转平均，并使用增量或全局估算3d结构。\n 4. 通过使用集群间约束来稳健地估计它们之间的相似变换，来估计单个集群的全局变换。\n\n# view graph\n\n通过单链接聚类分层生长，直到两个聚类之间不存在dij<η的边。\n\n\n# hybrid camera pose estimation with online partitioning for slam\n\n通过将空间强连接的摄像机聚集到每个块中，显著提高了局部ba的准确性，并即时更新相机运动估计。基于时间和空间共视将摄像机分块。\n\n块之间中间计算值的传播--\x3e1)动态提供良好的初始化；2)有效地避免了重复计算。\n\n 1. 根据时间和空间特征的对应关系开发了基于协同可见性的分区方案；\n 2. 引入运动平均；\n 3. 动态块间传播和中间计算值的块内广播。\n\n# 局部共视\n\n通过平均在一个3d点集上的相机数量，\n\n# 全局共视\n\n某一块和某一帧的共视\n\n\n# revisiting viewing graph solvability: an effective approach based on cycle consistency\n\n提供了一种新的共视和一种算法，用于确定view graph是否可解，即唯一地确定一组投影相机。\n\n两幅图像之间存在基本矩阵时，存在一条边。\n\n可解性的定义，当且仅当可用的基本矩阵唯一地确定其余基本矩阵时，图才是可解的，即输入图可以转换为完整图。\n\n\n# progressive structure from motion by iteratively prioritizing and refining match pairs\n\n从有问题的匹配对去恢复正确的重建结果。我们基于所有潜在匹配对构建了一个加权视图图，并提出一种渐进式sfm方法，该方法迭代地优先考虑和细化其匹配对。初始化和扩展。\n\n# 初始化\n\n从多个独立的最小生成树的联合对匹配对进行排序，并通过循环一致性推断的思想进行优化，其旨在通过分析其几何一致性来推断不正确的边。\n\n# 扩展\n\nseed reconstruction 迭代添加新的最小生成树和细化相应的匹配对来逐步扩展，当扩展到一定的完整性时终止。\n\n# colmap\n\n在重复结构或者短基线的情况匹配错误较多\n\n# 算法流程\n\n 1. 按照colmap的程序获得所有潜在的匹配对，构建加权视图图，边的权值越小，匹配的正确的可能性越大。\n\n 2. 初始化中，生成一个包含多个独立最小生成树的种子视图，并使用cci过滤种子视图中的异常值。\n\n 3. 扩展，迭代将其它最小生成树扩展进来，实现更密集的图。\n\n\n# irav3: hierarchical incremental rotation averaging on the fly\n\n# ira\n\n 1. initial triplet selection， 从场景图中选出最初的三个顶点；\n 2. nbv selection, 选择边多的下一个结点；\n 3. 局部优化当前新添加结点的旋转；\n 4. 全局优化所有结点的旋转。\n\n# ira++\n\n 1. 在输入的eg上进行社区检测聚类；\n 2. 对每个社区进行基于ira的旋转平均，获得在局部坐标系中的旋转；\n 3. 基于vsra的旋转估计，获得每个社区之间的相对旋转；\n 4. 再次执行基于ira的旋转平均，估计每个社区的绝对旋转；\n 5. 进行旋转对齐和优化。\n\n# irav3\n\n 1. 基于社区检测的种子重建；\n 2. 潜在聚类和顶点预选，下一最佳视图选择和聚类隶属关系，增量绝对旋转计算；\n 3. 3~5 同上",charsets:{cjk:!0}},{title:"论文随记",frontmatter:{title:"论文随记",date:"2022-03-26T12:47:36.000Z",permalink:"/pages/4a64fa/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/09.%E8%AE%BA%E6%96%87%E9%9A%8F%E8%AE%B0.html",relativePath:"02.科研/02.大规模三维重建/09.论文随记.md",key:"v-58cdf8c8",path:"/pages/4a64fa/",headers:[{level:3,title:"使用标记道路建图",slug:"使用标记道路建图",normalizedTitle:"使用标记道路建图",charIndex:552},{level:3,title:"生成点云",slug:"生成点云",normalizedTitle:"生成点云",charIndex:757},{level:3,title:"点云融合",slug:"点云融合",normalizedTitle:"点云融合",charIndex:639},{level:3,title:"回环检测",slug:"回环检测",normalizedTitle:"回环检测",charIndex:1031},{level:3,title:"本文的主要工作：",slug:"本文的主要工作",normalizedTitle:"本文的主要工作：",charIndex:1203},{level:3,title:"系统概述",slug:"系统概述",normalizedTitle:"系统概述",charIndex:1637},{level:3,title:"IPM Image",slug:"ipm-image",normalizedTitle:"ipm image",charIndex:1810},{level:3,title:"Feature Detection",slug:"feature-detection",normalizedTitle:"feature detection",charIndex:1852},{level:3,title:"Local Mapping",slug:"local-mapping",normalizedTitle:"local mapping",charIndex:1907},{level:3,title:"Loop Detection",slug:"loop-detection",normalizedTitle:"loop detection",charIndex:1970},{level:3,title:"Global Optimization",slug:"global-optimization",normalizedTitle:"global optimization",charIndex:2128},{level:3,title:"Localization",slug:"localization",normalizedTitle:"localization",charIndex:2244},{level:3,title:"Parking Spot Detection",slug:"parking-spot-detection",normalizedTitle:"parking spot detection",charIndex:2521},{level:3,title:"系统概述",slug:"系统概述-2",normalizedTitle:"系统概述",charIndex:1637},{level:3,title:"IPM",slug:"ipm",normalizedTitle:"ipm",charIndex:577},{level:3,title:"Pose Graph Optimization",slug:"pose-graph-optimization",normalizedTitle:"pose graph optimization",charIndex:2970},{level:3,title:"Local Map",slug:"local-map",normalizedTitle:"local map",charIndex:1907},{level:3,title:"Map Merging / Updating",slug:"map-merging-updating",normalizedTitle:"map merging / updating",charIndex:3224},{level:3,title:"Map Compression",slug:"map-compression",normalizedTitle:"map compression",charIndex:3330},{level:3,title:"Map Decompression",slug:"map-decompression",normalizedTitle:"map decompression",charIndex:3434},{level:3,title:"ICP Localization",slug:"icp-localization",normalizedTitle:"icp localization",charIndex:3489}],headersStr:"使用标记道路建图 生成点云 点云融合 回环检测 本文的主要工作： 系统概述 IPM Image Feature Detection Local Mapping Loop Detection Global Optimization Localization Parking Spot Detection 系统概述 IPM Pose Graph Optimization Local Map Map Merging / Updating Map Compression Map Decompression ICP Localization",content:"# 2019 mapping and locatization\n\n利用道路标记语义分割解决长期高精度视觉定位问题。\n\n结合语义与几何的点云配准方法。\n\n全球导航卫星系统（GNSS）。雷达、UWB技术虽然有高精度定位，但价格昂高。\n\n近年目标检测，语义分割提供了很多语义信息，这可以整合到建图和定位的过程中。\n\n通常部署环视摄像机以提高对遮挡的鲁棒性。\n\n[17] 中提出了使用 ID 进行停车位检测的尝试，他们将 ID 视为语义数据关联，并应用视觉基准标签来辅助闭环，从而获得更高的精度。(没有充分利用车道线信息)\n\nRoad-SLAM [18] 中的工作对道路标记的点云进行分割和分类，然后使用道路标记匹配执行闭环，从而获得米级定位精度。\n\n>  1. 使用生成的点云，融合模块被设计来构建用于匹配的局部子图。\n>  2. 为了纠正航位推算误差累积，采用基于分割结果的闭环检测重访位置。\n>  3. 依次应用位姿图优化和点云校正以保证全局一致性。\n>  4. 在定位过程中，进行全局初始化，将当前局部坐标与地图坐标对齐。\n>  5. 为了提高匹配精度，提出了基于语义和几何信息的ICP来匹配语义点云和当前子图，并使用扩展卡尔曼滤波器（EKF）算法与航位推算融合，实现高精度定位，无漂移积累 .\n\n\n# 使用标记道路建图\n\n>  1. 首先进行语义分割和IPM，将相机图像转换为单帧点云。\n>  2. 然后，提出了航位推算（IMU、轮速里程计）辅助的图像拼接和语义道路标记辅助的点云融合，以减少时间不同步和误分类的影响，构建准确的局部子地图。\n>  3. 为了获得全局一致的地图，设计了基于道路标记分割的闭环来检测重访区域。\n>  4. 最后，基于闭环结果，我们采用全局姿态图优化来确保所有姿态的一致性。\n\n\n# 生成点云\n\n>  1. 这里使用多类点云，根据原始的鱼眼相机图像，进行语义分割，将道路标记分为七类。\n>  2. 创建鸟瞰图。\n>  3. 基于鸟瞰图，通过提取带有道路标记标签的像素来创建点云。\n>  4. 由于四个鱼眼相机的时间难以同步，使用IMU和轮速里程计来补偿拼接误差。\n>  5. 为了确保点云配准算法保持恒定的计算复杂度，我们随机删除一些点以限制在单帧中观察到的点数。\n\n\n# 点云融合\n\n确定数据关联，设计合适的策略融合点云。\n\n对于给定的关联，没有找到相应匹配点的点直接添加到地图中。没有关联的按以下方式融合\n\n自己看去。\n\n\n# 回环检测\n\n通过 FAST方向 和旋转(ORB) 描述符和语义描述符，给出闭环候选，然后通过DBoW2模块计算词袋向量，最后计算关联得分分数。\n\n\n# 2020 AVP-SLAM\n\n在停车场工厂这样的环境，使用传统的几何特征几乎不切实际，会频繁的跟踪丢失。这里提出一种语义特征，可以很稳定的识别车道线，路标等，且不受视角和光线的影响。\n\n\n# 本文的主要工作：\n\n>  1. 提出在vslam中的语义特征。\n>  2. 提出完整的建图和定位系统。\n>  3. 构造真实的自动停车应用。\n\n\n\nGet:\n\n>  1. relative localization 也叫 odometry ， 一般先初始化开始的位置，然后关注当前帧的相对位姿。\n>  2. global localization 有一个固定的坐标，通常通过一个先验地图进行定位。\n>  3. 传统的特征方法一般都是利用集合特征（稀疏点、角点和稠密的平面），这里只需要估计关键点的位置，这些关键点可以进一步添加一个补充区分，例如SFIT、SURF、ORB、BRIEF描述子。一般通过提前视觉里程计来构建视觉地图，然后在这个地图内对相机进行定位。例如ORB特征的地图，之后可以通过ORB描述子进行匹配来定位。\n>  4. 基于道路特征的方法一般采用道路表面的道路标志（车道线、路边和标志等）。可以使用额外的设备（激光雷达）提前构建好精确的地图，\n\n\n# 系统概述\n\n>  1. 在前后左右使用分别安装相机，使用IMU和轮速里程计提供一个初始的相对位姿，但会存在累计误差。\n>  2. 首先构建一个全局的语义地图，使用神经网络提取语义特征（车道线、指示标志、减速带），因为存在累计误差，这里采用局部地图的回环检测减少误差。\n>  3. 其次进行定位，和建图部分差不多，后端采用EKF进行优化。\n\n\n# IPM Image\n\n将相机获取照片的像素点，投影到以车为中心的坐标系中。\n\n\n# Feature Detection\n\n使用主流的CNN方法取提取语义特征。大多数图像分割网络都可以。\n\n\n# Local Mapping\n\n将上一步语义分割的点，基于里程计，转换到世界坐标系，这些点组成一个local map。\n\n\n# Loop Detection\n\n因为里程计存在累计误差，这里使用回环检测来消除漂移。对于最新的local map，我们比较它周围的local map，这里两个local map通过ICP方法来匹配。如果有两个local maps匹配成功，计算一个相对位姿，然后放到全局位姿图优化器总进行优化，进而矫正漂移。\n\n\n# Global Optimization\n\n这里的位姿图中，节点是每一个local map的位姿，这里有两种边，一种是通过里程计测量两个local maps的相对位姿，另一种是回环检测边，约束形成闭环的local maps。\n\n\n# Localization\n\n基于已经构建好的语义地图，在车经过同样地方时可以定位。对于输入的合成图像，进行语义特征检测，转换到车的坐标系，然后通过在地图中匹配车当前获取的语义特征来估计车当前的位姿，这了使用ICP方法进行匹配\n\n\n\n绿色的是车当前获取的特征，橙色的估计的轨迹。\n\nICP方法的初始迭代值很重要，在最开始的初始化中，这里提供了两种方法，一是在停车场入口处放置标志，二是进入地下停车场前使用GPS给定在地图中的初始位置。在很少纹理的区域中，采用EKF，融合了里程计和视觉定位的结果，在过滤器中，里程计作为预测，视觉定位结果用来更新。\n\n\n# Parking Spot Detection\n\n停车位的角点用来预测停车线位置，如果停车线能够匹配角点，那么这次预测是准确的。\n\n\n# 2021 RoadMap\n\n车载测绘、云端维护、用户端定位的框架。在车辆上收集和预处理地图数据，将复杂的数据上传到云端，在云端整合多辆车的数据，并及时更新语义地图，最后经过压缩，分发到车辆中。提出一个新颖的想法，使用传感器丰富的车每天去收集数据和更新地图，最终受益于量产车上。\n\n\n\n\n# 系统概述\n\n>  1. 搭载前置摄像头，GPS，IMU和轮速里程计的车每天出去收集数据，前置摄像头收集的照片放到分割网络，提取语义特征，然后将语义特征转到到世界坐标系，最后建立局部地图，上传到云端。\n>  2. 云端收集到多辆上述的车的局部地图，融合成全局地图，然后对地图轮廓提取，最后将压缩后的语义地图发送给用户（量产车）。\n>  3. 用户端配备低成本传感器，下载云端的地图，然后进行定位。\n\n\n# IPM\n\n这里只对ROI的IPM，车前方12m * 8m。\n\n\n# Pose Graph Optimization\n\n虽然用上RTK-GNSS，厘米级精度，只能在空旷的区域。这里的位姿图优化也是有两种边，GNSS RTK对节点的约束，里程计对节点的约束。\n\n\n\n\n# Local Map\n\n同理，这里的语义特征都需要投影到全局坐标系中。这里语义特征分类用了窗口，当车移动时，一个区域可能会被观测多次，由于存在分割的噪声，这区域可能会被分为不同的类别。 使用统计过滤噪声。地图被分成许多的网络，当一个语义点进入一个网格，对应的语义标签加1，次数最多的语义代表这个网格。\n\n\n# Map Merging / Updating\n\n为了节省带宽，这里只选择局部地图中被标记的网络进行上传到云端，同理云端的地图也分为若干个网格，局部地图网格中的标签得分也加到全局地图中。这个过程是并行的。\n\n\n# Map Compression\n\n同样为了节省带宽，这里语义地图的可以被轮廓代表。首先，生成语义图的顶视图图像，每一个像素代表一个网格。其次，提取每一组语义的轮廓。最后，轮廓点存起来，发送到量产车。\n\n\n# Map Decompression\n\n量产车拿到压缩后的数据后，进行解压：用相同标签的点，填充轮廓。\n\n\n# ICP Localization\n\n恢复出语义地图后，同上一篇，使用ICP方法进行匹配，后端使用EKF融合里程计和视觉定位的信息，进行优化。\n\n\n\n绿色的车当前获取到的语义特征。\n\n实验中，还将语义地图与谷歌地图对齐。",normalizedContent:"# 2019 mapping and locatization\n\n利用道路标记语义分割解决长期高精度视觉定位问题。\n\n结合语义与几何的点云配准方法。\n\n全球导航卫星系统（gnss）。雷达、uwb技术虽然有高精度定位，但价格昂高。\n\n近年目标检测，语义分割提供了很多语义信息，这可以整合到建图和定位的过程中。\n\n通常部署环视摄像机以提高对遮挡的鲁棒性。\n\n[17] 中提出了使用 id 进行停车位检测的尝试，他们将 id 视为语义数据关联，并应用视觉基准标签来辅助闭环，从而获得更高的精度。(没有充分利用车道线信息)\n\nroad-slam [18] 中的工作对道路标记的点云进行分割和分类，然后使用道路标记匹配执行闭环，从而获得米级定位精度。\n\n>  1. 使用生成的点云，融合模块被设计来构建用于匹配的局部子图。\n>  2. 为了纠正航位推算误差累积，采用基于分割结果的闭环检测重访位置。\n>  3. 依次应用位姿图优化和点云校正以保证全局一致性。\n>  4. 在定位过程中，进行全局初始化，将当前局部坐标与地图坐标对齐。\n>  5. 为了提高匹配精度，提出了基于语义和几何信息的icp来匹配语义点云和当前子图，并使用扩展卡尔曼滤波器（ekf）算法与航位推算融合，实现高精度定位，无漂移积累 .\n\n\n# 使用标记道路建图\n\n>  1. 首先进行语义分割和ipm，将相机图像转换为单帧点云。\n>  2. 然后，提出了航位推算（imu、轮速里程计）辅助的图像拼接和语义道路标记辅助的点云融合，以减少时间不同步和误分类的影响，构建准确的局部子地图。\n>  3. 为了获得全局一致的地图，设计了基于道路标记分割的闭环来检测重访区域。\n>  4. 最后，基于闭环结果，我们采用全局姿态图优化来确保所有姿态的一致性。\n\n\n# 生成点云\n\n>  1. 这里使用多类点云，根据原始的鱼眼相机图像，进行语义分割，将道路标记分为七类。\n>  2. 创建鸟瞰图。\n>  3. 基于鸟瞰图，通过提取带有道路标记标签的像素来创建点云。\n>  4. 由于四个鱼眼相机的时间难以同步，使用imu和轮速里程计来补偿拼接误差。\n>  5. 为了确保点云配准算法保持恒定的计算复杂度，我们随机删除一些点以限制在单帧中观察到的点数。\n\n\n# 点云融合\n\n确定数据关联，设计合适的策略融合点云。\n\n对于给定的关联，没有找到相应匹配点的点直接添加到地图中。没有关联的按以下方式融合\n\n自己看去。\n\n\n# 回环检测\n\n通过 fast方向 和旋转(orb) 描述符和语义描述符，给出闭环候选，然后通过dbow2模块计算词袋向量，最后计算关联得分分数。\n\n\n# 2020 avp-slam\n\n在停车场工厂这样的环境，使用传统的几何特征几乎不切实际，会频繁的跟踪丢失。这里提出一种语义特征，可以很稳定的识别车道线，路标等，且不受视角和光线的影响。\n\n\n# 本文的主要工作：\n\n>  1. 提出在vslam中的语义特征。\n>  2. 提出完整的建图和定位系统。\n>  3. 构造真实的自动停车应用。\n\n\n\nget:\n\n>  1. relative localization 也叫 odometry ， 一般先初始化开始的位置，然后关注当前帧的相对位姿。\n>  2. global localization 有一个固定的坐标，通常通过一个先验地图进行定位。\n>  3. 传统的特征方法一般都是利用集合特征（稀疏点、角点和稠密的平面），这里只需要估计关键点的位置，这些关键点可以进一步添加一个补充区分，例如sfit、surf、orb、brief描述子。一般通过提前视觉里程计来构建视觉地图，然后在这个地图内对相机进行定位。例如orb特征的地图，之后可以通过orb描述子进行匹配来定位。\n>  4. 基于道路特征的方法一般采用道路表面的道路标志（车道线、路边和标志等）。可以使用额外的设备（激光雷达）提前构建好精确的地图，\n\n\n# 系统概述\n\n>  1. 在前后左右使用分别安装相机，使用imu和轮速里程计提供一个初始的相对位姿，但会存在累计误差。\n>  2. 首先构建一个全局的语义地图，使用神经网络提取语义特征（车道线、指示标志、减速带），因为存在累计误差，这里采用局部地图的回环检测减少误差。\n>  3. 其次进行定位，和建图部分差不多，后端采用ekf进行优化。\n\n\n# ipm image\n\n将相机获取照片的像素点，投影到以车为中心的坐标系中。\n\n\n# feature detection\n\n使用主流的cnn方法取提取语义特征。大多数图像分割网络都可以。\n\n\n# local mapping\n\n将上一步语义分割的点，基于里程计，转换到世界坐标系，这些点组成一个local map。\n\n\n# loop detection\n\n因为里程计存在累计误差，这里使用回环检测来消除漂移。对于最新的local map，我们比较它周围的local map，这里两个local map通过icp方法来匹配。如果有两个local maps匹配成功，计算一个相对位姿，然后放到全局位姿图优化器总进行优化，进而矫正漂移。\n\n\n# global optimization\n\n这里的位姿图中，节点是每一个local map的位姿，这里有两种边，一种是通过里程计测量两个local maps的相对位姿，另一种是回环检测边，约束形成闭环的local maps。\n\n\n# localization\n\n基于已经构建好的语义地图，在车经过同样地方时可以定位。对于输入的合成图像，进行语义特征检测，转换到车的坐标系，然后通过在地图中匹配车当前获取的语义特征来估计车当前的位姿，这了使用icp方法进行匹配\n\n\n\n绿色的是车当前获取的特征，橙色的估计的轨迹。\n\nicp方法的初始迭代值很重要，在最开始的初始化中，这里提供了两种方法，一是在停车场入口处放置标志，二是进入地下停车场前使用gps给定在地图中的初始位置。在很少纹理的区域中，采用ekf，融合了里程计和视觉定位的结果，在过滤器中，里程计作为预测，视觉定位结果用来更新。\n\n\n# parking spot detection\n\n停车位的角点用来预测停车线位置，如果停车线能够匹配角点，那么这次预测是准确的。\n\n\n# 2021 roadmap\n\n车载测绘、云端维护、用户端定位的框架。在车辆上收集和预处理地图数据，将复杂的数据上传到云端，在云端整合多辆车的数据，并及时更新语义地图，最后经过压缩，分发到车辆中。提出一个新颖的想法，使用传感器丰富的车每天去收集数据和更新地图，最终受益于量产车上。\n\n\n\n\n# 系统概述\n\n>  1. 搭载前置摄像头，gps，imu和轮速里程计的车每天出去收集数据，前置摄像头收集的照片放到分割网络，提取语义特征，然后将语义特征转到到世界坐标系，最后建立局部地图，上传到云端。\n>  2. 云端收集到多辆上述的车的局部地图，融合成全局地图，然后对地图轮廓提取，最后将压缩后的语义地图发送给用户（量产车）。\n>  3. 用户端配备低成本传感器，下载云端的地图，然后进行定位。\n\n\n# ipm\n\n这里只对roi的ipm，车前方12m * 8m。\n\n\n# pose graph optimization\n\n虽然用上rtk-gnss，厘米级精度，只能在空旷的区域。这里的位姿图优化也是有两种边，gnss rtk对节点的约束，里程计对节点的约束。\n\n\n\n\n# local map\n\n同理，这里的语义特征都需要投影到全局坐标系中。这里语义特征分类用了窗口，当车移动时，一个区域可能会被观测多次，由于存在分割的噪声，这区域可能会被分为不同的类别。 使用统计过滤噪声。地图被分成许多的网络，当一个语义点进入一个网格，对应的语义标签加1，次数最多的语义代表这个网格。\n\n\n# map merging / updating\n\n为了节省带宽，这里只选择局部地图中被标记的网络进行上传到云端，同理云端的地图也分为若干个网格，局部地图网格中的标签得分也加到全局地图中。这个过程是并行的。\n\n\n# map compression\n\n同样为了节省带宽，这里语义地图的可以被轮廓代表。首先，生成语义图的顶视图图像，每一个像素代表一个网格。其次，提取每一组语义的轮廓。最后，轮廓点存起来，发送到量产车。\n\n\n# map decompression\n\n量产车拿到压缩后的数据后，进行解压：用相同标签的点，填充轮廓。\n\n\n# icp localization\n\n恢复出语义地图后，同上一篇，使用icp方法进行匹配，后端使用ekf融合里程计和视觉定位的信息，进行优化。\n\n\n\n绿色的车当前获取到的语义特征。\n\n实验中，还将语义地图与谷歌地图对齐。",charsets:{cjk:!0}},{title:"theiaSfM代码",frontmatter:{title:"theiaSfM代码",date:"2022-08-30T13:27:20.000Z",permalink:"/pages/169752/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/11.theiaSfM%E4%BB%A3%E7%A0%81.html",relativePath:"02.科研/02.大规模三维重建/11.theiaSfM代码.md",key:"v-6e742411",path:"/pages/169752/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"雷达增强sfm",frontmatter:{title:"雷达增强sfm",date:"2022-07-07T12:47:36.000Z",permalink:"/pages/270f1d/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/08.%E9%9B%B7%E8%BE%BE%E5%A2%9E%E5%BC%BAsfm.html",relativePath:"02.科研/02.大规模三维重建/08.雷达增强sfm.md",key:"v-63fd0ca6",path:"/pages/270f1d/",headers:[{level:3,title:"Correspondence Search",slug:"correspondence-search",normalizedTitle:"correspondence search",charIndex:2},{level:3,title:"Relative Motion Estimation",slug:"relative-motion-estimation",normalizedTitle:"relative motion estimation",charIndex:126}],headersStr:"Correspondence Search Relative Motion Estimation",content:"# Correspondence Search\n\n用OpenMVG中SIFT提取特征，使用cascade hashing method暴力匹配。最后通过两视图几何验证匹配对，其中使用RANSAC估计F矩阵，足够多的特征几何一致性则进一步计算。\n\n\n# Relative Motion Estimation",normalizedContent:"# correspondence search\n\n用openmvg中sift提取特征，使用cascade hashing method暴力匹配。最后通过两视图几何验证匹配对，其中使用ransac估计f矩阵，足够多的特征几何一致性则进一步计算。\n\n\n# relative motion estimation",charsets:{cjk:!0}},{title:"An Efficient and Robust Hybrid SfM Method for Large-Scale Scenes",frontmatter:{title:"An Efficient and Robust Hybrid SfM Method for Large-Scale Scenes",date:"2023-03-31T09:46:15.000Z",permalink:"/pages/24dfc7/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/12.%E6%87%8A%E6%82%94%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%871.html",relativePath:"02.科研/02.大规模三维重建/12.懊悔阅读论文1.md",key:"v-389af7e5",path:"/pages/24dfc7/",headers:[{level:2,title:"图像聚类算法",slug:"图像聚类算法",normalizedTitle:"图像聚类算法",charIndex:2},{level:2,title:"子簇扩展算法",slug:"子簇扩展算法",normalizedTitle:"子簇扩展算法",charIndex:525},{level:2,title:"子簇的稀疏重建",slug:"子簇的稀疏重建",normalizedTitle:"子簇的稀疏重建",charIndex:536},{level:2,title:"子簇合并",slug:"子簇合并",normalizedTitle:"子簇合并",charIndex:548}],headersStr:"图像聚类算法 子簇扩展算法 子簇的稀疏重建 子簇合并",content:"# 图像聚类算法\n\n构建图，计算图中的边权值，使用归一化隔来完成图像划分。\n\n把整个图G={V,E} 划分为 {Gk∣Gk={Vk,Ek}}。\n\n现有方法的边的权重\n\nwpij=pnummin( feati, featj)\n\n其中 feati,featj 是每个图像对 i,j 的特征点数，pnum是与图像对同源点的点数。一般认为wpij越大，图像对之间的相关性越强。如果仅使用具有同源点的点数来计算边缘权重，则空间距离较远的弱连接图像对可能被划分为同一子簇，而空间距离较短但点数相对较少的图像对具有同源点可能被划分到不同的子簇中，导致子簇内图像的空间分布松散甚至碎片化。\n\n改进\n\n引入图像对的重叠区域、场景相关度信息、具有同源点的点数构造新的权重函数w(Eij)。\n\n * 图像对的重叠区域是图像空间中两个图像捕获的相同地面区域的表示。如果一个图像对的重叠面积很小，则认为该图像对更可能是弱连通的。\n * 图像的公共邻域数表示图像对中两幅图像的邻域集中具有相同ID的图像的数量。共同邻居的数量越多，图像对就越有可能是强连接的。\n * 图像对中具有同源点的点数表示两幅图像中匹配特征点的数量，具有同源点的点越多，两幅图像之间的相关性越强。\n\n\n# 子簇扩展算法\n\n\n# 子簇的稀疏重建\n\n\n# 子簇合并",normalizedContent:"# 图像聚类算法\n\n构建图，计算图中的边权值，使用归一化隔来完成图像划分。\n\n把整个图g={v,e} 划分为 {gk∣gk={vk,ek}}。\n\n现有方法的边的权重\n\nwpij=pnummin( feati, featj)\n\n其中 feati,featj 是每个图像对 i,j 的特征点数，pnum是与图像对同源点的点数。一般认为wpij越大，图像对之间的相关性越强。如果仅使用具有同源点的点数来计算边缘权重，则空间距离较远的弱连接图像对可能被划分为同一子簇，而空间距离较短但点数相对较少的图像对具有同源点可能被划分到不同的子簇中，导致子簇内图像的空间分布松散甚至碎片化。\n\n改进\n\n引入图像对的重叠区域、场景相关度信息、具有同源点的点数构造新的权重函数w(eij)。\n\n * 图像对的重叠区域是图像空间中两个图像捕获的相同地面区域的表示。如果一个图像对的重叠面积很小，则认为该图像对更可能是弱连通的。\n * 图像的公共邻域数表示图像对中两幅图像的邻域集中具有相同id的图像的数量。共同邻居的数量越多，图像对就越有可能是强连接的。\n * 图像对中具有同源点的点数表示两幅图像中匹配特征点的数量，具有同源点的点越多，两幅图像之间的相关性越强。\n\n\n# 子簇扩展算法\n\n\n# 子簇的稀疏重建\n\n\n# 子簇合并",charsets:{cjk:!0}},{title:"EC-SfM, Efficient Covisibility-based Structure-from-Motion for Both Sequential and Unordered Images",frontmatter:{title:"EC-SfM, Efficient Covisibility-based Structure-from-Motion for Both Sequential and Unordered Images",date:"2023-03-31T11:02:32.000Z",permalink:"/pages/f9d90b/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/14.%20%E6%87%8A%E6%82%94%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%873.html",relativePath:"02.科研/02.大规模三维重建/14. 懊悔阅读论文3.md",key:"v-39371ab4",path:"/pages/f9d90b/",headersStr:null,content:"对于无序的 Internet 图像，由于缺乏关于图像重叠的先验知识，SfM 非常慢。\n\n对于序列图像，知道相邻帧之间的大重叠，SfM 可以采用多种加速策略，这些策略仅适用于序列数据。\n\n为了进一步提高重建效率并打破这两种数据之间的策略差距，本文提出了一种基于协同可见性的高效增量SfM。与以前的方法不同，我们利用共视性和注册依赖性来描述适用于任何类型数据的图像连接。\n\n基于这种通用图像连接，我们提出了一个统一的框架来有效地重建序列图像、无序图像以及这两者的混合图像。对无序图像和混合数据的实验验证了所提出方法的有效性，该方法在特征匹配方面比现有技术快三倍，在不牺牲准确性的情况下重建速度快一个数量级。",normalizedContent:"对于无序的 internet 图像，由于缺乏关于图像重叠的先验知识，sfm 非常慢。\n\n对于序列图像，知道相邻帧之间的大重叠，sfm 可以采用多种加速策略，这些策略仅适用于序列数据。\n\n为了进一步提高重建效率并打破这两种数据之间的策略差距，本文提出了一种基于协同可见性的高效增量sfm。与以前的方法不同，我们利用共视性和注册依赖性来描述适用于任何类型数据的图像连接。\n\n基于这种通用图像连接，我们提出了一个统一的框架来有效地重建序列图像、无序图像以及这两者的混合图像。对无序图像和混合数据的实验验证了所提出方法的有效性，该方法在特征匹配方面比现有技术快三倍，在不牺牲准确性的情况下重建速度快一个数量级。",charsets:{cjk:!0}},{title:"A Simple and Efficient Merge of Two Sparse 3D Models with Overlapped Images",frontmatter:{title:"A Simple and Efficient Merge of Two Sparse 3D Models with Overlapped Images",date:"2023-03-31T11:00:10.000Z",permalink:"/pages/7387ee/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/13.%20%E6%87%8A%E6%82%94%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%872.html",relativePath:"02.科研/02.大规模三维重建/13. 懊悔阅读论文2.md",key:"v-7e805f34",path:"/pages/7387ee/",headersStr:null,content:"方法\n\n首先，根据从重叠图像重新投影的 3D 点计算两个模型之间的全局相似性变换矩阵。\n\n之后，重叠图像的相机参数和一个模型中的重新投影的 3D 点使用获得的全局相似性变换矩阵进行细化。\n\n最后，根据内部 2D-3D 对应估计两个 3D 模型之间的精确相似性变换矩阵，以准确对齐和合并两个 3D 模型。\n\n对比\n\n常见的稀疏 3D 模型合并方法将相似变换矩阵估计技术之一与 RANSAC 相结合。\n\n然而，一个重要的问题是，如果模型对齐偏向重叠区域中的某些部分，则合并后的模型可能会出现全局对齐错误。\n\n改进\n\n所提出的方法首先计算全局相似变换矩阵以减少全局未对齐问题。使用获得的全局相似性变换矩阵，所提出的方法细化了子模型的重叠区域。由于重叠区域的细化过程，可以更准确地对齐两个子模型。所提出的方法计算精确的相似变换矩阵并合并两个子模型。\n\n\n\n给定两个具有重叠图像和2D-3D对应关系的子模型，提出的方法\n\n * （a）计算子模型1和2的重新投入误差的平均值，\n * （b）计算重叠区域之间的全局相似性转换矩阵\n * （C ）使用全局相似性变换矩阵来完善子模型M1中的重叠区域，并且\n * （d）计算重叠区域之间的精确相似性转换矩阵，并合并两个子模型。\n\n给定两个稀疏3D模型M1,M2，具有重叠区域(R)M1，(R)M2，由已知的 2D-3D 对应关系和相机参数 {Pi}M1 和 { Pi}M2 的共享图像 {Ii}，所提出的方法执行以下过程\n\nStep1. 计算每个子模型的重叠区域的重投影误差的平均值，假设(R)M2的重投影误差均值低于(R)M1的\n\nStep2. 使用RANSAC筛选3D点来计算全局相似变换Tg，所选择3D内点Xj满足以下约束\n\n i) 1Tj{(xji−PiTg−1(Xj)M2)M12+(xji−PiTg(Xj)M1)M22}≤rthres ii) Tj≥Tthres\n\n其中Tj为Xj对应的track 长度，本文设置rthres=6, Tthres = 5。有了3D内点，应用方法[7]计算从M1到M2的全局相似变换Tg。\n\nStep3. 将M1中的Ii的相机参数PiM1替换为PiTgM2 ，然后将具有2D-3D对应关系的相机参数PiTgM2 的局部BA应用到M1。\n\nStep4. 选择内点2D-3D对应关系获得精确的相似变换矩阵Tm，内点(xji,Xj) 满足上述的i,ii，以及下面的条件\n\nmini{(xji−PiXj)M12+(xji−PiXj)M22}\n\n在选择完内点后，应用[5]来计算从M1到M2的精确相似变换矩阵Tm，来执行两个子模型M1和M2的合并过程。",normalizedContent:"方法\n\n首先，根据从重叠图像重新投影的 3d 点计算两个模型之间的全局相似性变换矩阵。\n\n之后，重叠图像的相机参数和一个模型中的重新投影的 3d 点使用获得的全局相似性变换矩阵进行细化。\n\n最后，根据内部 2d-3d 对应估计两个 3d 模型之间的精确相似性变换矩阵，以准确对齐和合并两个 3d 模型。\n\n对比\n\n常见的稀疏 3d 模型合并方法将相似变换矩阵估计技术之一与 ransac 相结合。\n\n然而，一个重要的问题是，如果模型对齐偏向重叠区域中的某些部分，则合并后的模型可能会出现全局对齐错误。\n\n改进\n\n所提出的方法首先计算全局相似变换矩阵以减少全局未对齐问题。使用获得的全局相似性变换矩阵，所提出的方法细化了子模型的重叠区域。由于重叠区域的细化过程，可以更准确地对齐两个子模型。所提出的方法计算精确的相似变换矩阵并合并两个子模型。\n\n\n\n给定两个具有重叠图像和2d-3d对应关系的子模型，提出的方法\n\n * （a）计算子模型1和2的重新投入误差的平均值，\n * （b）计算重叠区域之间的全局相似性转换矩阵\n * （c ）使用全局相似性变换矩阵来完善子模型m1中的重叠区域，并且\n * （d）计算重叠区域之间的精确相似性转换矩阵，并合并两个子模型。\n\n给定两个稀疏3d模型m1,m2，具有重叠区域(r)m1，(r)m2，由已知的 2d-3d 对应关系和相机参数 {pi}m1 和 { pi}m2 的共享图像 {ii}，所提出的方法执行以下过程\n\nstep1. 计算每个子模型的重叠区域的重投影误差的平均值，假设(r)m2的重投影误差均值低于(r)m1的\n\nstep2. 使用ransac筛选3d点来计算全局相似变换tg，所选择3d内点xj满足以下约束\n\n i) 1tj{(xji−pitg−1(xj)m2)m12+(xji−pitg(xj)m1)m22}≤rthres ii) tj≥tthres\n\n其中tj为xj对应的track 长度，本文设置rthres=6, tthres = 5。有了3d内点，应用方法[7]计算从m1到m2的全局相似变换tg。\n\nstep3. 将m1中的ii的相机参数pim1替换为pitgm2 ，然后将具有2d-3d对应关系的相机参数pitgm2 的局部ba应用到m1。\n\nstep4. 选择内点2d-3d对应关系获得精确的相似变换矩阵tm，内点(xji,xj) 满足上述的i,ii，以及下面的条件\n\nmini{(xji−pixj)m12+(xji−pixj)m22}\n\n在选择完内点后，应用[5]来计算从m1到m2的精确相似变换矩阵tm，来执行两个子模型m1和m2的合并过程。",charsets:{cjk:!0}},{title:"Graph-based parallel large scale structure from motion",frontmatter:{title:"Graph-based parallel large scale structure from motion",date:"2023-03-31T12:00:29.000Z",permalink:"/pages/696f8f/"},regularPath:"/02.%E7%A7%91%E7%A0%94/02.%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/15.%20%E6%87%8A%E6%82%94%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%874.html",relativePath:"02.科研/02.大规模三维重建/15. 懊悔阅读论文4.md",key:"v-18245398",path:"/pages/696f8f/",headersStr:null,content:"通过利用图结构，我们能够以分而治之的方式处理大规模数据集。\n\n首先，将图像建模为图节点，在特征匹配后从几何信息中检索边。\n\n然后通过图像聚类算法将图像划分为独立的簇，然后进行子图扩展步骤，通过沿着最大生成树行走来增强场景的连接性和完整性，用于构造簇之间的重叠图像。\n\n其次，将图像集群分布到服务器中以并行模式执行 SfM。\n\n第三，在局部重建完成后，我们构造一个最小生成树来找到准确的相似变换。\n\n然后将最小生成树转化为最小高度树以找到合适的锚节点，并进一步用于防止错误累积。",normalizedContent:"通过利用图结构，我们能够以分而治之的方式处理大规模数据集。\n\n首先，将图像建模为图节点，在特征匹配后从几何信息中检索边。\n\n然后通过图像聚类算法将图像划分为独立的簇，然后进行子图扩展步骤，通过沿着最大生成树行走来增强场景的连接性和完整性，用于构造簇之间的重叠图像。\n\n其次，将图像集群分布到服务器中以并行模式执行 sfm。\n\n第三，在局部重建完成后，我们构造一个最小生成树来找到准确的相似变换。\n\n然后将最小生成树转化为最小高度树以找到合适的锚节点，并进一步用于防止错误累积。",charsets:{cjk:!0}},{title:"EF论文理解",frontmatter:{title:"EF论文理解",date:"2022-03-26T11:01:06.000Z",permalink:"/pages/c6a110/"},regularPath:"/02.%E7%A7%91%E7%A0%94/01.%E5%AE%A4%E5%86%85%E5%AE%9E%E6%97%B6%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/02.EF%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3.html",relativePath:"02.科研/01.室内实时三维重建/02.EF论文理解.md",key:"v-372327de",path:"/pages/c6a110/",headers:[{level:2,title:"系统概述",slug:"系统概述",normalizedTitle:"系统概述",charIndex:2},{level:2,title:"融合预测跟踪",slug:"融合预测跟踪",normalizedTitle:"融合预测跟踪",charIndex:867},{level:3,title:"几何位姿估计",slug:"几何位姿估计",normalizedTitle:"几何位姿估计",charIndex:1432},{level:3,title:"亮度位姿估计",slug:"亮度位姿估计",normalizedTitle:"亮度位姿估计",charIndex:1622},{level:3,title:"联合优化",slug:"联合优化",normalizedTitle:"联合优化",charIndex:1772},{level:2,title:"变形图",slug:"变形图",normalizedTitle:"变形图",charIndex:2073},{level:3,title:"构造",slug:"构造",normalizedTitle:"构造",charIndex:2550},{level:3,title:"应用",slug:"应用",normalizedTitle:"应用",charIndex:2690},{level:3,title:"优化",slug:"优化",normalizedTitle:"优化",charIndex:1774},{level:2,title:"局部回环",slug:"局部回环",normalizedTitle:"局部回环",charIndex:827},{level:2,title:"全局回环",slug:"全局回环",normalizedTitle:"全局回环",charIndex:400},{level:2,title:"全局回环代码部分",slug:"全局回环代码部分",normalizedTitle:"全局回环代码部分",charIndex:4768}],headersStr:"系统概述 融合预测跟踪 几何位姿估计 亮度位姿估计 联合优化 变形图 构造 应用 优化 局部回环 全局回环 全局回环代码部分",content:"# 系统概述\n\n我们采取主流的稠密SLAM系统那样tracking 和 mapping 的结构，主要使用CUDA来实现tracking部分，OpenGL Shading语言来实现地图预测和管理。我们的方法可以实时的使用标准的RGB-D相机来估计一个环境的稠密3D地图，下面为我们方法的关键部分。\n\n>  1. 受到参考文献9的启发， 我们基于融合面元的模型来估计一个环境。\n> \n>  2. 当在最近经常观察的区域（active area）进行跟踪和数据融合时，将超过δt时间没有被观察到的区域转成inactive area，且这一部分不用来跟踪和数据融合。\n> \n>  3. 每一帧都尝试将当前估计的相机帧内的活动模型部分与位于同一帧内的非活动模型部分进行配准，如果配准成功，那么当前帧就与旧的不活跃的模型形成回环，然后整个模型将会非刚性变换，这旧的不活跃的模型将重新激活。\n> \n>  4. 对于全局回环检测，添加场景的预测视图到一个随机数据库中，每一帧都通过这个数据库来找匹配的预测视图。如果检测到匹配，将视图配准到一起，并检查这一次配准是否与模型的集合形状全局一致，如果是，在地图中用非刚性变换来反映这个配准，并且将它全局对齐。\n\n\n\n用有颜色的表面来表示活跃的模型，灰色区域表示非活跃的模型。\n\n 1.  初始时，所有的数据都是活跃模型，并且向左探索；\n\n 2.  随着时间推移，最近观察不到的区域被设置为非活跃状态；\n\n 3.  相机重新观察到了之前非活跃的区域，形成闭环并且配准表面，之前非活跃的区域重新激活；\n\n 4.  相机继续向右探索，形成了更多的闭环；\n\n 5.  继续探索新的区域；\n\n 6.  相机重新访问到非活跃的区域，但出现了漂移；\n\n 7.  说明图6的漂移不对齐，这里的红色箭头是活跃区域的点指向非活跃区域的点，这两点是等价的；\n\n 8.  一次全局闭环触发，对齐活跃与非活跃模型；\n\n 9.  继续向右探索，形成更多的局部回环，跟更多非活跃区域重新激活；\n\n 10. 最终全部地图着色？？\n\n\n# 融合预测跟踪\n\n我们的场景表示是一个无序列表的surfels Ms ，（与文献9的表示方式类似）\n\n点的位置信息法向量颜色信息权重面片的半径点的获取时间信息{p∈R3,点的位置信息n∈R3,法向量c∈N3,颜色信息(R,G,B)w∈R, 权重r∈R,  面片的半径t,点的获取时间信息\n\n然而，当使用地图进行姿态估计时，我们的方法有两个不同之处\n\n1. 不是仅通过用于几何帧到模型跟踪的碎片渲染来预测深度图，我们还预测模型面的全彩色碎片渲染以执行光度帧到模型跟踪；\n\n2. 我们定义了一个时间窗口阈值 δt，它将 M 划分为活跃和不活跃的面元。 只有标记为活动模型面元的面元才用于相机姿态估计和深度图融合。 当 M 中的一个面元自上次更新（即具有与其关联的原始深度测量以进行融合）以来的时间大于 δt 时，该面元被声明为非活动状态。\n\n我们描述了我们的联合光度和几何姿态估计的方法，这些方法来自一个的面元预测。\n\n我们定义图片域是Ω⊂N2, 深度图，像素，颜色...对每一张深度图计算法线图。p(u,D)=K−1vd(u), v是u的齐次形式，d(u)是u的深度。对于时间t的每个输入帧，我们通过当前实时输入的深度图和彩色图，与前一个位姿的活跃模型的预测深度图和彩色图，配准，来估计相机的位姿，这里的位姿用李群T来表示。\n\n\n# 几何位姿估计\n\n在当前实时深度图Dtl 与 来自最后一帧 Dt−1a 的预测的活动深度图模型之间，我们旨在找一个ξ 使得最小化投影误差。\n\nEicp=∑k((vk−exp⁡(ξ^)Tvtk)⋅nk)2\n\n其中，vtk是在Dtl中第k个顶点的相机坐标，vk和nk是上一时刻对应顶点的相机坐标和法线。T是从前一个相机位姿到当前位姿变换的估计，（exp⁡(ξ^)是一个增量）。\n\n\n# 亮度位姿估计\n\n在当前实时的颜色图Ctl 和 上一时刻 C^t−1a 的预测活跃颜色模型之间，我们旨在找一个ξ 使得亮度误差最小。\n\n，Ergb=∑u∈Ω(I(u,Ctl)−I(π(Kexp⁡(ξ^)Tp(u,Dtl)，C^t−1a)2\n\n这里的 T 同上，注意这里的 p 存在维数的变换。\n\n\n# 联合优化\n\nEtrack=Eicp+wrgbErgb\n\n我们使用高斯牛顿法非线性最小二乘法 与 三层金字塔 来优化该目标函数。为了解决每次迭代，我们计算最小二乘解\n\nargminξ‖Jξ+r‖2\n\n产生改进的相机变换估计\n\nT′=exp⁡(ξ^)Tξ^=[[w]×x0000]\n\n可以填充组合测量雅克比矩阵 J 和残差 r 的块（同时根据 wrgb 进行加权）并使用高度并行的树缩减 CUDA 求解以生成 6×6 法线方程组，然后由 Cholesky 在 CPU 上分解得到 ξ ，这个过程的结果是最新的相机位姿估计pt=TPt−1 ，它使得实时相机 Dtl 和 Ctl 当前活跃模型强对齐。\n\n\n# 变形图\n\n为了确保地图中的局部和全局表面一致性，我们在面元 M 集合中反映了成功的表面环闭合，这是通过闭环提供的表面约束对所有面元（活跃和非活跃）进行非刚性变换。我们采用嵌入变形技术的空间变形方法。\n\n变形图由分布在要变形的模型中的一组节点和边组成。每个节点Gn有，时间戳Gt0n，位置Ggn和一组邻居节点N(Gn)，放射变换GRn和Gtn，每个节点的邻居构成了图的（有向）边，一般邻居个数为4。\n\n面元的变形后的位置由下式给出\n\nM^ps=ϕ(Ms)=∑n∈I(Ms,G)wn(Ms)[GRn(Mps−Ggn)+Ggn+Gtn]\n\n面元变形后的法线由下式给出\n\nM^ns=∑n∈I(Ms,G)wn(Ms)GRn−1⊤Mns\n\n其中 ωn(Ms) 是一个标量，表示节点Gn对面元Ms的影响，当 n = k 时，总和为 1。\n\nwn(Ms)=(1−‖Mps−Ggn‖2/dmax)2\n\n这里dmax 是到Ms的 k + 1 - 最近节点的欧几里得距离。\n\n在下文中，我们描述了我们从一组面元 M 中采样变形图 G的方法以及我们确定图连通性的方法。\n\n\n# 构造\n\n每次初始化新的 Deformation Graph，每次初始化新的 Deformation Graph 要比保持更新同一个 graph 计算量小而且还要简单可行。初始时，从面元中系统抽样（均匀分布）节点，节点的位置和时间戳，都为面元的位置和时间戳。(后面的不懂)\n\n\n# 应用\n\n为了应用优化后的变形图（在下一节中详细说明）来更新地图，必须确定影响每个面元Ms的节点集。算法 1 中列出了实现 I(M s , G) 并将变形图 G 应用于给定面元的算法。当每个面元变形时，会在整个变形节点集合中搜索时间上最近的节点。这个 L 1 -范数最小化的解决方案实际上是对集合 G 的二分搜索，因为它已经是有序的。 从这里开始，收集时间上附近的其他节点，并选择最近的 k 个节点（在欧几里德距离意义上）作为 I(M s , G)。最后，每个节点的权重按照公式 10 计算，并应用公式 8 和 9 的变换。 更新后的面元 M̂ s 的所有其他属性均从 M s 复制。\n\n算法1描述为：\n\n>   \t1.  $\\alpha$ number of nodes to explore;\n>   \t2.  Find closest node in time;\n>   \t3.  Gather set of temporally nearby nodes $-\\alpha/2$  to  $\\alpha/2$ ;\n>   \t4.  Take closest k as influencing nodes;\n>   \t5.  Compute weights;\n>   \t6.  Apply transformations.\n\n\n# 优化\n\n给定一组表面对应 Q，可以优化变形图的参数以反映表面模型 M 中的表面配准。以下定义四个损失函数\n\n第一个最大化变形刚度：\n\nErot=∑l‖GRl⊤GRl−I‖F2\n\n使用 Frobenius 范数。 第二个是正则化项，可确保整个图的平滑变形：\n\nEreg =∑l∑n∈N(Gl)‖GRl(Ggn−Ggl)+Ggl+Gtl−(Ggn+Gtn)‖22\n\n第三个是最小化位置约束 Q 上的误差的约束项：\n\nEcon=∑p‖ϕ(Qsp)−Qdp‖22\n\n这些表面可以多次通过非刚性变形对齐，从而将新的数据融合到地图中已经访问过的区域。最后的误差函数保证非活跃区域固定，将活跃区域变形到非活跃区域的坐标系中：\n\nEpin=∑p‖ϕ(Qdp)−Qdp‖22\n\n最终的损失函数为：\n\nEdef=wrotErot+wregEreg+wconEcon+wconEpin\n\n我们使用高斯牛顿法迭代算误差函数最小的R和t，这个问题的雅克比矩阵是稀疏的，因此我们使用Cholesky分解来使有效地解决CPU系统上的问题。这里变形图使用GPU来计算，应用到整个表面贴图。\n\n\n# 局部回环\n\n为了确保整个地图的局部表面一致性，我们的系统在重新访问这些区域时会形成很多小的回环，我们融合到模型的活动区域，同时逐渐将一段时间内未出现的面元标记为不活动。非活跃区域不参与跟踪和融合过程，直到在活跃区域和非活跃区域形成回环，匹配到的非活跃区域中的点转变称活跃。\n\n将地图中的一组面元分为活跃区域和非活跃区域，如果全局回环检测没有检测到，那么就尝试计算这两个区域的匹配度。\n\n验证这次匹配是否有质量，最后添加一个条件，要让Etrack足够小，同时还要检查海森矩阵的特征值要小于一个阈值。\n\n如果实现了高质量的对齐，我们会生成一组表面约束Q，将他输入到上面优化过程中，进行对齐。我们均匀地采样一组像素坐标 U ⊂ Ω 来计算集合 Q。对于每个像素 u ∈ U 我们填充一个约束：\n\nQp=((HPt)p(u,Dta);Ptp(u,Dta);Tti(u);t)\n\n变形发生后，新的最新相机位姿解析为 P̂ t = HP t 。此时，作为对齐一部分的一组面元被重新激活，以允许实时摄像机跟踪并与现有的活动面元融合。活动模型深度的最新预测必须渲染以反映非活动面的深度测试的变形， 对于每个面元 M s ：\n\nMts={t if π(KP^t−1Mps)∈Ω and (KP^t−1Mps)z≲D~ta(π(KP^t−1Mps))Mts else. \n\n本节中描述的过程使模型的活动区域与模型的非活动区域紧密对齐，以实现紧密的局部表面环闭合。活动模型与非活动模型漂移太远，导致局部对齐无法收敛。我们采用基于外观的全局闭环方法来引导表面变形它将活动模型与底层非活动模型重新对齐，以获得紧密的全局闭环和表面全局一致性。\n\n\n# 全局回环\n\n我们利用Fern编码方法进行基于外观的位置识别，Ferns 将 RGB-D 图像编码为一串代码，由一组固定像素位置中每个 RGB-D 通道的二进制测试值组成。和上面一样，如果匹配成功，添加一组表面约束Q作为变形的输入，其中u是一个随机采样的Fern编码的像素位置：\n\nQp=((HEPi)p(u,Dta);Ptp(u,Dta);Eti;t)\n\n这里的回环也需要进行检验Econ，这里的变形不修改活跃和非活跃面元组。正确的全局闭环使地图的活动和非活动区域足够接近对齐，以在下一帧触发局部闭环，并且这允许地图从可能不正确的全局闭环中恢复。如果相机跟踪失败，我们还可以选择依赖Fern编码数据库进行全局重新定位。\n\n\n# 全局回环代码部分\n\n// 随机初始化 Ferns 的位置，像素通道和阈值大小\nvoid Ferns::generateFerns()\n{\n    for(int i = 0; i < num; i++)\n    {\n        Fern f;\n\n        //随机初始化 Fern 的位置\n        f.pos(0) = widthDist(random);\n        f.pos(1) = heightDist(random);\n\n        // 随机初始化每个通道的阈值\n        f.rgbd(0) = rgbDist(random);\n        f.rgbd(1) = rgbDist(random);\n        f.rgbd(2) = rgbDist(random);\n        f.rgbd(3) = dDist(random);\n\n        conservatory.push_back(f);\n    }\n}\n\n\n//新输入的帧和以前帧进行比较，如果相似度小于一定阈值，则将当前帧插入作为回环检测的关键帧\nbool Ferns::addFrame(GPUTexture * imageTexture, GPUTexture * vertexTexture, GPUTexture * normalTexture, const Eigen::Matrix4f & pose, int srcTime, const float threshold)\n{\n    Img<Eigen::Matrix<unsigned char, 3, 1>> img(height, width);\n    Img<Eigen::Vector4f> verts(height, width);\n    Img<Eigen::Vector4f> norms(height, width);\n\n    resize.image(imageTexture, img);\n    resize.vertex(vertexTexture, verts);\n    resize.vertex(normalTexture, norms);\n\n    Frame * frame = new Frame(num,\n                              frames.size(),\n                              pose,\n                              srcTime,\n                              width * height,\n                              (unsigned char *)img.data,\n                              (Eigen::Vector4f *)verts.data,\n                              (Eigen::Vector4f *)norms.data);\n\n    int * coOccurrences = new int[frames.size()];\n\n    memset(coOccurrences, 0, sizeof(int) * frames.size());\n\n    for(int i = 0; i < num; i++)\n    {\n        unsigned char code = badCode;\n\n        if(verts.at<Eigen::Vector4f>(conservatory.at(i).pos(1), conservatory.at(i).pos(0))(2) > 0)\n        {\n            const Eigen::Matrix<unsigned char, 3, 1> & pix = img.at<Eigen::Matrix<unsigned char, 3, 1>>(conservatory.at(i).pos(1), conservatory.at(i).pos(0));\n\n            //随机选取像素点处的编码\n            code = (pix(0) > conservatory.at(i).rgbd(0)) << 3 |\n                   (pix(1) > conservatory.at(i).rgbd(1)) << 2 |\n                   (pix(2) > conservatory.at(i).rgbd(2)) << 1 |\n                   (int(verts.at<Eigen::Vector4f>(conservatory.at(i).pos(1), conservatory.at(i).pos(0))(2) * 1000.0f) > conservatory.at(i).rgbd(3));\n\n            frame->goodCodes++;\n\n            // 计算和以前存储帧之间的相似度\n            for(size_t j = 0; j < conservatory.at(i).ids[code].size(); j++)\n            {\n                coOccurrences[conservatory.at(i).ids[code].at(j)]++;\n            }\n        }\n\n        frame->codes[i] = code;\n    }\n\n    float minimum = std::numeric_limits<float>::max();\n\n    if(frame->goodCodes > 0)\n    {\n        for(size_t i = 0; i < frames.size(); i++)\n        {\n            float maxCo = std::min(frame->goodCodes, frames.at(i)->goodCodes);\n\n            float dissim = (float)(maxCo - coOccurrences[i]) / (float)maxCo;\n\n            if(dissim < minimum)\n            {\n                minimum = dissim;\n            }\n        }\n    }\n\n    delete [] coOccurrences;\n\n    if((minimum > threshold || frames.size() == 0) && frame->goodCodes > 0)\n    {\n        for(int i = 0; i < num; i++)\n        {\n            if(frame->codes[i] != badCode)\n            {\n                //conservatory 存储关系：第一层 fern 的编号，第二层 code 的编号，第三层图像帧的编号\n                conservatory.at(i).ids[frame->codes[i]].push_back(frame->id);\n            }\n        }\n\n        frames.push_back(frame);\n\n        return true;\n    }\n    else\n    {\n        delete frame;\n\n        return false;\n    }\n}\n\n\n// 对于输入的图像进行全局的回环检测，通过判断和以前存储的帧编码相似度，判断当前帧是否作为关键帧\nEigen::Matrix4f Ferns::findFrame(std::vector<SurfaceConstraint> & constraints,\n                                 const Eigen::Matrix4f & currPose,\n                                 GPUTexture * vertexTexture,\n                                 GPUTexture * normalTexture,\n                                 GPUTexture * imageTexture,\n                                 const int time,\n                                 const bool lost)\n{\n    lastClosest = -1;\n\n    Img<Eigen::Matrix<unsigned char, 3, 1>> imgSmall(height, width);\n    Img<Eigen::Vector4f> vertSmall(height, width);\n    Img<Eigen::Vector4f> normSmall(height, width);\n\n    //对输入图像降采样 8X8 倍\n    resize.image(imageTexture, imgSmall);\n    resize.vertex(vertexTexture, vertSmall);\n    resize.vertex(normalTexture, normSmall);\n\n    Frame * frame = new Frame(num, 0, Eigen::Matrix4f::Identity(), 0, width * height);\n\n    int * coOccurrences = new int[frames.size()];\n\n    memset(coOccurrences, 0, sizeof(int) * frames.size());\n\n    for(int i = 0; i < num; i++)\n    {\n        unsigned char code = badCode;\n\n        if(vertSmall.at<Eigen::Vector4f>(conservatory.at(i).pos(1), conservatory.at(i).pos(0))(2) > 0)\n        {\n            const Eigen::Matrix<unsigned char, 3, 1> & pix = imgSmall.at<Eigen::Matrix<unsigned char, 3, 1>>(conservatory.at(i).pos(1), conservatory.at(i).pos(0));\n\n            //指定像素点处做编码\n            code = (pix(0) > conservatory.at(i).rgbd(0)) << 3 |\n                   (pix(1) > conservatory.at(i).rgbd(1)) << 2 |\n                   (pix(2) > conservatory.at(i).rgbd(2)) << 1 |\n                   (int(vertSmall.at<Eigen::Vector4f>(conservatory.at(i).pos(1), conservatory.at(i).pos(0))(2) * 1000.0f) > conservatory.at(i).rgbd(3));\n\n            frame->goodCodes++;\n\n            // conservatory.at(i) 表示第 i 个 fern 总共随机采样了 num 个\n            // conservatory.at(i).ids[code] 表示第 i 个 fern 编码值为 code 的 vector\n            // conservatory.at(i).ids[code].at(j) 值表示第 at(j) 帧图像\n            for(size_t j = 0; j < conservatory.at(i).ids[code].size(); j++)\n            {\n                // coOccurrences[conservatory.at(i).ids[code].at(j)] 表示和第 conservatory.at(i).ids[code].at(j) 帧图像的相似度\n                coOccurrences[conservatory.at(i).ids[code].at(j)]++;\n            }\n        }\n\n        frame->codes[i] = code;\n    }\n\n    float minimum = std::numeric_limits<float>::max();\n    int minId = -1;\n\n    //在所有帧中找相似度最小的帧\n    for(size_t i = 0; i < frames.size(); i++)\n    {\n        float maxCo = std::min(frame->goodCodes, frames.at(i)->goodCodes);\n\n        float dissim = (float)(maxCo - coOccurrences[i]) / (float)maxCo;\n\n        if(dissim < minimum && time - frames.at(i)->srcTime > 300)\n        {\n            minimum = dissim;\n            minId = i;\n        }\n    }\n\n\n//根据图像的编码计算两帧之间的相似度\nfloat Ferns::blockHDAware(const Frame * f1, const Frame * f2)\n{\n    int count = 0;\n    float val = 0;\n\n    for(int i = 0; i < num; i++)\n    {\n        if(f1->codes[i] != badCode && f2->codes[i] != badCode)\n        {\n            count++;\n\n            if(f1->codes[i] == f2->codes[i])\n            {\n                val += 1.0f;\n            }\n        }\n    }\n\n    return val / (float)count;\n}\n",normalizedContent:"# 系统概述\n\n我们采取主流的稠密slam系统那样tracking 和 mapping 的结构，主要使用cuda来实现tracking部分，opengl shading语言来实现地图预测和管理。我们的方法可以实时的使用标准的rgb-d相机来估计一个环境的稠密3d地图，下面为我们方法的关键部分。\n\n>  1. 受到参考文献9的启发， 我们基于融合面元的模型来估计一个环境。\n> \n>  2. 当在最近经常观察的区域（active area）进行跟踪和数据融合时，将超过δt时间没有被观察到的区域转成inactive area，且这一部分不用来跟踪和数据融合。\n> \n>  3. 每一帧都尝试将当前估计的相机帧内的活动模型部分与位于同一帧内的非活动模型部分进行配准，如果配准成功，那么当前帧就与旧的不活跃的模型形成回环，然后整个模型将会非刚性变换，这旧的不活跃的模型将重新激活。\n> \n>  4. 对于全局回环检测，添加场景的预测视图到一个随机数据库中，每一帧都通过这个数据库来找匹配的预测视图。如果检测到匹配，将视图配准到一起，并检查这一次配准是否与模型的集合形状全局一致，如果是，在地图中用非刚性变换来反映这个配准，并且将它全局对齐。\n\n\n\n用有颜色的表面来表示活跃的模型，灰色区域表示非活跃的模型。\n\n 1.  初始时，所有的数据都是活跃模型，并且向左探索；\n\n 2.  随着时间推移，最近观察不到的区域被设置为非活跃状态；\n\n 3.  相机重新观察到了之前非活跃的区域，形成闭环并且配准表面，之前非活跃的区域重新激活；\n\n 4.  相机继续向右探索，形成了更多的闭环；\n\n 5.  继续探索新的区域；\n\n 6.  相机重新访问到非活跃的区域，但出现了漂移；\n\n 7.  说明图6的漂移不对齐，这里的红色箭头是活跃区域的点指向非活跃区域的点，这两点是等价的；\n\n 8.  一次全局闭环触发，对齐活跃与非活跃模型；\n\n 9.  继续向右探索，形成更多的局部回环，跟更多非活跃区域重新激活；\n\n 10. 最终全部地图着色？？\n\n\n# 融合预测跟踪\n\n我们的场景表示是一个无序列表的surfels ms ，（与文献9的表示方式类似）\n\n点的位置信息法向量颜色信息权重面片的半径点的获取时间信息{p∈r3,点的位置信息n∈r3,法向量c∈n3,颜色信息(r,g,b)w∈r, 权重r∈r,  面片的半径t,点的获取时间信息\n\n然而，当使用地图进行姿态估计时，我们的方法有两个不同之处\n\n1. 不是仅通过用于几何帧到模型跟踪的碎片渲染来预测深度图，我们还预测模型面的全彩色碎片渲染以执行光度帧到模型跟踪；\n\n2. 我们定义了一个时间窗口阈值 δt，它将 m 划分为活跃和不活跃的面元。 只有标记为活动模型面元的面元才用于相机姿态估计和深度图融合。 当 m 中的一个面元自上次更新（即具有与其关联的原始深度测量以进行融合）以来的时间大于 δt 时，该面元被声明为非活动状态。\n\n我们描述了我们的联合光度和几何姿态估计的方法，这些方法来自一个的面元预测。\n\n我们定义图片域是ω⊂n2, 深度图，像素，颜色...对每一张深度图计算法线图。p(u,d)=k−1vd(u), v是u的齐次形式，d(u)是u的深度。对于时间t的每个输入帧，我们通过当前实时输入的深度图和彩色图，与前一个位姿的活跃模型的预测深度图和彩色图，配准，来估计相机的位姿，这里的位姿用李群t来表示。\n\n\n# 几何位姿估计\n\n在当前实时深度图dtl 与 来自最后一帧 dt−1a 的预测的活动深度图模型之间，我们旨在找一个ξ 使得最小化投影误差。\n\neicp=∑k((vk−exp⁡(ξ^)tvtk)⋅nk)2\n\n其中，vtk是在dtl中第k个顶点的相机坐标，vk和nk是上一时刻对应顶点的相机坐标和法线。t是从前一个相机位姿到当前位姿变换的估计，（exp⁡(ξ^)是一个增量）。\n\n\n# 亮度位姿估计\n\n在当前实时的颜色图ctl 和 上一时刻 c^t−1a 的预测活跃颜色模型之间，我们旨在找一个ξ 使得亮度误差最小。\n\n，ergb=∑u∈ω(i(u,ctl)−i(π(kexp⁡(ξ^)tp(u,dtl)，c^t−1a)2\n\n这里的 t 同上，注意这里的 p 存在维数的变换。\n\n\n# 联合优化\n\netrack=eicp+wrgbergb\n\n我们使用高斯牛顿法非线性最小二乘法 与 三层金字塔 来优化该目标函数。为了解决每次迭代，我们计算最小二乘解\n\nargminξ‖jξ+r‖2\n\n产生改进的相机变换估计\n\nt′=exp⁡(ξ^)tξ^=[[w]×x0000]\n\n可以填充组合测量雅克比矩阵 j 和残差 r 的块（同时根据 wrgb 进行加权）并使用高度并行的树缩减 cuda 求解以生成 6×6 法线方程组，然后由 cholesky 在 cpu 上分解得到 ξ ，这个过程的结果是最新的相机位姿估计pt=tpt−1 ，它使得实时相机 dtl 和 ctl 当前活跃模型强对齐。\n\n\n# 变形图\n\n为了确保地图中的局部和全局表面一致性，我们在面元 m 集合中反映了成功的表面环闭合，这是通过闭环提供的表面约束对所有面元（活跃和非活跃）进行非刚性变换。我们采用嵌入变形技术的空间变形方法。\n\n变形图由分布在要变形的模型中的一组节点和边组成。每个节点gn有，时间戳gt0n，位置ggn和一组邻居节点n(gn)，放射变换grn和gtn，每个节点的邻居构成了图的（有向）边，一般邻居个数为4。\n\n面元的变形后的位置由下式给出\n\nm^ps=ϕ(ms)=∑n∈i(ms,g)wn(ms)[grn(mps−ggn)+ggn+gtn]\n\n面元变形后的法线由下式给出\n\nm^ns=∑n∈i(ms,g)wn(ms)grn−1⊤mns\n\n其中 ωn(ms) 是一个标量，表示节点gn对面元ms的影响，当 n = k 时，总和为 1。\n\nwn(ms)=(1−‖mps−ggn‖2/dmax)2\n\n这里dmax 是到ms的 k + 1 - 最近节点的欧几里得距离。\n\n在下文中，我们描述了我们从一组面元 m 中采样变形图 g的方法以及我们确定图连通性的方法。\n\n\n# 构造\n\n每次初始化新的 deformation graph，每次初始化新的 deformation graph 要比保持更新同一个 graph 计算量小而且还要简单可行。初始时，从面元中系统抽样（均匀分布）节点，节点的位置和时间戳，都为面元的位置和时间戳。(后面的不懂)\n\n\n# 应用\n\n为了应用优化后的变形图（在下一节中详细说明）来更新地图，必须确定影响每个面元ms的节点集。算法 1 中列出了实现 i(m s , g) 并将变形图 g 应用于给定面元的算法。当每个面元变形时，会在整个变形节点集合中搜索时间上最近的节点。这个 l 1 -范数最小化的解决方案实际上是对集合 g 的二分搜索，因为它已经是有序的。 从这里开始，收集时间上附近的其他节点，并选择最近的 k 个节点（在欧几里德距离意义上）作为 i(m s , g)。最后，每个节点的权重按照公式 10 计算，并应用公式 8 和 9 的变换。 更新后的面元 m s 的所有其他属性均从 m s 复制。\n\n算法1描述为：\n\n>   \t1.  $\\alpha$ number of nodes to explore;\n>   \t2.  find closest node in time;\n>   \t3.  gather set of temporally nearby nodes $-\\alpha/2$  to  $\\alpha/2$ ;\n>   \t4.  take closest k as influencing nodes;\n>   \t5.  compute weights;\n>   \t6.  apply transformations.\n\n\n# 优化\n\n给定一组表面对应 q，可以优化变形图的参数以反映表面模型 m 中的表面配准。以下定义四个损失函数\n\n第一个最大化变形刚度：\n\nerot=∑l‖grl⊤grl−i‖f2\n\n使用 frobenius 范数。 第二个是正则化项，可确保整个图的平滑变形：\n\nereg =∑l∑n∈n(gl)‖grl(ggn−ggl)+ggl+gtl−(ggn+gtn)‖22\n\n第三个是最小化位置约束 q 上的误差的约束项：\n\necon=∑p‖ϕ(qsp)−qdp‖22\n\n这些表面可以多次通过非刚性变形对齐，从而将新的数据融合到地图中已经访问过的区域。最后的误差函数保证非活跃区域固定，将活跃区域变形到非活跃区域的坐标系中：\n\nepin=∑p‖ϕ(qdp)−qdp‖22\n\n最终的损失函数为：\n\nedef=wroterot+wregereg+wconecon+wconepin\n\n我们使用高斯牛顿法迭代算误差函数最小的r和t，这个问题的雅克比矩阵是稀疏的，因此我们使用cholesky分解来使有效地解决cpu系统上的问题。这里变形图使用gpu来计算，应用到整个表面贴图。\n\n\n# 局部回环\n\n为了确保整个地图的局部表面一致性，我们的系统在重新访问这些区域时会形成很多小的回环，我们融合到模型的活动区域，同时逐渐将一段时间内未出现的面元标记为不活动。非活跃区域不参与跟踪和融合过程，直到在活跃区域和非活跃区域形成回环，匹配到的非活跃区域中的点转变称活跃。\n\n将地图中的一组面元分为活跃区域和非活跃区域，如果全局回环检测没有检测到，那么就尝试计算这两个区域的匹配度。\n\n验证这次匹配是否有质量，最后添加一个条件，要让etrack足够小，同时还要检查海森矩阵的特征值要小于一个阈值。\n\n如果实现了高质量的对齐，我们会生成一组表面约束q，将他输入到上面优化过程中，进行对齐。我们均匀地采样一组像素坐标 u ⊂ ω 来计算集合 q。对于每个像素 u ∈ u 我们填充一个约束：\n\nqp=((hpt)p(u,dta);ptp(u,dta);tti(u);t)\n\n变形发生后，新的最新相机位姿解析为 p t = hp t 。此时，作为对齐一部分的一组面元被重新激活，以允许实时摄像机跟踪并与现有的活动面元融合。活动模型深度的最新预测必须渲染以反映非活动面的深度测试的变形， 对于每个面元 m s ：\n\nmts={t if π(kp^t−1mps)∈ω and (kp^t−1mps)z≲d~ta(π(kp^t−1mps))mts else. \n\n本节中描述的过程使模型的活动区域与模型的非活动区域紧密对齐，以实现紧密的局部表面环闭合。活动模型与非活动模型漂移太远，导致局部对齐无法收敛。我们采用基于外观的全局闭环方法来引导表面变形它将活动模型与底层非活动模型重新对齐，以获得紧密的全局闭环和表面全局一致性。\n\n\n# 全局回环\n\n我们利用fern编码方法进行基于外观的位置识别，ferns 将 rgb-d 图像编码为一串代码，由一组固定像素位置中每个 rgb-d 通道的二进制测试值组成。和上面一样，如果匹配成功，添加一组表面约束q作为变形的输入，其中u是一个随机采样的fern编码的像素位置：\n\nqp=((hepi)p(u,dta);ptp(u,dta);eti;t)\n\n这里的回环也需要进行检验econ，这里的变形不修改活跃和非活跃面元组。正确的全局闭环使地图的活动和非活动区域足够接近对齐，以在下一帧触发局部闭环，并且这允许地图从可能不正确的全局闭环中恢复。如果相机跟踪失败，我们还可以选择依赖fern编码数据库进行全局重新定位。\n\n\n# 全局回环代码部分\n\n// 随机初始化 ferns 的位置，像素通道和阈值大小\nvoid ferns::generateferns()\n{\n    for(int i = 0; i < num; i++)\n    {\n        fern f;\n\n        //随机初始化 fern 的位置\n        f.pos(0) = widthdist(random);\n        f.pos(1) = heightdist(random);\n\n        // 随机初始化每个通道的阈值\n        f.rgbd(0) = rgbdist(random);\n        f.rgbd(1) = rgbdist(random);\n        f.rgbd(2) = rgbdist(random);\n        f.rgbd(3) = ddist(random);\n\n        conservatory.push_back(f);\n    }\n}\n\n\n//新输入的帧和以前帧进行比较，如果相似度小于一定阈值，则将当前帧插入作为回环检测的关键帧\nbool ferns::addframe(gputexture * imagetexture, gputexture * vertextexture, gputexture * normaltexture, const eigen::matrix4f & pose, int srctime, const float threshold)\n{\n    img<eigen::matrix<unsigned char, 3, 1>> img(height, width);\n    img<eigen::vector4f> verts(height, width);\n    img<eigen::vector4f> norms(height, width);\n\n    resize.image(imagetexture, img);\n    resize.vertex(vertextexture, verts);\n    resize.vertex(normaltexture, norms);\n\n    frame * frame = new frame(num,\n                              frames.size(),\n                              pose,\n                              srctime,\n                              width * height,\n                              (unsigned char *)img.data,\n                              (eigen::vector4f *)verts.data,\n                              (eigen::vector4f *)norms.data);\n\n    int * cooccurrences = new int[frames.size()];\n\n    memset(cooccurrences, 0, sizeof(int) * frames.size());\n\n    for(int i = 0; i < num; i++)\n    {\n        unsigned char code = badcode;\n\n        if(verts.at<eigen::vector4f>(conservatory.at(i).pos(1), conservatory.at(i).pos(0))(2) > 0)\n        {\n            const eigen::matrix<unsigned char, 3, 1> & pix = img.at<eigen::matrix<unsigned char, 3, 1>>(conservatory.at(i).pos(1), conservatory.at(i).pos(0));\n\n            //随机选取像素点处的编码\n            code = (pix(0) > conservatory.at(i).rgbd(0)) << 3 |\n                   (pix(1) > conservatory.at(i).rgbd(1)) << 2 |\n                   (pix(2) > conservatory.at(i).rgbd(2)) << 1 |\n                   (int(verts.at<eigen::vector4f>(conservatory.at(i).pos(1), conservatory.at(i).pos(0))(2) * 1000.0f) > conservatory.at(i).rgbd(3));\n\n            frame->goodcodes++;\n\n            // 计算和以前存储帧之间的相似度\n            for(size_t j = 0; j < conservatory.at(i).ids[code].size(); j++)\n            {\n                cooccurrences[conservatory.at(i).ids[code].at(j)]++;\n            }\n        }\n\n        frame->codes[i] = code;\n    }\n\n    float minimum = std::numeric_limits<float>::max();\n\n    if(frame->goodcodes > 0)\n    {\n        for(size_t i = 0; i < frames.size(); i++)\n        {\n            float maxco = std::min(frame->goodcodes, frames.at(i)->goodcodes);\n\n            float dissim = (float)(maxco - cooccurrences[i]) / (float)maxco;\n\n            if(dissim < minimum)\n            {\n                minimum = dissim;\n            }\n        }\n    }\n\n    delete [] cooccurrences;\n\n    if((minimum > threshold || frames.size() == 0) && frame->goodcodes > 0)\n    {\n        for(int i = 0; i < num; i++)\n        {\n            if(frame->codes[i] != badcode)\n            {\n                //conservatory 存储关系：第一层 fern 的编号，第二层 code 的编号，第三层图像帧的编号\n                conservatory.at(i).ids[frame->codes[i]].push_back(frame->id);\n            }\n        }\n\n        frames.push_back(frame);\n\n        return true;\n    }\n    else\n    {\n        delete frame;\n\n        return false;\n    }\n}\n\n\n// 对于输入的图像进行全局的回环检测，通过判断和以前存储的帧编码相似度，判断当前帧是否作为关键帧\neigen::matrix4f ferns::findframe(std::vector<surfaceconstraint> & constraints,\n                                 const eigen::matrix4f & currpose,\n                                 gputexture * vertextexture,\n                                 gputexture * normaltexture,\n                                 gputexture * imagetexture,\n                                 const int time,\n                                 const bool lost)\n{\n    lastclosest = -1;\n\n    img<eigen::matrix<unsigned char, 3, 1>> imgsmall(height, width);\n    img<eigen::vector4f> vertsmall(height, width);\n    img<eigen::vector4f> normsmall(height, width);\n\n    //对输入图像降采样 8x8 倍\n    resize.image(imagetexture, imgsmall);\n    resize.vertex(vertextexture, vertsmall);\n    resize.vertex(normaltexture, normsmall);\n\n    frame * frame = new frame(num, 0, eigen::matrix4f::identity(), 0, width * height);\n\n    int * cooccurrences = new int[frames.size()];\n\n    memset(cooccurrences, 0, sizeof(int) * frames.size());\n\n    for(int i = 0; i < num; i++)\n    {\n        unsigned char code = badcode;\n\n        if(vertsmall.at<eigen::vector4f>(conservatory.at(i).pos(1), conservatory.at(i).pos(0))(2) > 0)\n        {\n            const eigen::matrix<unsigned char, 3, 1> & pix = imgsmall.at<eigen::matrix<unsigned char, 3, 1>>(conservatory.at(i).pos(1), conservatory.at(i).pos(0));\n\n            //指定像素点处做编码\n            code = (pix(0) > conservatory.at(i).rgbd(0)) << 3 |\n                   (pix(1) > conservatory.at(i).rgbd(1)) << 2 |\n                   (pix(2) > conservatory.at(i).rgbd(2)) << 1 |\n                   (int(vertsmall.at<eigen::vector4f>(conservatory.at(i).pos(1), conservatory.at(i).pos(0))(2) * 1000.0f) > conservatory.at(i).rgbd(3));\n\n            frame->goodcodes++;\n\n            // conservatory.at(i) 表示第 i 个 fern 总共随机采样了 num 个\n            // conservatory.at(i).ids[code] 表示第 i 个 fern 编码值为 code 的 vector\n            // conservatory.at(i).ids[code].at(j) 值表示第 at(j) 帧图像\n            for(size_t j = 0; j < conservatory.at(i).ids[code].size(); j++)\n            {\n                // cooccurrences[conservatory.at(i).ids[code].at(j)] 表示和第 conservatory.at(i).ids[code].at(j) 帧图像的相似度\n                cooccurrences[conservatory.at(i).ids[code].at(j)]++;\n            }\n        }\n\n        frame->codes[i] = code;\n    }\n\n    float minimum = std::numeric_limits<float>::max();\n    int minid = -1;\n\n    //在所有帧中找相似度最小的帧\n    for(size_t i = 0; i < frames.size(); i++)\n    {\n        float maxco = std::min(frame->goodcodes, frames.at(i)->goodcodes);\n\n        float dissim = (float)(maxco - cooccurrences[i]) / (float)maxco;\n\n        if(dissim < minimum && time - frames.at(i)->srctime > 300)\n        {\n            minimum = dissim;\n            minid = i;\n        }\n    }\n\n\n//根据图像的编码计算两帧之间的相似度\nfloat ferns::blockhdaware(const frame * f1, const frame * f2)\n{\n    int count = 0;\n    float val = 0;\n\n    for(int i = 0; i < num; i++)\n    {\n        if(f1->codes[i] != badcode && f2->codes[i] != badcode)\n        {\n            count++;\n\n            if(f1->codes[i] == f2->codes[i])\n            {\n                val += 1.0f;\n            }\n        }\n    }\n\n    return val / (float)count;\n}\n",charsets:{cjk:!0}},{title:"代码分析",frontmatter:{title:"代码分析",date:"2023-04-07T08:42:28.000Z",permalink:"/pages/3d257e/"},regularPath:"/02.%E7%A7%91%E7%A0%94/03.%E6%88%91%E7%9A%84%E5%B7%A5%E4%BD%9C/02.code.html",relativePath:"02.科研/03.我的工作/02.code.md",key:"v-76c0fdcc",path:"/pages/3d257e/",headers:[{level:2,title:"多子图重建结果合并",slug:"多子图重建结果合并",normalizedTitle:"多子图重建结果合并",charIndex:2},{level:3,title:"合并框架",slug:"合并框架",normalizedTitle:"合并框架",charIndex:16},{level:3,title:"采用LO-RANSAC计算相似变换",slug:"采用lo-ransac计算相似变换",normalizedTitle:"采用lo-ransac计算相似变换",charIndex:2239},{level:3,title:"计算两个点云的相似变换",slug:"计算两个点云的相似变换",normalizedTitle:"计算两个点云的相似变换",charIndex:4301},{level:3,title:"具体融合操作",slug:"具体融合操作",normalizedTitle:"具体融合操作",charIndex:4319},{level:2,title:"场景图划分操作",slug:"场景图划分操作",normalizedTitle:"场景图划分操作",charIndex:7800}],headersStr:"多子图重建结果合并 合并框架 采用LO-RANSAC计算相似变换 计算两个点云的相似变换 具体融合操作 场景图划分操作",content:"# 多子图重建结果合并\n\n\n# 合并框架\n\nvoid MergeClusters(\n    const SceneClustering::Cluster& cluster,\n    std::unordered_map<const SceneClustering::Cluster*, ReconstructionManager>*\n        reconstruction_managers) {\n  // Extract all reconstructions from all child clusters.\n  std::vector<Reconstruction*> reconstructions;\n  for (const auto& child_cluster : cluster.child_clusters) {\n    if (!child_cluster.child_clusters.empty()) {\n      MergeClusters(child_cluster, reconstruction_managers);\n    }\n\n    auto& reconstruction_manager = reconstruction_managers->at(&child_cluster);\n    for (size_t i = 0; i < reconstruction_manager.Size(); ++i) {\n      reconstructions.push_back(&reconstruction_manager.Get(i));\n    }\n  }\n\n  // Try to merge all child cluster reconstruction.\n  while (reconstructions.size() > 1) {\n    bool merge_success = false;\n    for (size_t i = 0; i < reconstructions.size(); ++i) {\n      for (size_t j = 0; j < i; ++j) {\n        const double kMaxReprojError = 8.0;\n        if (reconstructions[i]->Merge(*reconstructions[j], kMaxReprojError)) {\n          reconstructions.erase(reconstructions.begin() + j);\n          merge_success = true;\n          break;\n        }\n      }\n\n      if (merge_success) {\n        break;\n      }\n    }\n\n    if (!merge_success) {\n      break;\n    }\n  }\n\n  // Insert a new reconstruction manager for merged cluster.\n  auto& reconstruction_manager = (*reconstruction_managers)[&cluster];\n  for (const auto& reconstruction : reconstructions) {\n    reconstruction_manager.Add();\n    reconstruction_manager.Get(reconstruction_manager.Size() - 1) =\n        *reconstruction;\n  }\n\n  // Delete all merged child cluster reconstruction managers.\n  for (const auto& child_cluster : cluster.child_clusters) {\n    reconstruction_managers->erase(&child_cluster);\n  }\n}\n\n\n该函数实现了将一个聚类中的所有子聚类的重建结果进行合并的功能。具体实现步骤如下：\n\n 1. 遍历所有子聚类，将子聚类中的所有重建结果加入到一个 vector 中。\n 2. 对于 vector 中的所有重建结果，尝试进行合并。合并的条件是重投影误差小于一个阈值 kMaxReprojError。\n 3. 如果成功合并了两个重建结果，则将其中一个从 vector 中删除。\n 4. 将合并后的重建结果加入到新的聚类中。\n 5. 删除所有已经合并的子聚类的重建结果。\n\n该函数使用了一个 unordered_map 来保存每个聚类对应的 ReconstructionManager。在遍历子聚类时，递归调用 MergeClusters 函数，将子聚类的重建结果加入到 unordered_map 中。在合并重建结果时，从 unordered_map 中获取对应的 ReconstructionManager。最后，将合并后的重建结果再次加入到 unordered_map 中，以便后续的合并操作。\n\n\n# 采用LO-RANSAC计算相似变换\n\nbool ComputeAlignmentBetweenReconstructions(\n    const Reconstruction& src_reconstruction,\n    const Reconstruction& ref_reconstruction,\n    const double min_inlier_observations, const double max_reproj_error,\n    Eigen::Matrix3x4d* alignment) {\n  CHECK_GE(min_inlier_observations, 0.0);\n  CHECK_LE(min_inlier_observations, 1.0);\n\n  RANSACOptions ransac_options;\n  ransac_options.max_error = 1.0 - min_inlier_observations;\n  ransac_options.min_inlier_ratio = 0.2;\n\n  LORANSAC<ReconstructionAlignmentEstimator, ReconstructionAlignmentEstimator>\n      ransac(ransac_options);\n  ransac.estimator.SetMaxReprojError(max_reproj_error);\n  ransac.estimator.SetReconstructions(&src_reconstruction, &ref_reconstruction);\n  ransac.local_estimator.SetMaxReprojError(max_reproj_error);\n  ransac.local_estimator.SetReconstructions(&src_reconstruction,\n                                            &ref_reconstruction);\n\n  const auto& common_image_ids =\n      src_reconstruction.FindCommonRegImageIds(ref_reconstruction);\n\n  if (common_image_ids.size() < 3) {\n    return false;\n  }\n\n  std::vector<const Image*> src_images(common_image_ids.size());\n  std::vector<const Image*> ref_images(common_image_ids.size());\n  for (size_t i = 0; i < common_image_ids.size(); ++i) {\n    src_images[i] = &src_reconstruction.Image(common_image_ids[i]);\n    ref_images[i] = &ref_reconstruction.Image(common_image_ids[i]);\n  }\n\n  const auto report = ransac.Estimate(src_images, ref_images);\n\n  if (report.success) {\n    *alignment = report.model;\n  }\n\n  return report.success;\n}\n\n\n该函数实现了计算两个重建结果之间的相对位姿的功能。具体实现步骤如下：\n\n 1. 根据两个重建结果中共同观测到的图像，构建两个 vector，分别保存两个重建结果中对应的 Image 对象。\n 2. 使用 LORANSAC 算法，通过这些共同的图像来计算两个重建结果之间的相对位姿。其中，使用 ReconstructionAlignmentEstimator 类来估计相对位姿。\n 3. 如果计算成功，则将计算得到的相对位姿保存在 alignment 参数中。\n\n该函数使用了 RANSACOptions 结构体来设置 LORANSAC 算法的参数，包括最大误差和最小内点比例。在计算相对位姿时，使用了 ReconstructionAlignmentEstimator 类来估计相对位姿。该类中实现了一个 ComputeError 函数，用于计算重建结果之间的重投影误差。如果重投影误差小于一个阈值 max_reproj_error，则将对应的观测点视为内点。在计算相对位姿时，使用了两个重建结果中共同观测到的图像。如果共同图像的数量小于 3，则无法计算相对位姿，返回 false。\n\n\n# 计算两个点云的相似变换\n\n\n\n\n# 具体融合操作\n\nbool Reconstruction::Merge(const Reconstruction& reconstruction,\n                           const double max_reproj_error) {\n  const double kMinInlierObservations = 0.3;\n\n  Eigen::Matrix3x4d alignment;\n  if (!ComputeAlignmentBetweenReconstructions(reconstruction, *this,\n                                              kMinInlierObservations,\n                                              max_reproj_error, &alignment)) {\n    return false;\n  }\n\n  const SimilarityTransform3 tform(alignment);\n\n  // Find common and missing images in the two reconstructions.\n\n  std::unordered_set<image_t> common_image_ids;\n  common_image_ids.reserve(reconstruction.NumRegImages());\n  std::unordered_set<image_t> missing_image_ids;\n  missing_image_ids.reserve(reconstruction.NumRegImages());\n\n  for (const auto& image_id : reconstruction.RegImageIds()) {\n    if (ExistsImage(image_id)) {\n      common_image_ids.insert(image_id);\n    } else {\n      missing_image_ids.insert(image_id);\n    }\n  }\n\n  // Register the missing images in this reconstruction.\n\n  for (const auto image_id : missing_image_ids) {\n    auto reg_image = reconstruction.Image(image_id);\n    reg_image.SetRegistered(false);\n    AddImage(reg_image);\n    RegisterImage(image_id);\n    if (!ExistsCamera(reg_image.CameraId())) {\n      AddCamera(reconstruction.Camera(reg_image.CameraId()));\n    }\n    auto& image = Image(image_id);\n    tform.TransformPose(&image.Qvec(), &image.Tvec());\n  }\n\n  // Merge the two point clouds using the following two rules:\n  //    - copy points to this reconstruction with non-conflicting tracks,\n  //      i.e. points that do not have an already triangulated observation\n  //      in this reconstruction.\n  //    - merge tracks that are unambiguous, i.e. only merge points in the two\n  //      reconstructions if they have a one-to-one mapping.\n  // Note that in both cases no cheirality or reprojection test is performed.\n\n  for (const auto& point3D : reconstruction.Points3D()) {\n    Track new_track;\n    Track old_track;\n    std::unordered_set<point3D_t> old_point3D_ids;\n    for (const auto& track_el : point3D.second.Track().Elements()) {\n      if (common_image_ids.count(track_el.image_id) > 0) {\n        const auto& point2D =\n            Image(track_el.image_id).Point2D(track_el.point2D_idx);\n        if (point2D.HasPoint3D()) {\n          old_track.AddElement(track_el);\n          old_point3D_ids.insert(point2D.Point3DId());\n        } else {\n          new_track.AddElement(track_el);\n        }\n      } else if (missing_image_ids.count(track_el.image_id) > 0) {\n        Image(track_el.image_id).ResetPoint3DForPoint2D(track_el.point2D_idx);\n        new_track.AddElement(track_el);\n      }\n    }\n\n    const bool create_new_point = new_track.Length() >= 2;\n    const bool merge_new_and_old_point =\n        (new_track.Length() + old_track.Length()) >= 2 &&\n        old_point3D_ids.size() == 1;\n    if (create_new_point || merge_new_and_old_point) {\n      Eigen::Vector3d xyz = point3D.second.XYZ();\n      tform.TransformPoint(&xyz);\n      const auto point3D_id =\n          AddPoint3D(xyz, new_track, point3D.second.Color());\n      if (old_point3D_ids.size() == 1) {\n        MergePoints3D(point3D_id, *old_point3D_ids.begin());\n      }\n    }\n  }\n\n  FilterPoints3DWithLargeReprojectionError(max_reproj_error, Point3DIds());\n\n  return true;\n}\n\n\n这段代码实现了两个重建结果的合并操作。具体来说，它首先计算两个重建结果之间的对齐变换，然后将缺失的图像和点云添加到当前重建结果中。接下来，它根据一些规则将两个点云合并起来，包括将没有冲突轨迹的点复制到当前重建结果中，以及合并那些具有一对一映射的点。最后，它使用重投影误差过滤掉一些重建点。\n\n\n# 场景图划分操作\n\ncppvoid SceneClustering::PartitionFlatCluster(\n    const std::vector<std::pair<int, int>>& edges,\n    const std::vector<int>& weights) {\n  CHECK_EQ(edges.size(), weights.size());\n\n  // Partition the cluster using a normalized cut on the scene graph.\n  const auto labels =\n      ComputeNormalizedMinGraphCut(edges, weights, options_.branching);\n\n  // Assign the images to the clustered child clusters.\n  root_cluster_->child_clusters.resize(options_.branching);\n  for (const auto image_id : root_cluster_->image_ids) {\n    if (labels.count(image_id)) {\n      auto& child_cluster =\n          root_cluster_->child_clusters.at(labels.at(image_id));\n      child_cluster.image_ids.push_back(image_id);\n    }\n  }\n\n  // Sort child clusters by descending size of images and secondarily by lowest\n  // image id.\n  std::sort(root_cluster_->child_clusters.begin(),\n            root_cluster_->child_clusters.end(),\n            [](const Cluster& first, const Cluster& second) {\n              return first.image_ids.size() >= second.image_ids.size() &&\n                     *std::min_element(first.image_ids.begin(),\n                                       first.image_ids.end()) <\n                         *std::min_element(second.image_ids.begin(),\n                                           second.image_ids.end());\n            });\n\n  // For each image find all related images with their weights\n  std::unordered_map<int, std::vector<std::pair<int, int>>> related_images;\n  for (size_t i = 0; i < edges.size(); ++i) {\n    related_images[edges[i].first].emplace_back(edges[i].second, weights[i]);\n    related_images[edges[i].second].emplace_back(edges[i].first, weights[i]);\n  }\n\n  // Sort related images by decreasing weights\n  for (auto& image : related_images) {\n    std::sort(image.second.begin(), image.second.end(),\n              [](const std::pair<int, int>& first,\n                 const std::pair<int, int>& second) {\n                return first.second > second.second;\n              });\n  }\n\n  // For each cluster add as many of the needed matching images up to\n  // the max image overal allowance\n  // We do the process sequentially for each image to ensure that at\n  // least we get the best matches firat\n  for (int i = 0; i < options_.branching; ++i) {\n    auto& orig_image_ids = root_cluster_->child_clusters[i].image_ids;\n    std::set<int> cluster_images(\n        root_cluster_->child_clusters[i].image_ids.begin(),\n        root_cluster_->child_clusters[i].image_ids.end());\n    const size_t max_size = cluster_images.size() + options_.image_overlap;\n    // check up to all the desired matches\n    for (size_t j = 0; j < static_cast<size_t>(options_.num_image_matches) &&\n                       cluster_images.size() < max_size;\n         ++j) {\n      for (const image_t image_id : orig_image_ids) {\n        const auto& images = related_images[image_id];\n        if (j >= images.size()) {\n          continue;\n        }\n        // image not exists in cluster so we add it in the overlap set\n        const int related_id = images[j].first;\n        if (cluster_images.count(related_id) == 0) {\n          cluster_images.insert(related_id);\n        }\n        if (cluster_images.size() >= max_size) {\n          break;\n        }\n      }\n    }\n    orig_image_ids.clear();\n    orig_image_ids.insert(orig_image_ids.end(), cluster_images.begin(),\n                          cluster_images.end());\n  }\n}\n\n\n这段代码实现了场景聚类中的子聚类划分操作。具体来说，它首先调用 ComputeNormalizedMinGraphCut 函数对场景图进行归一化切割，得到每个图像所属的子聚类标签。然后，它将每个图像分配给对应的子聚类，并按照子聚类中图像数量从大到小、图像 ID 从小到大的顺序对子聚类进行排序。接着，它对每个子聚类中的图像进行匹配，以确保每个子聚类中的图像都与其他子聚类中的图像有一定的重叠。具体来说，它首先根据场景图中的边和权重构建一个图像之间的关系图，然后对于每个子聚类，它从该子聚类中的图像出发，按照关系图中的权重从大到小的顺序，依次添加与该图像有关系的其他图像，直到该子聚类中的图像数量达到一定的阈值。最后，它将每个子聚类中的图像重新赋值给对应的子聚类。",normalizedContent:"# 多子图重建结果合并\n\n\n# 合并框架\n\nvoid mergeclusters(\n    const sceneclustering::cluster& cluster,\n    std::unordered_map<const sceneclustering::cluster*, reconstructionmanager>*\n        reconstruction_managers) {\n  // extract all reconstructions from all child clusters.\n  std::vector<reconstruction*> reconstructions;\n  for (const auto& child_cluster : cluster.child_clusters) {\n    if (!child_cluster.child_clusters.empty()) {\n      mergeclusters(child_cluster, reconstruction_managers);\n    }\n\n    auto& reconstruction_manager = reconstruction_managers->at(&child_cluster);\n    for (size_t i = 0; i < reconstruction_manager.size(); ++i) {\n      reconstructions.push_back(&reconstruction_manager.get(i));\n    }\n  }\n\n  // try to merge all child cluster reconstruction.\n  while (reconstructions.size() > 1) {\n    bool merge_success = false;\n    for (size_t i = 0; i < reconstructions.size(); ++i) {\n      for (size_t j = 0; j < i; ++j) {\n        const double kmaxreprojerror = 8.0;\n        if (reconstructions[i]->merge(*reconstructions[j], kmaxreprojerror)) {\n          reconstructions.erase(reconstructions.begin() + j);\n          merge_success = true;\n          break;\n        }\n      }\n\n      if (merge_success) {\n        break;\n      }\n    }\n\n    if (!merge_success) {\n      break;\n    }\n  }\n\n  // insert a new reconstruction manager for merged cluster.\n  auto& reconstruction_manager = (*reconstruction_managers)[&cluster];\n  for (const auto& reconstruction : reconstructions) {\n    reconstruction_manager.add();\n    reconstruction_manager.get(reconstruction_manager.size() - 1) =\n        *reconstruction;\n  }\n\n  // delete all merged child cluster reconstruction managers.\n  for (const auto& child_cluster : cluster.child_clusters) {\n    reconstruction_managers->erase(&child_cluster);\n  }\n}\n\n\n该函数实现了将一个聚类中的所有子聚类的重建结果进行合并的功能。具体实现步骤如下：\n\n 1. 遍历所有子聚类，将子聚类中的所有重建结果加入到一个 vector 中。\n 2. 对于 vector 中的所有重建结果，尝试进行合并。合并的条件是重投影误差小于一个阈值 kmaxreprojerror。\n 3. 如果成功合并了两个重建结果，则将其中一个从 vector 中删除。\n 4. 将合并后的重建结果加入到新的聚类中。\n 5. 删除所有已经合并的子聚类的重建结果。\n\n该函数使用了一个 unordered_map 来保存每个聚类对应的 reconstructionmanager。在遍历子聚类时，递归调用 mergeclusters 函数，将子聚类的重建结果加入到 unordered_map 中。在合并重建结果时，从 unordered_map 中获取对应的 reconstructionmanager。最后，将合并后的重建结果再次加入到 unordered_map 中，以便后续的合并操作。\n\n\n# 采用lo-ransac计算相似变换\n\nbool computealignmentbetweenreconstructions(\n    const reconstruction& src_reconstruction,\n    const reconstruction& ref_reconstruction,\n    const double min_inlier_observations, const double max_reproj_error,\n    eigen::matrix3x4d* alignment) {\n  check_ge(min_inlier_observations, 0.0);\n  check_le(min_inlier_observations, 1.0);\n\n  ransacoptions ransac_options;\n  ransac_options.max_error = 1.0 - min_inlier_observations;\n  ransac_options.min_inlier_ratio = 0.2;\n\n  loransac<reconstructionalignmentestimator, reconstructionalignmentestimator>\n      ransac(ransac_options);\n  ransac.estimator.setmaxreprojerror(max_reproj_error);\n  ransac.estimator.setreconstructions(&src_reconstruction, &ref_reconstruction);\n  ransac.local_estimator.setmaxreprojerror(max_reproj_error);\n  ransac.local_estimator.setreconstructions(&src_reconstruction,\n                                            &ref_reconstruction);\n\n  const auto& common_image_ids =\n      src_reconstruction.findcommonregimageids(ref_reconstruction);\n\n  if (common_image_ids.size() < 3) {\n    return false;\n  }\n\n  std::vector<const image*> src_images(common_image_ids.size());\n  std::vector<const image*> ref_images(common_image_ids.size());\n  for (size_t i = 0; i < common_image_ids.size(); ++i) {\n    src_images[i] = &src_reconstruction.image(common_image_ids[i]);\n    ref_images[i] = &ref_reconstruction.image(common_image_ids[i]);\n  }\n\n  const auto report = ransac.estimate(src_images, ref_images);\n\n  if (report.success) {\n    *alignment = report.model;\n  }\n\n  return report.success;\n}\n\n\n该函数实现了计算两个重建结果之间的相对位姿的功能。具体实现步骤如下：\n\n 1. 根据两个重建结果中共同观测到的图像，构建两个 vector，分别保存两个重建结果中对应的 image 对象。\n 2. 使用 loransac 算法，通过这些共同的图像来计算两个重建结果之间的相对位姿。其中，使用 reconstructionalignmentestimator 类来估计相对位姿。\n 3. 如果计算成功，则将计算得到的相对位姿保存在 alignment 参数中。\n\n该函数使用了 ransacoptions 结构体来设置 loransac 算法的参数，包括最大误差和最小内点比例。在计算相对位姿时，使用了 reconstructionalignmentestimator 类来估计相对位姿。该类中实现了一个 computeerror 函数，用于计算重建结果之间的重投影误差。如果重投影误差小于一个阈值 max_reproj_error，则将对应的观测点视为内点。在计算相对位姿时，使用了两个重建结果中共同观测到的图像。如果共同图像的数量小于 3，则无法计算相对位姿，返回 false。\n\n\n# 计算两个点云的相似变换\n\n\n\n\n# 具体融合操作\n\nbool reconstruction::merge(const reconstruction& reconstruction,\n                           const double max_reproj_error) {\n  const double kmininlierobservations = 0.3;\n\n  eigen::matrix3x4d alignment;\n  if (!computealignmentbetweenreconstructions(reconstruction, *this,\n                                              kmininlierobservations,\n                                              max_reproj_error, &alignment)) {\n    return false;\n  }\n\n  const similaritytransform3 tform(alignment);\n\n  // find common and missing images in the two reconstructions.\n\n  std::unordered_set<image_t> common_image_ids;\n  common_image_ids.reserve(reconstruction.numregimages());\n  std::unordered_set<image_t> missing_image_ids;\n  missing_image_ids.reserve(reconstruction.numregimages());\n\n  for (const auto& image_id : reconstruction.regimageids()) {\n    if (existsimage(image_id)) {\n      common_image_ids.insert(image_id);\n    } else {\n      missing_image_ids.insert(image_id);\n    }\n  }\n\n  // register the missing images in this reconstruction.\n\n  for (const auto image_id : missing_image_ids) {\n    auto reg_image = reconstruction.image(image_id);\n    reg_image.setregistered(false);\n    addimage(reg_image);\n    registerimage(image_id);\n    if (!existscamera(reg_image.cameraid())) {\n      addcamera(reconstruction.camera(reg_image.cameraid()));\n    }\n    auto& image = image(image_id);\n    tform.transformpose(&image.qvec(), &image.tvec());\n  }\n\n  // merge the two point clouds using the following two rules:\n  //    - copy points to this reconstruction with non-conflicting tracks,\n  //      i.e. points that do not have an already triangulated observation\n  //      in this reconstruction.\n  //    - merge tracks that are unambiguous, i.e. only merge points in the two\n  //      reconstructions if they have a one-to-one mapping.\n  // note that in both cases no cheirality or reprojection test is performed.\n\n  for (const auto& point3d : reconstruction.points3d()) {\n    track new_track;\n    track old_track;\n    std::unordered_set<point3d_t> old_point3d_ids;\n    for (const auto& track_el : point3d.second.track().elements()) {\n      if (common_image_ids.count(track_el.image_id) > 0) {\n        const auto& point2d =\n            image(track_el.image_id).point2d(track_el.point2d_idx);\n        if (point2d.haspoint3d()) {\n          old_track.addelement(track_el);\n          old_point3d_ids.insert(point2d.point3did());\n        } else {\n          new_track.addelement(track_el);\n        }\n      } else if (missing_image_ids.count(track_el.image_id) > 0) {\n        image(track_el.image_id).resetpoint3dforpoint2d(track_el.point2d_idx);\n        new_track.addelement(track_el);\n      }\n    }\n\n    const bool create_new_point = new_track.length() >= 2;\n    const bool merge_new_and_old_point =\n        (new_track.length() + old_track.length()) >= 2 &&\n        old_point3d_ids.size() == 1;\n    if (create_new_point || merge_new_and_old_point) {\n      eigen::vector3d xyz = point3d.second.xyz();\n      tform.transformpoint(&xyz);\n      const auto point3d_id =\n          addpoint3d(xyz, new_track, point3d.second.color());\n      if (old_point3d_ids.size() == 1) {\n        mergepoints3d(point3d_id, *old_point3d_ids.begin());\n      }\n    }\n  }\n\n  filterpoints3dwithlargereprojectionerror(max_reproj_error, point3dids());\n\n  return true;\n}\n\n\n这段代码实现了两个重建结果的合并操作。具体来说，它首先计算两个重建结果之间的对齐变换，然后将缺失的图像和点云添加到当前重建结果中。接下来，它根据一些规则将两个点云合并起来，包括将没有冲突轨迹的点复制到当前重建结果中，以及合并那些具有一对一映射的点。最后，它使用重投影误差过滤掉一些重建点。\n\n\n# 场景图划分操作\n\ncppvoid sceneclustering::partitionflatcluster(\n    const std::vector<std::pair<int, int>>& edges,\n    const std::vector<int>& weights) {\n  check_eq(edges.size(), weights.size());\n\n  // partition the cluster using a normalized cut on the scene graph.\n  const auto labels =\n      computenormalizedmingraphcut(edges, weights, options_.branching);\n\n  // assign the images to the clustered child clusters.\n  root_cluster_->child_clusters.resize(options_.branching);\n  for (const auto image_id : root_cluster_->image_ids) {\n    if (labels.count(image_id)) {\n      auto& child_cluster =\n          root_cluster_->child_clusters.at(labels.at(image_id));\n      child_cluster.image_ids.push_back(image_id);\n    }\n  }\n\n  // sort child clusters by descending size of images and secondarily by lowest\n  // image id.\n  std::sort(root_cluster_->child_clusters.begin(),\n            root_cluster_->child_clusters.end(),\n            [](const cluster& first, const cluster& second) {\n              return first.image_ids.size() >= second.image_ids.size() &&\n                     *std::min_element(first.image_ids.begin(),\n                                       first.image_ids.end()) <\n                         *std::min_element(second.image_ids.begin(),\n                                           second.image_ids.end());\n            });\n\n  // for each image find all related images with their weights\n  std::unordered_map<int, std::vector<std::pair<int, int>>> related_images;\n  for (size_t i = 0; i < edges.size(); ++i) {\n    related_images[edges[i].first].emplace_back(edges[i].second, weights[i]);\n    related_images[edges[i].second].emplace_back(edges[i].first, weights[i]);\n  }\n\n  // sort related images by decreasing weights\n  for (auto& image : related_images) {\n    std::sort(image.second.begin(), image.second.end(),\n              [](const std::pair<int, int>& first,\n                 const std::pair<int, int>& second) {\n                return first.second > second.second;\n              });\n  }\n\n  // for each cluster add as many of the needed matching images up to\n  // the max image overal allowance\n  // we do the process sequentially for each image to ensure that at\n  // least we get the best matches firat\n  for (int i = 0; i < options_.branching; ++i) {\n    auto& orig_image_ids = root_cluster_->child_clusters[i].image_ids;\n    std::set<int> cluster_images(\n        root_cluster_->child_clusters[i].image_ids.begin(),\n        root_cluster_->child_clusters[i].image_ids.end());\n    const size_t max_size = cluster_images.size() + options_.image_overlap;\n    // check up to all the desired matches\n    for (size_t j = 0; j < static_cast<size_t>(options_.num_image_matches) &&\n                       cluster_images.size() < max_size;\n         ++j) {\n      for (const image_t image_id : orig_image_ids) {\n        const auto& images = related_images[image_id];\n        if (j >= images.size()) {\n          continue;\n        }\n        // image not exists in cluster so we add it in the overlap set\n        const int related_id = images[j].first;\n        if (cluster_images.count(related_id) == 0) {\n          cluster_images.insert(related_id);\n        }\n        if (cluster_images.size() >= max_size) {\n          break;\n        }\n      }\n    }\n    orig_image_ids.clear();\n    orig_image_ids.insert(orig_image_ids.end(), cluster_images.begin(),\n                          cluster_images.end());\n  }\n}\n\n\n这段代码实现了场景聚类中的子聚类划分操作。具体来说，它首先调用 computenormalizedmingraphcut 函数对场景图进行归一化切割，得到每个图像所属的子聚类标签。然后，它将每个图像分配给对应的子聚类，并按照子聚类中图像数量从大到小、图像 id 从小到大的顺序对子聚类进行排序。接着，它对每个子聚类中的图像进行匹配，以确保每个子聚类中的图像都与其他子聚类中的图像有一定的重叠。具体来说，它首先根据场景图中的边和权重构建一个图像之间的关系图，然后对于每个子聚类，它从该子聚类中的图像出发，按照关系图中的权重从大到小的顺序，依次添加与该图像有关系的其他图像，直到该子聚类中的图像数量达到一定的阈值。最后，它将每个子聚类中的图像重新赋值给对应的子聚类。",charsets:{cjk:!0}},{title:"Hybrid SfM",frontmatter:{title:"Hybrid SfM",date:"2023-04-12T09:51:49.000Z",permalink:"/pages/8f3964/"},regularPath:"/02.%E7%A7%91%E7%A0%94/03.%E6%88%91%E7%9A%84%E5%B7%A5%E4%BD%9C/10.hybrid.html",relativePath:"02.科研/03.我的工作/10.hybrid.md",key:"v-015ece1a",path:"/pages/8f3964/",headers:[{level:2,title:"一些综述",slug:"一些综述",normalizedTitle:"一些综述",charIndex:2},{level:2,title:"AdaSfM",slug:"adasfm",normalizedTitle:"adasfm",charIndex:643},{level:2,title:"Graph SfM",slug:"graph-sfm",normalizedTitle:"graph sfm",charIndex:965}],headersStr:"一些综述 AdaSfM Graph SfM",content:"# 一些综述\n\n37 Hsfm: Hybrid structure-from-motion 2017 CVPR\n\n通过RA获取旋转，然后采用P2P方式逐步配准相机中心\n\n16 Divide and conquer: Efficient large-scale structure from motion using graph partitioning 2014 ACCV\n\n通过图像的相似性分数构建场景图，然后并行执行特征匹配和局部SfM，合并局部重建\n\n18 Parallel structure from motion from local increment to global averaging 2017\n\n19 Very large-scale global SfM by distributed motion averaging 2018 CVPR\n\n17 Graph-based parallel large scale structure from motio 2020 PR\n\n发现最小啊生成树MST来解决最后的合并操作\n\n38 Progressive structure from motion 2018 ECCV\n\n再采用分治法之前，通过RA过滤了错误的对极几何\n\n39 Vio-aided structure from motion under challenging environments 2021 ICIT\n\n采用VINS进行回环检测与矫正\n\n\n# AdaSfM\n\n分区划分\n\n分区之间的重叠区域较少\n\n现存的方法使用图割和扩展的模式，在分区之间创建重叠区域，有两个缺点\n\n\n\n * 当试图变得太稀疏时，重叠区域不足以进行最终合并\n * 图割的方式倾向于分离那些弱约束的边，但重叠区域也是取决于弱约束的边\n\n分区合并\n\n分区合并时，对异常值不鲁棒，以及在样本数量不足时，估计的相似变换不准确\n\nAdaSfM: From Coarse Global to Fine Incremental Adaptive Structure from Motion\n\n解决问题分区划分，通过扩展分隔符，st分区之间的重叠区域增加，达到一个阈值后，则停止扩展。\n\n解决问题分区合并，动态设定内点率的阈值\n\n\n# Graph SfM\n\n一样的，采用图割的方式进行划分，绿色节点的边代表弱边，红色是切割线\n\n\n\n切割完之后，把子图当成一个节点，删掉的边作为新的边，再次将他们连接起来\n\n\n\n对这个新的图生成最大生成树\n\n\n\n再对最大生成树进行扩展一些边\n\n",normalizedContent:"# 一些综述\n\n37 hsfm: hybrid structure-from-motion 2017 cvpr\n\n通过ra获取旋转，然后采用p2p方式逐步配准相机中心\n\n16 divide and conquer: efficient large-scale structure from motion using graph partitioning 2014 accv\n\n通过图像的相似性分数构建场景图，然后并行执行特征匹配和局部sfm，合并局部重建\n\n18 parallel structure from motion from local increment to global averaging 2017\n\n19 very large-scale global sfm by distributed motion averaging 2018 cvpr\n\n17 graph-based parallel large scale structure from motio 2020 pr\n\n发现最小啊生成树mst来解决最后的合并操作\n\n38 progressive structure from motion 2018 eccv\n\n再采用分治法之前，通过ra过滤了错误的对极几何\n\n39 vio-aided structure from motion under challenging environments 2021 icit\n\n采用vins进行回环检测与矫正\n\n\n# adasfm\n\n分区划分\n\n分区之间的重叠区域较少\n\n现存的方法使用图割和扩展的模式，在分区之间创建重叠区域，有两个缺点\n\n\n\n * 当试图变得太稀疏时，重叠区域不足以进行最终合并\n * 图割的方式倾向于分离那些弱约束的边，但重叠区域也是取决于弱约束的边\n\n分区合并\n\n分区合并时，对异常值不鲁棒，以及在样本数量不足时，估计的相似变换不准确\n\nadasfm: from coarse global to fine incremental adaptive structure from motion\n\n解决问题分区划分，通过扩展分隔符，st分区之间的重叠区域增加，达到一个阈值后，则停止扩展。\n\n解决问题分区合并，动态设定内点率的阈值\n\n\n# graph sfm\n\n一样的，采用图割的方式进行划分，绿色节点的边代表弱边，红色是切割线\n\n\n\n切割完之后，把子图当成一个节点，删掉的边作为新的边，再次将他们连接起来\n\n\n\n对这个新的图生成最大生成树\n\n\n\n再对最大生成树进行扩展一些边\n\n",charsets:{cjk:!0}},{title:"hierarchical",frontmatter:{title:"hierarchical",date:"2023-02-01T12:47:36.000Z",permalink:"/pages/c06b1c/"},regularPath:"/02.%E7%A7%91%E7%A0%94/03.%E6%88%91%E7%9A%84%E5%B7%A5%E4%BD%9C/01.one.html",relativePath:"02.科研/03.我的工作/01.one.md",key:"v-5913e204",path:"/pages/c06b1c/",headers:[{level:2,title:"初步想法",slug:"初步想法",normalizedTitle:"初步想法",charIndex:2},{level:2,title:"合并思路",slug:"合并思路",normalizedTitle:"合并思路",charIndex:109},{level:3,title:"RANSAC算法步骤",slug:"ransac算法步骤",normalizedTitle:"ransac算法步骤",charIndex:118},{level:3,title:"LO-RANSAC",slug:"lo-ransac",normalizedTitle:"lo-ransac",charIndex:228},{level:2,title:"对比",slug:"对比",normalizedTitle:"对比",charIndex:425},{level:4,title:"An Efficient and Robust Hybrid SfM Method for Large-Scale Scenes",slug:"an-efficient-and-robust-hybrid-sfm-method-for-large-scale-scenes",normalizedTitle:"an efficient and robust hybrid sfm method for large-scale scenes",charIndex:431}],headersStr:"初步想法 合并思路 RANSAC算法步骤 LO-RANSAC 对比 An Efficient and Robust Hybrid SfM Method for Large-Scale Scenes",content:"# 初步想法\n\n 1. 读取colmap的database，执行scene_clustering分割场景，边的全重为匹配的内点数量，采用最小割算法。\n 2. 每一个叶子节点多线程执行增量重建。\n 3. 合并。\n\n\n# 合并思路\n\n\n# RANSAC算法步骤\n\n 1. 从所有数据中采样n个点，n个点是估计模型的最小点数；\n 2. 从采样出的n个点计算出模型；\n 3. 通过模型来确定所有数据的内点，当内点率达到指定值，算法终止。否则继续上述过程。\n\n\n# LO-RANSAC\n\n\n\n 1. 1~3同上；\n 2. 如果这次计算出的内点比以前某一次计算出的内点数多，那么就执行Local Optimization.\n\n\n\n局部优化步骤：\n\n从上一步的RANSAC估计的内点中，选取出内点，使用线性最小二乘法估计模型Mis。\n\n\n\n在Mis基础上，再进行iters次迭代求解得到Mr，每次迭代降低阈值θ。\n\n最后取所有的Mis，Mr，M中最好的。\n\n\n# 对比\n\n# An Efficient and Robust Hybrid SfM Method for Large-Scale Scenes\n\n划分问题\n\n * 场景划分阶段：子簇聚类后，子簇内图像的空间分布较为松散。子簇扩容时，扩容图像效率低，没有考虑子簇之间的连通性。\n * 子簇合并阶段：由于合并路径较长，现有方法容易造成误差累积，导致整个场景稀疏重建失败。\n\n改进\n\n * 首先，构建了子簇间多因素联合场景划分测度和预分配平衡图像扩展算法，有效解决了子簇内图像空间分布松散的问题，提高了子簇间的连接度。\n * 其次，使用全局GlobalACSfM方法在集群并行框架下完成子集群的局部稀疏重构。\n * 然后，提出了一种考虑子簇连通性的分散动态合并规则，以实现子簇之间的鲁棒合并。\n * 最后，使用公共数据集和倾斜摄影数据集进行实验验证。",normalizedContent:"# 初步想法\n\n 1. 读取colmap的database，执行scene_clustering分割场景，边的全重为匹配的内点数量，采用最小割算法。\n 2. 每一个叶子节点多线程执行增量重建。\n 3. 合并。\n\n\n# 合并思路\n\n\n# ransac算法步骤\n\n 1. 从所有数据中采样n个点，n个点是估计模型的最小点数；\n 2. 从采样出的n个点计算出模型；\n 3. 通过模型来确定所有数据的内点，当内点率达到指定值，算法终止。否则继续上述过程。\n\n\n# lo-ransac\n\n\n\n 1. 1~3同上；\n 2. 如果这次计算出的内点比以前某一次计算出的内点数多，那么就执行local optimization.\n\n\n\n局部优化步骤：\n\n从上一步的ransac估计的内点中，选取出内点，使用线性最小二乘法估计模型mis。\n\n\n\n在mis基础上，再进行iters次迭代求解得到mr，每次迭代降低阈值θ。\n\n最后取所有的mis，mr，m中最好的。\n\n\n# 对比\n\n# an efficient and robust hybrid sfm method for large-scale scenes\n\n划分问题\n\n * 场景划分阶段：子簇聚类后，子簇内图像的空间分布较为松散。子簇扩容时，扩容图像效率低，没有考虑子簇之间的连通性。\n * 子簇合并阶段：由于合并路径较长，现有方法容易造成误差累积，导致整个场景稀疏重建失败。\n\n改进\n\n * 首先，构建了子簇间多因素联合场景划分测度和预分配平衡图像扩展算法，有效解决了子簇内图像空间分布松散的问题，提高了子簇间的连接度。\n * 其次，使用全局globalacsfm方法在集群并行框架下完成子集群的局部稀疏重构。\n * 然后，提出了一种考虑子簇连通性的分散动态合并规则，以实现子簇之间的鲁棒合并。\n * 最后，使用公共数据集和倾斜摄影数据集进行实验验证。",charsets:{cjk:!0}},{title:"实验部分",frontmatter:{title:"实验部分",date:"2023-04-14T15:36:51.000Z",permalink:"/pages/a2edb6/"},regularPath:"/02.%E7%A7%91%E7%A0%94/03.%E6%88%91%E7%9A%84%E5%B7%A5%E4%BD%9C/15.%E5%AE%9E%E9%AA%8C.html",relativePath:"02.科研/03.我的工作/15.实验.md",key:"v-8f96befe",path:"/pages/a2edb6/",headersStr:null,content:"# 统一使用colmap查看模型\n导入txt文件夹\n\n# 统计信息，配准的图像，估计的点数，平均重投影误差\ncolmap model_analyzer --path txt文件夹\n\n\n# theiaSfM\n# 将theia生成的模型转换成colmap格式进行查看\n./export_colmap_files --output_folder=输出文件夹 --input_reconstruction_file=theia模型\n\n# theia模型的统计信息\n./compute_reconstruction_statistics --reconstruction=theia模型 --logtostderr\n\n\n\n",normalizedContent:"# 统一使用colmap查看模型\n导入txt文件夹\n\n# 统计信息，配准的图像，估计的点数，平均重投影误差\ncolmap model_analyzer --path txt文件夹\n\n\n# theiasfm\n# 将theia生成的模型转换成colmap格式进行查看\n./export_colmap_files --output_folder=输出文件夹 --input_reconstruction_file=theia模型\n\n# theia模型的统计信息\n./compute_reconstruction_statistics --reconstruction=theia模型 --logtostderr\n\n\n\n",charsets:{cjk:!0}},{title:"KeyFrame",frontmatter:{title:"KeyFrame",date:"2023-05-10T15:41:39.000Z",permalink:"/pages/03900a/"},regularPath:"/02.%E7%A7%91%E7%A0%94/03.%E6%88%91%E7%9A%84%E5%B7%A5%E4%BD%9C/30.two.html",relativePath:"02.科研/03.我的工作/30.two.md",key:"v-70073a00",path:"/pages/03900a/",headers:[{level:2,title:"关键帧选择",slug:"关键帧选择",normalizedTitle:"关键帧选择",charIndex:120},{level:2,title:"全局BA优化",slug:"全局ba优化",normalizedTitle:"全局ba优化",charIndex:340},{level:2,title:"普通帧优化",slug:"普通帧优化",normalizedTitle:"普通帧优化",charIndex:404}],headersStr:"关键帧选择 全局BA优化 普通帧优化",content:"近些年，structure from motion取得了巨大的进步，但在大规模场景重建仍然遇到困难。对于某些质量较差的图像，在BA的过程中会增加outliers，以及该图像观测到较差的三维点，导致BA收敛速度慢甚至不收敛。本文提出一种新颖的关键帧选择策略，该策略可以优化BA的效率。\n\n\n# 关键帧选择\n\n定义一个场景变化的因子，用于衡量该帧对地图点的贡献度。首先通过三角化可以测量出该帧可以观测到的3D点数num1，再计算其新增加的3D点数num2。\n\nnum1可以代表其可以观测到场景的3D点数，num2代表当时增长地图点数。\n\n综合考虑，num1保证场景的完整性，num2保证新增长的地图点的稳定性。\n\n所以关键帧选取为num1>α1 或者 num2>α2的图像。\n\n\n# 全局BA优化\n\n对于全局BA，仅仅添加关键帧到优化器中进行优化。减少冗余图像信息，避免陷入局部最优解，且提升优化速度。\n\n\n# 普通帧优化\n\n对于普通帧，从关键帧集合中选取与之匹配数量最多的关键帧参考，在进行全局BA之前，计算相对位姿变换δT=TiTkey，进行全局BA后，关键帧优化后的位姿为Tkey′。\n\n那么对于普通帧，通过传递优化，则普通帧优化后的位姿为Ti′=δTTkey′。",normalizedContent:"近些年，structure from motion取得了巨大的进步，但在大规模场景重建仍然遇到困难。对于某些质量较差的图像，在ba的过程中会增加outliers，以及该图像观测到较差的三维点，导致ba收敛速度慢甚至不收敛。本文提出一种新颖的关键帧选择策略，该策略可以优化ba的效率。\n\n\n# 关键帧选择\n\n定义一个场景变化的因子，用于衡量该帧对地图点的贡献度。首先通过三角化可以测量出该帧可以观测到的3d点数num1，再计算其新增加的3d点数num2。\n\nnum1可以代表其可以观测到场景的3d点数，num2代表当时增长地图点数。\n\n综合考虑，num1保证场景的完整性，num2保证新增长的地图点的稳定性。\n\n所以关键帧选取为num1>α1 或者 num2>α2的图像。\n\n\n# 全局ba优化\n\n对于全局ba，仅仅添加关键帧到优化器中进行优化。减少冗余图像信息，避免陷入局部最优解，且提升优化速度。\n\n\n# 普通帧优化\n\n对于普通帧，从关键帧集合中选取与之匹配数量最多的关键帧参考，在进行全局ba之前，计算相对位姿变换δt=titkey，进行全局ba后，关键帧优化后的位姿为tkey′。\n\n那么对于普通帧，通过传递优化，则普通帧优化后的位姿为ti′=δttkey′。",charsets:{cjk:!0}},{title:"实现流程",frontmatter:{title:"实现流程",date:"2023-04-08T18:01:25.000Z",permalink:"/pages/0c2f17/"},regularPath:"/02.%E7%A7%91%E7%A0%94/03.%E6%88%91%E7%9A%84%E5%B7%A5%E4%BD%9C/03.%E5%AE%9E%E7%8E%B0%E6%B5%81%E7%A8%8B.html",relativePath:"02.科研/03.我的工作/03.实现流程.md",key:"v-140f256d",path:"/pages/0c2f17/",headers:[{level:2,title:"实现流程",slug:"实现流程",normalizedTitle:"实现流程",charIndex:2},{level:3,title:"计算模型之间的相似变换",slug:"计算模型之间的相似变换",normalizedTitle:"计算模型之间的相似变换",charIndex:11},{level:3,title:"RANSAC估算俩堆点云的变换",slug:"ransac估算俩堆点云的变换",normalizedTitle:"ransac估算俩堆点云的变换",charIndex:209},{level:4,title:"RANSAC过程",slug:"ransac过程",normalizedTitle:"ransac过程",charIndex:265},{level:4,title:"LO-RANSAC过程",slug:"lo-ransac过程",normalizedTitle:"lo-ransac过程",charIndex:496},{level:4,title:"开始迭代",slug:"开始迭代",normalizedTitle:"开始迭代",charIndex:789},{level:5,title:"计算残差",slug:"计算残差",normalizedTitle:"计算残差",charIndex:888},{level:3,title:"Merge",slug:"merge",normalizedTitle:"merge",charIndex:1390},{level:3,title:"Filter",slug:"filter",normalizedTitle:"filter",charIndex:1873},{level:4,title:"计算重投影误差",slug:"计算重投影误差",normalizedTitle:"计算重投影误差",charIndex:1883},{level:3,title:"图割",slug:"图割",normalizedTitle:"图割",charIndex:1958},{level:4,title:"Partition",slug:"partition",normalizedTitle:"partition",charIndex:1964}],headersStr:"实现流程 计算模型之间的相似变换 RANSAC估算俩堆点云的变换 RANSAC过程 LO-RANSAC过程 开始迭代 计算残差 Merge Filter 计算重投影误差 图割 Partition",content:"# 实现流程\n\n\n# 计算模型之间的相似变换\n\n输入两个要对齐的模型，输出他们之间的相似变换矩阵alignment\n\n设置RANSAC的一些参数，最大误差，和内点率\n\n找到两个模型之间的公共图片I\n\n再提取出两份，reconstruction1 中的I表示为src_images，和reconstruction2中的I表示为ref_images\n\n使用RANSAC估算两个images集的相似变换\n\n公式参考\n\n\n# RANSAC估算俩堆点云的变换\n\n先初始化一个RANSAC，得到最大迭代次数max_num_trials\n\n# RANSAC过程\n\n * N=∞，sample_count=0\n\n * while N > sample_count\n   \n   * 选择一组样本，并记录它的内点数\n   \n   * 计算外点率e = 1- number_of_inliers/total_number_of_points\n   \n   * 计算最大迭代次数\n     \n     N=log⁡(1−p)log⁡(1−(1−e)s)\n   \n   * sample_count += 1\n\n# LO-RANSAC过程\n\n * N=∞，sample_count=0\n\n * while N > sample_count\n   \n   * 选择一组样本，并记录它的内点数\n   \n   * 计算外点率e = 1- number_of_inliers/total_number_of_points\n     \n     * 随机采样当前最优模型中的内点，估计新的模型（迭代10次），如果优于当前模型，则更新最优模型\n   \n   * 计算最大迭代次数\n     \n     N=log⁡(1−p)log⁡(1−(1−e)s)\n   \n   * sample_count += 1\n\n# 开始迭代\n\n 1. 从俩堆点云中随机采样需要的最少点数X_rand, Y_rand\n 2. 从当前的采样中，估算model Estimate(X_rand, Y_rand)\n 3. 局部优化\n\n# 计算残差\n\n对于每张图像，确定从一个图像正确投影到另一个图像以及从另一个图像正确投影回来的3D点的比率，考虑给定的对齐方式。残差定义为1减去这个比率，即误差阈值为0.3意味着该图像的70％点必须在给定的最大重投影误差阈值内重新投影。\n\n 1. 遍历所有公共图像\n\n 2. 遍历该图像中所有的特征点，并且该特征点在图像1和图像2都存在对应的3D点，num_common_points+1\n\n\n\n 3.  计算双向误差，如果小于最大重投影误差，则num_inliers+1\n 4.  计算外点率negative_inlier_ratio = 1- num_inliers/num_common_points\n 5.  如果统计外点率negative_inlier_ratio < max_residual，则support.num_inliers+1\n 6.  对比内点数，如果内点数相同，则比较外点率，更新当前最优模型\n 7.  随机采样当前最优模型中的内点，估计新的模型\n 8.  再对比新的模型是不是比上一步的最优模型的内点数更多\n 9.  更新最大迭代次数\n 10. 结束迭代，取出最优模型\n\n\n# Merge\n\n对比传入的reconstruction，生成common_image_ids 和 missing_image_ids，将missing_image_ids中的图像注册到当前的reconstruction中，注册很简单，将它本身的位姿乘以俩reconstruction的相似变换\n\nP′=s⋅(Rt01)⋅T−1\n\n使用以下两种规则进行点云合并\n\n * 复制非冲突的点云到当前重建中，即那些在当前重建中没有被三角化观测到的点。\n * 合并无歧义的tracks，即只将两个重建中的点合并，如果它们有一个一对一的映射。\n\n 1. 遍历传入的点云中的所有3D点\n    * 遍历这个3D点的track\n      * 如果当前这个track在common_imgaes中，加入到old_track中\n      * 如果当前这个track在missing_images中，加入到new_track中\n 2. 将3D点添加到当前的reconstruction中\n 3. 如果当前的reconstruction中已经存在这个新添加的3D点，那么将它们合并\n\n\n# Filter\n\n# 计算重投影误差\n\nPc=R⋅P+t(uv1)=1z⋅K⋅Pce2=‖(uv)−(pxpy)‖2\n\n如果大于一定重投影误差值，则将该3D点删除\n\n\n# 图割\n\n# Partition\n\n读取所有的边已经边的内点数，作为权重\n\nDATASETS   IMAGES   COLMAP                    THEIASFM                  LUD                       OURS\n                    NC      NP       T        NC      NP       T        NC      NP       T        NC      NP       T\n数学         96       53153   933523   353545   53153   933523   353545   53153   933523   353545   53153   933523   353545\n数学         96       53153   933523   353545   53153   933523   353545   53153   933523   353545   53153   933523   353545\n英语         92       53153   933523   353545   53153   933523   353545   53153   933523   353545   53153   933523   353545",normalizedContent:"# 实现流程\n\n\n# 计算模型之间的相似变换\n\n输入两个要对齐的模型，输出他们之间的相似变换矩阵alignment\n\n设置ransac的一些参数，最大误差，和内点率\n\n找到两个模型之间的公共图片i\n\n再提取出两份，reconstruction1 中的i表示为src_images，和reconstruction2中的i表示为ref_images\n\n使用ransac估算两个images集的相似变换\n\n公式参考\n\n\n# ransac估算俩堆点云的变换\n\n先初始化一个ransac，得到最大迭代次数max_num_trials\n\n# ransac过程\n\n * n=∞，sample_count=0\n\n * while n > sample_count\n   \n   * 选择一组样本，并记录它的内点数\n   \n   * 计算外点率e = 1- number_of_inliers/total_number_of_points\n   \n   * 计算最大迭代次数\n     \n     n=log⁡(1−p)log⁡(1−(1−e)s)\n   \n   * sample_count += 1\n\n# lo-ransac过程\n\n * n=∞，sample_count=0\n\n * while n > sample_count\n   \n   * 选择一组样本，并记录它的内点数\n   \n   * 计算外点率e = 1- number_of_inliers/total_number_of_points\n     \n     * 随机采样当前最优模型中的内点，估计新的模型（迭代10次），如果优于当前模型，则更新最优模型\n   \n   * 计算最大迭代次数\n     \n     n=log⁡(1−p)log⁡(1−(1−e)s)\n   \n   * sample_count += 1\n\n# 开始迭代\n\n 1. 从俩堆点云中随机采样需要的最少点数x_rand, y_rand\n 2. 从当前的采样中，估算model estimate(x_rand, y_rand)\n 3. 局部优化\n\n# 计算残差\n\n对于每张图像，确定从一个图像正确投影到另一个图像以及从另一个图像正确投影回来的3d点的比率，考虑给定的对齐方式。残差定义为1减去这个比率，即误差阈值为0.3意味着该图像的70％点必须在给定的最大重投影误差阈值内重新投影。\n\n 1. 遍历所有公共图像\n\n 2. 遍历该图像中所有的特征点，并且该特征点在图像1和图像2都存在对应的3d点，num_common_points+1\n\n\n\n 3.  计算双向误差，如果小于最大重投影误差，则num_inliers+1\n 4.  计算外点率negative_inlier_ratio = 1- num_inliers/num_common_points\n 5.  如果统计外点率negative_inlier_ratio < max_residual，则support.num_inliers+1\n 6.  对比内点数，如果内点数相同，则比较外点率，更新当前最优模型\n 7.  随机采样当前最优模型中的内点，估计新的模型\n 8.  再对比新的模型是不是比上一步的最优模型的内点数更多\n 9.  更新最大迭代次数\n 10. 结束迭代，取出最优模型\n\n\n# merge\n\n对比传入的reconstruction，生成common_image_ids 和 missing_image_ids，将missing_image_ids中的图像注册到当前的reconstruction中，注册很简单，将它本身的位姿乘以俩reconstruction的相似变换\n\np′=s⋅(rt01)⋅t−1\n\n使用以下两种规则进行点云合并\n\n * 复制非冲突的点云到当前重建中，即那些在当前重建中没有被三角化观测到的点。\n * 合并无歧义的tracks，即只将两个重建中的点合并，如果它们有一个一对一的映射。\n\n 1. 遍历传入的点云中的所有3d点\n    * 遍历这个3d点的track\n      * 如果当前这个track在common_imgaes中，加入到old_track中\n      * 如果当前这个track在missing_images中，加入到new_track中\n 2. 将3d点添加到当前的reconstruction中\n 3. 如果当前的reconstruction中已经存在这个新添加的3d点，那么将它们合并\n\n\n# filter\n\n# 计算重投影误差\n\npc=r⋅p+t(uv1)=1z⋅k⋅pce2=‖(uv)−(pxpy)‖2\n\n如果大于一定重投影误差值，则将该3d点删除\n\n\n# 图割\n\n# partition\n\n读取所有的边已经边的内点数，作为权重\n\ndatasets   images   colmap                    theiasfm                  lud                       ours\n                    nc      np       t        nc      np       t        nc      np       t        nc      np       t\n数学         96       53153   933523   353545   53153   933523   353545   53153   933523   353545   53153   933523   353545\n数学         96       53153   933523   353545   53153   933523   353545   53153   933523   353545   53153   933523   353545\n英语         92       53153   933523   353545   53153   933523   353545   53153   933523   353545   53153   933523   353545",charsets:{cjk:!0}},{title:"EC-SfM",frontmatter:{title:"EC-SfM",date:"2023-04-21T09:34:49.000Z",permalink:"/pages/f12e80/"},regularPath:"/02.%E7%A7%91%E7%A0%94/03.%E6%88%91%E7%9A%84%E5%B7%A5%E4%BD%9C/20.EC.html",relativePath:"02.科研/03.我的工作/20.EC.md",key:"v-37fa14fa",path:"/pages/f12e80/",headersStr:null,content:"基于协同可见性的高效增量SfM。利用共视性和注册依赖性来描述用于任何类型的数据的图像连接。\n\n笔记\n\n顺序策略的本质是在知道顺序数据中相邻帧的大重叠情况下，减少冗余匹配和优化\n\n从图像中提取共视关系和配准依赖关系，以更好地描述各种数据中的内部关系。\n\n警告\n\n依赖于频繁的BA来减少累计误差，但这带来了沉重的计算复杂度\n\n笔记\n\n基于层次的关键帧选择和纠错模块",normalizedContent:"基于协同可见性的高效增量sfm。利用共视性和注册依赖性来描述用于任何类型的数据的图像连接。\n\n笔记\n\n顺序策略的本质是在知道顺序数据中相邻帧的大重叠情况下，减少冗余匹配和优化\n\n从图像中提取共视关系和配准依赖关系，以更好地描述各种数据中的内部关系。\n\n警告\n\n依赖于频繁的ba来减少累计误差，但这带来了沉重的计算复杂度\n\n笔记\n\n基于层次的关键帧选择和纠错模块",charsets:{cjk:!0}},{title:"keyframe2",frontmatter:{title:"keyframe2",date:"2023-05-19T09:07:14.000Z",permalink:"/pages/bcf6cd/"},regularPath:"/02.%E7%A7%91%E7%A0%94/03.%E6%88%91%E7%9A%84%E5%B7%A5%E4%BD%9C/32.keyfram2.html",relativePath:"02.科研/03.我的工作/32.keyfram2.md",key:"v-e8e0160c",path:"/pages/bcf6cd/",headers:[{level:2,title:"关键帧选择",slug:"关键帧选择",normalizedTitle:"关键帧选择",charIndex:82},{level:3,title:"额外补充",slug:"额外补充",normalizedTitle:"额外补充",charIndex:315},{level:2,title:"优化普通帧",slug:"优化普通帧",normalizedTitle:"优化普通帧",charIndex:448}],headersStr:"关键帧选择 额外补充 优化普通帧",content:"这次偏向于选择观测点数少的帧，作为关键帧。因为BA的本质是，优化位姿，减小重投影误差。挑选出的关键帧会被优化多次，所以关键帧应该挑选出认为还没优化好的帧。\n\n\n# 关键帧选择\n\n遍历所有已经配准的帧，建立位姿副本。\n\n 1. 遍历该帧所有的三维点，遍历三维点所有的track，track包含如果包含有关键帧，那么三维点被3个以上关键帧track到，那么这个点称为冗余三维点，如果冗余三维点小于200，那么称该帧为关键帧。\n 2. 如果不是关键帧，那么该帧至少与一个关键帧相连。\n 3. 如果还不是关键帧，找到前后两个最近的关键帧，计算两个关键帧之间有多少个共视三维点，少于阈值就是关键帧。\n\n执行到这，说明该帧不是关键帧\n\n\n# 额外补充\n\n将循环匹配帧设为关键帧\n\n根据共视关系选择参考帧：遍历每一帧所有三维点，遍历每个三维点的track，找到那个关键帧，这个关键帧观测该帧最多的三维点。那么就设这个关键帧为该帧的参考帧。\n\n如果没有共视的关键帧，那么就前后找最近的关键帧作为参考帧。\n\n\n# 优化普通帧\n\n根据上述，普通帧都有一个关键帧作为它的参考帧，根据绑定关系，将关键帧的优化结果传递到普通帧。",normalizedContent:"这次偏向于选择观测点数少的帧，作为关键帧。因为ba的本质是，优化位姿，减小重投影误差。挑选出的关键帧会被优化多次，所以关键帧应该挑选出认为还没优化好的帧。\n\n\n# 关键帧选择\n\n遍历所有已经配准的帧，建立位姿副本。\n\n 1. 遍历该帧所有的三维点，遍历三维点所有的track，track包含如果包含有关键帧，那么三维点被3个以上关键帧track到，那么这个点称为冗余三维点，如果冗余三维点小于200，那么称该帧为关键帧。\n 2. 如果不是关键帧，那么该帧至少与一个关键帧相连。\n 3. 如果还不是关键帧，找到前后两个最近的关键帧，计算两个关键帧之间有多少个共视三维点，少于阈值就是关键帧。\n\n执行到这，说明该帧不是关键帧\n\n\n# 额外补充\n\n将循环匹配帧设为关键帧\n\n根据共视关系选择参考帧：遍历每一帧所有三维点，遍历每个三维点的track，找到那个关键帧，这个关键帧观测该帧最多的三维点。那么就设这个关键帧为该帧的参考帧。\n\n如果没有共视的关键帧，那么就前后找最近的关键帧作为参考帧。\n\n\n# 优化普通帧\n\n根据上述，普通帧都有一个关键帧作为它的参考帧，根据绑定关系，将关键帧的优化结果传递到普通帧。",charsets:{cjk:!0}},{title:"colmap增量代码",frontmatter:{title:"colmap增量代码",date:"2023-05-10T19:34:04.000Z",permalink:"/pages/0a2951/"},regularPath:"/02.%E7%A7%91%E7%A0%94/03.%E6%88%91%E7%9A%84%E5%B7%A5%E4%BD%9C/35.colmap%E5%A2%9E%E9%87%8F.html",relativePath:"02.科研/03.我的工作/35.colmap增量.md",key:"v-d5f92e9a",path:"/pages/0a2951/",headers:[{level:2,title:"RunSparseMapper",slug:"runsparsemapper",normalizedTitle:"runsparsemapper",charIndex:11},{level:3,title:"FindNext",slug:"findnext",normalizedTitle:"findnext",charIndex:1181},{level:3,title:"RegisterNextImage",slug:"registernextimage",normalizedTitle:"registernextimage",charIndex:1304},{level:3,title:"EstimateAbsolutePose",slug:"estimateabsolutepose",normalizedTitle:"estimateabsolutepose",charIndex:1382},{level:3,title:"RefineAbsolutePose",slug:"refineabsolutepose",normalizedTitle:"refineabsolutepose",charIndex:1457},{level:3,title:"TriangulateImage",slug:"triangulateimage",normalizedTitle:"triangulateimage",charIndex:1499},{level:3,title:"IterativeLocalRefinement",slug:"iterativelocalrefinement",normalizedTitle:"iterativelocalrefinement",charIndex:1528},{level:3,title:"IterativeGlobalRefinement",slug:"iterativeglobalrefinement",normalizedTitle:"iterativeglobalrefinement",charIndex:1572}],headersStr:"RunSparseMapper FindNext RegisterNextImage EstimateAbsolutePose RefineAbsolutePose TriangulateImage IterativeLocalRefinement IterativeGlobalRefinement",content:'稀疏重建入口\n\n\n# RunSparseMapper\n\nvoid AutomaticReconstructionController::RunSparseMapper() {\n  const auto sparse_path = JoinPaths(options_.workspace_path, "sparse");\n  if (ExistsDir(sparse_path)) {\n    auto dir_list = GetDirList(sparse_path);\n    std::sort(dir_list.begin(), dir_list.end());\n    if (dir_list.size() > 0) {\n      std::cout << std::endl\n                << "WARNING: Skipping sparse reconstruction because it is "\n                   "already computed"\n                << std::endl;\n      for (const auto& dir : dir_list) {\n        reconstruction_manager_->Read(dir);\n      }\n      return;\n    }\n  }\n\n  IncrementalMapperController mapper(\n      option_manager_.mapper.get(), *option_manager_.image_path,\n      *option_manager_.database_path, reconstruction_manager_);\n  active_thread_ = &mapper;\n  mapper.Start();\n  mapper.Wait();\n  active_thread_ = nullptr;\n\n  CreateDirIfNotExists(sparse_path);\n  reconstruction_manager_->Write(sparse_path, &option_manager_);\n}\n\n\nImage\n\n与另一幅图像至少有一个对应关系的 2D 点数。num_observations\n\n与其它图像的关联总数num_correspondences\n\n图像的每个特征点都有一个vector，由于存放与该特征点匹配的track（image_id, point2D_id）\n\nstd::vector<std::vector<Correspondence>> corrs;\n\n遍历所有的边，更新corrs\n\n\n# FindNext\n\n将所有未注册的图像，按照某种得分策略排序\n\n * 图像的可见3D点，2D-3D关联\n * 图像的可见3D点比率\n * 论文中的next best view策略\n\nvector<image_t> next_images\n\n\n# RegisterNextImage\n\n遍历vector<image_t> next_images，如果成功了就break\n\n寻找2D-3D点的关联\n\n\n# EstimateAbsolutePose\n\n对于不同的focal_length_factors，都进行一次位姿估计，最终选择内点数最多的估计\n\n\n# RefineAbsolutePose\n\n对当前帧观测到的3D点进行BA一次\n\n\n# TriangulateImage\n\n生成新的观测\n\n\n# IterativeLocalRefinement\n\n对改变了的观测进行一次BA\n\n\n# IterativeGlobalRefinement\n\n如果模型增长一定比率，则进行全局BA\n\n对已经配准的图像对，重新进行一次三角化',normalizedContent:'稀疏重建入口\n\n\n# runsparsemapper\n\nvoid automaticreconstructioncontroller::runsparsemapper() {\n  const auto sparse_path = joinpaths(options_.workspace_path, "sparse");\n  if (existsdir(sparse_path)) {\n    auto dir_list = getdirlist(sparse_path);\n    std::sort(dir_list.begin(), dir_list.end());\n    if (dir_list.size() > 0) {\n      std::cout << std::endl\n                << "warning: skipping sparse reconstruction because it is "\n                   "already computed"\n                << std::endl;\n      for (const auto& dir : dir_list) {\n        reconstruction_manager_->read(dir);\n      }\n      return;\n    }\n  }\n\n  incrementalmappercontroller mapper(\n      option_manager_.mapper.get(), *option_manager_.image_path,\n      *option_manager_.database_path, reconstruction_manager_);\n  active_thread_ = &mapper;\n  mapper.start();\n  mapper.wait();\n  active_thread_ = nullptr;\n\n  createdirifnotexists(sparse_path);\n  reconstruction_manager_->write(sparse_path, &option_manager_);\n}\n\n\nimage\n\n与另一幅图像至少有一个对应关系的 2d 点数。num_observations\n\n与其它图像的关联总数num_correspondences\n\n图像的每个特征点都有一个vector，由于存放与该特征点匹配的track（image_id, point2d_id）\n\nstd::vector<std::vector<correspondence>> corrs;\n\n遍历所有的边，更新corrs\n\n\n# findnext\n\n将所有未注册的图像，按照某种得分策略排序\n\n * 图像的可见3d点，2d-3d关联\n * 图像的可见3d点比率\n * 论文中的next best view策略\n\nvector<image_t> next_images\n\n\n# registernextimage\n\n遍历vector<image_t> next_images，如果成功了就break\n\n寻找2d-3d点的关联\n\n\n# estimateabsolutepose\n\n对于不同的focal_length_factors，都进行一次位姿估计，最终选择内点数最多的估计\n\n\n# refineabsolutepose\n\n对当前帧观测到的3d点进行ba一次\n\n\n# triangulateimage\n\n生成新的观测\n\n\n# iterativelocalrefinement\n\n对改变了的观测进行一次ba\n\n\n# iterativeglobalrefinement\n\n如果模型增长一定比率，则进行全局ba\n\n对已经配准的图像对，重新进行一次三角化',charsets:{cjk:!0}},{title:"Keyframe3",frontmatter:{title:"Keyframe3",date:"2023-05-23T10:22:40.000Z",permalink:"/pages/a0d165/"},regularPath:"/02.%E7%A7%91%E7%A0%94/03.%E6%88%91%E7%9A%84%E5%B7%A5%E4%BD%9C/36.keyframe3.html",relativePath:"02.科研/03.我的工作/36.keyframe3.md",key:"v-2ff99942",path:"/pages/a0d165/",headersStr:null,content:"启发于IterativeLocalRefinement模块\n\n该模块的优化方式为，对于每成功配准的一副图像，基于该图像中观测到的3D点，与该图像有共同观测的图像均加入的BA中。由一扩展到多的步骤。\n\n应用到全局BA，可以将其扩展成，由多到多的关系。\n\n对于两次全局BA之间的添加注册的帧，将其放入一个集合\n\n对于全局BA需要的优化的帧，也就是与该集合有共同观测的所有帧。",normalizedContent:"启发于iterativelocalrefinement模块\n\n该模块的优化方式为，对于每成功配准的一副图像，基于该图像中观测到的3d点，与该图像有共同观测的图像均加入的ba中。由一扩展到多的步骤。\n\n应用到全局ba，可以将其扩展成，由多到多的关系。\n\n对于两次全局ba之间的添加注册的帧，将其放入一个集合\n\n对于全局ba需要的优化的帧，也就是与该集合有共同观测的所有帧。",charsets:{cjk:!0}},{title:"《遥远的救世主》",frontmatter:{title:"《遥远的救世主》",date:"2023-05-28T16:17:36.000Z",permalink:"/pages/7cc66a/"},regularPath:"/03.%E7%94%9F%E6%B4%BB/05.%E9%81%A5%E8%BF%9C%E7%9A%84%E6%95%91%E4%B8%96%E4%B8%BB.html",relativePath:"03.生活/05.遥远的救世主.md",key:"v-4055a79c",path:"/pages/7cc66a/",headers:[{level:2,title:"丁元英",slug:"丁元英",normalizedTitle:"丁元英",charIndex:64},{level:2,title:"芮小丹",slug:"芮小丹",normalizedTitle:"芮小丹",charIndex:242},{level:2,title:"欧阳雪",slug:"欧阳雪",normalizedTitle:"欧阳雪",charIndex:306},{level:2,title:"叶晓明",slug:"叶晓明",normalizedTitle:"叶晓明",charIndex:349},{level:2,title:"冯世杰",slug:"冯世杰",normalizedTitle:"冯世杰",charIndex:472},{level:2,title:"刘冰",slug:"刘冰",normalizedTitle:"刘冰",charIndex:533},{level:2,title:"其它",slug:"其它",normalizedTitle:"其它",charIndex:690}],headersStr:"丁元英 芮小丹 欧阳雪 叶晓明 冯世杰 刘冰 其它",content:"看完能学到不少，我看的角度是人物的性格，做事方式，思考方式。我觉得剧情和逻辑作用是为了突出人物的，本身或许不具备价值。\n\n\n# 丁元英\n\n冷静，沉稳，做事有条理，有规划，能够透过现象看本质，知其然知其所以然。能够看透人性，市场的运行逻辑，懂得如何处理人情世故。其中格律诗利用廉价的人力成本，与知名乐胜公司竞争，这里与比亚迪公司初期造电池有相似之处。但人太冷静有时会显得冷血。打破常规，不按常理出牌，本质原因是没有人能够理解他，所以对于不同层次的人看到，会觉得他是疯子，魔鬼。\n\n\n# 芮小丹\n\n善良，聪明，热爱工作，坚守本职。有想法，有能力，敢闯。如果遇到不理解的，意见不合，她依然不会停下自己的脚步。\n\n\n# 欧阳雪\n\n刻苦，不爱慕虚荣，只想好好经营自己的饭店，有实力，很有大姐的风范。\n\n\n# 叶晓明\n\n踏实，谨慎。想成就一番事业，但是没有经验。靠丁当上总经理后，听从丁不炫耀，不卖弄，也很谨慎处理各种事情。但是被起诉后，没有先验知识只能撤退保全自己。退股后安心回到自己平静的生活。人和人之间的道德，放在公司和公司之间是不管用的。\n\n\n# 冯世杰\n\n踏实，一心只想王庙村，退股后，想到村民欠格律诗设备钱，用自己的股份偿还，并且又回到原来那个平静的生活。\n\n\n# 刘冰\n\n没有一个良好的自我认知，遇到问题后先是怪罪环境。\n\n----------------------------------------\n\n小说故事开头，丁来到古城，结尾，丁离开古城。离开时欧阳雪看着丁的背影，会有那种感觉，丁就是救世主。但是全篇我觉得都是讲要实事求是，奋斗，只有自己是自己的救世主。\n\n\n# 其它\n\n昨天晚上刷到B站视频吐槽这是垃圾之作，差点没睡着。\n\n视频内容大概讲了，对于up主自认为佛道学的很不错，抛出一堆啥啥啥句子，证明书中的佛学理解错了用错了。举例鄙视行文逻辑，认为乐胜那么大的公司，在不了解情况下去起诉格律诗，是神经病。\n\n看完之后我知道，up发这个视频，显现出他自视甚高，有点狂，为了批评而去批评。有蹭热度吸引流量的嫌疑。\n\n对于这些视频为什么能吸引流量，我觉得这种视频个人观点输出很高，机具引导性。对于一个什么一些观众来说，会比较浮躁，认为这些up主不错，很有想法，然后观众也很容易理解up的观点。\n\n我认为一些优质视频流量为什么小，难以理解，一会讲这个观点，一会讲那个观点，不静下心来看看不懂。因为不是讲故事，所以需要从各个方面去论证一件事。",normalizedContent:"看完能学到不少，我看的角度是人物的性格，做事方式，思考方式。我觉得剧情和逻辑作用是为了突出人物的，本身或许不具备价值。\n\n\n# 丁元英\n\n冷静，沉稳，做事有条理，有规划，能够透过现象看本质，知其然知其所以然。能够看透人性，市场的运行逻辑，懂得如何处理人情世故。其中格律诗利用廉价的人力成本，与知名乐胜公司竞争，这里与比亚迪公司初期造电池有相似之处。但人太冷静有时会显得冷血。打破常规，不按常理出牌，本质原因是没有人能够理解他，所以对于不同层次的人看到，会觉得他是疯子，魔鬼。\n\n\n# 芮小丹\n\n善良，聪明，热爱工作，坚守本职。有想法，有能力，敢闯。如果遇到不理解的，意见不合，她依然不会停下自己的脚步。\n\n\n# 欧阳雪\n\n刻苦，不爱慕虚荣，只想好好经营自己的饭店，有实力，很有大姐的风范。\n\n\n# 叶晓明\n\n踏实，谨慎。想成就一番事业，但是没有经验。靠丁当上总经理后，听从丁不炫耀，不卖弄，也很谨慎处理各种事情。但是被起诉后，没有先验知识只能撤退保全自己。退股后安心回到自己平静的生活。人和人之间的道德，放在公司和公司之间是不管用的。\n\n\n# 冯世杰\n\n踏实，一心只想王庙村，退股后，想到村民欠格律诗设备钱，用自己的股份偿还，并且又回到原来那个平静的生活。\n\n\n# 刘冰\n\n没有一个良好的自我认知，遇到问题后先是怪罪环境。\n\n----------------------------------------\n\n小说故事开头，丁来到古城，结尾，丁离开古城。离开时欧阳雪看着丁的背影，会有那种感觉，丁就是救世主。但是全篇我觉得都是讲要实事求是，奋斗，只有自己是自己的救世主。\n\n\n# 其它\n\n昨天晚上刷到b站视频吐槽这是垃圾之作，差点没睡着。\n\n视频内容大概讲了，对于up主自认为佛道学的很不错，抛出一堆啥啥啥句子，证明书中的佛学理解错了用错了。举例鄙视行文逻辑，认为乐胜那么大的公司，在不了解情况下去起诉格律诗，是神经病。\n\n看完之后我知道，up发这个视频，显现出他自视甚高，有点狂，为了批评而去批评。有蹭热度吸引流量的嫌疑。\n\n对于这些视频为什么能吸引流量，我觉得这种视频个人观点输出很高，机具引导性。对于一个什么一些观众来说，会比较浮躁，认为这些up主不错，很有想法，然后观众也很容易理解up的观点。\n\n我认为一些优质视频流量为什么小，难以理解，一会讲这个观点，一会讲那个观点，不静下心来看看不懂。因为不是讲故事，所以需要从各个方面去论证一件事。",charsets:{cjk:!0}},{title:"一时苦难",frontmatter:{title:"一时苦难",date:"2023-06-19T09:59:32.000Z",permalink:"/pages/149c7c/"},regularPath:"/02.%E7%A7%91%E7%A0%94/03.%E6%88%91%E7%9A%84%E5%B7%A5%E4%BD%9C/38.%E8%8B%A6%E9%9A%BE.html",relativePath:"02.科研/03.我的工作/38.苦难.md",key:"v-0545b0a1",path:"/pages/149c7c/",headers:[{level:2,title:"复杂区域的三维模型快速重建",slug:"复杂区域的三维模型快速重建",normalizedTitle:"复杂区域的三维模型快速重建",charIndex:2},{level:3,title:"一、完成的内容",slug:"一、完成的内容",normalizedTitle:"一、完成的内容",charIndex:20},{level:3,title:"二、所采用的方法以及取得的成果",slug:"二、所采用的方法以及取得的成果",normalizedTitle:"二、所采用的方法以及取得的成果",charIndex:300},{level:3,title:"三、创新点",slug:"三、创新点",normalizedTitle:"三、创新点",charIndex:18672}],headersStr:"复杂区域的三维模型快速重建 一、完成的内容 二、所采用的方法以及取得的成果 三、创新点",content:"# 复杂区域的三维模型快速重建\n\n\n# 一、完成的内容\n\n本系统旨在研究基于特征点提取和匹配的三维重建方法，利用多张图像中的特征点信息，恢复物体或场景的三维几何结构。本系统主要完成了以下内容：\n\n• 调研了国内外相关领域的研究现状和发展趋势，分析了三维重建的基本原理和关键技术，总结了三维重建的常用方法和评价指标。\n\n• 设计并实现了一个基于特征点提取和匹配的三维重建系统，包括特征检测、描述、匹配、去噪、相机标定、姿态计算、三维重建、优化、稠密重建和纹理重建等模块。\n\n• 在公开数据集上对所提出的系统进行了测试和评估，与其他三维重建方法进行了对比分析，验证了所提出方法的有效性和优越性。\n\n\n# 二、所采用的方法以及取得的成果\n\nSfM 是将 3D 结构从其投影重建为一系列从不同视点拍摄的图像的过程。增量 SfM（在本文中表示为 SfM）是一种具有迭代重建组件的顺序处理流水线。它通常从特征提取和匹配开始，然后是几何验证。生成的场景图作为重建阶段的基础，在逐步注册新图像、三角测量场景点、过滤异常值并使用束调整 (BA) 改进重建之前，该阶段使用精心选择的双视图重建为模型播种。以下介绍我们系统所采用的的方法，以及取得的成果。\n\n 1. 相机标定\n\n相机标定的过程是指通过一些已知的几何信息，来求解相机的内部参数，从而建立三维空间点和二维图像点之间的对应关系。\n\n一般来说，相机标定的步骤如下：\n\n * 准备一个标定物，通常是一个带有黑白棋盘格的平面，其角点的世界坐标系和图像坐标系是已知的。\n * 用相机从不同的角度和位置拍摄标定物的照片，至少需要三张以上。\n * 从照片中提取棋盘格的角点，得到每个角点在像素坐标系下的坐标。\n * 根据相机成像模型，建立三维空间点和二维图像点之间的投影关系，利用单应矩阵、透视投影、畸变校正等方法，求解相机的内部参数。\n * 利用最小二乘法或其他优化方法，对求解出的参数进行优化和误差分析。\n\n对于相机内部参数，我们系统中提供优化相机内参的算法，即使不通过相机标定的步骤获得相机内部参数，我们系统也可以通过算法来估计得到相对准确的相机内部参数，若追求更好的更准确的三维模型，一般是手动进行相机标定，将相机内部参数作为固定值。\n\n 2. 图像采集\n\nSFM过程中的图像采集过程是指从多个角度拍摄同一场景的图片，并按序号进行保存，以便后续进行特征提取，匹配，重建等步骤。\n\n * 图像的质量要高，清晰度要好，避免模糊，曝光过度或不足等问题。\n * 图像的数量要适中，不要太少或太多，太少会导致重建不完整或不准确，太多会增加计算量和内存消耗。\n * 图像的视角要有一定的重叠度，一般建议在60%~80%之间，以便提高特征匹配的成功率和稳定性。\n * 图像的视角要有一定的视差，即相机之间的相对位姿要有足够的变化，以便恢复出三维结构。如果图像之间的视差太小，可能会导致奇异性或退化情况。\n * 图像的拍摄环境要尽量保持一致，避免光照，阴影，反射等因素的干扰。同时，场景中的物体要尽量是静止的，避免动态物体的影响。\n\n 3. 特征提取\n\nSFM过程中的图像特征提取过程是指从图像中提取具有尺度和旋转不变性的特征点和描述子，以便后续进行特征匹配，计算基础矩阵，恢复相机位姿和三维结构等步骤。\n\n以下红色点为我们提取的特征点\n\n\n\n * 特征点的数量要适中，不要太少或太多，太少会导致匹配不稳定或失败，太多会增加计算量和内存消耗。\n * 特征点的分布要均匀，不要集中在某些区域，以便提高匹配的鲁棒性和准确性。\n * 特征点的描述子要具有较强的区分度，不要与其他特征点混淆，以便降低误匹配的概率。\n * 特征点的类型要适合场景的特点，例如对于纹理丰富的场景，可以使用SIFT，SURF等特征点，对于纹理较少的场景，可以使用Harris，FAST等角点。\n\n以下详细介绍我们采用的FAST角点。\n\n构建高斯尺度空间，产生不同尺度的高斯模糊图像。\n\n\n\n进行降采样，得到一系列尺寸不断缩小的图像，计算高斯差分函数。\n\nG(xi,yi,σ)=12πσ2exp(−((x−xi)2−(y−yi)22σ2))L(x,y,σ)=G(x,y,σ)∗I(x,y)\n\nDoG 空间极值检测：寻找 DoG 函数的极值点，每一个像素点和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。\n\n确定特征向量主方向:通过每个极值点的梯度来为极值点赋予方向，梯度幅值等于上 下两点像素值差的平方加上左右两点像素值差的平方，梯度方向则为上下两点像素值差与左 右两点像素值差的商。\n\n梯度幅值\n\nm(x,y)=(L(x+1,y)−L(x−1,y))2+(L(x,y+1)−L(x,y−1))2\n\n梯度方向\n\nθ(x,y)=tan−1(L(x,y+1)−L(x,y−1)L(x+1,y)−L(x−1,y))\n\n计算特征向量\n\n求取每个像素的梯度幅值与梯度方向，箭头方向代表该像素的梯度方向，长度代表梯度幅值，然后利用高斯窗口对其进行加权运算。在每个小块上绘制 8 个方向的梯度直方图，计算每个梯度方向的累加值。\n\n\n\n最终每个小块获得4 ∗ 4 ∗ 8 = 128 维的特征向量\n\n 4. 特征匹配\n\nSFM过程中的图像特征匹配过程是指从两两相邻的图像中找出具有相同或相似特征的点对，以便后续进行基础矩阵，本质矩阵，单应矩阵的计算，恢复相机位姿和三维结构等步骤。\n\n\n\n * 特征匹配的方法要适合特征点的类型和数量，可以使用暴力匹配，KD树，FLANN等方法。\n * 特征匹配的结果要满足一一对应的原则，即一个特征点只能匹配到另一个图像中的一个特征点，不能出现多对一或一对多的情况。\n * 特征匹配的结果要满足几何一致性的约束，即匹配点对之间要符合对极几何关系，可以使用基础矩阵或本质矩阵来检验和筛选。\n * 特征匹配的结果要满足运动一致性的约束，即匹配点对之间要符合相机运动模型，可以使用单应矩阵来检验和筛选。\n\n匹配结果如下\n\n\n\n我们系统中提供多种图像匹配方式，顺序匹配，词汇树匹配，暴力匹配，GPS空间匹配。\n\n * 顺序匹配\n\n对于顺序采集的图像，可以采用这一种方式进行图像间的匹配。这一种的匹配过程为，将所有图像进行编号后，对于每一张图像，我们取它先前的10张图像进行一一匹配，与这10张图像分别建立图像匹配关系，以便后续步骤用。除此之外，我们增加一个回环检测策略，每隔一定图像数量后，对图像进行一次回环检测，也就说，这一次匹配的目标图像不仅是先前的10张，而是先前随机的N张，用这种策略与更久远的图像建立匹配关系，从而达到检测回环的功能。对于顺序匹配，可以很快速的完成所有图像的匹配，并且有一定的检测回环能力，对于追求快速，采集的图像是顺序序列，则可以采用这种方式进行图像匹配。\n\n * 词汇树匹配\n\n对于词汇树匹配，需要我们在进行三维重建之前，构建一个词汇树，该词汇树，指导系统进行匹配。简单来说，需要训练一个模型，该模型覆盖了本次进行三维重建的所有场景，以至于我们拍摄的图像，可以明确推理出该图像是属于哪一部分场景，进而将属于某一场景的所有图像进行互相匹配。这种方式的匹配过程较为精确，而且高效，因为仅仅是属于某一场景的图像才进行相互匹配，并不会把两张毫无相干的图像进行互相匹配来浪费时间。这种匹配方式的精度取决于词汇树的构建，词汇树模型构建的精确，则匹配精确。\n\n * 暴力匹配\n\n对于暴力匹配，最简单的方式为，两两图像进行匹配，但是这种方式性能很差，可以稍微改进一下。我们将其改为，分块匹配。将所有图像进行分块，对块和块之间的图像进行匹配。这种方式性能较差，若没有图像的额外信息，才会使用该方式进行图像匹配。\n\n * GPS空间匹配\n\n对于GPS空间匹配，与词汇树匹配类似，利用GPS信息，确定图像某个具体范围位置，对存在于该范围的图像，我们进行两两匹配，对于无人机采集的图像，我们一般采用这种方式进行图像匹配。\n\n 5. 构建场景图\n\n使用一种图论的方法来表示和优化图像之间的匹配关系，从而提高重建的效率和质量。\n\n * 构建场景图的目的是为了找出最优的图像对来进行三角化和位姿估计，避免使用冗余或错误的匹配信息。\n\n * 构建场景图的方法是将所有图像看作一个无向图的节点，将两个图像之间的匹配点数或者重叠度看作边的权重，然后使用最小生成树算法（如Prim或Kruskal）来找出最大权重的边，形成一个连通且无环的子图。\n\n * 构建场景图的过程可以分为两个阶段：第一个阶段是根据所有图像对之间的匹配点数或者重叠度来构建一个初始的最大生成树；第二个阶段是根据每个图像对之间的几何一致性（如基础矩阵或单应矩阵）来对初始的最大生成树进行修剪和优化，去除错误或不稳定的边。\n\n * 构建场景图的结果是一个包含所有图像节点和部分匹配边的最大生成树，这个树可以用来指导后续的重建步骤，例如选择初始图像对，添加新的图像，进行局部或全局优化等。\n\n由于增量式SfM（Structure from Motion，运动结构恢复）需要在每次添加图像后都进行一次局部或全局的捆绑调整（Bundle Adjustment），这会导致效率较低，而且由于误差累积，容易出现漂移问题。因此，我需要使用图论的方式来表示和优化图像之间的匹配关系，从而提高重建的效率和质量。具体来说，我可以将所有图像看作一个无向图的节点，将两个图像之间的匹配点数或者重叠度看作边的权重，然后使用最小生成树算法（如Prim或Kruskal）来找出最大权重的边，形成一个连通且无环的子图。这样，我就可以根据这个子图来指导后续的重建步骤，例如选择初始图像对，添加新的图像，进行局部或全局优化等。\n\n我们的目标是使用图像的方式来重建三维模型，但是由于增量式的SfM算法效率较低，容易出现误差累积和漂移问题，所以你需要对图像之间的匹配关系进行优化。我们的思路是使用图论的方法，将图像间的匹配关系表示为一个无向图，其中每个顶点代表一张图像，每条边代表两张图像之间存在共同的可见区域。然后你将使用最大生成树算法，从这个无向图中找出一棵包含所有顶点且边权值之和最大的树。边权值可以根据两张图像之间的匹配点数目、基线长度、三角量测角度等因素来确定。最大生成树可以保证你选取的图像对具有较好的视角和匹配质量，从而提高重建效果。接下来，你将使用图割算法，将最大生成树划分为多个子图。图割算法可以根据子图中顶点和边的个数、边权值之和等条件来确定划分方案。划分后的子图可以看作是相对独立的小型场景，对每个子图单独进行增量式SfM重建，得到相机参数和三维点坐标。最后，你将使用捆绑调整算法，对所有子图进行全局优化，消除误差累积和漂移，并将所有子图合并为最终模型。\n\n 6. 增量SfM重建\n\n在增量式sfm中，选择下一幅图像的目的是为了扩展重建模型，增加场景覆盖范围和减少误差累积。选择下一幅图像的原则是要保证与已经重建的图像有足够多的匹配点，且具有较好的视差角度，以便于进行三角化和PnP。一种常用的方法是根据图像之间的匹配点数目、基线长度、三角量测角度等因素来确定边权值，然后从子图中找出一棵最大生成树，按照树的深度优先顺序遍历图像。这里我们采用一种下一个最佳视图策略来找到当前最适合重建的图像。\n\n下一个最佳视图规划已经在计算机视觉、摄影测量和机器人技术领域进行了研究 。在稳健的 SfM 中选择下一个最佳视图旨在最小化重建误差。在这里，我们提出了一种有效的下一个最佳视图策略，遵循一种最大化重建鲁棒性的不确定性驱动方法。选择下一个最佳视图至关重要，因为每个决定都会影响剩余的重建。一个错误的决定可能会导致一连串的相机错误注册和错误的三角测量。此外，选择下一个最佳视图会极大地影响姿势估计的质量以及三角测量的完整性和准确性。准确的姿态估计对于稳健的 SfM 至关重要，因为如果姿态不准确，点三角测量可能会失败。\n\n下一个最佳视图的候选者不是至少看到 Nt > 0 个三角点的尚未注册的图像。使用特征轨迹图可以有效地跟踪此统计信息。对于 Internet 数据集，此图可能非常密集，因为许多图像可能会看到相同的结构。因此，在重建的每一步都有许多候选视图可供选择。 Haner 等人提出的详尽协方差传播。是不可行的，因为需要在每个步骤中为每个候选者计算和分析协方差。我们提出的方法使用高效的多分辨率分析来近似他们的不确定性驱动方法。我们必须同时跟踪每个候选图像中可见点的数量及其分布。更多的可见点和这些点的更均匀分布应该导致更高的分数 S，这样具有更好条件的可见点配置的图像首先被注册。为了实现这个目标，我们将图像离散化为一个固定大小的网格，在两个维度上都有 Kl bins。每个单元格有两种不同的状态:空和满。每当空单元格中的一个点在重建过程中变得可见时，单元格的状态就会变为完整，并且图像的分数 Si 会增加一个权重 wl。通过这个方案，我们量化了可见点的数量。由于细胞只对总分有贡献一次，因此我们更倾向于在点聚集在图像的一部分中的情况下更均匀地分布(即只有少数细胞包含所有可见点)。但是，如果可见点的数量为 Nt < K2 l ，则此方案可能无法很好地捕获点的分布，因为每个点都可能落入单独的单元格中。因此，我们通过在每个连续级别使用更高分辨率 Kl = 2l 对图像进行分区，将先前描述的方法扩展到具有 l = 1...L 级别的多分辨率金字塔。得分在所有级别上累积，权重 wl = K2 l 与分辨率相关。该数据结构及其分数可以有效地在线更新。\n\n为了处理任意级别的异常值外点值,我们使用 RANSAC 制定了多视图三角剖分问题。我们考虑特征轨迹 T = {Tn | n =1...NT } 作为一组具有先验未知内点比率 ε 的测量值。测量 Tn 由归一化图像观察 ̄ xn∈ R2 和相应的相机位姿 Pn ∈ SE(3) 组成,定义从世界到相机帧的投影 P = [RT −RT t] 其中 R ∈ SO(3) 和 t ∈ R3。我们的目标是最大限度地支持符合条件良好的双视图三角剖分\n\nXab∼τ(xa,xb,Pa,Pb)witha≠b\n\n其中 τ 是任何选择的三角剖分方法(在我们的例如 DLT 方法 [26]),Xab 是三角点。请注意,我们不会从全景图像对(第 4.1 节)进行三角测量,以避免由于姿势估计不准确而导致错误的三角测量角度。条件良好的模型满足两个约束。首先,足够的三角剖分角\n\ncos⁡α=ta−Xab||ta−Xab||2⋅ta−Xab||tb−Xab||2\n\n其次,正深度 da 和 db w.r.t.视图 Pa 和 Pb(手性约束),深度定义为\n\nd=[p31p32p33p34][XabT1]T\n\n其中 pmn 表示 P 的第 m 行和第 n 列中的元素。如果 Tn 具有正深度 dn 且其重投影误差\n\nen=||xn−[x/zy/z]||2with[xyz]=Pn[Xab1]\n\n小于某个阈值 t。 RANSAC 将 K 最大化作为一种迭代方法,并且通常它会随机均匀地对大小为 2 的最小集合进行采样。但是,由于对于小 NT 可能会多次采样相同的最小集,因此我们将随机采样器定义为仅生成唯一样本。为确保至少对一个无离群值的最小集进行采样,有置信度η,RANSAC 必须至少运行 K 次迭代。由于先验内点比率未知,我们将其设置为较小的初始值 ǫ0 并在我们找到更大的共识集(自适应停止标准)时调整 K。因为特征轨迹可能包含多个独立点,所以我们通过从剩余测量中删除共识集来递归地运行此过程。如果最新共识集的大小小于三,则递归停止。 为了减少累积误差，我们在图像配准和三角测量后执行 BA。通常，不需要在每个步骤 之后执行全局 BA，因为增量 SfM 只会影响局部模型。因此，我们在每次图像配准后对连 接最多的图像集执行局部 BA。类似于 VisualSFM，我们仅在将模型增长一定百分比后才 执行全局 BA，从而导致 SfM 的摊销线性运行时间。参数化。为了考虑潜在的异常值，我们使用 Cauchy 函数作为局部 BA 中的稳健损失函数 ρj。对于几百个摄像头的问题，我们使用稀疏直接求解器，对于更大的问题，我们依赖 PCG。我们使用 Ceres Solver 并提供在任意图像组合之间共享任意复杂度相机模型的选项。对于无序的互联网照片，我们依 赖于具有一个径向畸变参数的简单相机模型，因为估计依赖于纯粹的自校准。过滤。BA之后，一些观察结果与模型不符。在全局 BA 之后，我们还检查退化相机，例如由全景图或人工增强图像引起的。通常，这些相机只有离群值观测值，或者它们的内在函数会收敛到一个虚假的最小值。因此，我们不将焦距和失真参数限制在先验固定范围内，而是让它们在 BA 中自由 优化。由于主点校准是一个不适定的问题，我们将其固定在未校准相机的图像中心。具 有异常视野或大失真系数幅度的相机被认为是错误估计并在全局 BA 之后被过滤。\n\nPnP（Perspective-n-Point）是指已知n个3D空间点以及它们在图像上的投影位置时，估算相机所在的位姿的问题。PnP对该图像进行配准的过程是利用已经重建的3D点和新图像中的匹配点，求解相机的旋转矩阵和平移向量。由于匹配点中可能存在异常值，因此通常使用RANSAC等鲁棒估计方法来剔除异常值，并使用最小化重投影误差的方法来优化相机位姿 。\n\nPnP问题可以用数学语言描述如下：\n\nxi=K(RXi+t),i=1,…,n\n\n其中，xi是第i个3D点Xi在图像上的投影坐标，K是相机的内参矩阵，R和t是相机的旋转矩阵和平移向量，即相机的位姿。求解PnP问题就是求解R和t。\n\nPnP问题有多种算法，我们使用以下三种常见的算法：\n\n * 直接线性变换法（Direct Linear Transform，DLT）：这种方法假设相机已经校准过了，即已知K。对于每组3D-2D匹配点，可以得到两个线性方程，一共有12个未知数（R和t的元素）。至少需要6组匹配点才能求解线性方程组。设有n组匹配点，则可以写成矩阵形式：\n   \n   AF=0\n   \n   其中，A是一个2n×12的矩阵，F是一个12×1的向量，包含了R和t的元素。当n=6时，可以直接求解线性方程组。当n>6时，可以使用奇异值分解（SVD）等方法求解最小二乘解。然后，将F恢复为R和t。\n   \n   这种方法的优点是简单快速，缺点是只考虑了线性意义下的最优解，没有考虑几何约束（例如旋转矩阵的正交性）。\n\n * P3P：这种方法是已知三个3D目标点与其2D投影之间的对应关系，来确定标定相机的位姿问题。这种方法利用了三角约束，给出三角约束意义下的最优解。具体来说，可以使用相似三角形、四元数等方法来减少未知参数的个数，把P3P方程组转化为四次方程或者六次方程。然后，使用牛顿迭代法等方法求解方程的实根。\n   \n   这种方法的优点是考虑了几何约束，缺点是可能存在多解或者缺解的情况。为了得到唯一的解，至少还应引入一个点，构建两个三角形，进行求解。另一种方法是使用RANSAC等鲁棒估计方法，将点集划分为三个点子集，检查这些子集的一致性。\n\n * RPnP：这种方法是一种鲁棒的O(n)复杂度的PnP算法，可以处理任意数量的3D-2D匹配点。这种方法的思想是先建立一个新的正交坐标系，然后求解正交坐标系到相机坐标系之间的旋转和平移矩阵。具体来说，可以使用主成分分析（PCA）等方法确定旋转轴，然后使用最小二乘法等方法求解旋转角和平移矢量的方程。\n   \n   这种方法的优点是鲁棒、高效、通用，缺点是需要进行非线性优化，可能陷入局部最优解。\n\n对于以上三种方法，我们分别进行求解，由于构建的求解方式不一致，我们对三种方式求解的结果进行精度分析，选取目前认为最优的结果作为PnP的结果。\n\nBA是指捆绑调整（Bundle Adjustment）的缩写，它是一种非线性最小二乘优化方法，用于从多个视角下的匹配点，同时恢复出相机的内外参数和3D空间点的坐标。BA的目标是最小化重投影误差，即将3D点投影到各个相机上得到的2D坐标与实际观测到的2D坐标之间的距离平方和。\n\nBA的数学模型可以表示为：\n\nminC,X=∑nj=∑mρ(∥π(Cj,Xi)−xij∥2)\n\n其中，Cj是第j个相机的参数（包括内参和外参），Xi是第i个3D点的坐标，π(Cj,Xi)是将3D点Xi投影到第j个相机上得到的2D坐标，xij是第j个相机上观测到的第i个3D点对应的2D坐标，ρ是一个鲁棒损失函数，用于降低异常值的影响。\n\n为了求解这个优化问题，需要计算目标函数关于相机参数和3D点坐标的偏导数，即雅可比矩阵。然后可以使用高斯-牛顿法或者列文伯格-马夸尔特法等方法来迭代地更新相机参数和3D点坐标，直到收敛或者达到最大迭代次数。\n\nBA 是 SfM 中的主要性能瓶颈。我们提出了一种方法，该方法利用增量 SfM 和密集照片集合的固有特性，通过将冗余相机聚类到高场景重叠组中来更有效地参数 化 BA。由于兴趣点的受欢迎程度不同，照片集通常具有高度不均匀的可见性模式。此外，无序集合通常聚集成在许多图像中共同可见的点片段。许多以前的工作利用这一 事实来提高 BA 的效率，将摄像机和点划分为子图，子图通过分隔符变量连接，将划分 作为连接摄像机和点参数图上的图切割问题。然后 BA 在固定相机和点和改进分隔符变量 之间交替，反之亦然。将具有低秩的多个点折叠为单个因素，对相机施加高秩约束，从而在相机共享许多点时提供计算优势。我们提出的方法是 受这些先前工作的启发。我们将问题划分为内部参数被分解的子图。SfM根据图像和点的参数是否受到最新增量模型扩展的影响，将图像和点分为两组。对于大问题，大部分场景不受影响，因为模型通常在局部扩展。BA 自然会针对新扩展的部分进行更多优化，而其他部分只会在漂移的情况下进行改进。此外，照片集通常相机分布不均匀，有许多冗余视点。受这些观察的启发，我们将未 受影响的场景部分划分为组 G = {Gr | r = 1...NG} 的高度重叠图像并将每个组 Gr 参数 化为单个相机。受最新扩展影响的图像被独立分组，以允许对其参数进行最佳细化。这会导致标准 BA 参数化。对于未受影响的图像，我们创建基数NGr组。如果图像是在最新的模型扩展期间添加的，或者如果超过 εr的观测值比具有大于 r 像素的重投影误差（以改进重新三角化相机），我们认为图像受到影响。一组内的图像应尽可能冗余，图像之间的共同可见点的数量是描述它们相互影响程度的度量。对于具有 NX 个点的场景，每个图像都可以用二进制可见性向量 vi ∈ {0, 1}NX 来描述，其中如果点 Xn 在图像 i 中可见，则 vi 中的第 n 个条目为 1，否则为 0。图像 a 和 b 之间的交 互程度是使用对它们的向量 vi 的按位运算计算的\n\nVab=||va∧vb||||va∨vb||\n\n为了构建组，我们将图像排序为 I= {Ii | ‖vi‖≥‖vi 1‖}。我们通过从 ̄ I 中删除第一个图像 Ia 并找到使 Vab 最大化的图像 Ib 来初始化一个组 Gr。\n\nf Vab > V 和 |Gr| < S，图像 Ib 从 ̄ I 中移除并添加到组 Gr。否则，将初始化一个新组。为了减少寻找 Ib 的时间，我们采用启发式方法将搜索限制在 Kr 空间最近邻，其共同观察方向在 ±β 度范围内，其动机是这些图像很可能共享许多点.然后对组中的每个图像进行参数化 w.r.t.一个共同的组局部坐标系。分组图像的 BA 成本函数是\n\nEg=∑jρ(||πg(Gr,Pc,Xk)−xj||22)\n\n使用外部组参数 Gr ∈ SE(3) 和固定的 Pc。然后将组 r 中图像的投影矩阵定义为组和图像姿态 Pcr = PcGr 的串联。总成本 E 是分组和未分组成本贡献的总和。为了有效连接 Gr 和 Pi 的旋转分量，我们依赖四元数。由于计算 πg 相对于 π 的相对开销较小，因此较大的组大小会带来更大的性能优势。请注意，即使对于两个组的情况，我们也观察到了计算优势。此外，性能优势取决于问题的大小，因为摄像机数量的减少对直接方法的立方计算复杂度的影响大于间接方法的线性复杂度。\n\n 7. 三角化测量\n\n三角化是指根据两个或多个视角下的匹配点，恢复出它们对应的3D空间点的过程。三角化是sfm中重要的一步，它可以扩展重建模型，增加场景覆盖范围和减少误差累积。\n\n三角化的基本原理是利用射影几何中的交叉比不变性，即两条直线上的四个点的交叉比在不同视角下保持不变。因此，如果已知两个视角下的匹配点以及相机的位姿，就可以通过求解线性方程组或者最小化重投影误差等方法，得到3D空间点的坐标。\n\n\n\n三角化有多种算法，这里简单介绍三种常见的算法：\n\n * 线性三角化：这种方法假设相机已经校准过了，即已知相机的内参矩阵。对于每组2D-2D匹配点，可以得到一个线性方程，一共有4个未知数（3D点的齐次坐标）。至少需要两组匹配点才能求解线性方程组。设有n组匹配点，则可以写成矩阵形式：\n   \n   AX=0\n   \n   其中，A是一个2n×4的矩阵，X是一个4×1的向量，包含了3D点的齐次坐标。当n=2时，可以直接求解线性方程组。当n>2时，可以使用奇异值分解（SVD）等方法求解最小二乘解。然后，将X转换为非齐次坐标。\n   \n   这种方法的优点是简单快速，缺点是只考虑了线性意义下的最优解，没有考虑几何约束（例如相机位姿和3D点之间的一致性）。\n\n * 非线性三角化：这种方法是在线性三角化的基础上，使用非线性优化方法来进一步提高精度和鲁棒性。具体来说，可以使用高斯-牛顿法或者列文伯格-马夸尔特法等方法来最小化重投影误差：\n   \n   minX∑i=1n∥π(Pi,X)−xi∥2\n   \n   其中，π(Pi,X)是将3D点X投影到第i个相机上得到的2D坐标，xi是第i个相机上观测到的2D坐标，Pi是第i个相机的投影矩阵。这种方法需要给定一个初始值，通常可以使用线性三角化得到的结果作为初始值。\n   \n   这种方法的优点是考虑了几何约束，缺点是需要进行迭代优化，可能陷入局部最优解或者收敛速度慢。\n\n * 鲁棒三角化：这种方法是在非线性三角化的基础上，使用鲁棒损失函数来降低异常值的影响。具体来说，可以使用Huber损失函数或者Tukey损失函数等方法来替代平方损失函数，使得重投影误差对于异常值不敏感：\n   \n   minX∑i=1nρ(∥π(Pi,X)−xi∥2)\n   \n   其中，ρ是一个鲁棒损失函数，例如：\n   \n   ρ(x)={xx<cc+c22x−c2x≥c\n   \n   这种方法的优点是鲁棒性高，缺点是需要选择合适的鲁棒损失函数和参数，以及进行迭代优化。\n\n重新三角测量。类似于 VisualSfM，我们执行重新三角测量 (RT) 以在全局 BA（预 BA RT）之前考虑漂移效应。然而，BA 通常会显着改善相机和点参数。因此，我们建议通 过额外的 BA 后 RT 步骤来扩展非常有效的 BA 前 RT。此步骤的目的是通过继续跟踪以 前未能三角化的点（例如，由于姿势不准确等）来提高重建的完整性。 我们不增加三角化阈值，而是继续跟踪具有误差低于过滤阈值的观测值。此外，我们尝试合 并轨道，从而为下一个 BA 步骤提供更多的冗余。迭代优化。 Bundler 和 VisualSfM 执 行 BA 和过滤的单个实例。由于漂移或 BA 前 RT，通常 BA 中的大部分观察结果是异常 值，随后被过滤掉。由于 BA 受到异常值的严重影响，因此 BA 的第二步可以显着改善结 果。因此，我们建议在迭代优化中执行 BA、RT 和过滤，直到过滤的观察值和 BA 后 RT 点的数量减少。在大多数情况下，第二次迭代后结果会显着改善并且优化会收敛。\n\n 8. 合并最终模型\n\n上述方法，我们已经得到了各个子图的SfM结果，我们最后一步是将各个子模型合并。\n\n * 求解各个子图的图像集。你可以根据子图之间的拓扑关系，将相邻或相交的子图分为一组，形成一个图像集。例如，如果你有四个子图A，B，C，D，其中A和B有重叠部分，B和C有重叠部分，C和D有重叠部分，那么你可以将A，B，C分为一组，形成一个图像集ABC；将B，C，D分为一组，形成一个图像集BCD。\n * 找出各个子图中重叠的部分。你可以在每个图像集中进行特征点匹配，找出不同子图之间共享的特征点。例如，在图像集ABC中，你可以找出A和B之间共享的特征点AB；在图像集BCD中，你可以找出B和C之间共享的特征点BC；在两个图像集之间，你可以找出B和C之间共享的特征点BC’。\n * 利用重叠的部分，求解两个子图的相似变换。你可以根据共享特征点之间的对应关系，求解两个子图之间的相似变换矩阵（Similarity Matrix），使得两个子图能够对齐。例如，在图像集ABC中，你可以根据AB之间的对应关系，求解A到B的相似变换矩阵SAB；在图像集BCD中，你可以根据BC之间的对应关系，求解B到C的相似变换矩阵SBC；在两个图像集之间，你可以根据BC’之间的对应关系，求解B到C’的相似变换矩阵SBC’。\n * 将各个子图的模型进行融合。你可以根据相似变换矩阵，将各个子图的模型变换到同一个坐标系下，然后进行模型融合。例如，在图像集ABC中，你可以将A的模型变换为SABA；在图像集BCD中，你可以将D的模型变换为SBCD；在两个图像集之间，你可以将C的模型变换为SBC’*C；然后将所有的模型进行融合，得到最终的三维重建结果。\n\n具体过程如下：\n\n输入两个要对齐的模型，输出他们之间的相似变换矩阵alignment设置RANSAC的一些参数，最大误差，和内点率找到两个模型之间的公共图片I再提取出两份，reconstruction1 中的I表示为src_images，和reconstruction2中的I表示为ref_images使用RANSAC估算两个images集的相似变换\n\n两点云中的所有相机中心的坐标\n\nX=(x1,⋯,xn)Y=(y1,⋯,yn)\n\n我们将其转为矩阵形式\n\nM=[a1a2⋯anb1b2⋯bnc1c2⋯cn]\n\n去中心化\n\nM―=[a1−a―a2−a―⋯an−a―b1−b―b2−b―⋯bn−b―c1−c―c2−c―⋯cn−c―]\n\n分别计算奇异值，与协方差矩阵\n\nσ2=1n∑i=1n(xi−x―)2∑xy=1n∑i=1n(yi−y―)(xi−x―)\n\n最后进行奇异值分解\n\n∑xy=UDVT\n\n其中\n\nR=USVC=1σ2tr(DS)t=y―−cRx―\n\n先初始化一个RANSAC，得到最大迭代次数max_num_trials。\n\n * N=∞，sample_count=0\n\n * while N > sample_count\n   \n   * 选择一组样本，并记录它的内点数\n   \n   * 计算外点率e = 1- number_of_inliers/total_number_of_points\n     \n     * 随机采样当前最优模型中的内点，估计新的模型（迭代10次），如果优于当前模型，则更新最优模型\n   \n   * 计算最大迭代次数\n     \n     N=log⁡(1−p)log⁡(1−(1−e)s)\n   \n   * sample_count += 1\n\n开始迭代\n\n 1. 从俩堆点云中随机采样需要的最少点数X_rand, Y_rand\n 2. 从当前的采样中，估算model Estimate(X_rand, Y_rand)\n 3. 局部优化\n\n计算残差\n\n对于每张图像，确定从一个图像正确投影到另一个图像以及从另一个图像正确投影回来的3D点的比率，考虑给定的对齐方式。残差定义为1减去这个比率，即误差阈值为0.3意味着该图像的70％点必须在给定的最大重投影误差阈值内重新投影。\n\n 1.  遍历所有公共图像\n 2.  遍历该图像中所有的特征点，并且该特征点在图像1和图像2都存在对应的3D点，num_common_points+1\n 3.  计算双向误差，如果小于最大重投影误差，则num_inliers+1\n 4.  计算外点率negative_inlier_ratio = 1- num_inliers/num_common_points\n 5.  如果统计外点率negative_inlier_ratio < max_residual，则support.num_inliers+1\n 6.  对比内点数，如果内点数相同，则比较外点率，更新当前最优模型\n 7.  随机采样当前最优模型中的内点，估计新的模型\n 8.  再对比新的模型是不是比上一步的最优模型的内点数更多\n 9.  更新最大迭代次数\n 10. 结束迭代，取出最优模型\n\n融合\n\n对比传入的reconstruction，生成common_image_ids 和 missing_image_ids，将missing_image_ids中的图像注册到当前的reconstruction中，注册很简单，将它本身的位姿乘以俩reconstruction的相似变换\n\nP′=s⋅(Rt01)⋅T−1\n\n使用以下两种规则进行点云合并\n\n * 复制非冲突的点云到当前重建中，即那些在当前重建中没有被三角化观测到的点。\n * 合并无歧义的tracks，即只将两个重建中的点合并，如果它们有一个一对一的映射。\n\n 1. 遍历传入的点云中的所有3D点\n    * 遍历这个3D点的track\n      * 如果当前这个track在common_imgaes中，加入到old_track中\n      * 如果当前这个track在missing_images中，加入到new_track中\n 2. 将3D点添加到当前的reconstruction中\n 3. 如果当前的reconstruction中已经存在这个新添加的3D点，那么将它们合并\n\n过滤误差较大的三维点\n\n计算重投影误差\n\nPc=R⋅P+t(uv1)=1z⋅K⋅Pce2=‖(uv)−(pxpy)‖2\n\n如果大于一定重投影误差值，则将该3D点删除\n\n得到最终结果\n\n\n\n在稠密重建MVS方面，我们采用了多视几何的方法，使用SfM处理得到的相机姿态和三角测量得到的稀疏点云，运用光束法进行三角剖分，以得到高质量的三维重建结果。在这个过程中，我们采用了多种算法和方法，如多视几何恢复三维结构、MVSNet等深度学习方法等，通过大量的实验，我们发现这些方法在稠密重建方面都表现出了较好的效果。经过稠密点云计算、成像约束等操作后，我们得出的重建模型与实际场景相符合度高，重建结果细节丰富，具有一定的可视化效果。\n\n我们采用了PatchMatch一种计算机视觉算法，用于求解图像匹配的问题。它由Barnes、Shechtman和Finkelstein在2009年发表，是一种快速而且高效的方法，用于在两幅图像中寻找匹配的图像块。\n\n在PatchMatch算法中，每个像素点的匹配过程被看作一个寻找最优匹配的过程，而最优匹配点的目标是找到使两个匹配图像块误差最小的位置，从而确定每个像素点在另一幅图像中的对应位置。为了达到这个目标，PatchMatch算法采用了多尺度的策略，并利用相似图像块的局部性质来缩小匹配搜索区域的范围。为了进一步提高匹配速度，快速近似最近邻搜索技术被引入，大大缩短了算法的运行时间。\n\nPatchMatch匹配算法步骤\n\n初始化：初始化就是给每个patch的最近邻赋初值，也就是给图中的每个块随机赋予一个初始的匹配块\n\n迭代：从左上角至右下角依次遍历每个patch，每个patch进行匹配传递和随机搜索两个步骤\n\n匹配传递：匹配传递的思想是一个patch会试图借用邻居的匹配关系，来查询是否能得到更好的匹配，如果能得到更好的匹配，就更新自己的最近邻。这样一个patch如果拥有好的匹配成绩，它与另一张图中patch的匹配关系会被周围的邻居patch学习。最终每个patch会计算一个偏移值，用来表示所匹配块在另一张图中的位置\n\n随机搜索：每次匹配过后，对于得到的还会继续对其施加一个随机搜索的策略，试图通过扰动看看能不能让其跳出局部最优\n\n每次随机搜索会在上一步匹配传递的基础上，在不断指数衰减的半径区域里随机匹配若干次，直到半径缩到1个像素以下。\n\n\n\n该算法的核心思想是基于简化的假设，即在两幅图像中所寻找的匹配图像块的位置和相应误差值应该是较为接近的，因此可以通过随机的方式得到初始的近似匹配，通过不断迭代，逐步优化误差值，并不断缩小匹配图像块的搜索区域，最终找到最优的匹配位置。\n\nPatchMatch算法虽然简单，但是在实践中具有较高的鲁棒性和准确性，能够在短时间内处理大量的匹配任务，尤其对于处理图像缺陷修复、图像填充、图像修补、图像合成和场景重建等任务具有独特的优势。因此，在计算机视觉领域，PatchMatch算法越来越得到广泛的应用，并成为图像匹配领域的一个重要研究方向之一。\n\n在不断优化误差值时，PatchMatch算法通过引入了多尺度的策略，可以使得算法更快地收敛至最优解。PatchMath算法在处理大型图像时还可以通过快速近似最近邻搜索来加快算法速度，PathchMatch结果如下图所示。\n\n\n\n最近邻字段可以通过为字段分配随机值或使用先验信息来初始化。当使用随机偏移进行初始化时，我们在图像 B 的整个范围内使用独立的均匀样本。在第 4 节中描述的应用程序中，我们使用从粗到细的逐渐调整大小的过程，因此我们可以选择使用一个初始猜测从金字塔中的上一层升级。然而，如果我们只使用这个初始猜测，算法有时会陷入次优的局部最小值。为了保持这个先验的质量但仍然保留一些逃离这种最小值的能力，我们使用随机初始化执行算法的一些早期迭代，然后仅在 D 较小的补丁处与上采样初始化合并，然后执行剩余的迭代。\n\n初始化后，我们执行改进 NNF 的迭代过程。算法的每次迭代按如下方式进行：按扫描顺序（从左到右，从上到下）检查偏移量，并且每个偏移量都经过传播，然后进行随机搜索。这些操作在补丁级别交错：如果 Pj 和 Sj 分别表示补丁 j 的传播和随机搜索，那么我们按以下顺序进行：P1，S1，P2，S2，...。 . . , Pn, 锡。传播。我们尝试使用 f (x − 1, y) 和 f (x, y − 1) 的已知偏移量来改进 f (x, y)，假设补丁偏移量可能相同。例如，如果在 (x − 1, y) 处有一个很好的映射，我们会尝试将该映射向右平移一个像素，用于我们在 (x, y) 处的映射。令 D(v) 表示 A 中 (x, y) 处的补丁与 B 中的补丁 (x, y) + v 之间的补丁距离（误差）。我们将 f (x, y) 的新值设为{D( f (x, y)), D( f (x − 1, y)), D( f (x, y − 1))} 的 arg min。结果是，如果 (x, y) 具有正确的映射并且位于相干区域 R 中，则 (x, y) 下方和右侧的所有 R 都将被正确的映射填充。此外，在偶数次迭代中，我们通过以反向扫描顺序检查偏移量来向上和向左传播信息，使用 f (x + 1, y) 和 f (x, y + 1) 作为我们的候选偏移量。随机搜索。令 v0 = f(x, y)。我们尝试通过在距 v0 呈指数递减的距离处测试一系列候选偏移来改进 f (x, y)：\n\nui=v0+waiRi\n\n其中 Ri 是 [−1, 1] × [−1, 1] 中的均匀随机数，w 是较大的最大搜索“半径”，α 是搜索窗口大小之间的固定比率。我们检查 i = 0, 1, 2, ... 的补丁，直到当前搜索半径 wαi 低于 1 个像素。在我们的应用程序中，w 是最大图像维度，α = 1/2，除非另有说明。请注意，搜索窗口必须限制在 B 的范围内。停止条件。虽然根据应用程序可能会使用不同的停止标准，但在实践中我们发现它可以很好地迭代固定次数。此处显示的所有结果都是通过总共 4-5 次迭代计算得出的，之后 NNF 几乎总是收敛。收敛如图 3 和随附的视频所示。效率。可以通过几种方式提高这种朴素方法的效率。在传播和随机搜索阶段，当尝试使用候选偏移量 u 改进偏移量 f (v) 时，如果 D(u) 的部分和超过当前已知距离 D( f (v))，则可以提前终止.此外，在传播阶段，当使用边长为 p 和 Lq 范数的方形补丁时，距离的变化可以在 O(p) 而不是 O(p2) 时间内递增计算，方法是注意求和中的冗余项重叠区域。但是，这会产生额外的内存开销来存储当前最佳距离 D( f (x, y))。 GPU 实现。第 4 节中描述的编辑系统依赖于 NNF 估计算法的 CPU 实现，但我们还在 GPU 上制作了一个完全并行化变体的原型。为此，我们在随机搜索和传播的迭代之间交替，其中每个阶段并行处理整个偏移量字段。虽然传播本质上是一个串行操作，但我们采用了 Rong 和 Tan 的跳洪方案来执行多次迭代的传播。尽管我们的 CPU 版本能够在整个扫描线上传播信息，但我们发现实际上不需要长距离传播，最大跳跃距离为 8 就足够了。我们还在每个跳跃距离仅使用 4 个邻居，而不是 Rong 和 Tan 提出的 8 个邻居。\n\n我们的迭代算法在极限内收敛到精确的 NNF。在这里，我们为这种收敛提供了一个理论分析，表明它在前几次迭代中以高概率收敛得最快。此外，我们表明，在只需要近似补丁匹配的常见情况下，该算法收敛得更快。因此，通过将计算限制为少量迭代，我们的算法最适合用作近似算法。我们首先分析收敛到精确的最近邻域，然后将此分析扩展到更有用的收敛到近似解的情况。假设 A 和 B 具有相同的大小（M 个像素）并且使用随机初始化。尽管在这个初始猜测中任何一个位置被分配最佳偏移的几率微乎其微 (1/M)，但至少一个偏移被正确分配的几率非常好 (1 − (1 − 1/M)M ) ) 或对于大 M 大约为 1 − 1/e。由于随机搜索在小的局部区域中非常密集，我们还可以将“正确”分配视为正确偏移量周围大小为 C 像素的小邻域内的任何分配。这样的偏移量将在随机搜索的大约一次迭代中得到纠正。在这样的邻域中至少分配一个偏移量的可能性非常大：(1 − (1 −C/M)M ) 或对于大 M，1 − exp(−C)。\n\n现在我们为我们的算法考虑一个具有挑战性的综合测试用例：一个大小为 m 像素的独特区域 R 位于一对其他方面均一的图像 A 和 B 中的两个不同位置（插图所示）。这个图像是一个困难的案例，因为背景没有提供关于在哪里可以找到独特区域的偏移量的信息。均匀背景中的补丁可以匹配大量其他相同的补丁，这些补丁在一次迭代中以非常高的概率通过随机猜测找到，因此我们只考虑不同区域 R 的收敛。如果不同区域 R 中的任何一个偏移量是在正确偏移量的邻域 C 内，然后我们假设在少量迭代之后，由于小局部区域中随机搜索的密度（前面提到的），所有 R 都将通过传播是正确的（对于符号简单假设这是瞬时的）。现在假设 R 还没有收敛。考虑我们的算法在最大尺度 w 下执行的随机搜索。规模为 w 的随机搜索迭代独立地对图像 B 进行采样，并且这些样本中的任何一个落在正确偏移量的邻域 C 内的概率 p 为\n\nP=1−(1−CM)m\n\n在进行任何迭代之前，收敛的概率为 p。我们没有在迭代 0, 1, ...,t − 1 上收敛并在迭代 t 上收敛的概率是 p(1 − p)t 。概率因此形成几何分布，预期收敛时间为t = 1/p − 1。为了简化，让相对特征尺寸为γ = m/M，然后随着分辨率M变大取极限：\n\n<t>=[1−(1−CM)γM]−1−1limM⟶∞<t>=[1−exp⁡(−Cγ)]−1−1\n\n通过对小 γ 的泰勒展开，t = (Cγ)−1 − 1 2 = M/(Cm) − 1 2 。也就是说，对于大图像分辨率和相对于图像分辨率 M 的小特征尺寸 m，我们预期的收敛迭代次数保持不变。我们对从 0.1 到 2 兆像素的分辨率 M 的图像进行了模拟，证实了这个模型。例如，我们发现对于 m = 202 的区域，算法在对 M = 20002 的图像进行 5 次迭代后以非常高的概率收敛。上面的测试用例很难，但不是精确匹配的最差测试用例。精确匹配的最坏情况是当图像 B 包含高度重复的纹理和许多与 A 中的不同特征相似的干扰物时。偏移可能会被其中一个干扰物“困住”，有效邻域区域大小 C 可能是减少到 1（即，只有完全匹配才能在随机搜索期间将解决方案从干扰项中拉出）。然而在实践中，对于许多图像分析和合成应用程序，例如我们在本文中展示的应用程序，找到近似匹配（根据补丁相似性）不会导致任何明显的差异。\n\n在纹理重建方面，我们使用了多视觉立体投影的方法，将特定区域内的多张图像投影到三维重建模型上，从而得到了真实的纹理信息。我们的纹理重建方法采用了多标定照相机和多时刻捕获信息等技术，确保了纹理映射的准确性和一致性。通过采用贴图和参数空间纹理映射等算法，我们成功地为三维重建模型添加了逼真的纹理信息。经过反复验证和调整，我们的纹理重建结果非常出色，可以有效地提高三维模型的逼真度和真实感。\n\n\n\n\n# 三、创新点\n\n本系统在基于特征点提取和匹配的三维重建方法上有以下创新点：\n\n我们结合了增量SfM和全局SfM的优化方法，构建场景图，并将大场景划分为多个小场景，并行对多个小场景进行增量重建，最后通过融合的方式将多个小场景合并为大场景。同时在一些优化过程中，我们提出了多种优化策略，从而可以得到较高精度的三维模型。\n\n我们结合传统计算机视觉技术和深度学习技术，在不同阶段使用不同类型的特征表示来提高三维重建效果。在特征检测阶段使用SIFT特征，在稠密重建阶段使用MVSNet深度预测。\n\n我们提出了一种基于光束法的稠密重建方法，在保证精度和鲁棒性的同时降低了计算复杂度。我们利用SfM得到的相机姿态信息来约束光束法搜索空间，并利用深度学习预测深度信息来加速光束法求解过程。\n\n我们提出了一种基于多视觉立体投影的纹理重建方法，在保证纹理质量和一致性的同时增加了纹理多样性。我们利用多标定照相机捕获不同角度、不同光照条件下的图像，并利用参数空间纹理映射算法将它们融合到三维模型上。",normalizedContent:"# 复杂区域的三维模型快速重建\n\n\n# 一、完成的内容\n\n本系统旨在研究基于特征点提取和匹配的三维重建方法，利用多张图像中的特征点信息，恢复物体或场景的三维几何结构。本系统主要完成了以下内容：\n\n• 调研了国内外相关领域的研究现状和发展趋势，分析了三维重建的基本原理和关键技术，总结了三维重建的常用方法和评价指标。\n\n• 设计并实现了一个基于特征点提取和匹配的三维重建系统，包括特征检测、描述、匹配、去噪、相机标定、姿态计算、三维重建、优化、稠密重建和纹理重建等模块。\n\n• 在公开数据集上对所提出的系统进行了测试和评估，与其他三维重建方法进行了对比分析，验证了所提出方法的有效性和优越性。\n\n\n# 二、所采用的方法以及取得的成果\n\nsfm 是将 3d 结构从其投影重建为一系列从不同视点拍摄的图像的过程。增量 sfm（在本文中表示为 sfm）是一种具有迭代重建组件的顺序处理流水线。它通常从特征提取和匹配开始，然后是几何验证。生成的场景图作为重建阶段的基础，在逐步注册新图像、三角测量场景点、过滤异常值并使用束调整 (ba) 改进重建之前，该阶段使用精心选择的双视图重建为模型播种。以下介绍我们系统所采用的的方法，以及取得的成果。\n\n 1. 相机标定\n\n相机标定的过程是指通过一些已知的几何信息，来求解相机的内部参数，从而建立三维空间点和二维图像点之间的对应关系。\n\n一般来说，相机标定的步骤如下：\n\n * 准备一个标定物，通常是一个带有黑白棋盘格的平面，其角点的世界坐标系和图像坐标系是已知的。\n * 用相机从不同的角度和位置拍摄标定物的照片，至少需要三张以上。\n * 从照片中提取棋盘格的角点，得到每个角点在像素坐标系下的坐标。\n * 根据相机成像模型，建立三维空间点和二维图像点之间的投影关系，利用单应矩阵、透视投影、畸变校正等方法，求解相机的内部参数。\n * 利用最小二乘法或其他优化方法，对求解出的参数进行优化和误差分析。\n\n对于相机内部参数，我们系统中提供优化相机内参的算法，即使不通过相机标定的步骤获得相机内部参数，我们系统也可以通过算法来估计得到相对准确的相机内部参数，若追求更好的更准确的三维模型，一般是手动进行相机标定，将相机内部参数作为固定值。\n\n 2. 图像采集\n\nsfm过程中的图像采集过程是指从多个角度拍摄同一场景的图片，并按序号进行保存，以便后续进行特征提取，匹配，重建等步骤。\n\n * 图像的质量要高，清晰度要好，避免模糊，曝光过度或不足等问题。\n * 图像的数量要适中，不要太少或太多，太少会导致重建不完整或不准确，太多会增加计算量和内存消耗。\n * 图像的视角要有一定的重叠度，一般建议在60%~80%之间，以便提高特征匹配的成功率和稳定性。\n * 图像的视角要有一定的视差，即相机之间的相对位姿要有足够的变化，以便恢复出三维结构。如果图像之间的视差太小，可能会导致奇异性或退化情况。\n * 图像的拍摄环境要尽量保持一致，避免光照，阴影，反射等因素的干扰。同时，场景中的物体要尽量是静止的，避免动态物体的影响。\n\n 3. 特征提取\n\nsfm过程中的图像特征提取过程是指从图像中提取具有尺度和旋转不变性的特征点和描述子，以便后续进行特征匹配，计算基础矩阵，恢复相机位姿和三维结构等步骤。\n\n以下红色点为我们提取的特征点\n\n\n\n * 特征点的数量要适中，不要太少或太多，太少会导致匹配不稳定或失败，太多会增加计算量和内存消耗。\n * 特征点的分布要均匀，不要集中在某些区域，以便提高匹配的鲁棒性和准确性。\n * 特征点的描述子要具有较强的区分度，不要与其他特征点混淆，以便降低误匹配的概率。\n * 特征点的类型要适合场景的特点，例如对于纹理丰富的场景，可以使用sift，surf等特征点，对于纹理较少的场景，可以使用harris，fast等角点。\n\n以下详细介绍我们采用的fast角点。\n\n构建高斯尺度空间，产生不同尺度的高斯模糊图像。\n\n\n\n进行降采样，得到一系列尺寸不断缩小的图像，计算高斯差分函数。\n\ng(xi,yi,σ)=12πσ2exp(−((x−xi)2−(y−yi)22σ2))l(x,y,σ)=g(x,y,σ)∗i(x,y)\n\ndog 空间极值检测：寻找 dog 函数的极值点，每一个像素点和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。\n\n确定特征向量主方向:通过每个极值点的梯度来为极值点赋予方向，梯度幅值等于上 下两点像素值差的平方加上左右两点像素值差的平方，梯度方向则为上下两点像素值差与左 右两点像素值差的商。\n\n梯度幅值\n\nm(x,y)=(l(x+1,y)−l(x−1,y))2+(l(x,y+1)−l(x,y−1))2\n\n梯度方向\n\nθ(x,y)=tan−1(l(x,y+1)−l(x,y−1)l(x+1,y)−l(x−1,y))\n\n计算特征向量\n\n求取每个像素的梯度幅值与梯度方向，箭头方向代表该像素的梯度方向，长度代表梯度幅值，然后利用高斯窗口对其进行加权运算。在每个小块上绘制 8 个方向的梯度直方图，计算每个梯度方向的累加值。\n\n\n\n最终每个小块获得4 ∗ 4 ∗ 8 = 128 维的特征向量\n\n 4. 特征匹配\n\nsfm过程中的图像特征匹配过程是指从两两相邻的图像中找出具有相同或相似特征的点对，以便后续进行基础矩阵，本质矩阵，单应矩阵的计算，恢复相机位姿和三维结构等步骤。\n\n\n\n * 特征匹配的方法要适合特征点的类型和数量，可以使用暴力匹配，kd树，flann等方法。\n * 特征匹配的结果要满足一一对应的原则，即一个特征点只能匹配到另一个图像中的一个特征点，不能出现多对一或一对多的情况。\n * 特征匹配的结果要满足几何一致性的约束，即匹配点对之间要符合对极几何关系，可以使用基础矩阵或本质矩阵来检验和筛选。\n * 特征匹配的结果要满足运动一致性的约束，即匹配点对之间要符合相机运动模型，可以使用单应矩阵来检验和筛选。\n\n匹配结果如下\n\n\n\n我们系统中提供多种图像匹配方式，顺序匹配，词汇树匹配，暴力匹配，gps空间匹配。\n\n * 顺序匹配\n\n对于顺序采集的图像，可以采用这一种方式进行图像间的匹配。这一种的匹配过程为，将所有图像进行编号后，对于每一张图像，我们取它先前的10张图像进行一一匹配，与这10张图像分别建立图像匹配关系，以便后续步骤用。除此之外，我们增加一个回环检测策略，每隔一定图像数量后，对图像进行一次回环检测，也就说，这一次匹配的目标图像不仅是先前的10张，而是先前随机的n张，用这种策略与更久远的图像建立匹配关系，从而达到检测回环的功能。对于顺序匹配，可以很快速的完成所有图像的匹配，并且有一定的检测回环能力，对于追求快速，采集的图像是顺序序列，则可以采用这种方式进行图像匹配。\n\n * 词汇树匹配\n\n对于词汇树匹配，需要我们在进行三维重建之前，构建一个词汇树，该词汇树，指导系统进行匹配。简单来说，需要训练一个模型，该模型覆盖了本次进行三维重建的所有场景，以至于我们拍摄的图像，可以明确推理出该图像是属于哪一部分场景，进而将属于某一场景的所有图像进行互相匹配。这种方式的匹配过程较为精确，而且高效，因为仅仅是属于某一场景的图像才进行相互匹配，并不会把两张毫无相干的图像进行互相匹配来浪费时间。这种匹配方式的精度取决于词汇树的构建，词汇树模型构建的精确，则匹配精确。\n\n * 暴力匹配\n\n对于暴力匹配，最简单的方式为，两两图像进行匹配，但是这种方式性能很差，可以稍微改进一下。我们将其改为，分块匹配。将所有图像进行分块，对块和块之间的图像进行匹配。这种方式性能较差，若没有图像的额外信息，才会使用该方式进行图像匹配。\n\n * gps空间匹配\n\n对于gps空间匹配，与词汇树匹配类似，利用gps信息，确定图像某个具体范围位置，对存在于该范围的图像，我们进行两两匹配，对于无人机采集的图像，我们一般采用这种方式进行图像匹配。\n\n 5. 构建场景图\n\n使用一种图论的方法来表示和优化图像之间的匹配关系，从而提高重建的效率和质量。\n\n * 构建场景图的目的是为了找出最优的图像对来进行三角化和位姿估计，避免使用冗余或错误的匹配信息。\n\n * 构建场景图的方法是将所有图像看作一个无向图的节点，将两个图像之间的匹配点数或者重叠度看作边的权重，然后使用最小生成树算法（如prim或kruskal）来找出最大权重的边，形成一个连通且无环的子图。\n\n * 构建场景图的过程可以分为两个阶段：第一个阶段是根据所有图像对之间的匹配点数或者重叠度来构建一个初始的最大生成树；第二个阶段是根据每个图像对之间的几何一致性（如基础矩阵或单应矩阵）来对初始的最大生成树进行修剪和优化，去除错误或不稳定的边。\n\n * 构建场景图的结果是一个包含所有图像节点和部分匹配边的最大生成树，这个树可以用来指导后续的重建步骤，例如选择初始图像对，添加新的图像，进行局部或全局优化等。\n\n由于增量式sfm（structure from motion，运动结构恢复）需要在每次添加图像后都进行一次局部或全局的捆绑调整（bundle adjustment），这会导致效率较低，而且由于误差累积，容易出现漂移问题。因此，我需要使用图论的方式来表示和优化图像之间的匹配关系，从而提高重建的效率和质量。具体来说，我可以将所有图像看作一个无向图的节点，将两个图像之间的匹配点数或者重叠度看作边的权重，然后使用最小生成树算法（如prim或kruskal）来找出最大权重的边，形成一个连通且无环的子图。这样，我就可以根据这个子图来指导后续的重建步骤，例如选择初始图像对，添加新的图像，进行局部或全局优化等。\n\n我们的目标是使用图像的方式来重建三维模型，但是由于增量式的sfm算法效率较低，容易出现误差累积和漂移问题，所以你需要对图像之间的匹配关系进行优化。我们的思路是使用图论的方法，将图像间的匹配关系表示为一个无向图，其中每个顶点代表一张图像，每条边代表两张图像之间存在共同的可见区域。然后你将使用最大生成树算法，从这个无向图中找出一棵包含所有顶点且边权值之和最大的树。边权值可以根据两张图像之间的匹配点数目、基线长度、三角量测角度等因素来确定。最大生成树可以保证你选取的图像对具有较好的视角和匹配质量，从而提高重建效果。接下来，你将使用图割算法，将最大生成树划分为多个子图。图割算法可以根据子图中顶点和边的个数、边权值之和等条件来确定划分方案。划分后的子图可以看作是相对独立的小型场景，对每个子图单独进行增量式sfm重建，得到相机参数和三维点坐标。最后，你将使用捆绑调整算法，对所有子图进行全局优化，消除误差累积和漂移，并将所有子图合并为最终模型。\n\n 6. 增量sfm重建\n\n在增量式sfm中，选择下一幅图像的目的是为了扩展重建模型，增加场景覆盖范围和减少误差累积。选择下一幅图像的原则是要保证与已经重建的图像有足够多的匹配点，且具有较好的视差角度，以便于进行三角化和pnp。一种常用的方法是根据图像之间的匹配点数目、基线长度、三角量测角度等因素来确定边权值，然后从子图中找出一棵最大生成树，按照树的深度优先顺序遍历图像。这里我们采用一种下一个最佳视图策略来找到当前最适合重建的图像。\n\n下一个最佳视图规划已经在计算机视觉、摄影测量和机器人技术领域进行了研究 。在稳健的 sfm 中选择下一个最佳视图旨在最小化重建误差。在这里，我们提出了一种有效的下一个最佳视图策略，遵循一种最大化重建鲁棒性的不确定性驱动方法。选择下一个最佳视图至关重要，因为每个决定都会影响剩余的重建。一个错误的决定可能会导致一连串的相机错误注册和错误的三角测量。此外，选择下一个最佳视图会极大地影响姿势估计的质量以及三角测量的完整性和准确性。准确的姿态估计对于稳健的 sfm 至关重要，因为如果姿态不准确，点三角测量可能会失败。\n\n下一个最佳视图的候选者不是至少看到 nt > 0 个三角点的尚未注册的图像。使用特征轨迹图可以有效地跟踪此统计信息。对于 internet 数据集，此图可能非常密集，因为许多图像可能会看到相同的结构。因此，在重建的每一步都有许多候选视图可供选择。 haner 等人提出的详尽协方差传播。是不可行的，因为需要在每个步骤中为每个候选者计算和分析协方差。我们提出的方法使用高效的多分辨率分析来近似他们的不确定性驱动方法。我们必须同时跟踪每个候选图像中可见点的数量及其分布。更多的可见点和这些点的更均匀分布应该导致更高的分数 s，这样具有更好条件的可见点配置的图像首先被注册。为了实现这个目标，我们将图像离散化为一个固定大小的网格，在两个维度上都有 kl bins。每个单元格有两种不同的状态:空和满。每当空单元格中的一个点在重建过程中变得可见时，单元格的状态就会变为完整，并且图像的分数 si 会增加一个权重 wl。通过这个方案，我们量化了可见点的数量。由于细胞只对总分有贡献一次，因此我们更倾向于在点聚集在图像的一部分中的情况下更均匀地分布(即只有少数细胞包含所有可见点)。但是，如果可见点的数量为 nt < k2 l ，则此方案可能无法很好地捕获点的分布，因为每个点都可能落入单独的单元格中。因此，我们通过在每个连续级别使用更高分辨率 kl = 2l 对图像进行分区，将先前描述的方法扩展到具有 l = 1...l 级别的多分辨率金字塔。得分在所有级别上累积，权重 wl = k2 l 与分辨率相关。该数据结构及其分数可以有效地在线更新。\n\n为了处理任意级别的异常值外点值,我们使用 ransac 制定了多视图三角剖分问题。我们考虑特征轨迹 t = {tn | n =1...nt } 作为一组具有先验未知内点比率 ε 的测量值。测量 tn 由归一化图像观察  xn∈ r2 和相应的相机位姿 pn ∈ se(3) 组成,定义从世界到相机帧的投影 p = [rt −rt t] 其中 r ∈ so(3) 和 t ∈ r3。我们的目标是最大限度地支持符合条件良好的双视图三角剖分\n\nxab∼τ(xa,xb,pa,pb)witha=b\n\n其中 τ 是任何选择的三角剖分方法(在我们的例如 dlt 方法 [26]),xab 是三角点。请注意,我们不会从全景图像对(第 4.1 节)进行三角测量,以避免由于姿势估计不准确而导致错误的三角测量角度。条件良好的模型满足两个约束。首先,足够的三角剖分角\n\ncos⁡α=ta−xab||ta−xab||2⋅ta−xab||tb−xab||2\n\n其次,正深度 da 和 db w.r.t.视图 pa 和 pb(手性约束),深度定义为\n\nd=[p31p32p33p34][xabt1]t\n\n其中 pmn 表示 p 的第 m 行和第 n 列中的元素。如果 tn 具有正深度 dn 且其重投影误差\n\nen=||xn−[x/zy/z]||2with[xyz]=pn[xab1]\n\n小于某个阈值 t。 ransac 将 k 最大化作为一种迭代方法,并且通常它会随机均匀地对大小为 2 的最小集合进行采样。但是,由于对于小 nt 可能会多次采样相同的最小集,因此我们将随机采样器定义为仅生成唯一样本。为确保至少对一个无离群值的最小集进行采样,有置信度η,ransac 必须至少运行 k 次迭代。由于先验内点比率未知,我们将其设置为较小的初始值 o0 并在我们找到更大的共识集(自适应停止标准)时调整 k。因为特征轨迹可能包含多个独立点,所以我们通过从剩余测量中删除共识集来递归地运行此过程。如果最新共识集的大小小于三,则递归停止。 为了减少累积误差，我们在图像配准和三角测量后执行 ba。通常，不需要在每个步骤 之后执行全局 ba，因为增量 sfm 只会影响局部模型。因此，我们在每次图像配准后对连 接最多的图像集执行局部 ba。类似于 visualsfm，我们仅在将模型增长一定百分比后才 执行全局 ba，从而导致 sfm 的摊销线性运行时间。参数化。为了考虑潜在的异常值，我们使用 cauchy 函数作为局部 ba 中的稳健损失函数 ρj。对于几百个摄像头的问题，我们使用稀疏直接求解器，对于更大的问题，我们依赖 pcg。我们使用 ceres solver 并提供在任意图像组合之间共享任意复杂度相机模型的选项。对于无序的互联网照片，我们依 赖于具有一个径向畸变参数的简单相机模型，因为估计依赖于纯粹的自校准。过滤。ba之后，一些观察结果与模型不符。在全局 ba 之后，我们还检查退化相机，例如由全景图或人工增强图像引起的。通常，这些相机只有离群值观测值，或者它们的内在函数会收敛到一个虚假的最小值。因此，我们不将焦距和失真参数限制在先验固定范围内，而是让它们在 ba 中自由 优化。由于主点校准是一个不适定的问题，我们将其固定在未校准相机的图像中心。具 有异常视野或大失真系数幅度的相机被认为是错误估计并在全局 ba 之后被过滤。\n\npnp（perspective-n-point）是指已知n个3d空间点以及它们在图像上的投影位置时，估算相机所在的位姿的问题。pnp对该图像进行配准的过程是利用已经重建的3d点和新图像中的匹配点，求解相机的旋转矩阵和平移向量。由于匹配点中可能存在异常值，因此通常使用ransac等鲁棒估计方法来剔除异常值，并使用最小化重投影误差的方法来优化相机位姿 。\n\npnp问题可以用数学语言描述如下：\n\nxi=k(rxi+t),i=1,…,n\n\n其中，xi是第i个3d点xi在图像上的投影坐标，k是相机的内参矩阵，r和t是相机的旋转矩阵和平移向量，即相机的位姿。求解pnp问题就是求解r和t。\n\npnp问题有多种算法，我们使用以下三种常见的算法：\n\n * 直接线性变换法（direct linear transform，dlt）：这种方法假设相机已经校准过了，即已知k。对于每组3d-2d匹配点，可以得到两个线性方程，一共有12个未知数（r和t的元素）。至少需要6组匹配点才能求解线性方程组。设有n组匹配点，则可以写成矩阵形式：\n   \n   af=0\n   \n   其中，a是一个2n×12的矩阵，f是一个12×1的向量，包含了r和t的元素。当n=6时，可以直接求解线性方程组。当n>6时，可以使用奇异值分解（svd）等方法求解最小二乘解。然后，将f恢复为r和t。\n   \n   这种方法的优点是简单快速，缺点是只考虑了线性意义下的最优解，没有考虑几何约束（例如旋转矩阵的正交性）。\n\n * p3p：这种方法是已知三个3d目标点与其2d投影之间的对应关系，来确定标定相机的位姿问题。这种方法利用了三角约束，给出三角约束意义下的最优解。具体来说，可以使用相似三角形、四元数等方法来减少未知参数的个数，把p3p方程组转化为四次方程或者六次方程。然后，使用牛顿迭代法等方法求解方程的实根。\n   \n   这种方法的优点是考虑了几何约束，缺点是可能存在多解或者缺解的情况。为了得到唯一的解，至少还应引入一个点，构建两个三角形，进行求解。另一种方法是使用ransac等鲁棒估计方法，将点集划分为三个点子集，检查这些子集的一致性。\n\n * rpnp：这种方法是一种鲁棒的o(n)复杂度的pnp算法，可以处理任意数量的3d-2d匹配点。这种方法的思想是先建立一个新的正交坐标系，然后求解正交坐标系到相机坐标系之间的旋转和平移矩阵。具体来说，可以使用主成分分析（pca）等方法确定旋转轴，然后使用最小二乘法等方法求解旋转角和平移矢量的方程。\n   \n   这种方法的优点是鲁棒、高效、通用，缺点是需要进行非线性优化，可能陷入局部最优解。\n\n对于以上三种方法，我们分别进行求解，由于构建的求解方式不一致，我们对三种方式求解的结果进行精度分析，选取目前认为最优的结果作为pnp的结果。\n\nba是指捆绑调整（bundle adjustment）的缩写，它是一种非线性最小二乘优化方法，用于从多个视角下的匹配点，同时恢复出相机的内外参数和3d空间点的坐标。ba的目标是最小化重投影误差，即将3d点投影到各个相机上得到的2d坐标与实际观测到的2d坐标之间的距离平方和。\n\nba的数学模型可以表示为：\n\nminc,x=∑nj=∑mρ(∥π(cj,xi)−xij∥2)\n\n其中，cj是第j个相机的参数（包括内参和外参），xi是第i个3d点的坐标，π(cj,xi)是将3d点xi投影到第j个相机上得到的2d坐标，xij是第j个相机上观测到的第i个3d点对应的2d坐标，ρ是一个鲁棒损失函数，用于降低异常值的影响。\n\n为了求解这个优化问题，需要计算目标函数关于相机参数和3d点坐标的偏导数，即雅可比矩阵。然后可以使用高斯-牛顿法或者列文伯格-马夸尔特法等方法来迭代地更新相机参数和3d点坐标，直到收敛或者达到最大迭代次数。\n\nba 是 sfm 中的主要性能瓶颈。我们提出了一种方法，该方法利用增量 sfm 和密集照片集合的固有特性，通过将冗余相机聚类到高场景重叠组中来更有效地参数 化 ba。由于兴趣点的受欢迎程度不同，照片集通常具有高度不均匀的可见性模式。此外，无序集合通常聚集成在许多图像中共同可见的点片段。许多以前的工作利用这一 事实来提高 ba 的效率，将摄像机和点划分为子图，子图通过分隔符变量连接，将划分 作为连接摄像机和点参数图上的图切割问题。然后 ba 在固定相机和点和改进分隔符变量 之间交替，反之亦然。将具有低秩的多个点折叠为单个因素，对相机施加高秩约束，从而在相机共享许多点时提供计算优势。我们提出的方法是 受这些先前工作的启发。我们将问题划分为内部参数被分解的子图。sfm根据图像和点的参数是否受到最新增量模型扩展的影响，将图像和点分为两组。对于大问题，大部分场景不受影响，因为模型通常在局部扩展。ba 自然会针对新扩展的部分进行更多优化，而其他部分只会在漂移的情况下进行改进。此外，照片集通常相机分布不均匀，有许多冗余视点。受这些观察的启发，我们将未 受影响的场景部分划分为组 g = {gr | r = 1...ng} 的高度重叠图像并将每个组 gr 参数 化为单个相机。受最新扩展影响的图像被独立分组，以允许对其参数进行最佳细化。这会导致标准 ba 参数化。对于未受影响的图像，我们创建基数ngr组。如果图像是在最新的模型扩展期间添加的，或者如果超过 εr的观测值比具有大于 r 像素的重投影误差（以改进重新三角化相机），我们认为图像受到影响。一组内的图像应尽可能冗余，图像之间的共同可见点的数量是描述它们相互影响程度的度量。对于具有 nx 个点的场景，每个图像都可以用二进制可见性向量 vi ∈ {0, 1}nx 来描述，其中如果点 xn 在图像 i 中可见，则 vi 中的第 n 个条目为 1，否则为 0。图像 a 和 b 之间的交 互程度是使用对它们的向量 vi 的按位运算计算的\n\nvab=||va∧vb||||va∨vb||\n\n为了构建组，我们将图像排序为 i= {ii | ‖vi‖≥‖vi 1‖}。我们通过从  i 中删除第一个图像 ia 并找到使 vab 最大化的图像 ib 来初始化一个组 gr。\n\nf vab > v 和 |gr| < s，图像 ib 从  i 中移除并添加到组 gr。否则，将初始化一个新组。为了减少寻找 ib 的时间，我们采用启发式方法将搜索限制在 kr 空间最近邻，其共同观察方向在 ±β 度范围内，其动机是这些图像很可能共享许多点.然后对组中的每个图像进行参数化 w.r.t.一个共同的组局部坐标系。分组图像的 ba 成本函数是\n\neg=∑jρ(||πg(gr,pc,xk)−xj||22)\n\n使用外部组参数 gr ∈ se(3) 和固定的 pc。然后将组 r 中图像的投影矩阵定义为组和图像姿态 pcr = pcgr 的串联。总成本 e 是分组和未分组成本贡献的总和。为了有效连接 gr 和 pi 的旋转分量，我们依赖四元数。由于计算 πg 相对于 π 的相对开销较小，因此较大的组大小会带来更大的性能优势。请注意，即使对于两个组的情况，我们也观察到了计算优势。此外，性能优势取决于问题的大小，因为摄像机数量的减少对直接方法的立方计算复杂度的影响大于间接方法的线性复杂度。\n\n 7. 三角化测量\n\n三角化是指根据两个或多个视角下的匹配点，恢复出它们对应的3d空间点的过程。三角化是sfm中重要的一步，它可以扩展重建模型，增加场景覆盖范围和减少误差累积。\n\n三角化的基本原理是利用射影几何中的交叉比不变性，即两条直线上的四个点的交叉比在不同视角下保持不变。因此，如果已知两个视角下的匹配点以及相机的位姿，就可以通过求解线性方程组或者最小化重投影误差等方法，得到3d空间点的坐标。\n\n\n\n三角化有多种算法，这里简单介绍三种常见的算法：\n\n * 线性三角化：这种方法假设相机已经校准过了，即已知相机的内参矩阵。对于每组2d-2d匹配点，可以得到一个线性方程，一共有4个未知数（3d点的齐次坐标）。至少需要两组匹配点才能求解线性方程组。设有n组匹配点，则可以写成矩阵形式：\n   \n   ax=0\n   \n   其中，a是一个2n×4的矩阵，x是一个4×1的向量，包含了3d点的齐次坐标。当n=2时，可以直接求解线性方程组。当n>2时，可以使用奇异值分解（svd）等方法求解最小二乘解。然后，将x转换为非齐次坐标。\n   \n   这种方法的优点是简单快速，缺点是只考虑了线性意义下的最优解，没有考虑几何约束（例如相机位姿和3d点之间的一致性）。\n\n * 非线性三角化：这种方法是在线性三角化的基础上，使用非线性优化方法来进一步提高精度和鲁棒性。具体来说，可以使用高斯-牛顿法或者列文伯格-马夸尔特法等方法来最小化重投影误差：\n   \n   minx∑i=1n∥π(pi,x)−xi∥2\n   \n   其中，π(pi,x)是将3d点x投影到第i个相机上得到的2d坐标，xi是第i个相机上观测到的2d坐标，pi是第i个相机的投影矩阵。这种方法需要给定一个初始值，通常可以使用线性三角化得到的结果作为初始值。\n   \n   这种方法的优点是考虑了几何约束，缺点是需要进行迭代优化，可能陷入局部最优解或者收敛速度慢。\n\n * 鲁棒三角化：这种方法是在非线性三角化的基础上，使用鲁棒损失函数来降低异常值的影响。具体来说，可以使用huber损失函数或者tukey损失函数等方法来替代平方损失函数，使得重投影误差对于异常值不敏感：\n   \n   minx∑i=1nρ(∥π(pi,x)−xi∥2)\n   \n   其中，ρ是一个鲁棒损失函数，例如：\n   \n   ρ(x)={xx<cc+c22x−c2x≥c\n   \n   这种方法的优点是鲁棒性高，缺点是需要选择合适的鲁棒损失函数和参数，以及进行迭代优化。\n\n重新三角测量。类似于 visualsfm，我们执行重新三角测量 (rt) 以在全局 ba（预 ba rt）之前考虑漂移效应。然而，ba 通常会显着改善相机和点参数。因此，我们建议通 过额外的 ba 后 rt 步骤来扩展非常有效的 ba 前 rt。此步骤的目的是通过继续跟踪以 前未能三角化的点（例如，由于姿势不准确等）来提高重建的完整性。 我们不增加三角化阈值，而是继续跟踪具有误差低于过滤阈值的观测值。此外，我们尝试合 并轨道，从而为下一个 ba 步骤提供更多的冗余。迭代优化。 bundler 和 visualsfm 执 行 ba 和过滤的单个实例。由于漂移或 ba 前 rt，通常 ba 中的大部分观察结果是异常 值，随后被过滤掉。由于 ba 受到异常值的严重影响，因此 ba 的第二步可以显着改善结 果。因此，我们建议在迭代优化中执行 ba、rt 和过滤，直到过滤的观察值和 ba 后 rt 点的数量减少。在大多数情况下，第二次迭代后结果会显着改善并且优化会收敛。\n\n 8. 合并最终模型\n\n上述方法，我们已经得到了各个子图的sfm结果，我们最后一步是将各个子模型合并。\n\n * 求解各个子图的图像集。你可以根据子图之间的拓扑关系，将相邻或相交的子图分为一组，形成一个图像集。例如，如果你有四个子图a，b，c，d，其中a和b有重叠部分，b和c有重叠部分，c和d有重叠部分，那么你可以将a，b，c分为一组，形成一个图像集abc；将b，c，d分为一组，形成一个图像集bcd。\n * 找出各个子图中重叠的部分。你可以在每个图像集中进行特征点匹配，找出不同子图之间共享的特征点。例如，在图像集abc中，你可以找出a和b之间共享的特征点ab；在图像集bcd中，你可以找出b和c之间共享的特征点bc；在两个图像集之间，你可以找出b和c之间共享的特征点bc’。\n * 利用重叠的部分，求解两个子图的相似变换。你可以根据共享特征点之间的对应关系，求解两个子图之间的相似变换矩阵（similarity matrix），使得两个子图能够对齐。例如，在图像集abc中，你可以根据ab之间的对应关系，求解a到b的相似变换矩阵sab；在图像集bcd中，你可以根据bc之间的对应关系，求解b到c的相似变换矩阵sbc；在两个图像集之间，你可以根据bc’之间的对应关系，求解b到c’的相似变换矩阵sbc’。\n * 将各个子图的模型进行融合。你可以根据相似变换矩阵，将各个子图的模型变换到同一个坐标系下，然后进行模型融合。例如，在图像集abc中，你可以将a的模型变换为saba；在图像集bcd中，你可以将d的模型变换为sbcd；在两个图像集之间，你可以将c的模型变换为sbc’*c；然后将所有的模型进行融合，得到最终的三维重建结果。\n\n具体过程如下：\n\n输入两个要对齐的模型，输出他们之间的相似变换矩阵alignment设置ransac的一些参数，最大误差，和内点率找到两个模型之间的公共图片i再提取出两份，reconstruction1 中的i表示为src_images，和reconstruction2中的i表示为ref_images使用ransac估算两个images集的相似变换\n\n两点云中的所有相机中心的坐标\n\nx=(x1,⋯,xn)y=(y1,⋯,yn)\n\n我们将其转为矩阵形式\n\nm=[a1a2⋯anb1b2⋯bnc1c2⋯cn]\n\n去中心化\n\nm―=[a1−a―a2−a―⋯an−a―b1−b―b2−b―⋯bn−b―c1−c―c2−c―⋯cn−c―]\n\n分别计算奇异值，与协方差矩阵\n\nσ2=1n∑i=1n(xi−x―)2∑xy=1n∑i=1n(yi−y―)(xi−x―)\n\n最后进行奇异值分解\n\n∑xy=udvt\n\n其中\n\nr=usvc=1σ2tr(ds)t=y―−crx―\n\n先初始化一个ransac，得到最大迭代次数max_num_trials。\n\n * n=∞，sample_count=0\n\n * while n > sample_count\n   \n   * 选择一组样本，并记录它的内点数\n   \n   * 计算外点率e = 1- number_of_inliers/total_number_of_points\n     \n     * 随机采样当前最优模型中的内点，估计新的模型（迭代10次），如果优于当前模型，则更新最优模型\n   \n   * 计算最大迭代次数\n     \n     n=log⁡(1−p)log⁡(1−(1−e)s)\n   \n   * sample_count += 1\n\n开始迭代\n\n 1. 从俩堆点云中随机采样需要的最少点数x_rand, y_rand\n 2. 从当前的采样中，估算model estimate(x_rand, y_rand)\n 3. 局部优化\n\n计算残差\n\n对于每张图像，确定从一个图像正确投影到另一个图像以及从另一个图像正确投影回来的3d点的比率，考虑给定的对齐方式。残差定义为1减去这个比率，即误差阈值为0.3意味着该图像的70％点必须在给定的最大重投影误差阈值内重新投影。\n\n 1.  遍历所有公共图像\n 2.  遍历该图像中所有的特征点，并且该特征点在图像1和图像2都存在对应的3d点，num_common_points+1\n 3.  计算双向误差，如果小于最大重投影误差，则num_inliers+1\n 4.  计算外点率negative_inlier_ratio = 1- num_inliers/num_common_points\n 5.  如果统计外点率negative_inlier_ratio < max_residual，则support.num_inliers+1\n 6.  对比内点数，如果内点数相同，则比较外点率，更新当前最优模型\n 7.  随机采样当前最优模型中的内点，估计新的模型\n 8.  再对比新的模型是不是比上一步的最优模型的内点数更多\n 9.  更新最大迭代次数\n 10. 结束迭代，取出最优模型\n\n融合\n\n对比传入的reconstruction，生成common_image_ids 和 missing_image_ids，将missing_image_ids中的图像注册到当前的reconstruction中，注册很简单，将它本身的位姿乘以俩reconstruction的相似变换\n\np′=s⋅(rt01)⋅t−1\n\n使用以下两种规则进行点云合并\n\n * 复制非冲突的点云到当前重建中，即那些在当前重建中没有被三角化观测到的点。\n * 合并无歧义的tracks，即只将两个重建中的点合并，如果它们有一个一对一的映射。\n\n 1. 遍历传入的点云中的所有3d点\n    * 遍历这个3d点的track\n      * 如果当前这个track在common_imgaes中，加入到old_track中\n      * 如果当前这个track在missing_images中，加入到new_track中\n 2. 将3d点添加到当前的reconstruction中\n 3. 如果当前的reconstruction中已经存在这个新添加的3d点，那么将它们合并\n\n过滤误差较大的三维点\n\n计算重投影误差\n\npc=r⋅p+t(uv1)=1z⋅k⋅pce2=‖(uv)−(pxpy)‖2\n\n如果大于一定重投影误差值，则将该3d点删除\n\n得到最终结果\n\n\n\n在稠密重建mvs方面，我们采用了多视几何的方法，使用sfm处理得到的相机姿态和三角测量得到的稀疏点云，运用光束法进行三角剖分，以得到高质量的三维重建结果。在这个过程中，我们采用了多种算法和方法，如多视几何恢复三维结构、mvsnet等深度学习方法等，通过大量的实验，我们发现这些方法在稠密重建方面都表现出了较好的效果。经过稠密点云计算、成像约束等操作后，我们得出的重建模型与实际场景相符合度高，重建结果细节丰富，具有一定的可视化效果。\n\n我们采用了patchmatch一种计算机视觉算法，用于求解图像匹配的问题。它由barnes、shechtman和finkelstein在2009年发表，是一种快速而且高效的方法，用于在两幅图像中寻找匹配的图像块。\n\n在patchmatch算法中，每个像素点的匹配过程被看作一个寻找最优匹配的过程，而最优匹配点的目标是找到使两个匹配图像块误差最小的位置，从而确定每个像素点在另一幅图像中的对应位置。为了达到这个目标，patchmatch算法采用了多尺度的策略，并利用相似图像块的局部性质来缩小匹配搜索区域的范围。为了进一步提高匹配速度，快速近似最近邻搜索技术被引入，大大缩短了算法的运行时间。\n\npatchmatch匹配算法步骤\n\n初始化：初始化就是给每个patch的最近邻赋初值，也就是给图中的每个块随机赋予一个初始的匹配块\n\n迭代：从左上角至右下角依次遍历每个patch，每个patch进行匹配传递和随机搜索两个步骤\n\n匹配传递：匹配传递的思想是一个patch会试图借用邻居的匹配关系，来查询是否能得到更好的匹配，如果能得到更好的匹配，就更新自己的最近邻。这样一个patch如果拥有好的匹配成绩，它与另一张图中patch的匹配关系会被周围的邻居patch学习。最终每个patch会计算一个偏移值，用来表示所匹配块在另一张图中的位置\n\n随机搜索：每次匹配过后，对于得到的还会继续对其施加一个随机搜索的策略，试图通过扰动看看能不能让其跳出局部最优\n\n每次随机搜索会在上一步匹配传递的基础上，在不断指数衰减的半径区域里随机匹配若干次，直到半径缩到1个像素以下。\n\n\n\n该算法的核心思想是基于简化的假设，即在两幅图像中所寻找的匹配图像块的位置和相应误差值应该是较为接近的，因此可以通过随机的方式得到初始的近似匹配，通过不断迭代，逐步优化误差值，并不断缩小匹配图像块的搜索区域，最终找到最优的匹配位置。\n\npatchmatch算法虽然简单，但是在实践中具有较高的鲁棒性和准确性，能够在短时间内处理大量的匹配任务，尤其对于处理图像缺陷修复、图像填充、图像修补、图像合成和场景重建等任务具有独特的优势。因此，在计算机视觉领域，patchmatch算法越来越得到广泛的应用，并成为图像匹配领域的一个重要研究方向之一。\n\n在不断优化误差值时，patchmatch算法通过引入了多尺度的策略，可以使得算法更快地收敛至最优解。patchmath算法在处理大型图像时还可以通过快速近似最近邻搜索来加快算法速度，pathchmatch结果如下图所示。\n\n\n\n最近邻字段可以通过为字段分配随机值或使用先验信息来初始化。当使用随机偏移进行初始化时，我们在图像 b 的整个范围内使用独立的均匀样本。在第 4 节中描述的应用程序中，我们使用从粗到细的逐渐调整大小的过程，因此我们可以选择使用一个初始猜测从金字塔中的上一层升级。然而，如果我们只使用这个初始猜测，算法有时会陷入次优的局部最小值。为了保持这个先验的质量但仍然保留一些逃离这种最小值的能力，我们使用随机初始化执行算法的一些早期迭代，然后仅在 d 较小的补丁处与上采样初始化合并，然后执行剩余的迭代。\n\n初始化后，我们执行改进 nnf 的迭代过程。算法的每次迭代按如下方式进行：按扫描顺序（从左到右，从上到下）检查偏移量，并且每个偏移量都经过传播，然后进行随机搜索。这些操作在补丁级别交错：如果 pj 和 sj 分别表示补丁 j 的传播和随机搜索，那么我们按以下顺序进行：p1，s1，p2，s2，...。 . . , pn, 锡。传播。我们尝试使用 f (x − 1, y) 和 f (x, y − 1) 的已知偏移量来改进 f (x, y)，假设补丁偏移量可能相同。例如，如果在 (x − 1, y) 处有一个很好的映射，我们会尝试将该映射向右平移一个像素，用于我们在 (x, y) 处的映射。令 d(v) 表示 a 中 (x, y) 处的补丁与 b 中的补丁 (x, y) + v 之间的补丁距离（误差）。我们将 f (x, y) 的新值设为{d( f (x, y)), d( f (x − 1, y)), d( f (x, y − 1))} 的 arg min。结果是，如果 (x, y) 具有正确的映射并且位于相干区域 r 中，则 (x, y) 下方和右侧的所有 r 都将被正确的映射填充。此外，在偶数次迭代中，我们通过以反向扫描顺序检查偏移量来向上和向左传播信息，使用 f (x + 1, y) 和 f (x, y + 1) 作为我们的候选偏移量。随机搜索。令 v0 = f(x, y)。我们尝试通过在距 v0 呈指数递减的距离处测试一系列候选偏移来改进 f (x, y)：\n\nui=v0+wairi\n\n其中 ri 是 [−1, 1] × [−1, 1] 中的均匀随机数，w 是较大的最大搜索“半径”，α 是搜索窗口大小之间的固定比率。我们检查 i = 0, 1, 2, ... 的补丁，直到当前搜索半径 wαi 低于 1 个像素。在我们的应用程序中，w 是最大图像维度，α = 1/2，除非另有说明。请注意，搜索窗口必须限制在 b 的范围内。停止条件。虽然根据应用程序可能会使用不同的停止标准，但在实践中我们发现它可以很好地迭代固定次数。此处显示的所有结果都是通过总共 4-5 次迭代计算得出的，之后 nnf 几乎总是收敛。收敛如图 3 和随附的视频所示。效率。可以通过几种方式提高这种朴素方法的效率。在传播和随机搜索阶段，当尝试使用候选偏移量 u 改进偏移量 f (v) 时，如果 d(u) 的部分和超过当前已知距离 d( f (v))，则可以提前终止.此外，在传播阶段，当使用边长为 p 和 lq 范数的方形补丁时，距离的变化可以在 o(p) 而不是 o(p2) 时间内递增计算，方法是注意求和中的冗余项重叠区域。但是，这会产生额外的内存开销来存储当前最佳距离 d( f (x, y))。 gpu 实现。第 4 节中描述的编辑系统依赖于 nnf 估计算法的 cpu 实现，但我们还在 gpu 上制作了一个完全并行化变体的原型。为此，我们在随机搜索和传播的迭代之间交替，其中每个阶段并行处理整个偏移量字段。虽然传播本质上是一个串行操作，但我们采用了 rong 和 tan 的跳洪方案来执行多次迭代的传播。尽管我们的 cpu 版本能够在整个扫描线上传播信息，但我们发现实际上不需要长距离传播，最大跳跃距离为 8 就足够了。我们还在每个跳跃距离仅使用 4 个邻居，而不是 rong 和 tan 提出的 8 个邻居。\n\n我们的迭代算法在极限内收敛到精确的 nnf。在这里，我们为这种收敛提供了一个理论分析，表明它在前几次迭代中以高概率收敛得最快。此外，我们表明，在只需要近似补丁匹配的常见情况下，该算法收敛得更快。因此，通过将计算限制为少量迭代，我们的算法最适合用作近似算法。我们首先分析收敛到精确的最近邻域，然后将此分析扩展到更有用的收敛到近似解的情况。假设 a 和 b 具有相同的大小（m 个像素）并且使用随机初始化。尽管在这个初始猜测中任何一个位置被分配最佳偏移的几率微乎其微 (1/m)，但至少一个偏移被正确分配的几率非常好 (1 − (1 − 1/m)m ) ) 或对于大 m 大约为 1 − 1/e。由于随机搜索在小的局部区域中非常密集，我们还可以将“正确”分配视为正确偏移量周围大小为 c 像素的小邻域内的任何分配。这样的偏移量将在随机搜索的大约一次迭代中得到纠正。在这样的邻域中至少分配一个偏移量的可能性非常大：(1 − (1 −c/m)m ) 或对于大 m，1 − exp(−c)。\n\n现在我们为我们的算法考虑一个具有挑战性的综合测试用例：一个大小为 m 像素的独特区域 r 位于一对其他方面均一的图像 a 和 b 中的两个不同位置（插图所示）。这个图像是一个困难的案例，因为背景没有提供关于在哪里可以找到独特区域的偏移量的信息。均匀背景中的补丁可以匹配大量其他相同的补丁，这些补丁在一次迭代中以非常高的概率通过随机猜测找到，因此我们只考虑不同区域 r 的收敛。如果不同区域 r 中的任何一个偏移量是在正确偏移量的邻域 c 内，然后我们假设在少量迭代之后，由于小局部区域中随机搜索的密度（前面提到的），所有 r 都将通过传播是正确的（对于符号简单假设这是瞬时的）。现在假设 r 还没有收敛。考虑我们的算法在最大尺度 w 下执行的随机搜索。规模为 w 的随机搜索迭代独立地对图像 b 进行采样，并且这些样本中的任何一个落在正确偏移量的邻域 c 内的概率 p 为\n\np=1−(1−cm)m\n\n在进行任何迭代之前，收敛的概率为 p。我们没有在迭代 0, 1, ...,t − 1 上收敛并在迭代 t 上收敛的概率是 p(1 − p)t 。概率因此形成几何分布，预期收敛时间为t = 1/p − 1。为了简化，让相对特征尺寸为γ = m/m，然后随着分辨率m变大取极限：\n\n<t>=[1−(1−cm)γm]−1−1limm⟶∞<t>=[1−exp⁡(−cγ)]−1−1\n\n通过对小 γ 的泰勒展开，t = (cγ)−1 − 1 2 = m/(cm) − 1 2 。也就是说，对于大图像分辨率和相对于图像分辨率 m 的小特征尺寸 m，我们预期的收敛迭代次数保持不变。我们对从 0.1 到 2 兆像素的分辨率 m 的图像进行了模拟，证实了这个模型。例如，我们发现对于 m = 202 的区域，算法在对 m = 20002 的图像进行 5 次迭代后以非常高的概率收敛。上面的测试用例很难，但不是精确匹配的最差测试用例。精确匹配的最坏情况是当图像 b 包含高度重复的纹理和许多与 a 中的不同特征相似的干扰物时。偏移可能会被其中一个干扰物“困住”，有效邻域区域大小 c 可能是减少到 1（即，只有完全匹配才能在随机搜索期间将解决方案从干扰项中拉出）。然而在实践中，对于许多图像分析和合成应用程序，例如我们在本文中展示的应用程序，找到近似匹配（根据补丁相似性）不会导致任何明显的差异。\n\n在纹理重建方面，我们使用了多视觉立体投影的方法，将特定区域内的多张图像投影到三维重建模型上，从而得到了真实的纹理信息。我们的纹理重建方法采用了多标定照相机和多时刻捕获信息等技术，确保了纹理映射的准确性和一致性。通过采用贴图和参数空间纹理映射等算法，我们成功地为三维重建模型添加了逼真的纹理信息。经过反复验证和调整，我们的纹理重建结果非常出色，可以有效地提高三维模型的逼真度和真实感。\n\n\n\n\n# 三、创新点\n\n本系统在基于特征点提取和匹配的三维重建方法上有以下创新点：\n\n我们结合了增量sfm和全局sfm的优化方法，构建场景图，并将大场景划分为多个小场景，并行对多个小场景进行增量重建，最后通过融合的方式将多个小场景合并为大场景。同时在一些优化过程中，我们提出了多种优化策略，从而可以得到较高精度的三维模型。\n\n我们结合传统计算机视觉技术和深度学习技术，在不同阶段使用不同类型的特征表示来提高三维重建效果。在特征检测阶段使用sift特征，在稠密重建阶段使用mvsnet深度预测。\n\n我们提出了一种基于光束法的稠密重建方法，在保证精度和鲁棒性的同时降低了计算复杂度。我们利用sfm得到的相机姿态信息来约束光束法搜索空间，并利用深度学习预测深度信息来加速光束法求解过程。\n\n我们提出了一种基于多视觉立体投影的纹理重建方法，在保证纹理质量和一致性的同时增加了纹理多样性。我们利用多标定照相机捕获不同角度、不同光照条件下的图像，并利用参数空间纹理映射算法将它们融合到三维模型上。",charsets:{cjk:!0}},{title:"读书随笔",frontmatter:{title:"读书随笔",date:"2022-07-08T15:10:15.000Z",permalink:"/pages/db78e2"},regularPath:"/03.%E7%94%9F%E6%B4%BB/01.%E9%9A%8F%E7%AC%94.html",relativePath:"03.生活/01.随笔.md",key:"v-8263629e",path:"/pages/db78e2/",headers:[{level:2,title:"《遇见未知的自己》",slug:"《遇见未知的自己》",normalizedTitle:"《遇见未知的自己》",charIndex:2},{level:3,title:"01.我是谁",slug:"_01-我是谁",normalizedTitle:"01.我是谁",charIndex:16},{level:3,title:"04.失落了真实的自己",slug:"_04-失落了真实的自己",normalizedTitle:"04.失落了真实的自己",charIndex:101},{level:3,title:"12.潜意识的表达方式",slug:"_12-潜意识的表达方式",normalizedTitle:"12.潜意识的表达方式",charIndex:227},{level:3,title:"13.我们身体的障碍",slug:"_13-我们身体的障碍",normalizedTitle:"13.我们身体的障碍",charIndex:310},{level:2,title:"《非暴力沟通》",slug:"《非暴力沟通》",normalizedTitle:"《非暴力沟通》",charIndex:1344},{level:2,title:"《可能性的艺术》",slug:"《可能性的艺术》",normalizedTitle:"《可能性的艺术》",charIndex:1501},{level:2,title:"《叫魂》",slug:"《叫魂》",normalizedTitle:"《叫魂》",charIndex:2413},{level:2,title:"《置身事内》",slug:"《置身事内》",normalizedTitle:"《置身事内》",charIndex:2485}],headersStr:"《遇见未知的自己》 01.我是谁 04.失落了真实的自己 12.潜意识的表达方式 13.我们身体的障碍 《非暴力沟通》 《可能性的艺术》 《叫魂》 《置身事内》",content:"# 《遇见未知的自己》\n\n\n# 01.我是谁\n\n第一次看到本我，以前从来没有想过我是谁这个问题，或者说我也是像若凌一样，我只是我所处的环境。这是一个值得我深思的问题，我估计看完也不知道我是谁。\n\n\n# 04.失落了真实的自己\n\n快乐和喜悦是不同的，快乐是由外在事物引发的，喜悦是由内向外的绽放。对我来说，平时上下班路上要走10~15分钟，虽然有时候一群人走会很快乐，能谈天说地，但偶尔我还是喜欢一个人走，一个人去湖边逛，能有更多的“心理斗争”。\n\n\n# 12.潜意识的表达方式\n\n你不是你的工作，你不是你的表现，你不是你的成功，你不是你的失败。这些外在的东西，丝毫动摇不到你那内在的真我，看清楚小我的虚假认同！\n\n\n# 13.我们身体的障碍\n\n细胞记忆这个细思极恐\n\n小我不断抓取一些东西，以证明我们存在，越向外抓取，越远离我们的内心。\n\n小我增长。回忆起以前，身边的人很多都是这样，我也是这样。每次见面，聚会，每个人都有说不完的故事，后来慢慢的我觉得我说不过他们了，我觉得的我的生活经历不够丰富了，就慢慢很少分享生活。虽然我分享生活少了，但我还是想聆听他们的故事。\n\n一些天生的恐惧，所求不得的愤怒，希望落空的悲伤，都只是一种能量的自然流动而已，它会来，就一定会走。这句话很治愈，我也是这样的。有时候做一些事情前的紧张，恐惧，“任务失败”的悲伤，这些也只是暂时出现，我还是会完成这些事。\n\n臣服事实。\n\n跳出自我看自我。\n\n“应该”，“必须”。以前我也总是接受这种观念，我就应该怎么怎么样，必须怎么怎么样...后来变成，我有时也会对别人这样说，你应该这样，必须这样。现在仔细想想，真是愚蠢至极。每个人都有自己的思想，我也不可能是“神”，每个人都应该按照自己的思想活着，“试图改变他人的想法”，这个我觉得真的很不尊重他人。\n\n亲爱的，外面没有别人。所有外在事物都是你内心投射出来的结果。这可能就是《盗梦空间》的筑梦师吧。\n\n《我允许》\n\n> 我允许任何事情的发生\n> \n> 我允许，事情是如此的开始\n> \n> 如此的发展，如此的结局\n> \n> 因为我知道，\n> \n> 所有的事情，都是因缘和合而来\n> \n> 一切的发生，都是必然\n> \n> 若我觉得应该是另外一种可能\n> \n> 伤害的，只是自己\n> \n> 我唯一能做的\n> \n> 就是允许\n\n心想事成这个，让自己随时随地都处在你已经得到了你想要的东西之后的感受。嗯，，，em...这个，我暂时还不是很理解。\n\n“担心”是最差的礼物，不如给他祝福。是的，过度的担心会使人焦虑起来，让人过多的关心担心这件事上，反而适得其反。 这个不是最后看到的，但是是最快感受到的。我之前有段时间就比较担心你，担心你实习要去到哪里，还会有没有时间复习考研，考研怎么规划，做毕设，在外地实习租的房子怎么处理，好多问题想问...（上次说打电话就想跟你聊 “觉得对方那样做才是对的”，和 《侧耳倾听》里，岛雯不好好上学，写自己的老人故事（我先记着））。周五说我们 属于有点“暧昧”了，会影响我们中其它的生活状态。我也感觉到我的学习效率有所影响（当然这个原因是多方面）。嗯，，，我们现在适合分享书上知识，理解，看法，不要过度担心彼此，彼此祝福，彼此进步：）\n\n\n# 《非暴力沟通》\n\n第九章 爱自己\n\n在日常生活中，有觉知地根据需要和价值观来选择行动，而不是为了履行职责、获得外在的奖励，或是逃避内疚、羞愧和乘法，我们便是在培养对自己的爱。\n\n我生气，因为他们....\n\n我生气，因为我需要....\n\n让我愤怒的并非他人的行为，而是我在头脑中对他人及其行为的看法和解读。\n\n\n# 《可能性的艺术》\n\n只懂一个国家的人不懂任何国家。\n\n你有保持沉默的权利，但是你所说的的每句话都将成为呈堂证供。\n\n优胜者偏见。\n\n当我们研究一个东西是往往在用一把隐藏的尺子来进行分析判断。\n\n国家能力，一个很重要的体现：征税能力，丹麦45.3%。\n\n国家能力越强越好吗，秦朝中国，民有二男以上不分异者，倍其赋。不高奸者腰斩。\n\n衡量政治发展的两个尺度，一个是衡量民主问责，一个是衡量国家能力。\n\n可以说，比较的事业本质上是一种俯瞰的事业，从“此时此地”抽离，来到多样性的“上空”，从宏观开始领略，然后慢慢聚焦到围观，也就是从森林开始，慢慢聚焦的树木。这样做的好处，就是不管你在分析多么具体的问题，在你脑海的深处，始终有一种比例感，有一篇隐隐约约的森林，它提醒着你，你所见到的只是现象，而现象未必是真想。可能我思考得越多，就越相信，智慧的本质就是对事务比例的公正判断。\n\n我们之所以没有意识到这一点，很大程度上是因为人类天生更关注现实而不是历史，而且我们习惯于用理想而不是过去来衡量当下。\n\n不要让最好成为更好的敌人。\n\n经济全球化让发达国家的工人竞争变大，压力变大。中国的民工能够影响阿富汗的局势。\n\n国家是特定疆域内合法地垄断暴力机构，其它暴力机构都是违法的，不允许的。\n\n每一次政治趋势的巨大变化，都会带来政治学研究框架的巨大变化。\n\n“重新带回国家”，1968年有学者认为，共产主义国家和西方自由主义国家都属于有效的而不是软弱的政治系统，也就是它们是一类国家，都是“强国家”。到苏东巨变，说到底，美国和苏联不是同一类国家，统治形式很重要，于是国家视角走向了沉寂。这个观点又被取而代之，“制度主义”，至于国家则是那个被“关进笼子”里的“老虎”。到如今，中国的崛起，以及民主化浪潮在很多地方的受挫，使得人又开始怀疑制度主义。如果制度主义是对的，那么，为什么没有采取西方制度的中国能够冉冉升起？二很多采用了西方制度的国家则深陷泥沼。或许其中还有重要的剩余变量，国家。\n\n国家的本质是暴力从分散走向垄断。一个强国家一定是实现了暴力高度垄断的国家，也就意味着分散暴力的减少。\n\n国家的另一个重大功能，是提供公共服务。\n\n\n# 《叫魂》\n\n1768年春天，浙江某个地方要修一座桥，要招标，有一个石匠拿下了这个工程，然后这个时候有谣言石匠要偷人魂魄来打庄，\n\n\n\n\n\n\n# 《置身事内》\n\n 1. 政府部门之间，受条条块块之间的约束，条条之间的业务关系，块块之间的领导关系。\n 2. 市级业务之内的事情，市政府可以直接决定，夸市的事情，需要上级省政府出台协调。行政交界处地区的经济发展一般比较落后，省政府不会把有限的资源优先配置到边界地区。\n 3. 信息的不对称，一方面上级具有决定权，但下级拥有绝对的信息优势，实际情况决定权还是在下级手上。一般有上级的监督和审查。一件事该不该做？要做到什么程度？怎么样算做得好？做好了算谁的功劳？做砸了由谁负责？这些问题往往没有清楚的标准。说不出清楚的情况越多，权力就一定会向个人集中。\n 4. 从原来的包干制，地方预算内收入与中央分成，预算外归地方。地方想尽办法让预算内收入减少，增加预算外收入（藏富于企业）。手里没把米，叫鸡都不来。要增加中央财政收入，分税制改革。增值税变共享税，中央拿75%。总之地方财政收入逐年下跌。\n 5. 地方政府事情变多了，但手里可支配的资源减少了。分税制改革时，国有土地转让的决定权和收益都留给地方，土地财政。\n 6. 土地金融，将土地做为抵押物，向银行贷款。另一方面政府不能直接向银行借钱，但政府成立专门的公司，就可以。。。供给不平衡，政府限制城市住房用地，来提高土地价格，借更多的钱。\n 7. 工业化中政府角色，政府会干预市场的运转，补贴哪个行业，补贴哪个公司。\n\n我如果知道你是安好的，我会很放心。为自己的安全感负责，及时满足对方的情感需求。\n\n不见面的时间，多提升自己，看书、运动、兴趣爱好、改善外形，提升对自己的信心。\n\n理解和信任是爱的基础，相信自己，相信最初的选择。\n\n积极的分享，让双方对彼此的生活有参与感，需要更多美好体验细节的积累。\n\n固定的交流时间，有期待，目的是为了增进感情。\n\n自身有故事，在对方看来是吸引点。没有感情是靠聊天就能维系的，能维系感情的是相互吸引。\n\n多一些共同经历，看书，分享观点。\n\n引导对方投入，和自己投入。\n\n未来。",normalizedContent:"# 《遇见未知的自己》\n\n\n# 01.我是谁\n\n第一次看到本我，以前从来没有想过我是谁这个问题，或者说我也是像若凌一样，我只是我所处的环境。这是一个值得我深思的问题，我估计看完也不知道我是谁。\n\n\n# 04.失落了真实的自己\n\n快乐和喜悦是不同的，快乐是由外在事物引发的，喜悦是由内向外的绽放。对我来说，平时上下班路上要走10~15分钟，虽然有时候一群人走会很快乐，能谈天说地，但偶尔我还是喜欢一个人走，一个人去湖边逛，能有更多的“心理斗争”。\n\n\n# 12.潜意识的表达方式\n\n你不是你的工作，你不是你的表现，你不是你的成功，你不是你的失败。这些外在的东西，丝毫动摇不到你那内在的真我，看清楚小我的虚假认同！\n\n\n# 13.我们身体的障碍\n\n细胞记忆这个细思极恐\n\n小我不断抓取一些东西，以证明我们存在，越向外抓取，越远离我们的内心。\n\n小我增长。回忆起以前，身边的人很多都是这样，我也是这样。每次见面，聚会，每个人都有说不完的故事，后来慢慢的我觉得我说不过他们了，我觉得的我的生活经历不够丰富了，就慢慢很少分享生活。虽然我分享生活少了，但我还是想聆听他们的故事。\n\n一些天生的恐惧，所求不得的愤怒，希望落空的悲伤，都只是一种能量的自然流动而已，它会来，就一定会走。这句话很治愈，我也是这样的。有时候做一些事情前的紧张，恐惧，“任务失败”的悲伤，这些也只是暂时出现，我还是会完成这些事。\n\n臣服事实。\n\n跳出自我看自我。\n\n“应该”，“必须”。以前我也总是接受这种观念，我就应该怎么怎么样，必须怎么怎么样...后来变成，我有时也会对别人这样说，你应该这样，必须这样。现在仔细想想，真是愚蠢至极。每个人都有自己的思想，我也不可能是“神”，每个人都应该按照自己的思想活着，“试图改变他人的想法”，这个我觉得真的很不尊重他人。\n\n亲爱的，外面没有别人。所有外在事物都是你内心投射出来的结果。这可能就是《盗梦空间》的筑梦师吧。\n\n《我允许》\n\n> 我允许任何事情的发生\n> \n> 我允许，事情是如此的开始\n> \n> 如此的发展，如此的结局\n> \n> 因为我知道，\n> \n> 所有的事情，都是因缘和合而来\n> \n> 一切的发生，都是必然\n> \n> 若我觉得应该是另外一种可能\n> \n> 伤害的，只是自己\n> \n> 我唯一能做的\n> \n> 就是允许\n\n心想事成这个，让自己随时随地都处在你已经得到了你想要的东西之后的感受。嗯，，，em...这个，我暂时还不是很理解。\n\n“担心”是最差的礼物，不如给他祝福。是的，过度的担心会使人焦虑起来，让人过多的关心担心这件事上，反而适得其反。 这个不是最后看到的，但是是最快感受到的。我之前有段时间就比较担心你，担心你实习要去到哪里，还会有没有时间复习考研，考研怎么规划，做毕设，在外地实习租的房子怎么处理，好多问题想问...（上次说打电话就想跟你聊 “觉得对方那样做才是对的”，和 《侧耳倾听》里，岛雯不好好上学，写自己的老人故事（我先记着））。周五说我们 属于有点“暧昧”了，会影响我们中其它的生活状态。我也感觉到我的学习效率有所影响（当然这个原因是多方面）。嗯，，，我们现在适合分享书上知识，理解，看法，不要过度担心彼此，彼此祝福，彼此进步：）\n\n\n# 《非暴力沟通》\n\n第九章 爱自己\n\n在日常生活中，有觉知地根据需要和价值观来选择行动，而不是为了履行职责、获得外在的奖励，或是逃避内疚、羞愧和乘法，我们便是在培养对自己的爱。\n\n我生气，因为他们....\n\n我生气，因为我需要....\n\n让我愤怒的并非他人的行为，而是我在头脑中对他人及其行为的看法和解读。\n\n\n# 《可能性的艺术》\n\n只懂一个国家的人不懂任何国家。\n\n你有保持沉默的权利，但是你所说的的每句话都将成为呈堂证供。\n\n优胜者偏见。\n\n当我们研究一个东西是往往在用一把隐藏的尺子来进行分析判断。\n\n国家能力，一个很重要的体现：征税能力，丹麦45.3%。\n\n国家能力越强越好吗，秦朝中国，民有二男以上不分异者，倍其赋。不高奸者腰斩。\n\n衡量政治发展的两个尺度，一个是衡量民主问责，一个是衡量国家能力。\n\n可以说，比较的事业本质上是一种俯瞰的事业，从“此时此地”抽离，来到多样性的“上空”，从宏观开始领略，然后慢慢聚焦到围观，也就是从森林开始，慢慢聚焦的树木。这样做的好处，就是不管你在分析多么具体的问题，在你脑海的深处，始终有一种比例感，有一篇隐隐约约的森林，它提醒着你，你所见到的只是现象，而现象未必是真想。可能我思考得越多，就越相信，智慧的本质就是对事务比例的公正判断。\n\n我们之所以没有意识到这一点，很大程度上是因为人类天生更关注现实而不是历史，而且我们习惯于用理想而不是过去来衡量当下。\n\n不要让最好成为更好的敌人。\n\n经济全球化让发达国家的工人竞争变大，压力变大。中国的民工能够影响阿富汗的局势。\n\n国家是特定疆域内合法地垄断暴力机构，其它暴力机构都是违法的，不允许的。\n\n每一次政治趋势的巨大变化，都会带来政治学研究框架的巨大变化。\n\n“重新带回国家”，1968年有学者认为，共产主义国家和西方自由主义国家都属于有效的而不是软弱的政治系统，也就是它们是一类国家，都是“强国家”。到苏东巨变，说到底，美国和苏联不是同一类国家，统治形式很重要，于是国家视角走向了沉寂。这个观点又被取而代之，“制度主义”，至于国家则是那个被“关进笼子”里的“老虎”。到如今，中国的崛起，以及民主化浪潮在很多地方的受挫，使得人又开始怀疑制度主义。如果制度主义是对的，那么，为什么没有采取西方制度的中国能够冉冉升起？二很多采用了西方制度的国家则深陷泥沼。或许其中还有重要的剩余变量，国家。\n\n国家的本质是暴力从分散走向垄断。一个强国家一定是实现了暴力高度垄断的国家，也就意味着分散暴力的减少。\n\n国家的另一个重大功能，是提供公共服务。\n\n\n# 《叫魂》\n\n1768年春天，浙江某个地方要修一座桥，要招标，有一个石匠拿下了这个工程，然后这个时候有谣言石匠要偷人魂魄来打庄，\n\n\n\n\n\n\n# 《置身事内》\n\n 1. 政府部门之间，受条条块块之间的约束，条条之间的业务关系，块块之间的领导关系。\n 2. 市级业务之内的事情，市政府可以直接决定，夸市的事情，需要上级省政府出台协调。行政交界处地区的经济发展一般比较落后，省政府不会把有限的资源优先配置到边界地区。\n 3. 信息的不对称，一方面上级具有决定权，但下级拥有绝对的信息优势，实际情况决定权还是在下级手上。一般有上级的监督和审查。一件事该不该做？要做到什么程度？怎么样算做得好？做好了算谁的功劳？做砸了由谁负责？这些问题往往没有清楚的标准。说不出清楚的情况越多，权力就一定会向个人集中。\n 4. 从原来的包干制，地方预算内收入与中央分成，预算外归地方。地方想尽办法让预算内收入减少，增加预算外收入（藏富于企业）。手里没把米，叫鸡都不来。要增加中央财政收入，分税制改革。增值税变共享税，中央拿75%。总之地方财政收入逐年下跌。\n 5. 地方政府事情变多了，但手里可支配的资源减少了。分税制改革时，国有土地转让的决定权和收益都留给地方，土地财政。\n 6. 土地金融，将土地做为抵押物，向银行贷款。另一方面政府不能直接向银行借钱，但政府成立专门的公司，就可以。。。供给不平衡，政府限制城市住房用地，来提高土地价格，借更多的钱。\n 7. 工业化中政府角色，政府会干预市场的运转，补贴哪个行业，补贴哪个公司。\n\n我如果知道你是安好的，我会很放心。为自己的安全感负责，及时满足对方的情感需求。\n\n不见面的时间，多提升自己，看书、运动、兴趣爱好、改善外形，提升对自己的信心。\n\n理解和信任是爱的基础，相信自己，相信最初的选择。\n\n积极的分享，让双方对彼此的生活有参与感，需要更多美好体验细节的积累。\n\n固定的交流时间，有期待，目的是为了增进感情。\n\n自身有故事，在对方看来是吸引点。没有感情是靠聊天就能维系的，能维系感情的是相互吸引。\n\n多一些共同经历，看书，分享观点。\n\n引导对方投入，和自己投入。\n\n未来。",charsets:{cjk:!0}},{title:"一群游戏天才",frontmatter:{title:"一群游戏天才",date:"2023-06-03T16:56:13.000Z",permalink:"/pages/76e940/"},regularPath:"/03.%E7%94%9F%E6%B4%BB/06.game.html",relativePath:"03.生活/06.game.md",key:"v-012dc53d",path:"/pages/76e940/",headersStr:null,content:"约翰卡马克，从小造过炸药，修改过游戏，写过游戏，开过公司，技术大牛。\n\n约翰罗梅罗，游戏技术大牛，设计师，与卡马克一同开办公司。\n\n两位天才遇到一起，想给世界一点震撼。\n\n----------------------------------------\n\n罗梅罗在软盘公司正缺人手，认为公司的其他程序员都是傻逼，继续一位天才，一通电话后，卡马克开着新改装的小车到了软盘公司，两人一拍即合，便开始和合作之旅。\n\n激情澎湃的两人，在短时间内便开发了许多游戏，两人所在的工作室也撑起了软盘公司的利润收入。很快两人便觉得这里不满，想在游戏中添加更多的想法，于是谋生了窃公司电脑的想法。没到周五，将公司电脑搬到一个湖边别墅，便开始没日没夜的专注于自己的游戏开发，到工作日之时便把电脑搬回公司。“想好了，我们走”。很快的，公司容不下两人施展拳脚，便连通公司的几位有技术的人员，一同挖走，创办id software公司。\n\n这时，电脑游戏简单的背景不变的单一游戏，受限于当时电脑性能，让其不能渲染实时变化的场景。对比之下，任天堂的游戏机已经可以实现变化场景的游戏。可电脑性能问题，终究抵挡不住卡马克的热情，很快便实现了横向卷轴技术，欺骗电脑不需要每次都重新绘制场景，只需要将绘制过的重复利用起来。不过多久，卡马克和其团队便一比一的模仿任天堂的马里奥游戏，区别将马里奥替换为戴夫。心高气盛的他们，将他们做出来的游戏，发给任天堂请求说，我们可以为你做游戏机的游戏电脑移植版。很显然，任天堂根本不屑于理会他们，并且发了一封侵权律师函。\n\n卡马克是一名技术纯粹者，开源软件的倡导者，反对申请软件专利，但是也一直处于孤军奋战。他认为，世界没有难题，只差一台计算机，书，和一个冰箱以及可乐和披萨，便可以创造世界。之后他纷纷突破游戏引擎，实现3D，贴图，光影等技术，使得他的游戏DOOM，成为当时美国无人不爱的游戏，对游戏领域的发展影响巨大，被称为“电子海洛因”。但是他那纯粹的技术爱好者，团队里其他元老纷纷离开了，到2013年，他也离开了自己创办的id software。\n\n离开后，卡马克还爱好火箭发射器，并成了一个私人研发团队。搞火箭，马斯克固然也不会放过这样的人才，但是卡马克还是拒绝了，并说，找到了自己喜欢的方向，VR。\n\n加入了FaceBook，开始了VR之旅，尽管他再天才，做出了很大努力，这个行业终究也没能激起很大浪花。在2022年获得了VR终身成就奖，但是颁奖词却说，对VR取得的进展并不满意，厌烦了自己的公司拥有这么多的资源，但是都浪费在了奇奇怪怪的事情上面。\n\n离开了VR，感慨到，过去总是在一些方向确定的领域，游戏，火箭，VR。这次趁着年轻，踏入一个不知会走向何方的领域，通用人工智能。",normalizedContent:"约翰卡马克，从小造过炸药，修改过游戏，写过游戏，开过公司，技术大牛。\n\n约翰罗梅罗，游戏技术大牛，设计师，与卡马克一同开办公司。\n\n两位天才遇到一起，想给世界一点震撼。\n\n----------------------------------------\n\n罗梅罗在软盘公司正缺人手，认为公司的其他程序员都是傻逼，继续一位天才，一通电话后，卡马克开着新改装的小车到了软盘公司，两人一拍即合，便开始和合作之旅。\n\n激情澎湃的两人，在短时间内便开发了许多游戏，两人所在的工作室也撑起了软盘公司的利润收入。很快两人便觉得这里不满，想在游戏中添加更多的想法，于是谋生了窃公司电脑的想法。没到周五，将公司电脑搬到一个湖边别墅，便开始没日没夜的专注于自己的游戏开发，到工作日之时便把电脑搬回公司。“想好了，我们走”。很快的，公司容不下两人施展拳脚，便连通公司的几位有技术的人员，一同挖走，创办id software公司。\n\n这时，电脑游戏简单的背景不变的单一游戏，受限于当时电脑性能，让其不能渲染实时变化的场景。对比之下，任天堂的游戏机已经可以实现变化场景的游戏。可电脑性能问题，终究抵挡不住卡马克的热情，很快便实现了横向卷轴技术，欺骗电脑不需要每次都重新绘制场景，只需要将绘制过的重复利用起来。不过多久，卡马克和其团队便一比一的模仿任天堂的马里奥游戏，区别将马里奥替换为戴夫。心高气盛的他们，将他们做出来的游戏，发给任天堂请求说，我们可以为你做游戏机的游戏电脑移植版。很显然，任天堂根本不屑于理会他们，并且发了一封侵权律师函。\n\n卡马克是一名技术纯粹者，开源软件的倡导者，反对申请软件专利，但是也一直处于孤军奋战。他认为，世界没有难题，只差一台计算机，书，和一个冰箱以及可乐和披萨，便可以创造世界。之后他纷纷突破游戏引擎，实现3d，贴图，光影等技术，使得他的游戏doom，成为当时美国无人不爱的游戏，对游戏领域的发展影响巨大，被称为“电子海洛因”。但是他那纯粹的技术爱好者，团队里其他元老纷纷离开了，到2013年，他也离开了自己创办的id software。\n\n离开后，卡马克还爱好火箭发射器，并成了一个私人研发团队。搞火箭，马斯克固然也不会放过这样的人才，但是卡马克还是拒绝了，并说，找到了自己喜欢的方向，vr。\n\n加入了facebook，开始了vr之旅，尽管他再天才，做出了很大努力，这个行业终究也没能激起很大浪花。在2022年获得了vr终身成就奖，但是颁奖词却说，对vr取得的进展并不满意，厌烦了自己的公司拥有这么多的资源，但是都浪费在了奇奇怪怪的事情上面。\n\n离开了vr，感慨到，过去总是在一些方向确定的领域，游戏，火箭，vr。这次趁着年轻，踏入一个不知会走向何方的领域，通用人工智能。",charsets:{cjk:!0}},{title:"程序员的打怪升级",frontmatter:{title:"程序员的打怪升级",date:"2023-06-14T15:47:57.000Z",permalink:"/pages/f5ba2a/"},regularPath:"/03.%E7%94%9F%E6%B4%BB/07.%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%89%93%E6%80%AA%E5%8D%87%E7%BA%A7.html",relativePath:"03.生活/07.程序员的打怪升级.md",key:"v-095f08a6",path:"/pages/f5ba2a/",headers:[{level:2,title:"供需关系",slug:"供需关系",normalizedTitle:"供需关系",charIndex:196},{level:2,title:"渠道",slug:"渠道",normalizedTitle:"渠道",charIndex:627},{level:2,title:"职业路线",slug:"职业路线",normalizedTitle:"职业路线",charIndex:720},{level:2,title:"职业画布",slug:"职业画布",normalizedTitle:"职业画布",charIndex:731},{level:2,title:"新手快速起步",slug:"新手快速起步",normalizedTitle:"新手快速起步",charIndex:742},{level:2,title:"职业老手",slug:"职业老手",normalizedTitle:"职业老手",charIndex:908},{level:2,title:"瓶颈",slug:"瓶颈",normalizedTitle:"瓶颈",charIndex:977}],headersStr:"供需关系 渠道 职业路线 职业画布 新手快速起步 职业老手 瓶颈",content:"一个程序员值多少钱\n\n\n\n简历就是我的价值主张，我到公司来，我能完成这些工作，为公司带来这样的价值，而我只要这一点点的薪水，所以赶紧雇佣我吧。\n\n公司雇佣一个人，并不是看他有多牛，而是能给公司带来什么价值。一个人拥有一系列技能，在不同公司创造的价值是不同的，于是拿到的薪资也不一样。除此之外，薪资还受市场供需，信息透明度影响。\n\n员工的价值一般是在之前的工作经历和业绩基础上来估算。\n\n\n# 供需关系\n\n每一波浪潮带来的新兴市场和高利润行业交叉的细分市场职位就会更之前一些。\n\n专注细分市场：削减宽度来提升深度的求职策略。\n\n把原来覆盖整个市场的经历，用到一小块上，让我在这个细分领域做得比别人更好。在所有经历都投入到细分市场之前，要考量这个细分市场的大小和发展。\n\n专注新兴市场：利用技术边界的变动来拉平经验差距的求职策略。\n\n当一个新技术出来的时候，原来不能做的事情变得能做了，原来的一些规则和经验变得不好用了，这是一个非常好的新人切入机会，例如iOS刚出来。最简单判断一个新兴市场是否靠谱，看资本的流入速度，有资本涌入，就会催生大量公司，就会大量招人，然而供应端也还小。云计算、移动开发、直播、区块链、人工智能。\n\n量化分析\n\n招聘网站的招聘启事中包含了大量的信息，通过爬虫可以获取某职位所需要的技能。但是数据量很大，用统计值来估计与真实自己会有很大误差。所以最好的方式，每隔一段时间去面试看看，真实了解需求，以及薪资，这个是真金白银的。\n\n\n# 渠道\n\n内推一般都有面试机会。正好有个熟识的朋友在这家公司，既可以了解这个团队是否好相处，是否加班，老板是否靠谱等，同时员工一般内推也会有奖励，所以一般员工都乐意干内推这件事。\n\n\n# 职业路线\n\n\n\n\n# 职业画布\n\n\n\n\n# 新手快速起步\n\n充电期\n\n还是新人的时候，并不是一进来就能给公司贡献价值，而公司还要支付我的工资，所以最重要的就是，尽快充满电，脱离这个状态。\n\n放电器\n\n时间久了发现自己在技术上再也没有成长空间了，如果还是一个初中级开发者，那就要留意了。离职了原来的同事还是可以变成朋友的，离职多了就习惯了，也就不会纠结人情......\n\n\n# 职业老手\n\n谁对谁错没有意义，没人犯错才有意义。\n\n公司不能培养自己，要学会自己培养自己。\n\n规划好我的职业，哪年都不会有危机。\n\n\n# 瓶颈\n\n瓶颈一：不明白人和机器的区别\n\n> 一旦进入管理线，我们会非常明显的感受到和以前的不同。因为之前主要都是和机器打交道，纯逻辑的二元化生物，非此即彼，非常好相处。\n> \n> 但是从管理线开始呢，我们就要开始和人打交道了。这些人可能是你的下属、也可能是公司其他部门的同事，比如我们「深恶痛绝」的产品经理、测试部门、HR部门（ 招聘面试 ）等等。各种各样的人都会进入到你的工作中来，人嘛，都是情绪化的动物，和机器是完全不同的。所以我们在进入管理线的时候，要尽快适应和他们打交道的方法。\n\n瓶颈二：不理解规则的意义，崇尚自由主义\n\n> 当程序员的时候，往往是单枪匹马解决问题，很多东西自己想怎么来就怎么来。但当你走上管理岗位以后，人一多就会发现，不能由着每个人按自己的想法来，不然这个程序员用 PHP ，旁边那个用 Python ，代码库格式百花齐放，完全没法看。\n> \n> 所以规则是为了提升整体的生产效率，所做的一些妥协。不要敌视规则，现在你可以一定程度的参与规则的制定了，尝试好好的改进它和利用它。\n\n瓶颈三：缺乏良好的沟通和表达能力\n\n> 在开发岗时，虽然也需要一定的沟通和表达能力，但其实基本也就写文档、和做工作汇报时会用到；但在管理岗上，就不一样了。\n> \n> 这是一个承上启下的岗位，一方面你需要理解领导的意图，将其转化为对应的解决方案，再提交领导审阅，想办法说服领导支持你的方案；另一方面你又要培养新人，确保他们明白自己要做的工作，习得对应的技能，能按时按量的完成开发工作。在这种岗位，一旦在沟通和表达中出现问题，就会被成倍的放大。\n> \n> 这种能力需要花时间去培养，很难一蹴而就。但好在我们虽然是管理岗，但它依然是技术相关的，它描述的依然是非常理性的东西，不太会出现创意行业那种「跳跃性思维」和「无法用语言来表述的感觉」之类的内容。所以基本上，只要我们把条理性把握好，就能输出简单易懂的内容。即使它可能有一点点枯燥，但会很清晰。如果你还能自然的嵌几个笑话进去，那么应付技术讲座就绰绰有余了。\n\n瓶颈四：不能迅猛的招聘和培养下属，将工作分担下去\n\n> 招聘和培养下属，是中层管理者除技术以外最重要的能力之一，我们要持续而稳定的为公司提供研发能力，确保能支持公司现在的业务，并能跟得上未来的发展。\n> \n> 所以我们必须掌握一整套的方法，包括如何招聘新人、招聘进来以后如何培养、试用期如何识别种子选手、转正后如何最大的为公司贡献价值，还要留意他们对公司的满意度啊、个人的发展意愿和发展空间，以免刚培养出来就跳槽了之类的。\n> \n> 掌握不好这些技能，就无法放大自己的能力，所有的事情都只好亲力亲为，天天加班。为了避免这种悲惨未来，我们甚至从进入管理线之前，就应该有意识的去培养这些能力。首先要养成写技术博客或者笔记的习惯；然后可以试试把日常工作中的经验和教训总结下来，以书籍或课程的方式分享出去，这样除了能提升能力，还可以挣点零花钱。\n\n瓶颈五：面对大挑战时失去斗志，茫然无措\n\n> 刚进入管理线，或者突然老板给了你一个难度很大的任务的时候，面对千头万绪的事情，很容易发蒙。这种时候，首先要镇定下来，然后将这个任务拆分成一个一个的小挑战，去分析其中的风险，从而制定出一系列容易达到的小目标。\n> \n> 当我们不断的去完成这些难度不大的小目标时，会获得持续的小成功，这些成功堆积起来的信心，最后会帮助我们解决掉最后的那个难题。因为在难题面前，最常见的失败就是失去信心。你都不相信自己能做出来的时候，那当然就做不出来了。\n\n一个小建议：来一次「迷你技术创业」\n\n> 管理是非常依赖于实践的事情，你看着那些管理大师的巨著，然后在脑海中演练，其实最后什么用都没有的，只有实际经历过，才能感同身受。\n> \n> 好在我们是程序员，可以从无到有的创建一个软件。所以我们可以利用业余时间，去开发一个商业软件，或者 Lead 一个开源项目。当你控制着一个有业务在流动的组织的时候，就能清晰的感受到各种问题、然后想出自己的解决方案，并能看到这些方案最终的效果。\n> \n> 这样做，不但可以更深入的理解人和组织，也可以更好的理解商业。产品如何被设计、被制作、被销售、被运营；现金如何变成资源、商品最后又变回更多的钱。当你明白了这些之后，就能对自己的岗位有新的看法，也能和老板们有更多的共同语言。",normalizedContent:"一个程序员值多少钱\n\n\n\n简历就是我的价值主张，我到公司来，我能完成这些工作，为公司带来这样的价值，而我只要这一点点的薪水，所以赶紧雇佣我吧。\n\n公司雇佣一个人，并不是看他有多牛，而是能给公司带来什么价值。一个人拥有一系列技能，在不同公司创造的价值是不同的，于是拿到的薪资也不一样。除此之外，薪资还受市场供需，信息透明度影响。\n\n员工的价值一般是在之前的工作经历和业绩基础上来估算。\n\n\n# 供需关系\n\n每一波浪潮带来的新兴市场和高利润行业交叉的细分市场职位就会更之前一些。\n\n专注细分市场：削减宽度来提升深度的求职策略。\n\n把原来覆盖整个市场的经历，用到一小块上，让我在这个细分领域做得比别人更好。在所有经历都投入到细分市场之前，要考量这个细分市场的大小和发展。\n\n专注新兴市场：利用技术边界的变动来拉平经验差距的求职策略。\n\n当一个新技术出来的时候，原来不能做的事情变得能做了，原来的一些规则和经验变得不好用了，这是一个非常好的新人切入机会，例如ios刚出来。最简单判断一个新兴市场是否靠谱，看资本的流入速度，有资本涌入，就会催生大量公司，就会大量招人，然而供应端也还小。云计算、移动开发、直播、区块链、人工智能。\n\n量化分析\n\n招聘网站的招聘启事中包含了大量的信息，通过爬虫可以获取某职位所需要的技能。但是数据量很大，用统计值来估计与真实自己会有很大误差。所以最好的方式，每隔一段时间去面试看看，真实了解需求，以及薪资，这个是真金白银的。\n\n\n# 渠道\n\n内推一般都有面试机会。正好有个熟识的朋友在这家公司，既可以了解这个团队是否好相处，是否加班，老板是否靠谱等，同时员工一般内推也会有奖励，所以一般员工都乐意干内推这件事。\n\n\n# 职业路线\n\n\n\n\n# 职业画布\n\n\n\n\n# 新手快速起步\n\n充电期\n\n还是新人的时候，并不是一进来就能给公司贡献价值，而公司还要支付我的工资，所以最重要的就是，尽快充满电，脱离这个状态。\n\n放电器\n\n时间久了发现自己在技术上再也没有成长空间了，如果还是一个初中级开发者，那就要留意了。离职了原来的同事还是可以变成朋友的，离职多了就习惯了，也就不会纠结人情......\n\n\n# 职业老手\n\n谁对谁错没有意义，没人犯错才有意义。\n\n公司不能培养自己，要学会自己培养自己。\n\n规划好我的职业，哪年都不会有危机。\n\n\n# 瓶颈\n\n瓶颈一：不明白人和机器的区别\n\n> 一旦进入管理线，我们会非常明显的感受到和以前的不同。因为之前主要都是和机器打交道，纯逻辑的二元化生物，非此即彼，非常好相处。\n> \n> 但是从管理线开始呢，我们就要开始和人打交道了。这些人可能是你的下属、也可能是公司其他部门的同事，比如我们「深恶痛绝」的产品经理、测试部门、hr部门（ 招聘面试 ）等等。各种各样的人都会进入到你的工作中来，人嘛，都是情绪化的动物，和机器是完全不同的。所以我们在进入管理线的时候，要尽快适应和他们打交道的方法。\n\n瓶颈二：不理解规则的意义，崇尚自由主义\n\n> 当程序员的时候，往往是单枪匹马解决问题，很多东西自己想怎么来就怎么来。但当你走上管理岗位以后，人一多就会发现，不能由着每个人按自己的想法来，不然这个程序员用 php ，旁边那个用 python ，代码库格式百花齐放，完全没法看。\n> \n> 所以规则是为了提升整体的生产效率，所做的一些妥协。不要敌视规则，现在你可以一定程度的参与规则的制定了，尝试好好的改进它和利用它。\n\n瓶颈三：缺乏良好的沟通和表达能力\n\n> 在开发岗时，虽然也需要一定的沟通和表达能力，但其实基本也就写文档、和做工作汇报时会用到；但在管理岗上，就不一样了。\n> \n> 这是一个承上启下的岗位，一方面你需要理解领导的意图，将其转化为对应的解决方案，再提交领导审阅，想办法说服领导支持你的方案；另一方面你又要培养新人，确保他们明白自己要做的工作，习得对应的技能，能按时按量的完成开发工作。在这种岗位，一旦在沟通和表达中出现问题，就会被成倍的放大。\n> \n> 这种能力需要花时间去培养，很难一蹴而就。但好在我们虽然是管理岗，但它依然是技术相关的，它描述的依然是非常理性的东西，不太会出现创意行业那种「跳跃性思维」和「无法用语言来表述的感觉」之类的内容。所以基本上，只要我们把条理性把握好，就能输出简单易懂的内容。即使它可能有一点点枯燥，但会很清晰。如果你还能自然的嵌几个笑话进去，那么应付技术讲座就绰绰有余了。\n\n瓶颈四：不能迅猛的招聘和培养下属，将工作分担下去\n\n> 招聘和培养下属，是中层管理者除技术以外最重要的能力之一，我们要持续而稳定的为公司提供研发能力，确保能支持公司现在的业务，并能跟得上未来的发展。\n> \n> 所以我们必须掌握一整套的方法，包括如何招聘新人、招聘进来以后如何培养、试用期如何识别种子选手、转正后如何最大的为公司贡献价值，还要留意他们对公司的满意度啊、个人的发展意愿和发展空间，以免刚培养出来就跳槽了之类的。\n> \n> 掌握不好这些技能，就无法放大自己的能力，所有的事情都只好亲力亲为，天天加班。为了避免这种悲惨未来，我们甚至从进入管理线之前，就应该有意识的去培养这些能力。首先要养成写技术博客或者笔记的习惯；然后可以试试把日常工作中的经验和教训总结下来，以书籍或课程的方式分享出去，这样除了能提升能力，还可以挣点零花钱。\n\n瓶颈五：面对大挑战时失去斗志，茫然无措\n\n> 刚进入管理线，或者突然老板给了你一个难度很大的任务的时候，面对千头万绪的事情，很容易发蒙。这种时候，首先要镇定下来，然后将这个任务拆分成一个一个的小挑战，去分析其中的风险，从而制定出一系列容易达到的小目标。\n> \n> 当我们不断的去完成这些难度不大的小目标时，会获得持续的小成功，这些成功堆积起来的信心，最后会帮助我们解决掉最后的那个难题。因为在难题面前，最常见的失败就是失去信心。你都不相信自己能做出来的时候，那当然就做不出来了。\n\n一个小建议：来一次「迷你技术创业」\n\n> 管理是非常依赖于实践的事情，你看着那些管理大师的巨著，然后在脑海中演练，其实最后什么用都没有的，只有实际经历过，才能感同身受。\n> \n> 好在我们是程序员，可以从无到有的创建一个软件。所以我们可以利用业余时间，去开发一个商业软件，或者 lead 一个开源项目。当你控制着一个有业务在流动的组织的时候，就能清晰的感受到各种问题、然后想出自己的解决方案，并能看到这些方案最终的效果。\n> \n> 这样做，不但可以更深入的理解人和组织，也可以更好的理解商业。产品如何被设计、被制作、被销售、被运营；现金如何变成资源、商品最后又变回更多的钱。当你明白了这些之后，就能对自己的岗位有新的看法，也能和老板们有更多的共同语言。",charsets:{cjk:!0}},{title:"一些期刊",frontmatter:{title:"一些期刊",date:"2023-06-06T09:00:30.000Z",permalink:"/pages/c8b13e/"},regularPath:"/02.%E7%A7%91%E7%A0%94/03.%E6%88%91%E7%9A%84%E5%B7%A5%E4%BD%9C/66.sci.html",relativePath:"02.科研/03.我的工作/66.sci.md",key:"v-5fc224a0",path:"/pages/c8b13e/",headersStr:null,content:"IEEE Geoscience and Remote Sensing Letters (GRSL)\n\nInternational Journal of Remote Sensing\n\nIEEE Sensors Journal\n\nPattern Recognition Letters",normalizedContent:"ieee geoscience and remote sensing letters (grsl)\n\ninternational journal of remote sensing\n\nieee sensors journal\n\npattern recognition letters",charsets:{}},{title:"爱情观变迁",frontmatter:{title:"爱情观变迁",date:"2023-06-21T13:53:13.000Z",permalink:"/pages/4dc62f/"},regularPath:"/03.%E7%94%9F%E6%B4%BB/09.%E7%88%B1%E6%83%85%E8%A7%82%E5%8F%98%E8%BF%81.html",relativePath:"03.生活/09.爱情观变迁.md",key:"v-373c2e99",path:"/pages/4dc62f/",headers:[{level:2,title:"“对我好”的含义变化",slug:"对我好-的含义变化",normalizedTitle:"“对我好”的含义变化",charIndex:2},{level:3,title:"做好你应该做的事",slug:"做好你应该做的事",normalizedTitle:"做好你应该做的事",charIndex:17},{level:3,title:"满足我的需求",slug:"满足我的需求",normalizedTitle:"满足我的需求",charIndex:109},{level:3,title:"认同我的一切",slug:"认同我的一切",normalizedTitle:"认同我的一切",charIndex:197},{level:3,title:"困境",slug:"困境",normalizedTitle:"困境",charIndex:307},{level:3,title:"结论",slug:"结论",normalizedTitle:"结论",charIndex:384}],headersStr:"“对我好”的含义变化 做好你应该做的事 满足我的需求 认同我的一切 困境 结论",content:"# “对我好”的含义变化\n\n\n# 做好你应该做的事\n\n强调门当户对和情感表演型制度，知行合一。经营夫妻关系的过程：男主外，女主内，每个人做好自己的角色。\n\n在传统的婚姻里，对我好，就是你应该做到你要做的角色。\n\n\n# 满足我的需求\n\n浪漫爱情崛起，强调个体的自主选择。男性保护和宠爱女性，女性崇拜和肯定男性，也变成跨越阶级的一种途径，还有爱情可视化，共同成长（也就是满足自己的需求）。\n\n\n# 认同我的一切\n\n自我的确定性，坠入情网能让人摆脱作为不起眼的凡人的感觉，提升自我价值感，情绪价值的崛起，承诺不会先于感情。一时的爱意只代表那当下的，情绪会变化，所以承诺变得不可靠，所以需要无时无刻得到爱的验证。\n\n\n# 困境\n\n在国内社会快速发展，用几十年就达成了三种的演变。以至于社会上存在不同的群体，有时又会将上述三种关系杂合在一起，这三种关系本身就是矛盾的。\n\n\n# 结论\n\n当爱情无法实现自由、平等和情感的满足时候，人们就把消极自由，或者“不选择”作为了最终的选择。爱情是两个独立个体的连接，如何满足双方需求的平衡，如何保持认同与独立意志的平衡。爱情是学习的，幸福是要练习的。",normalizedContent:"# “对我好”的含义变化\n\n\n# 做好你应该做的事\n\n强调门当户对和情感表演型制度，知行合一。经营夫妻关系的过程：男主外，女主内，每个人做好自己的角色。\n\n在传统的婚姻里，对我好，就是你应该做到你要做的角色。\n\n\n# 满足我的需求\n\n浪漫爱情崛起，强调个体的自主选择。男性保护和宠爱女性，女性崇拜和肯定男性，也变成跨越阶级的一种途径，还有爱情可视化，共同成长（也就是满足自己的需求）。\n\n\n# 认同我的一切\n\n自我的确定性，坠入情网能让人摆脱作为不起眼的凡人的感觉，提升自我价值感，情绪价值的崛起，承诺不会先于感情。一时的爱意只代表那当下的，情绪会变化，所以承诺变得不可靠，所以需要无时无刻得到爱的验证。\n\n\n# 困境\n\n在国内社会快速发展，用几十年就达成了三种的演变。以至于社会上存在不同的群体，有时又会将上述三种关系杂合在一起，这三种关系本身就是矛盾的。\n\n\n# 结论\n\n当爱情无法实现自由、平等和情感的满足时候，人们就把消极自由，或者“不选择”作为了最终的选择。爱情是两个独立个体的连接，如何满足双方需求的平衡，如何保持认同与独立意志的平衡。爱情是学习的，幸福是要练习的。",charsets:{cjk:!0}},{title:"技术人的求职指南",frontmatter:{title:"技术人的求职指南",date:"2023-06-16T21:07:57.000Z",permalink:"/pages/c1356f/"},regularPath:"/03.%E7%94%9F%E6%B4%BB/08.%E6%8A%80%E6%9C%AF%E4%BA%BA%E7%9A%84%E6%B1%82%E8%81%8C%E6%8C%87%E5%8D%97.html",relativePath:"03.生活/08.技术人的求职指南.md",key:"v-78f813a7",path:"/pages/c1356f/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"归档",frontmatter:{archivesPage:!0,title:"归档",permalink:"/archives/",article:!1},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-a2a48808",path:"/archives/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"Home",frontmatter:{home:!0,heroImage:"/img/tiger.png",heroText:"北冥无鱼",tagline:"🚀小蓉蓉家的有志少年",actionText:"开始阅读 →",actionLink:"/pages/8e69ed/",bannerBg:"none",features:[{title:"Java",details:"兴趣使然，让自我全神贯注，全身心投入",link:"/pages/8e69ed/"},{title:"科研",details:"权衡，委曲求全，让自我更全面",link:"/pages/aa9650/"},{title:"生活",details:"多愁善感，但情绪稳定",link:"/pages/db78e2/"}],postList:"simple"},regularPath:"/",relativePath:"index.md",key:"v-05363355",path:"/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"软挑",frontmatter:{title:"软挑",date:"2023-04-06T10:39:42.000Z",permalink:"/pages/a7f8a5/"},regularPath:"/03.%E7%94%9F%E6%B4%BB/02.%E8%BD%AF%E6%8C%91%E6%AF%94%E8%B5%9B.html",relativePath:"03.生活/02.软挑比赛.md",key:"v-7887f0dc",path:"/pages/a7f8a5/",headers:[{level:3,title:"readMapOK",slug:"readmapok",normalizedTitle:"readmapok",charIndex:18},{level:3,title:"work->init()",slug:"work-init",normalizedTitle:"work-&gt;init()",charIndex:null},{level:3,title:"readFrameOK",slug:"readframeok",normalizedTitle:"readframeok",charIndex:93},{level:3,title:"schedulingRobot",slug:"schedulingrobot",normalizedTitle:"schedulingrobot",charIndex:136},{level:3,title:"work->schedulingRobot()",slug:"work-schedulingrobot",normalizedTitle:"work-&gt;schedulingrobot()",charIndex:null},{level:3,title:"findWorkbenchBuy()， findWorkbenchSell()",slug:"findworkbenchbuy-findworkbenchsell",normalizedTitle:"findworkbenchbuy()， findworkbenchsell()",charIndex:906},{level:3,title:"robot->pathMove(), 控制机器人运动",slug:"robot-pathmove-控制机器人运动",normalizedTitle:"robot-&gt;pathmove(), 控制机器人运动",charIndex:null}],headersStr:"readMapOK work->init() readFrameOK schedulingRobot work->schedulingRobot() findWorkbenchBuy()， findWorkbenchSell() robot->pathMove(), 控制机器人运动",content:"主函数有个Work对象\n\n\n\n\n# readMapOK\n\n读取判题器发送过来的地图数据，数据格式参考任务书\n\n\n# work->init()\n\n拿到地图数据后进行一些初始化工作\n\n\n# readFrameOK\n\n读取判题器发送过来的每一帧数据，数据格式参考任务书\n\n\n# schedulingRobot\n\n调度机器人，返回需要的指令 orders\n\n最后将 orders printf给判题器。\n\n以上所有操作都是在work对象来操作的。\n\n\n# work->schedulingRobot()\n\nvector<string> schedulingRobot(int frameId) {\n    // 这里是要返回的机器人控制指令orders\n    vector<string> orders;\n\n    // 操作四个机器人\n    for (const auto &robot: robots) {\n        // 1. 如果机器人没有目标工作台，给机器人设立一个目标工作台. 调用2,或3\n        // 2.  findWorkBenchService->findWorkbenchBuy();\n        // 3.  findWorkBenchService->findWorkbenchSell();\n\n        // 4. 有了目标工作台,判断机器人是否已经到达工作台, 调用5 或6\n        // 5. 买, push买的指令, 并且同时设立目标工作台 调用3\n        // 6. 卖, push卖的指令, 并且同时设立目标工作台 调用2\n\n        // 7. 机器人有目标, 让机器人按照路径走,调用\n        // 8. robot->pathMove(), 返回运动控制指令\n    }\n    // 9. 这里写碰撞检测, 调用\n    // 10. collisionService->avoid(),返回运动控制指令,会覆盖8的控制指令\n\n    // 返回这一帧所有指令\n    return orders;\n}\n\n\n\n# findWorkbenchBuy()， findWorkbenchSell()\n\n如果可以给机器人设定一个目标工作台，那么函数的最后会给机器人设置target工作台，并且会给他路径\n\nauto &workbench = item.first;\n// 这里有两条路径，一条是原始的路径，optimPath是筛选出关键点后的路径\nvector<vector<double>> path, optimPath;\nbool succeed = findPath(*robot, *workbench, path, optimPath);\nif (succeed) {\n    int workbenchId = workbench->getWorkbenchId();\n    // 给机器人路径\n    robot->setPath(optimPath);\n    robot->setTargetWorkBenchId(workbenchId);\n    robot->pidClear();\n}\n\n\n函数的其他部分是如何给机器人分发工作台的问题，不用管。\n\n\n# robot->pathMove(), 控制机器人运动\n\n// 机器人会拿到一个 path路径, 机器人记录当前路径中的哪一步\nvector<string> pathMove() {\n    vector<string> res;\n    // 遍历路径中的每一步\n    for (; path_step < path.size(); ++path_step) {\n        // 拿到路径中某一步的坐标(x,y)\n        double targetX = path[path_step][0];\n        double targetY = path[path_step][1];\n        // 让机器人运动到(x,y)\n\t\t// 根据机器人当前的位置,计算运动到(x,y)需要的速度和角速度\n        // 最后push 速度指令和角速度指令到 res中，最后返回\n        return res;\n    }\n    return res;\n\n}\n",normalizedContent:"主函数有个work对象\n\n\n\n\n# readmapok\n\n读取判题器发送过来的地图数据，数据格式参考任务书\n\n\n# work->init()\n\n拿到地图数据后进行一些初始化工作\n\n\n# readframeok\n\n读取判题器发送过来的每一帧数据，数据格式参考任务书\n\n\n# schedulingrobot\n\n调度机器人，返回需要的指令 orders\n\n最后将 orders printf给判题器。\n\n以上所有操作都是在work对象来操作的。\n\n\n# work->schedulingrobot()\n\nvector<string> schedulingrobot(int frameid) {\n    // 这里是要返回的机器人控制指令orders\n    vector<string> orders;\n\n    // 操作四个机器人\n    for (const auto &robot: robots) {\n        // 1. 如果机器人没有目标工作台，给机器人设立一个目标工作台. 调用2,或3\n        // 2.  findworkbenchservice->findworkbenchbuy();\n        // 3.  findworkbenchservice->findworkbenchsell();\n\n        // 4. 有了目标工作台,判断机器人是否已经到达工作台, 调用5 或6\n        // 5. 买, push买的指令, 并且同时设立目标工作台 调用3\n        // 6. 卖, push卖的指令, 并且同时设立目标工作台 调用2\n\n        // 7. 机器人有目标, 让机器人按照路径走,调用\n        // 8. robot->pathmove(), 返回运动控制指令\n    }\n    // 9. 这里写碰撞检测, 调用\n    // 10. collisionservice->avoid(),返回运动控制指令,会覆盖8的控制指令\n\n    // 返回这一帧所有指令\n    return orders;\n}\n\n\n\n# findworkbenchbuy()， findworkbenchsell()\n\n如果可以给机器人设定一个目标工作台，那么函数的最后会给机器人设置target工作台，并且会给他路径\n\nauto &workbench = item.first;\n// 这里有两条路径，一条是原始的路径，optimpath是筛选出关键点后的路径\nvector<vector<double>> path, optimpath;\nbool succeed = findpath(*robot, *workbench, path, optimpath);\nif (succeed) {\n    int workbenchid = workbench->getworkbenchid();\n    // 给机器人路径\n    robot->setpath(optimpath);\n    robot->settargetworkbenchid(workbenchid);\n    robot->pidclear();\n}\n\n\n函数的其他部分是如何给机器人分发工作台的问题，不用管。\n\n\n# robot->pathmove(), 控制机器人运动\n\n// 机器人会拿到一个 path路径, 机器人记录当前路径中的哪一步\nvector<string> pathmove() {\n    vector<string> res;\n    // 遍历路径中的每一步\n    for (; path_step < path.size(); ++path_step) {\n        // 拿到路径中某一步的坐标(x,y)\n        double targetx = path[path_step][0];\n        double targety = path[path_step][1];\n        // 让机器人运动到(x,y)\n\t\t// 根据机器人当前的位置,计算运动到(x,y)需要的速度和角速度\n        // 最后push 速度指令和角速度指令到 res中，最后返回\n        return res;\n    }\n    return res;\n\n}\n",charsets:{cjk:!0}}],themeConfig:{nav:[{text:"首页",link:"/"},{text:"Java",link:"/pages/e0425d/"},{text:"科研",link:"/pages/7387ee/"},{text:"生活",link:"/pages/db78e2/"},{text:"C++",link:"/pages/4df89e/"},{text:"归档",link:"/archives/"}],sidebarDepth:2,logo:"/img/tiger.png",repo:"xugaoyi/vuepress-theme-vdoing",searchMaxSuggestions:10,sidebar:{"/01.Java/":[{title:"Java基础",collapsable:!0,children:[["01.Java基础/01.Java集合框架.md","Java集合框架","/pages/8e69ed/"],["01.Java基础/02.HashMap.md","Hashmap","/pages/ce6e6c/"],["01.Java基础/03.Java刷题.md","Java常用api","/pages/672ba8/"],["01.Java基础/05.流操作.md","流操作","/pages/4b289e/"],["01.Java基础/06.线程池.md","线程池","/pages/d47d28/"]]},{title:"中间件",collapsable:!0,children:[["02.中间件/00.消息队列.md","消息队列","/pages/9749fb/"],["02.中间件/01.ZooKeeper.md","ZooKeeper","/pages/467ce0/"],["02.中间件/02.Kafka.md","Kafka","/pages/11f4c8/"],["02.中间件/03.RabbitMQ.md","RabbitMQ","/pages/2ca146/"]]},{title:"微服务",collapsable:!0,children:[["03.微服务/01.Sentinel.md","限流","/pages/526796/"],["03.微服务/02.Seata.md","分布式事务","/pages/7c79c1/"],["03.微服务/03.Redis.md","分布式缓存","/pages/566e96/"],["03.微服务/04.Canal.md","缓存同步","/pages/663ad9/"],["03.微服务/05.常见面试题.md","常见面试题","/pages/78eabe/"]]},{title:"框架",collapsable:!0,children:[["04.框架/01.spring.md","Spring","/pages/23ed38/"],["04.框架/02.springboot.md","Spring Boot 自动装配","/pages/071fc0/"],["04.框架/03.springbooteasy.md","Spring Boot 自动装配简易理解","/pages/418390/"],["04.框架/04.Controller.md","Controller接收请求方式","/pages/4ce008/"],["04.框架/10.NIO.md","NIO","/pages/533bbc/"],["04.框架/11.Netty.md","Netty","/pages/20bd69/"]]},{title:"数据库",collapsable:!0,children:[["05.数据库/01.MySQL基础.md","MySQL基础","/pages/c7801c/"],["05.数据库/02.MySQL是怎么运行的.md","《MySQL是怎么运行的》","/pages/e0425d/"],["05.数据库/03.MySQL函数.md","MySQL函数","/pages/e60c12/"],["05.数据库/04.MySQL易忘点.md","MySQL易忘点","/pages/c38f55/"],["05.数据库/07.MySQL锁.md","锁","/pages/8d8ba3/"]]},{title:"项目记录",collapsable:!0,children:[["06.项目记录/01.statistics.md","在Ubuntu上统计软件使用时长","/pages/361d44/"],["06.项目记录/10.nowcode.md","论坛","/pages/b95b70/"],["06.项目记录/20.comunity.md","自律社区","/pages/532cfb/"],["06.项目记录/30.raft.md","分布式共识Raft算法","/pages/20b125/"],["06.项目记录/40.doubao.md","番茄时间社区","/pages/b3c8f6/"]]},{title:"秋招",collapsable:!0,children:[["99.秋招/11.Redis.md","Redis","/pages/729f52/"],["99.秋招/12.framework.md","Spring","/pages/d76f3c/"],["99.秋招/13.cloud.md","微服务","/pages/b0a322/"],["99.秋招/14.message.md","消息队列","/pages/a20dff/"],["99.秋招/15.juc.md","并发编程","/pages/15ac4e/"],["99.秋招/16.jvm.md","Java 虚拟机","/pages/f1bf72/"],["99.秋招/17.设计模式.md","设计模式","/pages/33bbc8/"],["99.秋招/18.一些场景.md","场景设计","/pages/46dd43/"],["99.秋招/33.test.md","test","/pages/545d12/"],["99.秋招/99.一些疑问.md","疑问","/pages/69d257/"]]}],catalogue:{},"/02.科研/":[{title:"室内实时三维重建",collapsable:!0,children:[["01.室内实时三维重建/01.kinectFusion.md","kinectFusion","/pages/aa9650/"],["01.室内实时三维重建/02.EF论文理解.md","EF论文理解","/pages/c6a110/"],["01.室内实时三维重建/03.Surfel Meshing .md","Surfel Meshing","/pages/7bbbf3/"],["01.室内实时三维重建/06.BAD_SLAM.md","BAD_SLAM","/pages/24a5f4/"],["01.室内实时三维重建/07.FlashFusion论文阅读.md","FlashFusion论文阅读","/pages/a2be9b/"],["01.室内实时三维重建/08.intrinsic3d论文阅读.md","intrinsic3d论文阅读","/pages/c06e38/"],["01.室内实时三维重建/09.factor.md","factor","/pages/0af3d9/"],["01.室内实时三维重建/10.CLD_MVS.md","CLD_MVS","/pages/3a8868/"],["01.室内实时三维重建/11.TextureMe.md","TextureMe","/pages/49bbb9/"],["01.室内实时三维重建/13.orbslam论文阅读笔记.md","orbslam论文阅读笔记","/pages/ed705b/"],["01.室内实时三维重建/14.ORB_SLAM2原理、代码流程文档.md","ORB_SLAM2原理、代码流程文档","/pages/cc3afe/"]]},{title:"大规模三维重建",collapsable:!0,children:[["02.大规模三维重建/01.MVS.md","MVS","/pages/98600a/"],["02.大规模三维重建/02.基于信息论自主探索.md","基于信息论自主探索","/pages/8487b5/"],["02.大规模三维重建/03.TheiaSfM代码阅读.md","TheiaSfM代码阅读","/pages/299ec4/"],["02.大规模三维重建/04.基于投票的增量重建.md","基于投票的增量重建","/pages/9af622/"],["02.大规模三维重建/05.外点去除.md","外点去除","/pages/7453b3/"],["02.大规模三维重建/06.学习opengl.md","学习opengl","/pages/cc38e6/"],["02.大规模三维重建/07.密集匹配.md","密集匹配","/pages/8a4bae/"],["02.大规模三维重建/08.雷达增强sfm.md","雷达增强sfm","/pages/270f1d/"],["02.大规模三维重建/09.论文随记.md","论文随记","/pages/4a64fa/"],["02.大规模三维重建/10.自我描述.md","自我描述","/pages/fc7936/"],["02.大规模三维重建/11.theiaSfM代码.md","theiaSfM代码","/pages/169752/"],["02.大规模三维重建/12.懊悔阅读论文1.md","An Efficient and Robust Hybrid SfM Method for Large-Scale Scenes","/pages/24dfc7/"],["02.大规模三维重建/13. 懊悔阅读论文2.md","A Simple and Efficient Merge of Two Sparse 3D Models with Overlapped Images","/pages/7387ee/"],["02.大规模三维重建/14. 懊悔阅读论文3.md","EC-SfM, Efficient Covisibility-based Structure-from-Motion for Both Sequential and Unordered Images","/pages/f9d90b/"],["02.大规模三维重建/15. 懊悔阅读论文4.md","Graph-based parallel large scale structure from motion","/pages/696f8f/"]]},{title:"我的工作",collapsable:!0,children:[["03.我的工作/01.one.md","hierarchical","/pages/c06b1c/"],["03.我的工作/02.code.md","代码分析","/pages/3d257e/"],["03.我的工作/03.实现流程.md","实现流程","/pages/0c2f17/"],["03.我的工作/10.hybrid.md","Hybrid SfM","/pages/8f3964/"],["03.我的工作/15.实验.md","实验部分","/pages/a2edb6/"],["03.我的工作/20.EC.md","EC-SfM","/pages/f12e80/"],["03.我的工作/30.two.md","KeyFrame","/pages/03900a/"],["03.我的工作/32.keyfram2.md","keyframe2","/pages/bcf6cd/"],["03.我的工作/35.colmap增量.md","colmap增量代码","/pages/0a2951/"],["03.我的工作/36.keyframe3.md","Keyframe3","/pages/a0d165/"],["03.我的工作/38.苦难.md","一时苦难","/pages/149c7c/"],["03.我的工作/66.sci.md","一些期刊","/pages/c8b13e/"]]}],"/03.生活/":[["01.随笔.md","读书随笔","/pages/db78e2"],["02.软挑比赛.md","软挑","/pages/a7f8a5/"],["05.遥远的救世主.md","《遥远的救世主》","/pages/7cc66a/"],["06.game.md","一群游戏天才","/pages/76e940/"],["07.程序员的打怪升级.md","程序员的打怪升级","/pages/f5ba2a/"],["08.技术人的求职指南.md","技术人的求职指南","/pages/c1356f/"],["09.爱情观变迁.md","爱情观变迁","/pages/4dc62f/"]]},updateBar:{showToArticle:!0,moreArticle:"/archives"},pageStyle:"line",category:!1,tag:!1,archive:!0,author:{name:"Wenli",href:"https://github.com/lzxiaohuihui"},social:{icons:[{iconClass:"icon-youjian",title:"发邮件",link:"mailto:895827938@qq.com"},{iconClass:"icon-github",title:"GitHub",link:"https://github.com/lzxiaohuihui"},{iconClass:"icon-erji",title:"听音乐",link:"https://music.163.com/#/playlist?id=782007907"}]},footer:{createYear:2023,copyrightInfo:"Evan Xu | MIT License"},htmlModules:{}}};var Sl=t(96),Tl=t(97),Al=t(12);var Il={computed:{$filterPosts(){return this.$site.pages.filter(n=>{const{frontmatter:{pageComponent:e,article:t,home:r}}=n;return!(e||!1===t||!0===r)})},$sortPosts(){return(n=this.$filterPosts).sort((n,e)=>{const t=n.frontmatter.sticky,r=e.frontmatter.sticky;return t&&r?t==r?Object(Al.a)(n,e):t-r:t&&!r?-1:!t&&r?1:Object(Al.a)(n,e)}),n;var n},$sortPostsByDate(){return(n=this.$filterPosts).sort((n,e)=>Object(Al.a)(n,e)),n;var n},$groupPosts(){return function(n){const e={},t={};for(let r=0,a=n.length;r<a;r++){const{frontmatter:{categories:a,tags:i}}=n[r];"array"===Object(Al.n)(a)&&a.forEach(t=>{t&&(e[t]||(e[t]=[]),e[t].push(n[r]))}),"array"===Object(Al.n)(i)&&i.forEach(e=>{e&&(t[e]||(t[e]=[]),t[e].push(n[r]))})}return{categories:e,tags:t}}(this.$sortPosts)},$categoriesAndTags(){return function(n){const e=[],t=[];for(let t in n.categories)e.push({key:t,length:n.categories[t].length});for(let e in n.tags)t.push({key:e,length:n.tags[e].length});return{categories:e,tags:t}}(this.$groupPosts)}}};Ht.component(Sl.default),Ht.component(Tl.default);function Cl(n){return n.toString().padStart(2,"0")}t(247);Ht.component("Badge",()=>Promise.all([t.e(0),t.e(3)]).then(t.bind(null,428))),Ht.component("CodeBlock",()=>Promise.resolve().then(t.bind(null,96))),Ht.component("CodeGroup",()=>Promise.resolve().then(t.bind(null,97)));t(248);var zl={name:"Demo",props:{collapse:{type:Boolean,default:!1}},data:()=>({showCode:!1,copied:!1,codeNavIndex:0,codeNavConfigs:[]}),created(){this.showCode=this.collapse,this.makeCodeNavConfigs()},methods:{toggleCode(){this.showCode=!this.showCode},copyCode(){const n=this.$el.querySelectorAll("pre")[this.codeNavIndex];n.setAttribute("contenteditable","true"),n.focus(),document.execCommand("selectAll",!1,null),this.copied=document.execCommand("copy"),n.removeAttribute("contenteditable"),setTimeout(()=>{this.copied=!1},1e3)},codeNavBtnHandler(n){this.codeNavIndex=n},makeCodeNavConfigs(){const n=this.$slots,e=[];let t;for(const r in n)0==r.indexOf("code-")&&(t=r.replace("code-","").replace(/^\S/,n=>n.toUpperCase()),e.push({title:t,slotName:r}));this.codeNavConfigs=e}}},Bl=(t(249),Object(xl.a)(zl,(function(){var n=this,e=n._self._c;return e("div",{staticClass:"demo-wrap"},[e("div",{staticClass:"demo-nav"},[e("i",{staticClass:"demo-nav-btn",on:{click:n.toggleCode}},[e("svg",{staticClass:"icon",attrs:{t:"1572515960134",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"1097",width:"20",height:"20"}},[e("path",{attrs:{d:"M888 64H136q-30.016 0-51.008 20.992T64 136v752.992q0 28.992 20.992 50.496t51.008 21.504h752.992q28.992 0 50.496-21.504t21.504-50.496V136q0-30.016-21.504-51.008T888 64zM228.992 548.992q-15.008 0-25.504-10.496t-10.496-25.504 10.016-26.016l115.008-115.008-115.008-116.992q-10.016-11.008-10.016-25.504t10.496-24.992 25.504-10.496 24.992 10.016l140.992 142.016q10.016 11.008 10.016 26.016t-11.008 24.992l-140 140.992q-10.016 11.008-24.992 11.008z m389.024 0l-199.008-0.992q-15.008 0-25.504-10.496T383.008 512t10.496-25.504 25.504-10.496l199.008 0.992q15.008 0 25.504 10.496t10.496 25.504-11.008 25.504-24.992 10.496z","p-id":"1098"}})])]),n._v(" "),e("i",{class:n.showCode?"demo-icon-arrow active":"demo-icon-arrow"},[e("svg",{staticClass:"icon",attrs:{t:"1572587847226",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"3297",width:"16",height:"16"}},[e("path",{attrs:{d:"M830.687738 603.071182c0 9.614985-3.933589 17.949814-11.799744 25.007557-7.867178 7.05672-17.222243 10.56052-28.065196 10.512425L232.716714 638.591163c-10.789741 0-20.144806-3.5038-28.064172-10.512425-7.919367-7.009647-11.852956-15.344476-11.799744-25.007557 0.053212-9.660011 3.986801-17.996886 11.799744-25.00551l279.05253-248.641917c7.867178-7.009647 17.22122-10.513448 28.065196-10.513448 10.842952 0 20.196994 3.504824 28.064172 10.513448l279.05253 248.641917C826.754149 585.074296 830.687738 593.411171 830.687738 603.071182z","p-id":"3298"}})])])]),n._v(" "),e("transition",{attrs:{name:"code-fade"}},[e("div",{directives:[{name:"show",rawName:"v-show",value:n.showCode,expression:"showCode"}],staticClass:"demo-code"},[e("div",{staticClass:"demo-code-nav"},n._l(n.codeNavConfigs,(function(t,r){return e("button",{key:r,class:["demo-code-btn",n.codeNavIndex===r?"active":""],on:{click:function(e){return n.codeNavBtnHandler(r)}}},[n._v(n._s(t.title))])})),0),n._v(" "),e("div",{staticClass:"demo-code-content"},[n._l(n.codeNavConfigs,(function(t,r){return e("div",{directives:[{name:"show",rawName:"v-show",value:n.codeNavIndex===r,expression:"codeNavIndex === index"}],key:r,staticClass:"demo-code-item"},[n._t(t.slotName)],2)})),n._v(" "),e("i",{staticClass:"demo-code-content-copy",on:{click:n.copyCode}},[e("svg",{staticClass:"icon",staticStyle:{fill:"#fff"},attrs:{t:"1572585974849",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"1695",width:"20",height:"20"}},[e("path",{attrs:{d:"M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z","p-id":"1696"}})])]),n._v(" "),e("transition",{attrs:{name:"slide-fade"}},[n.copied?e("span",{staticClass:"demo-code-content-copied"},[n._v("Copied")]):n._e()])],2)])]),n._v(" "),e("div",{staticClass:"demo-main"},[n.$slots.demo?e("div",{staticClass:"demo-component-wrap"},[n._t("demo")],2):n._e()])],1)}),[],!1,null,null,null).exports);function Rl(n){const e=document.documentElement.getBoundingClientRect(),t=n.getBoundingClientRect();return{x:t.left-e.left,y:t.top-e.top}}var Ml=[({Vue:n,options:e,router:t,siteData:r,isServer:a})=>{a||t.afterEach(()=>{var n;n=function(){setTimeout((function(){void 0===window._AdBlockInit&&function(){const n=document.getElementsByClassName("wwads-cn"),e=document.querySelector(".wwads-content");n[0]&&!e&&(n[0].innerHTML="<style>.wwads-horizontal,.wwads-vertical{background-color:#f4f8fa;padding:5px;min-height:120px;margin-top:20px;box-sizing:border-box;border-radius:3px;font-family:sans-serif;display:flex;min-width:150px;position:relative;overflow:hidden;}.wwads-horizontal{flex-wrap:wrap;justify-content:center}.wwads-vertical{flex-direction:column;align-items:center;padding-bottom:32px}.wwads-horizontal a,.wwads-vertical a{text-decoration:none}.wwads-horizontal .wwads-img,.wwads-vertical .wwads-img{margin:5px}.wwads-horizontal .wwads-content,.wwads-vertical .wwads-content{margin:5px}.wwads-horizontal .wwads-content{flex:130px}.wwads-vertical .wwads-content{margin-top:10px}.wwads-horizontal .wwads-text,.wwads-content .wwads-text{font-size:14px;line-height:1.4;color:#0e1011;-webkit-font-smoothing:antialiased}.wwads-horizontal .wwads-poweredby,.wwads-vertical .wwads-poweredby{display:block;font-size:11px;color:#a6b7bf;margin-top:1em}.wwads-vertical .wwads-poweredby{position:absolute;left:10px;bottom:10px}.wwads-horizontal .wwads-poweredby span,.wwads-vertical .wwads-poweredby span{transition:all 0.2s ease-in-out;margin-left:-1em}.wwads-horizontal .wwads-poweredby span:first-child,.wwads-vertical .wwads-poweredby span:first-child{opacity:0}.wwads-horizontal:hover .wwads-poweredby span,.wwads-vertical:hover .wwads-poweredby span{opacity:1;margin-left:0}.wwads-horizontal .wwads-hide,.wwads-vertical .wwads-hide{position:absolute;right:-23px;bottom:-23px;width:46px;height:46px;border-radius:23px;transition:all 0.3s ease-in-out;cursor:pointer;}.wwads-horizontal .wwads-hide:hover,.wwads-vertical .wwads-hide:hover{background:rgb(0 0 0 /0.05)}.wwads-horizontal .wwads-hide svg,.wwads-vertical .wwads-hide svg{position:absolute;left:10px;top:10px;fill:#a6b7bf}.wwads-horizontal .wwads-hide:hover svg,.wwads-vertical .wwads-hide:hover svg{fill:#3E4546}</style><a href='https://wwads.cn/page/whitelist-wwads' class='wwads-img' target='_blank' rel='nofollow'><img src='https://fastly.jsdelivr.net/gh/xugaoyi/image_store@master/blog/wwads.2a3pidhlh4ys.webp' width='130'></a><div class='wwads-content'><a href='https://wwads.cn/page/whitelist-wwads' class='wwads-text' target='_blank' rel='nofollow'>为了本站的长期运营，请将我们的网站加入广告拦截器的白名单，感谢您的支持！<span style='color: #11a8cd'>如何添加白名单?</span></a><a href='https://wwads.cn/page/end-user-privacy' class='wwads-poweredby' title='万维广告 ～ 让广告更优雅，且有用' target='_blank'><span>广告</span></a></div><a class='wwads-hide' onclick='parentNode.remove()' title='隐藏广告'><svg xmlns='http://www.w3.org/2000/svg' width='6' height='7'><path d='M.879.672L3 2.793 5.121.672a.5.5 0 11.707.707L3.708 3.5l2.12 2.121a.5.5 0 11-.707.707l-2.12-2.12-2.122 2.12a.5.5 0 11-.707-.707l2.121-2.12L.172 1.378A.5.5 0 01.879.672z'></path></svg></a>")}()}),3e3)},"complete"===document.readyState||"interactive"===document.readyState?setTimeout(n,1):document.addEventListener("DOMContentLoaded",n),setTimeout(()=>{const n=document.querySelector(".page-wwads");if(!n)return;const e=n.querySelector(".wwads-hide");e&&(e.onclick=()=>{n.style.display="none"}),"none"===n.style.display&&(n.style.display="flex")},900)})},({Vue:n,options:e,router:t,siteData:r})=>{r.pages.map(n=>{const{frontmatter:{date:e,author:t}}=n;"string"==typeof e&&"Z"===e.charAt(e.length-1)&&(n.frontmatter.date=function(n){n instanceof Date||(n=new Date(n));return`${n.getUTCFullYear()}-${Cl(n.getUTCMonth()+1)}-${Cl(n.getUTCDate())} ${Cl(n.getUTCHours())}:${Cl(n.getUTCMinutes())}:${Cl(n.getUTCSeconds())}`}(e)),t?n.author=t:r.themeConfig.author&&(n.author=r.themeConfig.author)}),n.mixin(Il)},{},({Vue:n})=>{n.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},({Vue:n})=>{n.component("RecoDemo",Bl)},({Vue:n,router:e})=>{e.options.scrollBehavior=(e,t,r)=>{if(r)return window.scrollTo({top:r.y,behavior:"smooth"});if(!e.hash)return window.scrollTo({top:0,behavior:"smooth"});{if(n.$vuepress.$get("disableScrollBehavior"))return;const t=e.hash.slice(1),r=document.getElementById(t)||document.querySelector(`[name='${t}']`);if(r)return window.scrollTo({top:Rl(r).y,behavior:"smooth"})}}},({router:n})=>{"undefined"!=typeof window&&(window._hmt=window._hmt||[],function(){var n=document.createElement("script");n.src="https://hm.baidu.com/hm.js?01293bffa6c3962016c08ba685c79d78";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(n,e)}(),n.afterEach((function(n){_hmt.push(["_trackPageview",n.fullPath])})))}],Ll=[];class Pl extends class{constructor(){this.store=new Ht({data:{state:{}}})}$get(n){return this.store.state[n]}$set(n,e){Ht.set(this.store.state,n,e)}$emit(...n){this.store.$emit(...n)}$on(...n){this.store.$on(...n)}}{}Object.assign(Pl.prototype,{getPageAsyncComponent:os,getLayoutAsyncComponent:ss,getAsyncComponent:ls,getVueComponent:cs});var Ol={install(n){const e=new Pl;n.$vuepress=e,n.prototype.$vuepress=e}};function Dl(n,e){const t=e.toLowerCase();return n.options.routes.some(n=>n.path.toLowerCase()===t)}var jl={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(n){const e=this.pageKey||this.$parent.$page.key;return us("pageKey",e),Ht.component(e)||Ht.component(e,os(e)),Ht.component(e)?n(e):n("")}},Nl={functional:!0,props:{slotKey:String,required:!0},render:(n,{props:e,slots:t})=>n("div",{class:["content__"+e.slotKey]},t()[e.slotKey])},Fl={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},ql=(t(250),t(251),Object(xl.a)(Fl,(function(){var n=this._self._c;return n("span",[n("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[n("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),n("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),n("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),Kl={functional:!0,render(n,{parent:e,children:t}){if(e._isMounted)return t;e.$once("hook:mounted",()=>{e.$forceUpdate()})}};Ht.config.productionTip=!1,Ht.use($o),Ht.use(Ol),Ht.mixin(function(n,e,t=Ht){!function(n){n.locales&&Object.keys(n.locales).forEach(e=>{n.locales[e].path=e});Object.freeze(n)}(e),t.$vuepress.$set("siteData",e);const r=new(n(t.$vuepress.$get("siteData"))),a=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(r)),i={};return Object.keys(a).reduce((n,e)=>(e.startsWith("$")&&(n[e]=a[e].get),n),i),{computed:i}}(n=>class{setPage(n){this.__page=n}get $site(){return n}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:n={}}=this.$site;let e,t;for(const r in n)"/"===r?t=n[r]:0===this.$page.path.indexOf(r)&&(e=n[r]);return e||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:n}=this.$page.frontmatter;return"string"==typeof n&&n}get $title(){const n=this.$page,{metaTitle:e}=this.$page.frontmatter;if("string"==typeof e)return e;const t=this.$siteTitle,r=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?r?r+" | "+t:t:r||"VuePress"}get $description(){const n=function(n){if(n){const e=n.filter(n=>"description"===n.name)[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(n,e){for(let t=0;t<n.length;t++){const r=n[t];if(r.path.toLowerCase()===e.toLowerCase())return r}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},El)),Ht.component("Content",jl),Ht.component("ContentSlotsDistributor",Nl),Ht.component("OutboundLink",ql),Ht.component("ClientOnly",Kl),Ht.component("Layout",ss("Layout")),Ht.component("NotFound",ss("NotFound")),Ht.prototype.$withBase=function(n){const e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.9.2",hash:"ed3b802"},async function(n){const e="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:El.routerBase||El.base,t=new $o({base:e,mode:"history",fallback:!1,routes:wl,scrollBehavior:(n,e,t)=>t||(n.hash?!Ht.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})});!function(n){n.beforeEach((e,t,r)=>{if(Dl(n,e.path))r();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){const t=e.path.replace(/\/$/,"")+".html";Dl(n,t)?r(t):r()}else r();else{const t=e.path+"/",a=e.path+".html";Dl(n,a)?r(a):Dl(n,t)?r(t):r()}})}(t);const r={};try{await Promise.all(Ml.filter(n=>"function"==typeof n).map(e=>e({Vue:Ht,options:r,router:t,siteData:El,isServer:n})))}catch(n){console.error(n)}return{app:new Ht(Object.assign(r,{router:t,render:n=>n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},Ll.map(e=>n(e)))])})),router:t}}(!1).then(({app:n,router:e})=>{e.onReady(()=>{n.$mount("#app")})})}]);