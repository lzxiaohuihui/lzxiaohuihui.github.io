(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{344:function(a,t,s){"use strict";s.r(t);var n=s(3),e=Object(n.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h2",{attrs:{id:"阻塞队列"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#阻塞队列"}},[a._v("#")]),a._v(" 阻塞队列")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230224151245096.png",alt:"image-20230224151245096"}})]),a._v(" "),t("p",[t("strong",[a._v("BlockingQueue")])]),a._v(" "),t("ul",[t("li",[a._v("解决线程通信的问题")]),a._v(" "),t("li",[a._v("阻塞方法：put、take")])]),a._v(" "),t("p",[t("strong",[a._v("生产者消费者模式")])]),a._v(" "),t("ul",[t("li",[a._v("生产者：产生数据的线程")]),a._v(" "),t("li",[a._v("消费者：使用数据的线程")])]),a._v(" "),t("p",[t("strong",[a._v("实现类")])]),a._v(" "),t("ul",[t("li",[a._v("ArrayBlockingQueue")]),a._v(" "),t("li",[a._v("LinkedBlockQueue")]),a._v(" "),t("li",[a._v("PriorityBlockingQueue，SynchronousQueue，DelayQueue等")])]),a._v(" "),t("p",[t("strong",[a._v("示例")])]),a._v(" "),t("ul",[t("li",[a._v("生产者线程")])]),a._v(" "),t("div",{staticClass:"language-java extra-class"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Producer")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("implements")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Runnable")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("private")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("BlockingQueue")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v(" queue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("public")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Producer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("BlockingQueue")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v(" queue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("queue "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" queue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[a._v("@Override")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("public")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("void")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("run")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("try")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("int")]),a._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v(" i "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v(" i"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("++")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Thread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sleep")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n                queue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("put")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Thread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("currentThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("getName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"生产:"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" queue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("size")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("catch")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Exception")]),a._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n            e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("printStackTrace")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])])]),t("ul",[t("li",[a._v("消费者线程")])]),a._v(" "),t("div",{staticClass:"language-java extra-class"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Consumer")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("implements")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Runnable")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("private")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("BlockingQueue")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v(" queue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("public")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Consumer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("BlockingQueue")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v(" queue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("queue "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" queue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[a._v("@Override")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("public")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("void")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("run")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("try")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("while")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Thread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sleep")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("new")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Random")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("nextInt")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n                queue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("take")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n                "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("System")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("out"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("println")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Thread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("currentThread")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("getName")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"消费:"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" queue"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("size")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("catch")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Exception")]),a._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n            e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("printStackTrace")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])])]),t("p",[t("strong",[a._v("结果")])]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230224152954733.png",alt:"image-20230224152954733"}})]),a._v(" "),t("h2",{attrs:{id:"kafka入门"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka入门"}},[a._v("#")]),a._v(" Kafka入门")]),a._v(" "),t("ul",[t("li",[a._v("Kafka是一个分布式的流媒体平台；")]),a._v(" "),t("li",[a._v("应用："),t("strong",[a._v("消息系统")]),a._v("、日志收集、用户行为追踪、流失处理。")])]),a._v(" "),t("p",[a._v("Kafka是一个消息队列，放里面放数据叫生产者，取数据叫消费者。")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227103114319.png",alt:"image-20230227103114319"}})]),a._v(" "),t("p",[a._v("一个消息中间件，队列不单单只有一个，然后给每个队列取个名字，叫topic。")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227103159778.png",alt:"image-20230227103159778"}})]),a._v(" "),t("p",[a._v("然后生产者，消费者就到指定的消息队列中存取数据就可以了。")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227103243177.png",alt:"image-20230227103243177"}})]),a._v(" "),t("p",[a._v("为了提高一个队列的吞吐量，Kafka会把topic分区")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227103347739.png",alt:"image-20230227103347739"}})]),a._v(" "),t("p",[a._v("实际上，生产者消费者是到指定topic，指定分区中存取数据")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227103438959.png",alt:"image-20230227103438959"}})]),a._v(" "),t("p",[a._v("一台Kafka服务器叫做Broker")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227103516668.png",alt:"image-20230227103516668"}})]),a._v(" "),t("p",[a._v("一个话题中的多个分区，可能存在不同的服务器上")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227104352461.png",alt:"image-20230227104352461"}})]),a._v(" "),t("p",[a._v("Kafka将数据存放在不同的分区上，同时也会将分区备份，存在不同的broker上。备份分区只用做备份，不做读写。当某个broker挂了，那么就从其它broker中的分区作为主分区。")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227104842361.png",alt:"image-20230227104842361"}})]),a._v(" "),t("p",[a._v("消费者")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227110518895.png",alt:"image-20230227110518895"}})]),a._v(" "),t("p",[a._v("消费者可以有多个，形成一个消费者组。比如本来一个消费者要消费三个分区，那么可以通过一个消费者组，让三个消费者分别消费一个分区。")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("使用消息队列不可能是单机的（必然是分布式or集群）")])]),a._v(" "),t("li",[t("p",[a._v("Kafka会将partition以消息日志的方式(落磁盘)存储起来，通过 顺序访问IO和缓存(等到一定的量或时间)才真正把数据写到磁盘上，来提高速度。")])]),a._v(" "),t("li",[t("p",[a._v("Kafka会将数据写到partition，单个partition的写入是有顺序的。如果要保证全局有序，那只能写入一个partition中。如果要消费也有序，消费者也只能有一个。")])]),a._v(" "),t("li",[t("p",[a._v("凡是分布式就无法避免网络抖动/机器宕机等问题的发生，很有可能消费者A读取了数据，还没来得及消费，就挂掉了。Zookeeper发现消费者A挂了，让消费者B去消费原本消费者A的分区，等消费者A重连的时候，发现已经重复消费同一条数据了。(各种各样的情况，消费者超时等等都有可能…)")]),a._v(" "),t("p",[a._v("如果业务上不允许重复消费的问题，最好消费者那端做业务上的校验（如果已经消费过了，就不消费了）")])])]),a._v(" "),t("h2",{attrs:{id:"kafka为什么这么快"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka为什么这么快"}},[a._v("#")]),a._v(" Kafka为什么这么快")]),a._v(" "),t("ul",[t("li",[t("code",[a._v("顺序写")])])]),a._v(" "),t("p",[a._v("虽然说Kafka中的数据持久到到磁盘中，磁盘读写速度比不上内存读写速度。")]),a._v(" "),t("p",[a._v("都知道完成一次磁盘io，需要经过寻道、旋转和读写数据。")]),a._v(" "),t("p",[a._v("因为Kafka中某一个分区内的数据是有序的，队列FIFO，所以可以采用顺序写的方式进行持久化。")]),a._v(" "),t("p",[a._v("Kafka采用顺序写的方式，来省去寻道和旋转产生的时间，从而提高写入磁盘的速度。")]),a._v(" "),t("p",[a._v("每一个分区（Partition）对应多个物理文件（Segment）。")]),a._v(" "),t("ul",[t("li",[t("code",[a._v("零拷贝")])])]),a._v(" "),t("p",[a._v("消费者读取磁盘中的数据，使用传统的IO模型，需要拷贝四次")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227114404871.png",alt:"image-20230227114404871"}})]),a._v(" "),t("p",[a._v("零拷贝方式，减少用户态和内核态直接的切换")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227114649861.png",alt:"image-20230227114649861"}})]),a._v(" "),t("ul",[t("li",[t("code",[a._v("PageCache")])])]),a._v(" "),t("p",[a._v("生产者生产消息到Broker时，先写入到page cache中，page cache存在内存当中，但不受jvm的GC管理，这样可以避免每次生产消费都需要磁盘io。")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227120624806.png",alt:"image-20230227120624806"}})]),a._v(" "),t("ul",[t("li",[t("code",[a._v("网络模型")])])]),a._v(" "),t("p",[a._v("采用基于池化思想，避免为每个连接创建线程，连接完成后将业务处理交给线程池处理。")]),a._v(" "),t("p",[a._v("基于 IO 复用模型，多个连接共用同一个阻塞对象，不用等待所有的连接。")]),a._v(" "),t("ul",[t("li",[t("code",[a._v("批量与压缩")])])]),a._v(" "),t("p",[a._v("生产者向Broker发送消息是按照批量来发送，假设带宽是10MB/s，那么发送一个10MB的消息比发送1MB的消息10次要快。")]),a._v(" "),t("p",[a._v("多数情况下，系统的瓶颈不在磁盘IO，而是在网络IO。")]),a._v(" "),t("ul",[t("li",[t("code",[a._v("分区并发")])])]),a._v(" "),t("p",[a._v("Kafka的message是按topic分类存储的，topic中的数据又是按照一个一个的partition即分区存储到不同broker节点。")]),a._v(" "),t("p",[a._v("每个partition对应了操作系统上的一个文件夹，partition实际上又是按照segment分段存储的。每次文件操作也是直接操作segment。")]),a._v(" "),t("p",[a._v("为了进一步的查询优化，Kafka又默认为分段后的数据文件建立了索引文件。")]),a._v(" "),t("h2",{attrs:{id:"夺命连环问"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#夺命连环问"}},[a._v("#")]),a._v(" 夺命连环问")]),a._v(" "),t("h3",{attrs:{id:"说说你对kafka的理解"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#说说你对kafka的理解"}},[a._v("#")]),a._v(" 说说你对Kafka的理解")]),a._v(" "),t("blockquote",[t("p",[a._v("Kafka是一个流式数据处理平台，具有消息系统的能力，也有实时流式数据处理分析能能力，只是我们通常把它当做消息队列系统来用。")]),a._v(" "),t("p",[a._v("主要由三个方面组成，ZooKeeper、Kafka核心和存储。")]),a._v(" "),t("p",[a._v("Kafka一般作为分布式系统来用，所以需要每个Kafka服务器启动时需要将自己注册到ZooKeeper中，由ZooKeeper来统一管理。")]),a._v(" "),t("p",[a._v("然后Kafka本身，有消息、话题、生产者、消费者、分片、Broker、组等等。")]),a._v(" "),t("p",[a._v("最后是存储方面，用来持久化存储Kafka的数据，都会以日志的形式最终存入到磁盘中。")])]),a._v(" "),t("h3",{attrs:{id:"消息队列模型知道吗-kafka是怎么做到支持这两种模型的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息队列模型知道吗-kafka是怎么做到支持这两种模型的"}},[a._v("#")]),a._v(" 消息队列模型知道吗？kafka是怎么做到支持这两种模型的？")]),a._v(" "),t("blockquote",[t("p",[t("code",[a._v("点对点")]),a._v("：消息只能被一个消费者消费，消费完后消息删除。")]),a._v(" "),t("p",[t("code",[a._v("发布订阅")]),a._v("：相当于广播模式，消息可以被所有消费者消费。")]),a._v(" "),t("p",[a._v("消费者组，由多个消费者组成，一个组内只会由一个消费者去消费一个分区的消息。")])]),a._v(" "),t("h3",{attrs:{id:"能说说kafka通信过程原理吗"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#能说说kafka通信过程原理吗"}},[a._v("#")]),a._v(" 能说说kafka通信过程原理吗？")]),a._v(" "),t("blockquote",[t("ol",[t("li",[a._v("首先Kafka Broker启动时，将自己注册到ZooKeeper中；")]),a._v(" "),t("li",[a._v("生产者根据配置的地址连接到指定的Broker，建立TCP连接；")]),a._v(" "),t("li",[a._v("发送消息；")]),a._v(" "),t("li",[a._v("消费者和协调者Broker创建TCP连接；")]),a._v(" "),t("li",[a._v("开始消费消息。")])])]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230227152322197.png",alt:"image-20230227152322197"}})]),a._v(" "),t("h3",{attrs:{id:"发送消息时如何选择分区的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#发送消息时如何选择分区的"}},[a._v("#")]),a._v(" 发送消息时如何选择分区的？")]),a._v(" "),t("blockquote",[t("ol",[t("li",[a._v("轮询，按照顺序消息依次发送到不同的分区")]),a._v(" "),t("li",[a._v("随机，随机发送到某个分区")])]),a._v(" "),t("p",[a._v("如果消息指定key，那么会根据消息的key进行hash，然后对partition分区数量取模，决定落在哪个分区上，所以，对于相同key的消息来说，总是会发送到同一个分区上，也是我们常说的消息分区有序性。")]),a._v(" "),t("p",[a._v("很常见的场景就是我们希望下单、支付消息有顺序，这样以订单ID作为key发送消息就达到了分区有序性的目的。")]),a._v(" "),t("p",[a._v("如果没有指定key，会执行默认的轮询负载均衡策略，比如第一条消息落在P0，第二条消息落在P1，然后第三条又在P1。")]),a._v(" "),t("p",[a._v("除此之外，对于一些特定的业务场景和需求，还可以通过实现"),t("code",[a._v("Partitioner")]),a._v("接口，重写"),t("code",[a._v("configure")]),a._v("和"),t("code",[a._v("partition")]),a._v("方法来达到自定义分区的效果。")])]),a._v(" "),t("h3",{attrs:{id:"为什么需要分区-有什么好处"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#为什么需要分区-有什么好处"}},[a._v("#")]),a._v(" 为什么需要分区？有什么好处？")]),a._v(" "),t("blockquote",[t("p",[a._v("如果说不分区的话，我们发消息写数据都只能保存到一个节点上，这样的话就算这个服务器节点性能再好最终也支撑不住。")]),a._v(" "),t("p",[a._v("分区带来了负载均衡和横向扩展的能力。")]),a._v(" "),t("p",[a._v("发送消息时可以根据分区的数量存在不同的Broker上，提升了并发读写消息能力。")])]),a._v(" "),t("h3",{attrs:{id:"详细说说消费者组和消费者重平衡"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#详细说说消费者组和消费者重平衡"}},[a._v("#")]),a._v(" 详细说说消费者组和消费者重平衡？")]),a._v(" "),t("blockquote",[t("p",[a._v("一般来说，消费者数量和所有主题分区的数量保持一致最好，消费者组可以让Kafka支持传统的两种消息队列模型。")]),a._v(" "),t("p",[a._v("Kafka中有一个协调者来 完成分区的分配，而重平衡Rebalance就是指的有新消费者加入的情况，比如刚开始我们只有消费者A在消费消息，过了一段时间消费者B和C加入了，这时候分区就需要重新分配。")])]),a._v(" "),t("h3",{attrs:{id:"分区分配策略"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分区分配策略"}},[a._v("#")]),a._v(" 分区分配策略？")]),a._v(" "),t("blockquote",[t("p",[t("strong",[a._v("Range")])]),a._v(" "),t("p",[a._v("对同一个主题的分区，排序优先均匀分给前面的消费者，排在前面的消费者获得的消息 >= 后面的消费者。")]),a._v(" "),t("p",[t("strong",[a._v("RoundRobin")])]),a._v(" "),t("p",[a._v("轮询，按顺序以此分配给消费者。")]),a._v(" "),t("p",[t("strong",[a._v("Sticky")])]),a._v(" "),t("p",[a._v("之前这个分区 分给消费者，那么下次还是尽量分给他，避免频繁的销毁创建连接。")])]),a._v(" "),t("h3",{attrs:{id:"消息传递语义剖析"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息传递语义剖析"}},[a._v("#")]),a._v(" 消息传递语义剖析")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230228085755025.png",alt:"image-20230228085755025"}})]),a._v(" "),t("blockquote",[t("p",[a._v("1）首先当 Producer 向 Broker 发送数据后，会进行 commit，如果commit成功，由于 Replica 副本机制的存在，则意味着消息不会丢失，但是 Producer 发送数据给 Broker 后，遇到网络问题而造成通信中断，那么 Producer 就无法准确判断该消息是否已经被提交（commit），这就可能造成 at least once 语义。")]),a._v(" "),t("p",[a._v("2）在 Kafka 0.11.0.0 之前， 如果 Producer 没有收到消息 commit 的响应结果，它只能重新发送消息，确保消息已经被正确的传输到 Broker，重新发送的时候会将消息再次写入日志中；而在 0.11.0.0 版本之后， Producer 支持幂等传递选项，保证重新发送不会导致消息在日志出现重复。为了实现这个, Broker 为 Producer 分配了一个ID，并通过每条消息的序列号进行去重。也支持了类似事务语义来保证将消息发送到多个 Topic 分区中，保证所有消息要么都写入成功，要么都失败，这个主要用在 Topic 之间的 exactly once 语义。")]),a._v(" "),t("p",[t("strong",[a._v("其中启用幂等传递的方法配置")]),a._v("：enable.idempotence = true。")]),a._v(" "),t("p",[t("strong",[a._v("启用事务支持的方法配置")]),a._v('：设置属性 transcational.id = "指定值"。')]),a._v(" "),t("p",[a._v("3）从 Consumer 角度来剖析, 我们知道 Offset 是由 Consumer 自己来维护的, 如果 Consumer 收到消息后更新 Offset， 这时 Consumer 异常 crash 掉， 那么新的 Consumer 接管后再次重启消费，就会造成 at most once 语义（消息会丢，但不重复）。")]),a._v(" "),t("p",[a._v("4）如果 Consumer 消费消息完成后, 再更新 Offset，如果这时 Consumer crash 掉，那么新的 Consumer 接管后重新用这个 Offset 拉取消息， 这时就会造成 at least once 语义（消息不丢，但被多次重复处理）。")])]),a._v(" "),t("h3",{attrs:{id:"kafka三次消息传递"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kafka三次消息传递"}},[a._v("#")]),a._v(" Kafka三次消息传递")]),a._v(" "),t("blockquote",[t("p",[a._v("1）Producer 端发送消息给 Kafka Broker 端。")]),a._v(" "),t("p",[a._v("2）Kafka Broker 将消息进行同步并持久化数据。")]),a._v(" "),t("p",[a._v("3）Consumer 端从Kafka Broker 将消息拉取并进行消费。")])]),a._v(" "),t("p",[a._v("Kafka 只对「"),t("strong",[a._v("已提交")]),a._v("」的消息做「"),t("strong",[a._v("最大限度的持久化保证不丢失")]),a._v("」"),t("strong",[a._v("。")])]),a._v(" "),t("p",[t("strong",[a._v("已提交")]),a._v("的数据指Producer段发送的消息已经有"),t("strong",[a._v("N")]),a._v("个Broker成功收到了，而且至少有一个Broker存活，那么就能保证消息持久化保证不丢失。")]),a._v(" "),t("h3",{attrs:{id:"消息丢失场景"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#消息丢失场景"}},[a._v("#")]),a._v(" 消息丢失场景")]),a._v(" "),t("h4",{attrs:{id:"producer端"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#producer端"}},[a._v("#")]),a._v(" Producer端")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230228090806497.png",alt:"image-20230228090806497"}})]),a._v(" "),t("blockquote",[t("p",[a._v("1）首先我们要知道一点就是Producer 端是直接与 Broker 中的 Leader Partition 交互的，所以在 Producer 端初始化中就需要通过 Partitioner 分区器从 Kafka 集群中获取到相关 Topic 对应的 Leader Partition 的元数据。")]),a._v(" "),t("p",[a._v("2）待获取到 Leader Partition 的元数据后直接将消息发送过去。")]),a._v(" "),t("p",[a._v("3）Kafka Broker 对应的 Leader Partition 收到消息会先写入 Page Cache，定时刷盘进行持久化（顺序写入磁盘）。")]),a._v(" "),t("p",[a._v("4）Follower Partition 拉取 Leader Partition 的消息并保持同 Leader Partition 数据一致，待消息拉取完毕后需要给 Leader Partition 回复 ACK 确认消息。")]),a._v(" "),t("p",[a._v("5）待 Kafka Leader 与 Follower Partition 同步完数据并收到所有 ISR 中的 Replica 副本的 ACK 后，Leader Partition 会给 Producer 回复 ACK 确认消息。")])]),a._v(" "),t("p",[a._v("丢失情况可能发生在Producer端异步发送消息给Broker")]),a._v(" "),t("ul",[t("li",[t("strong",[a._v("网络原因：")]),a._v(" 由于网络抖动导致数据没有发送过去")]),a._v(" "),t("li",[a._v("**数据原因：**消息体太大超出Broker接收范围")])]),a._v(" "),t("p",[a._v("通过配置参数来确认消息是否发送成功")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230228091555181.png",alt:"image-20230228091555181"}})]),a._v(" "),t("h4",{attrs:{id:"broker端"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#broker端"}},[a._v("#")]),a._v(" Broker端")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230228091748206.png",alt:"image-20230228091748206"}})]),a._v(" "),t("p",[a._v("KafkaBroker 集群接收到数据后会将数据进行持久化存储到磁盘，为了提高吞吐量和性能，采用的是「"),t("strong",[a._v("异步批量刷盘的策略")]),a._v("」，也就是说按照一定的消息量和间隔时间进行刷盘。首先会将数据存储到 「"),t("strong",[a._v("PageCache")]),a._v("」 中，至于什么时候将 Cache 中的数据刷盘是由「"),t("strong",[a._v("操作系统")]),a._v("」根据自己的策略决定或者调用 fsync 命令进行强制刷盘，如果此时 Broker 宕机 Crash 掉，且选举了一个落后 Leader Partition 很多的 Follower Partition 成为新的 Leader Partition，那么落后的消息数据就会丢失。")]),a._v(" "),t("h4",{attrs:{id:"consumer端"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#consumer端"}},[a._v("#")]),a._v(" Consumer端")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://lzh-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230228092113890.png",alt:"image-20230228092113890"}})]),a._v(" "),t("blockquote",[t("p",[a._v("1）Consumer 拉取数据之前跟Producer 发送数据一样, 需要通过订阅关系获取到集群元数据,找到相关 Topic 对应的 Leader Partition 的元数据。")]),a._v(" "),t("p",[a._v("2）然后 Consumer 通过 Pull 模式主动的去 Kafka 集群中拉取消息。")]),a._v(" "),t("p",[a._v("3）在这个过程中，有个消费者组的概念（"),t("strong",[a._v("不了解的可以看上面链接文章")]),a._v("），多个 Consumer 可以组成一个消费者组即 Consumer Group，每个消费者组都有一个Group-Id。同一个 Consumer Group 中的 Consumer 可以消费同一个 Topic 下不同分区的数据，但是不会出现多个 Consumer 去消费同一个分区的数据。")]),a._v(" "),t("p",[a._v("4）拉取到消息后进行业务逻辑处理，待处理完成后，会进行 ACK 确认，即提交 Offset 消费位移进度记录。")]),a._v(" "),t("p",[a._v("5）最后 Offset 会被保存到 Kafka Broker 集群中的 "),t("strong",[a._v("__consumer_offsets")]),a._v(" 这个 Topic 中，且每个 Consumer 保存自己的 Offset 进度。")])]),a._v(" "),t("p",[a._v("Consumer拉取后消息最终是要提交Offset，那么这里就可能会丢失数据")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("可能使用的「"),t("strong",[a._v("自动提交 Offset 方式")]),a._v("」")])]),a._v(" "),t("li",[t("p",[a._v("拉取消息后「"),t("strong",[a._v("先提交 Offset，后处理消息")]),a._v("」，如果此时处理消息的时候异常宕机，由于 Offset 已经提交了, 待 Consumer 重启后，会从之前已提交的 Offset 下一个位置重新开始消费， 之前未处理完成的消息不会被再次处理，对于该 Consumer 来说消息就丢失了。")])]),a._v(" "),t("li",[t("p",[a._v("拉取消息后「"),t("strong",[a._v("先处理消息，在进行提交 Offset")]),a._v("」， 如果此时在提交之前发生异常宕机，由于没有提交成功 Offset， 待下次 Consumer 重启后还会从上次的 Offset 重新拉取消息，不会出现消息丢失的情况， 但是会出现重复消费的情况，这里只能业务自己保证幂等性。")])])]),a._v(" "),t("h4",{attrs:{id:"解决方案"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#解决方案"}},[a._v("#")]),a._v(" 解决方案")]),a._v(" "),t("p",[a._v("发送的调用方式改为异步方式")]),a._v(" "),t("div",{staticClass:"language-java extra-class"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Future")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("RecordMetadata")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("send")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("ProducerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Callback")]),a._v(" callback"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v(" \n")])])]),t("div",{staticClass:"language-java extra-class"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("public")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Future")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("RecordMetadata")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("send")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("ProducerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v(" record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Callback")]),a._v(" callback"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v(" \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("//intercept the record, which can be potentially modified; this method does not throw exceptions ")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("ProducerRecord")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v(" interceptedRecord "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("interceptors "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("null")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("?")]),a._v(" record "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("interceptors"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("onSend")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("record"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v(" \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("doSend")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("interceptedRecord"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" callback"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n\n")])])]),t("p",[a._v("然后就是修改一些配置项")]),a._v(" "),t("p",[a._v("producer端发送消息重试次数，retries 设为最大值；")]),a._v(" "),t("p",[a._v("重试时间retry.backoff.ms 设为300ms；")]),a._v(" "),t("p",[a._v("unclean.leader.election.enable ，false表示不要在ISR列表外的follow选举leader，因为那些副本落后原来leader很多；")]),a._v(" "),t("p",[a._v("replication.factor，设置分区副本的个数，>=3；")]),a._v(" "),t("p",[a._v("min.insync.replicas，ISR个数，也是“已提交”个数；")]),a._v(" "),t("p",[a._v("enable.auto.commit = false，设置消费端手动移位offset，业务自己保证幂等性。")])])}),[],!1,null,null,null);t.default=e.exports}}]);